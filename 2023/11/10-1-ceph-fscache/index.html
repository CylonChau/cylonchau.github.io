<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>当cephfs和fscache结合时在K8s环境下的全集群规模故障 | Cylon&#39;s Collection</title>
<meta name="keywords" content="cephfs, fscache">
<meta name="description" content="当cephfs和fscache结合时在K8s环境下的全集群规模故障 - Cylon&#39;s Collection">
<meta name="author" content="cylon">
<link rel="canonical" href="https://www.oomkill.com/2023/11/10-1-ceph-fscache/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.df0e7f0648f287aca44f5b657ff5602f436346895340daaa6589b3049a979f73.css" integrity="sha256-3w5/Bkjyh6ykT1tlf/VgL0NjRolTQNqqZYmzBJqXn3M=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://www.oomkill.com/favicon.ico">
<link rel="apple-touch-icon" href="https://www.oomkill.com/apple-touch-icon.png">

<meta name="twitter:title" content="当cephfs和fscache结合时在K8s环境下的全集群规模故障 | Cylon&#39;s Collection" />
<meta name="twitter:description" content="" />
<meta property="og:title" content="当cephfs和fscache结合时在K8s环境下的全集群规模故障 | Cylon&#39;s Collection" />
<meta property="og:description" content="" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.oomkill.com/2023/11/10-1-ceph-fscache/" />
<meta property="article:section" content="posts" />
  <meta property="article:published_time" content="2023-11-11T00:00:00&#43;00:00" />
  <meta property="article:modified_time" content="2023-11-18T23:10:36&#43;08:00" />


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://www.oomkill.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "当cephfs和fscache结合时在K8s环境下的全集群规模故障",
      "item": "https://www.oomkill.com/2023/11/10-1-ceph-fscache/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "当cephfs和fscache结合时在K8s环境下的全集群规模故障 | Cylon's Collection",
  "name": "当cephfs和fscache结合时在K8s环境下的全集群规模故障",
  "description": "",
  "keywords": [
    "cephfs", "fscache"
  ],
  "wordCount" : "2593",
  "inLanguage": "zh",
  "datePublished": "2023-11-11T00:00:00Z",
  "dateModified": "2023-11-18T23:10:36+08:00",
  "author":{
    "@type": "Person",
    "name": "cylon"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.oomkill.com/2023/11/10-1-ceph-fscache/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Cylon's Collection",
    "logo": {
      "@type": "ImageObject",
      "url": "https://www.oomkill.com/favicon.ico"
    }
  }
}
</script><script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary-bg: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list-page {
                background: var(--theme);
            }

            .list-page:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list-page:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

</head>

<body class=" type-posts kind-page layout-" id="top"><script data-no-instant>
function switchTheme(theme) {
  switch (theme) {
    case 'light':
      document.body.classList.remove('dark');
      break;
    case 'dark':
      document.body.classList.add('dark');
      break;
    
    default:
      if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
      }
  }
}

function isDarkTheme() {
  return document.body.className.includes("dark");
}

function getPrefTheme() {
  return localStorage.getItem("pref-theme");
}

function setPrefTheme(theme) {
  switchTheme(theme)
  localStorage.setItem("pref-theme", theme);
}

const toggleThemeCallbacks = {}
toggleThemeCallbacks['main'] = (isDark) => {
  
  if (isDark) {
    setPrefTheme('light');
  } else {
    setPrefTheme('dark');
  }
}




window.addEventListener('toggle-theme', function() {
  
  const isDark = isDarkTheme()
  for (const key in toggleThemeCallbacks) {
    toggleThemeCallbacks[key](isDark)
  }
});


function toggleThemeListener() {
  
  window.dispatchEvent(new CustomEvent('toggle-theme'));
}

</script>
<script>
  
  (function() {
    const defaultTheme = 'auto';
    const prefTheme = getPrefTheme();
    const theme = prefTheme ? prefTheme : defaultTheme;

    switchTheme(theme);
  })();
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://www.oomkill.com" accesskey="h" title="Cylon&#39;s Collection (Alt + H)">Cylon&#39;s Collection</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://www.oomkill.com/archives/" title="归档"
                >归档
                </a>
            </li>
            <li>
                <a href="https://www.oomkill.com/tags/" title="标签"
                >标签
                </a>
            </li>
            <li>
                <a href="https://www.oomkill.com/search/" title="搜索 (Alt &#43; /)"data-no-instant accesskey=/
                >搜索
                </a>
            </li>
            <li>
                <a href="https://www.oomkill.com/about/" title="关于"
                >关于
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main post">

<article class="post-single">
  <header class="post-header"><h1 class="post-title">当cephfs和fscache结合时在K8s环境下的全集群规模故障</h1>
    <div class="post-meta"><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select: text;"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select: text;"></rect><line x1="16" y1="2" x2="16" y2="6" style="user-select: text;"></line><line x1="8" y1="2" x2="8" y2="6" style="user-select: text;"></line><line x1="3" y1="10" x2="21" y2="10" style="user-select: text;"></line></svg>
  <span>2023-11-11</span></span><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select: text;"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select: text;"></rect><line x1="16" y1="2" x2="16" y2="6" style="user-select: text;"></line><line x1="8" y1="2" x2="8" y2="6" style="user-select: text;"></line><line x1="3" y1="10" x2="21" y2="10" style="user-select: text;"></line></svg>
  <span>Edited on 2023-11-18</span></span><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon" style="user-select: text;"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z" style="user-select: text;"></path><line x1="7" y1="7" x2="7" y2="7" style="user-select: text;"></line></svg>
  <span class="post-tags"><a href="https://www.oomkill.com/tags/storage/">storage</a><a href="https://www.oomkill.com/tags/troubleshooting/">troubleshooting</a></span></span><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><circle cx="12" cy="12" r="9"></circle><polyline points="12 7 12 12 15 15"></polyline></svg>
  <span>6 分钟</span></span>

      
      
    </div>
  </header> <div class="toc side right">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">目录</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e4%bb%80%e4%b9%88%e6%98%affscache" aria-label="什么是fscache">什么是fscache</a></li>
                <li>
                    <a href="#cephfs-%e4%b8%ad%e7%9a%84-fscache" aria-label="cephfs 中的 fscache">cephfs 中的 fscache</a></li>
                <li>
                    <a href="#%e7%bb%93%e5%90%88fscache%e7%9a%84kubernetes%e4%b8%ad%e4%bd%bf%e7%94%a8cephfs%e9%80%a0%e6%88%90%e7%9a%84%e9%9b%86%e7%be%a4%e8%a7%84%e6%a8%a1%e6%95%85%e9%9a%9c" aria-label="结合fscache的kubernetes中使用cephfs造成的集群规模故障">结合fscache的kubernetes中使用cephfs造成的集群规模故障</a><ul>
                        
                <li>
                    <a href="#%e6%95%85%e9%9a%9c%e5%8f%91%e7%94%9f%e7%8e%af%e5%a2%83" aria-label="故障发生环境">故障发生环境</a></li>
                <li>
                    <a href="#%e6%95%85%e9%9a%9c%e7%9a%84%e6%8f%8f%e8%bf%b0" aria-label="故障的描述">故障的描述</a></li>
                <li>
                    <a href="#%e6%95%85%e9%9a%9c%e5%88%86%e6%9e%90" aria-label="故障分析">故障分析</a></li>
                <li>
                    <a href="#kubelet%e7%9a%84%e9%94%99%e8%af%af%e6%97%a5%e5%bf%97" aria-label="kubelet的错误日志">kubelet的错误日志</a></li></ul>
                </li>
                <li>
                    <a href="#%e9%97%ae%e9%a2%98%e5%a6%82%e4%bd%95%e8%a7%a3%e5%86%b3" aria-label="问题如何解决">问题如何解决</a><ul>
                        
                <li>
                    <a href="#%e9%99%84ceph-mds-%e7%ae%a1%e7%90%86%e5%ae%a2%e6%88%b7%e7%ab%af" aria-label="附：ceph mds 管理客户端">附：ceph mds 管理客户端</a></li></ul>
                </li>
                <li>
                    <a href="#reference" aria-label="Reference">Reference</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content">
    





<div class="copyrightTopBlock">
    <p>本文发布于<a href="https://www.oomkill.com/about" target="_blank">Cylon的收藏册</a>，转载请著名原文链接~</p>
    <div class="articleSuffix-bg"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 147.78 155.96"> <path d="M10.5,99.81a1.9,1.9,0,0,0-.53-.09,1.66,1.66,0,0,0-1.64,1.65A1.64,1.64,0,0,0,10,103a1.57,1.57,0,0,0,.87-.25l26.76,26.82.45-1.08L11.52,101.91A1.65,1.65,0,0,0,10.5,99.81Zm-.13,2a.57.57,0,0,1-.8,0,.58.58,0,0,1-.17-.41.58.58,0,0,1,.57-.57h0a.57.57,0,0,1,.56.58A.55.55,0,0,1,10.37,101.77Z" style="fill:#c5c9e0"></path><path d="M56.15,117.58H39.06l0-.09a1.65,1.65,0,0,0-1.36-1H37.5a1.65,1.65,0,1,0,1.56,2.19H55.7L92.92,156h41.44v-1.08h-41Zm-18.25.94a.56.56,0,0,1-.79,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.56-.57h0a.58.58,0,0,1,.57.58A.54.54,0,0,1,37.9,118.52Z" style="fill:#c5c9e0"></path><path d="M23.52,50.32a1.65,1.65,0,0,0,1.55-1.11H55.28l48-48.13h31.06V0H102.85l-48,48.13H25.07a1.64,1.64,0,0,0-2.09-1,1.64,1.64,0,0,0,.54,3.2Zm0-2.21a.57.57,0,0,1,0,1.13.57.57,0,1,1,0-1.13Z" style="fill:#c5c9e0"></path><polygon points="102.86 0 102.86 0 102.86 0 102.86 0" style="fill:#c5c9e0"></polygon><path d="M107.72,12.14h26.64V11.07H107.27L57.4,61H3.09a1.66,1.66,0,0,0-1.45-.86H1.52A1.65,1.65,0,1,0,2.81,63a1.59,1.59,0,0,0,.45-.87H57.85ZM2.05,62.23a.57.57,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.56-.57h.09a.57.57,0,0,1,.32,1Z" style="fill:#c5c9e0"></path><path d="M134.36,43.22V42.14h-22.3l-9.62,9.63a1.64,1.64,0,0,0-2.19.77,1.61,1.61,0,0,0-.17.71,1.65,1.65,0,1,0,3.29,0,1.61,1.61,0,0,0-.16-.72l9.3-9.32Zm-32.64,10.6a.57.57,0,0,1,0-1.13.57.57,0,0,1,0,1.13Z" style="fill:#c5c9e0"></path><path d="M147,52.3l-9,9H111.48a1.64,1.64,0,0,0-1.61-1.33h-.14a1.65,1.65,0,1,0,1.6,2.41h27.19l9.26-9.29L147,52.3Zm-37.15,9.85a.56.56,0,0,1-.56-.57h0a.56.56,0,0,1,.56-.56h0a.57.57,0,1,1,0,1.13Z" style="fill:#c5c9e0"></path><path d="M66.79,75.35l11,11.06h56.53V85.33H78.27l-11-11.06H49.49L37.12,86.67a1.64,1.64,0,0,0-2.09,1,1.61,1.61,0,0,0-.09.54,1.65,1.65,0,0,0,3.29,0,1.68,1.68,0,0,0-.26-.89l12-12ZM36.58,88.79a.57.57,0,1,1,.57-.56A.57.57,0,0,1,36.58,88.79Z" style="fill:#c5c9e0"></path><path d="M110.61,95.55,92.8,113.4a1.62,1.62,0,1,0,.77.76l17.49-17.53h23.31V95.55ZM92.49,115.28a.56.56,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.57-.57h0a.58.58,0,0,1,.56.58A.55.55,0,0,1,92.49,115.28Z" style="fill:#c5c9e0"></path><path d="M97.89,122.3H76.62L64.2,109.85a1.65,1.65,0,0,0-.77-2.2,1.77,1.77,0,0,0-.72-.17h-.14a1.65,1.65,0,0,0,.15,3.29,1.58,1.58,0,0,0,.71-.17l12.74,12.77H98.34l17.48-17.52h18.54v-1.08h-19ZM63.12,109.53a.56.56,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,1.14,0A.54.54,0,0,1,63.12,109.53Z" style="fill:#c5c9e0"></path> </svg> </div>
</div><p>本文记录了在 kubernetes 环境中，使用 cephfs 时当启用了 fscache 时，由于网络问题，或者 ceph 集群问题导致的整个 k8s 集群规模的挂载故障问题。</p>
<h2 id="什么是fscache">什么是fscache<a hidden class="anchor" aria-hidden="true" href="#什么是fscache">¶</a></h2>
<p>fscache 是网络文件系统的通用缓存，例如 NFS, CephFS都可以使用其进行缓存从而提高 IO</p>
<p>FS-Cache是在访问之前，将整个打开的每个 netfs 文件完全加载到 Cache 中，之后的挂载是从该缓存而不是 netfs 的 inode 中提供</p>
<p>fscache主要提供了下列功能：</p>
<ul>
<li>一次可以使用多个缓存</li>
<li>可以随时添加/删除缓存</li>
<li>Cookie 分为 “卷”, “数据文件”, “缓存”
<ul>
<li>缓存 cookie 代表整个缓存，通常不可见到“网络文件系统”</li>
<li>卷 cookie 来表示一组 文件</li>
<li>数据文件 cookie 用于缓存数据</li>
</ul>
</li>
</ul>
<p>下图是一个 NFS 使用 fscache 的示意图，CephFS 原理与其类似</p>
<p>
  <img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/Cache-NFS-Share-Data-with-FS-Cache-1.webp" alt="Cache-NFS-Share-Data-with-FS-Cache-1"  /></p>
<center>图1：FS-Cache 架构 </center>
<center><em>Source：</em>https://computingforgeeks.com/how-to-cache-nfs-share-data-with-fs-cache-on-linux/</center><br>
<p>CephFS 也是可以被缓存的一种网络文件系统，可以通过其内核模块看到对应的依赖</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">root@client:~# lsmod <span class="p">|</span> grep ceph
</span></span><span class="line"><span class="cl">ceph                  <span class="m">376832</span>  <span class="m">1</span>
</span></span><span class="line"><span class="cl">libceph               <span class="m">315392</span>  <span class="m">1</span> ceph
</span></span><span class="line"><span class="cl">fscache                <span class="m">65536</span>  <span class="m">1</span> ceph
</span></span><span class="line"><span class="cl">libcrc32c              <span class="m">16384</span>  <span class="m">3</span> xfs,raid456,libceph
</span></span><span class="line"><span class="cl">root@client:~# modinfo ceph
</span></span><span class="line"><span class="cl">filename:       /lib/modules/4.15.0-112-generic/kernel/fs/ceph/ceph.ko
</span></span><span class="line"><span class="cl">license:        GPL
</span></span><span class="line"><span class="cl">description:    Ceph filesystem <span class="k">for</span> Linux
</span></span><span class="line"><span class="cl">author:         Patience Warnick &lt;patience@newdream.net&gt;
</span></span><span class="line"><span class="cl">author:         Yehuda Sadeh &lt;yehuda@hq.newdream.net&gt;
</span></span><span class="line"><span class="cl">author:         Sage Weil &lt;sage@newdream.net&gt;
</span></span><span class="line"><span class="cl">alias:          fs-ceph
</span></span><span class="line"><span class="cl">srcversion:     B2806F4EAACAC1E19EE7AFA
</span></span><span class="line"><span class="cl">depends:        libceph,fscache
</span></span><span class="line"><span class="cl">retpoline:      Y
</span></span><span class="line"><span class="cl">intree:         Y
</span></span><span class="line"><span class="cl">name:           ceph
</span></span><span class="line"><span class="cl">vermagic:       4.15.0-112-generic SMP mod_unload
</span></span><span class="line"><span class="cl">signat:         PKCS#7
</span></span><span class="line"><span class="cl">signer:        
</span></span><span class="line"><span class="cl">sig_key:       
</span></span><span class="line"><span class="cl">sig_hashalgo:   md4
</span></span></code></pre></td></tr></table>
</div>
</div><p>在启用了fs-cache后，内核日志可以看到对应 cephfs 挂载时 ceph 被注册到 fscache中</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="o">[</span>  11457.592011<span class="o">]</span> FS-Cache: Loaded
</span></span><span class="line"><span class="cl"><span class="o">[</span>  11457.617265<span class="o">]</span> Key <span class="nb">type</span> ceph registered
</span></span><span class="line"><span class="cl"><span class="o">[</span>  11457.617686<span class="o">]</span> libceph: loaded <span class="o">(</span>mon/osd proto 15/24<span class="o">)</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>  11457.640554<span class="o">]</span> FS-Cache: Netfs <span class="s1">&#39;ceph&#39;</span> registered <span class="k">for</span> caching
</span></span><span class="line"><span class="cl"><span class="o">[</span>  11457.640558<span class="o">]</span> ceph: loaded <span class="o">(</span>mds proto 32<span class="o">)</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>  11457.640978<span class="o">]</span> libceph: parse_ips bad ip <span class="s1">&#39;mon1.ichenfu.com:6789,mon2.ichenfu.com:6789,mon3.ichenfu.com:6789&#39;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>当 monitor / OSD 拒绝连接时，所有该节点后续创建的挂载均会使用缓存，除非 umount 所有挂载后重新挂载才可以重新与 ceph mon 建立连接</p>
</blockquote>
<h2 id="cephfs-中的-fscache">cephfs 中的 fscache<a hidden class="anchor" aria-hidden="true" href="#cephfs-中的-fscache">¶</a></h2>
<p>ceph 官方在 2023年11月5日的一篇博客 <sup><a href="#1">[1]</a></sup> 中介绍了，cephfs 与 fscache 结合的介绍。这个功能的加入最显著的成功就是 ceph node 流向 OSD 网络被大大减少，尤其是在读取多的情况下。</p>
<p>这个机制可以在代码 commit 中看到其原理：“在第一次通过文件引用inode时创建缓存cookie。之后，直到我们处理掉inode，我们都不会摆脱cookie” <sup><a href="#2">[2]</a></sup></p>
<h2 id="结合fscache的kubernetes中使用cephfs造成的集群规模故障">结合fscache的kubernetes中使用cephfs造成的集群规模故障<a hidden class="anchor" aria-hidden="true" href="#结合fscache的kubernetes中使用cephfs造成的集群规模故障">¶</a></h2>
<p>在了解了上面的基础知识后，就可以引入故障了，下面是故障产生环境的配置</p>
<h3 id="故障发生环境">故障发生环境<a hidden class="anchor" aria-hidden="true" href="#故障发生环境">¶</a></h3>
<table>
<thead>
<tr>
<th>软件</th>
<th>版本</th>
</tr>
</thead>
<tbody>
<tr>
<td>Centos</td>
<td>7.9</td>
</tr>
<tr>
<td>Ceph</td>
<td>nautilus (14.20)</td>
</tr>
<tr>
<td>Kernel</td>
<td>4.18.16</td>
</tr>
</tbody>
</table>
<h3 id="故障的描述">故障的描述<a hidden class="anchor" aria-hidden="true" href="#故障的描述">¶</a></h3>
<p>当网络出现问题时，如果使用了 cephfs 的 Pod 就会出现大量故障，具体故障表现方式有下面几种</p>
<ul>
<li>
<p>新部署的 Pod 处于 Waiting 状态</p>
</li>
<li>
<p>新部署的 Pod 可以启动成功，但是无法读取 cephfs 的挂载目录，主要故障表现为下面几种形式：</p>
<ul>
<li>ceph mount error 5 = input/output error <sup><a href="#3">[3]</a></sup></li>
<li>cephfs mount failure.permission denied</li>
</ul>
</li>
<li>
<p>旧 Pod 无法被删除</p>
</li>
<li>
<p>新部署的 Pod 无法启动</p>
</li>
</ul>
<blockquote>
<p>注：上面故障引用都是在网络上找到相同报错的一些提示，并不完全切合本文中故障描述</p>
</blockquote>
<p>去对应节点查看日志会发现有下面几个特征</p>
<p>
  <img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/IMG_20231108_150726-ink.jpeg" alt="IMG_20231108_150726-ink"  /></p>
<center>图2-1：故障发生的节点报错</center>
<p>
  <img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/IMG_20231109_193023-ink.jpeg" alt="IMG_20231109_193023-ink"  /></p>
<center>图2-2：故障发生的节点报错</center>
<p>
  <img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/IMG_20231109_192930-ink.jpeg" alt="IMG_20231109_192930-ink"  /></p>
<center>图2-3：故障发生的节点报错</center>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">    [ 1815.029831] ceph: mds0 closed our session
</span></span><span class="line"><span class="cl">    [ 1815.029833] ceph: mds0 reconnect start
</span></span><span class="line"><span class="cl">    [ 1815.052219] ceph: mds0 reconnect denied
</span></span><span class="line"><span class="cl">    [ 1815.052229] ceph:  dropping dirty Fw state for ffff9d9085da1340 1099512175611
</span></span><span class="line"><span class="cl">    [ 1815.052231] ceph:  dropping dirty+flushing Fw state for ffff9d9085da1340 1099512175611
</span></span><span class="line"><span class="cl">    [ 1815.273008] libceph: mds0 10.99.10.4:6801 socket closed (con state NEGOTIATING)
</span></span><span class="line"><span class="cl">    [ 1816.033241] ceph: mds0 rejected session
</span></span><span class="line"><span class="cl">    [ 1829.018643] ceph: mds0 hung
</span></span><span class="line"><span class="cl">    [ 1880.088504] ceph: mds0 came back
</span></span><span class="line"><span class="cl">    [ 1880.088662] ceph: mds0 caps renewed
</span></span><span class="line"><span class="cl">    [ 1880.094018] ceph: get_quota_realm: ino (10000000afe.fffffffffffffffe) null i_snap_realm
</span></span><span class="line"><span class="cl">    [ 1881.100367] ceph: get_quota_realm: ino (10000000afe.fffffffffffffffe) null i_snap_realm
</span></span><span class="line"><span class="cl">    [ 2046.768969] conntrack: generic helper won&#39;t handle protocol 47. Please consider loading the specific helper module.
</span></span><span class="line"><span class="cl">    [ 2061.731126] ceph: get_quota_realm: ino (10000000afe.fffffffffffffffe) null i_snap_realm
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="故障分析">故障分析<a hidden class="anchor" aria-hidden="true" href="#故障分析">¶</a></h3>
<p>由上面的三张图我们可以得到几个关键点</p>
<ol>
<li>connection reset</li>
<li>session lost, hunting for new mon</li>
<li>ceph: get_quota_realm()</li>
<li>reconnection denied</li>
<li>mds1 hung</li>
<li>mds1 caps stale</li>
</ol>
<p>这三张图上的日志是一个故障恢复的顺序，而问题节点（通常为整个集群 Node）内核日志都会在刷 <code>ceph: get_quota_realm()</code> 这种日志，首先我们需要确认第一个问题，<code>ceph: get_quota_realm()</code> 是什么原因导致，在互联网上找了一个 linux kernel 关于修复这个问题的提交记录，通过 commit，我们可以看到这个函数产生的原因</p>
<blockquote>
<p>get_quota_realm() enters infinite loop if quota inode has no caps.
This can happen after client gets evicted.  <sup><a href="#4">[4]</a></sup></p>
</blockquote>
<p>这里可以看到，修复的内容是当客户端被驱逐时，这个函数会进入无限 loop ，当 inode 配额没有被授权的用户，常常发生在客户端被驱逐。</p>
<p>通过这个 commit，我们可以确定了后面 4 - 6 问题的疑问，即客户端被 ceph mds 驱逐（加入了黑名单），在尝试重连时就会发生 <code>reconnection denied</code> 接着发生陈腐的被授权认证的用户 (caps stale)。<font color="#f8070d" size=3>接着由于本身没有真实的卸载，而是使用了一个共享的 cookie 这个时候就会发生节点新挂载的目录是没有权限写，或者是  input/output error 的错误</font>，这些错误表象是根据不同情况下而定，比如说被拉黑和丢失的会话。</p>
<h3 id="kubelet的错误日志">kubelet的错误日志<a hidden class="anchor" aria-hidden="true" href="#kubelet的错误日志">¶</a></h3>
<p>此时当新的使用了 volumes 去挂载 cephfs时，由于旧的 Pod 产生的工作目录 (/var/lib/kubelet) 下的 Pod 挂载会因为 cephfs caps stale  而导致无法卸载，这是就会存在 “孤儿Pod”，“不能同步 Pod 的状态”，“不能创建新的Pod挂载，因为目录已存在”。</p>
<p>kubelet 日志如下所示：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubelet_volumes.go:66<span class="o">]</span> pod <span class="s2">&#34;5446c441-9162-45e8-e11f46893932&#34;</span> found, but error stat /var/lib/kubelet/pods/5446c441-9162-45e8-e11f46893932/volumes/kubernetes.io~cephfs/xxxxx: permission denied occurred during checking mounted volumes from disk
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">pod_workers.go:119<span class="o">]</span> Error syncing pod <span class="s2">&#34;5446c441-9162-45e8-e11f46893932&#34;</span> <span class="o">(</span><span class="s2">&#34;xxxxx-xxx-xxx-xxxx-xxx_xxxxx(5446c441-9162-45e8-e11f46893932)&#34;</span>, skipping: failed to <span class="s2">&#34;StartContainer&#34;</span> <span class="k">for</span> <span class="s2">&#34;xxxxx-xxx-xxx&#34;</span> with RunContainerError: <span class="s2">&#34;failed to start container \&#34;719346531es654113s3216e1456313d51as132156\&#34;: Error response from daemon: error while createing mount source path &#39;/var/lib/kubelet/pods/5446c441-9162-45446c441-9162-45e8-e11f46893932/volumes/kubernetes.io~cephfs/xxxxxx-xx&#39;: mkdir /var/lib/kubelet/pods/5446c441-9162-45446c441-9162-45e8-e11f46893932/volumes/kubernetes.io~cephfs/xxxxxx-xx: file exists&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="问题如何解决">问题如何解决<a hidden class="anchor" aria-hidden="true" href="#问题如何解决">¶</a></h2>
<p>首先上面我们阐述了问题出现背景以及原因，要想解决这些错误，要分为两个步骤：</p>
<ol>
<li>首先驱逐 Kubernetes  Node 节点上所有挂载 cephfs 的 Pod，这步骤是为了优雅的结束 fscache 的 cookie cache 机制，使节点可以正常的提供服务</li>
<li>解决使用 fscache 因网络问题导致的会话丢失问题的重连现象</li>
</ol>
<p>这里主要以步骤2来阐述，解决这个问题就是通过两个方式，一个是不使用 fscache，另一个则是不让 mds 拉黑客户端，关闭 fscache 的成本很难，至今没有尝试成功，这里通过配置 ceph 服务使得 ceph mds 不会拉黑因出现网络问题丢失连接的客户端。</p>
<p>ceph 中阐述了驱逐的概念 “当某个文件系统客户端不响应或者有其它异常行为时，有必要强制切断它到文件系统的访问，这个过程就叫做<em>驱逐</em>。”  <sup><a href="#5">[5]</a></sup></p>
<p>要想解决这个问题，ceph 提供了一个参数来解决这个问题，<code>mds_session_blacklist_on_timeout</code></p>
<blockquote>
<p>It is possible to respond to slow clients by simply dropping their MDS sessions, but permit them to re-open sessions and permit them to continue talking to OSDs.  To enable this mode, set <code>mds_session_blacklist_on_timeout</code> to false on your MDS nodes. <sup><a href="#6">[6]</a></sup></p>
</blockquote>
<p>最终在配置后，上述问题解决</p>
<h3 id="附ceph-mds-管理客户端">附：ceph mds 管理客户端<a hidden class="anchor" aria-hidden="true" href="#附ceph-mds-管理客户端">¶</a></h3>
<p>查看一个客户端的连接</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">ceph daemon mds.xxxxxxxx session ls <span class="p">|</span>grep -E <span class="s1">&#39;inst|hostname|kernel_version&#39;</span><span class="p">|</span>grep xxxx
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;inst&#34;</span>: <span class="s2">&#34;client.105123 v1:192.168.0.0:0/11243531&#34;</span>,
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;hostname&#34;</span>: <span class="s2">&#34;xxxxxxxxxxxxxxxxxx&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>手动驱逐一个客户端</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">ceph tell mds.0 client evict <span class="nv">id</span><span class="o">=</span><span class="m">105123</span>
</span></span><span class="line"><span class="cl">2023-11-12 13:25:23:381 7fa3a67fc700 <span class="m">0</span> client.105123 ms_handle_reset on v2:192.168.0.0:6800/112351231
</span></span><span class="line"><span class="cl">2023-11-12 13:25:23:421 7fa3a67fc700 <span class="m">0</span> client.105123 ms_handle_reset on v2:192.168.0.0:6800/112351231
</span></span></code></pre></td></tr></table>
</div>
</div><p>查看 ceph 的配置参数</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">ceph config dump
</span></span><span class="line"><span class="cl">WHO     MASK  LEVEL     OPTION                                VALUE RO
</span></span><span class="line"><span class="cl">  mon         advanced  auth_allow_insecure_global_id_reclaim <span class="nb">false</span>
</span></span><span class="line"><span class="cl">  mon         advanced  mon_allow_pool_delete                 <span class="nb">false</span>
</span></span><span class="line"><span class="cl">  mds         advanced  mds_session_blacklist_on_evict        <span class="nb">false</span>
</span></span><span class="line"><span class="cl">  mds         advanced  mds_session_blacklist_on_timeout      <span class="nb">false</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>当出现问题无法卸载时应如何解决？</p>
<p>当我们遇到问题时，卸载目录会出现被占用情况，通过 mount 和 fuser 都无法卸载</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">umount -f /tmp/998
</span></span><span class="line"><span class="cl">umount： /tmp/998: target is buy.
</span></span><span class="line"><span class="cl">        <span class="o">(</span>In some cases useful info about processes that use th device is found by losf<span class="o">(</span>8<span class="o">)</span> or fuser<span class="o">(</span>1<span class="o">))</span>
</span></span><span class="line"><span class="cl">        the device is found by losf<span class="o">(</span>8<span class="o">)</span> or fuser<span class="o">(</span>1<span class="o">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">fuser -v1 /root/test
</span></span><span class="line"><span class="cl">Cannot stat /root/test: Input/output error
</span></span></code></pre></td></tr></table>
</div>
</div><p>这个时候由于 cephfs 挂载问题会导致整个文件系统不可用，例如 df -h, ls dir 等，此时可以使用 umount 的懒卸载模式 <code>umount -l</code>，这会告诉内核当不占用时被卸载，由于这个问题是出现问题，而不是长期占用，这里用懒卸载后会立即卸载，从而解决了 stuck 的问题。</p>
<h2 id="reference">Reference<a hidden class="anchor" aria-hidden="true" href="#reference">¶</a></h2>
<p><sup id="1">[1]</sup> <a href="https://ceph.io/en/news/blog/2013/first-impressions-through-fscache-and-ceph/">First Impressions Through Fscache and Ceph</a></p>
<p><sup id="2">[2]</sup> <a href="https://lwn.net/Articles/563146/">ceph: persistent caching with fscache</a></p>
<p><sup id="3">[3]</sup> <a href="https://tracker.ceph.com/issues/51191">Cannot Mount CephFS No Timeout, mount error 5 = Input/output error</a></p>
<p><sup id="4">[4]</sup> <a href="https://patchwork.kernel.org/project/ceph-devel/patch/20190531122802.12814-3-zyan@redhat.com/">ceph: fix infinite loop in get_quota_realm()</a></p>
<p><sup id="5">[5]</sup> <a href="https://drunkard.github.io/cephfs/eviction/">Ceph 文件系统客户端的驱逐</a></p>
<p><sup id="6">[6]</sup> <a href="https://docs.ceph.com/en/mimic/cephfs/eviction/#advanced-configuring-blacklisting">advanced-configuring-blacklisting</a></p>


    
    


<div class="copyrightBlock" >
    <div class="articleSuffix-bg"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 147.78 155.96"> <path d="M10.5,99.81a1.9,1.9,0,0,0-.53-.09,1.66,1.66,0,0,0-1.64,1.65A1.64,1.64,0,0,0,10,103a1.57,1.57,0,0,0,.87-.25l26.76,26.82.45-1.08L11.52,101.91A1.65,1.65,0,0,0,10.5,99.81Zm-.13,2a.57.57,0,0,1-.8,0,.58.58,0,0,1-.17-.41.58.58,0,0,1,.57-.57h0a.57.57,0,0,1,.56.58A.55.55,0,0,1,10.37,101.77Z" style="fill:#c5c9e0"></path><path d="M56.15,117.58H39.06l0-.09a1.65,1.65,0,0,0-1.36-1H37.5a1.65,1.65,0,1,0,1.56,2.19H55.7L92.92,156h41.44v-1.08h-41Zm-18.25.94a.56.56,0,0,1-.79,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.56-.57h0a.58.58,0,0,1,.57.58A.54.54,0,0,1,37.9,118.52Z" style="fill:#c5c9e0"></path><path d="M23.52,50.32a1.65,1.65,0,0,0,1.55-1.11H55.28l48-48.13h31.06V0H102.85l-48,48.13H25.07a1.64,1.64,0,0,0-2.09-1,1.64,1.64,0,0,0,.54,3.2Zm0-2.21a.57.57,0,0,1,0,1.13.57.57,0,1,1,0-1.13Z" style="fill:#c5c9e0"></path><polygon points="102.86 0 102.86 0 102.86 0 102.86 0" style="fill:#c5c9e0"></polygon><path d="M107.72,12.14h26.64V11.07H107.27L57.4,61H3.09a1.66,1.66,0,0,0-1.45-.86H1.52A1.65,1.65,0,1,0,2.81,63a1.59,1.59,0,0,0,.45-.87H57.85ZM2.05,62.23a.57.57,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.56-.57h.09a.57.57,0,0,1,.32,1Z" style="fill:#c5c9e0"></path><path d="M134.36,43.22V42.14h-22.3l-9.62,9.63a1.64,1.64,0,0,0-2.19.77,1.61,1.61,0,0,0-.17.71,1.65,1.65,0,1,0,3.29,0,1.61,1.61,0,0,0-.16-.72l9.3-9.32Zm-32.64,10.6a.57.57,0,0,1,0-1.13.57.57,0,0,1,0,1.13Z" style="fill:#c5c9e0"></path><path d="M147,52.3l-9,9H111.48a1.64,1.64,0,0,0-1.61-1.33h-.14a1.65,1.65,0,1,0,1.6,2.41h27.19l9.26-9.29L147,52.3Zm-37.15,9.85a.56.56,0,0,1-.56-.57h0a.56.56,0,0,1,.56-.56h0a.57.57,0,1,1,0,1.13Z" style="fill:#c5c9e0"></path><path d="M66.79,75.35l11,11.06h56.53V85.33H78.27l-11-11.06H49.49L37.12,86.67a1.64,1.64,0,0,0-2.09,1,1.61,1.61,0,0,0-.09.54,1.65,1.65,0,0,0,3.29,0,1.68,1.68,0,0,0-.26-.89l12-12ZM36.58,88.79a.57.57,0,1,1,.57-.56A.57.57,0,0,1,36.58,88.79Z" style="fill:#c5c9e0"></path><path d="M110.61,95.55,92.8,113.4a1.62,1.62,0,1,0,.77.76l17.49-17.53h23.31V95.55ZM92.49,115.28a.56.56,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.57-.57h0a.58.58,0,0,1,.56.58A.55.55,0,0,1,92.49,115.28Z" style="fill:#c5c9e0"></path><path d="M97.89,122.3H76.62L64.2,109.85a1.65,1.65,0,0,0-.77-2.2,1.77,1.77,0,0,0-.72-.17h-.14a1.65,1.65,0,0,0,.15,3.29,1.58,1.58,0,0,0,.71-.17l12.74,12.77H98.34l17.48-17.52h18.54v-1.08h-19ZM63.12,109.53a.56.56,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,1.14,0A.54.54,0,0,1,63.12,109.53Z" style="fill:#c5c9e0"></path> </svg> </div>
    <p>本文发布于<a href="https://www.oomkill.com/about" target="_blank">Cylon的收藏册</a>，转载请著名原文链接~</p>
    <p>链接：<a href="https://www.oomkill.com/2023/11/10-1-ceph-fscache/" target="_blank">https://www.oomkill.com/2023/11/10-1-ceph-fscache/</a></p>
    <p style="margin-bottom: 0px;">版权：本作品采用<a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">「署名-非商业性使用-相同方式共享 4.0 国际」</a> 许可协议进行许可。</p>
    </div>
</div>
  </div>

  <footer class="post-footer">
    
<nav class="paginav">
  <a class="prev" href="https://www.oomkill.com/2023/11/ch07-in-cluster-pod/">
    <span class="title"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left" style="user-select: text;"><line x1="19" y1="12" x2="5" y2="12" style="user-select: text;"></line><polyline points="12 19 5 12 12 5" style="user-select: text;"></polyline>
      </polyline></svg>&nbsp; </span>
    
    <span>client-go - Pod使用in-cluster方式访问集群</span>
  </a>
  <a class="next" href="https://www.oomkill.com/2023/11/ch03-argo-add-cluster/" >
    <span class="title"> </span>
    
    <span>初识Argo cd - 注册/删除k8s集群&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right" style="user-select: text;"><line x1="5" y1="12" x2="19" y2="12" style="user-select: text;"></line><polyline points="12 5 19 12 12 19" style="user-select: text;"></polyline></svg></span>
  </a>
</nav>

  </footer>

  
  <div class="pagination__title">
    <span class="pagination__title-h"></span>
  </div>
  
  
  
  
    <div class="comments-separator"></div>
    

<h3>相关阅读</h3>
<ul>
	
	<li><a href="/2023/09/6-1-ceph-rebalance/">Ceph重新平衡 - Rebalance</a></li>
	
	<li><a href="/2023/09/11-1-ceph-common-cmd/">ceph常用命令</a></li>
	
</ul>

  

  
    
      <div class="comments-separator"></div>
<div class="comments">
    <script>
    function loadComment() {
        let theme = localStorage.getItem('pref-theme') === 'dark' ? 'dark' : 'light';
        let s = document.createElement('script');
        s.src = 'https://giscus.app/client.js';
        s.setAttribute('data-repo', 'cylonchau\/cylonchau.github.io');
        s.setAttribute('data-repo-id', 'R_kgDOIRlNSQ');
        s.setAttribute('data-category', 'Announcements');
        s.setAttribute('data-category-id', 'DIC_kwDOIRlNSc4CXy1U');
        s.setAttribute('data-mapping', 'title');
        s.setAttribute('data-reactions-enabled', '1');
        s.setAttribute('data-emit-metadata', '1');
        s.setAttribute('data-input-position', 'top');
        s.setAttribute('data-lang', 'zh-TW');
        s.setAttribute('data-theme', theme);
        s.setAttribute('crossorigin', 'anonymous');
        s.setAttribute('async', '');
        document.querySelector('div.comments').innerHTML = '';
        document.querySelector('div.comments').appendChild(s);
    }
    loadComment();
    </script>
</div>
</article>
    </main>
    
<footer class="footer">
  <p>
  Copyright
  <span>&copy; 2024 <a href="https://www.oomkill.com">Cylon&#39;s Collection</a></span></p>
  <span style="display: inline-block; margin-left: 1em;">
    Powered by
    <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> on github-page & Theme
    <a href="https://github.com/reorx/hugo-PaperModX/" rel="noopener" target="_blank">PaperModX</a>
  </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
  (function() {
     
    const disableThemeToggle = '' == '1';
    if (disableThemeToggle) {
      return;
    }

    let button = document.getElementById("theme-toggle")
    
    button.removeEventListener('click', toggleThemeListener)
    
    button.addEventListener('click', toggleThemeListener)
  })();
</script>

<script>
  (function () {
    let menu = document.getElementById('menu')
    if (menu) {
      menu.scrollLeft = localStorage.getItem("menu-scroll-position");
      menu.onscroll = function () {
        localStorage.setItem("menu-scroll-position", menu.scrollLeft);
      }
    }

    const disableSmoothScroll = '' == '1';
    const enableInstantClick = '1' == '1';
    
    if (window.matchMedia('(prefers-reduced-motion: reduce)').matches || disableSmoothScroll || enableInstantClick) {
      return;
    }
    
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener("click", function (e) {
        e.preventDefault();
        var id = this.getAttribute("href").substr(1);
        document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
          behavior: "smooth"
        });
        if (id === "top") {
          history.replaceState(null, null, " ");
        } else {
          history.pushState(null, null, `#${id}`);
        }
      });
    });
  })();
</script>

<script>
  document.addEventListener('scroll', function (e) {
      const readProgress = document.getElementById("read_progress");
      const scrollHeight = document.documentElement.scrollHeight;
      const clientHeight = document.documentElement.clientHeight;
      const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
      readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
  })
</script>

<script>
  var menu = document.getElementById('menu')
  if (menu) {
      menu.scrollLeft = localStorage.getItem("menu-scroll-position");
      menu.onscroll = function () {
          localStorage.setItem("menu-scroll-position", menu.scrollLeft);
      }
  }

  document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener("click", function (e) {
          e.preventDefault();
          var id = this.getAttribute("href").substr(1);
          if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
              document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                  behavior: "smooth"
              });
          } else {
              document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
          }
          if (id === "top") {
              history.replaceState(null, null, " ");
          } else {
              history.pushState(null, null, `#${id}`);
          }
      });
  });
</script>
<script>
  var mybutton = document.getElementById("top-link");
  window.onscroll = function () {
      if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
          mybutton.style.visibility = "visible";
          mybutton.style.opacity = "1";
      } else {
          mybutton.style.visibility = "hidden";
          mybutton.style.opacity = "0";
      }
  };
</script>
<script>
  if (window.scrollListeners) {
    
    for (const listener of scrollListeners) {
      window.removeEventListener('scroll', listener)
    }
  }
  window.scrollListeners = []
</script>



<script src="/js/medium-zoom.min.js" data-no-instant
></script>
<script>
  document.querySelectorAll('pre > code').forEach((codeblock) => {
    const container = codeblock.parentNode.parentNode;

    const copybutton = document.createElement('button');
    copybutton.classList.add('copy-code');
    copybutton.innerText = 'copy';

    function copyingDone() {
      copybutton.innerText = 'copied';
      setTimeout(() => {
        copybutton.innerText = 'copy';
      }, 2000);
    }

    copybutton.addEventListener('click', (cb) => {
      if ('clipboard' in navigator) {
        navigator.clipboard.writeText(codeblock.textContent);
        copyingDone();
        return;
      }

      const range = document.createRange();
      range.selectNodeContents(codeblock);
      const selection = window.getSelection();
      selection.removeAllRanges();
      selection.addRange(range);
      try {
        document.execCommand('copy');
        copyingDone();
      } catch (e) { };
      selection.removeRange(range);
    });

    if (container.classList.contains("highlight")) {
      container.appendChild(copybutton);
    } else if (container.parentNode.firstChild == container) {
      
    } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
      
      codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
    } else {
      
      codeblock.parentNode.appendChild(copybutton);
    }
  });
</script>




<script>
  
  
  (function() {
    const enableTocScroll = '1' == '1'
    if (!enableTocScroll) {
      return
    }
    if (!document.querySelector('.toc')) {
      console.log('no toc found, ignore toc scroll')
      return
    }
    

    
    const scrollListeners = window.scrollListeners
    const headings = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id]');
    const activeClass = 'active';

    
    let activeHeading = headings[0];
    getLinkByHeading(activeHeading).classList.add(activeClass);

    const onScroll = () => {
      const passedHeadings = [];
      for (const h of headings) {
        
        if (getOffsetTop(h) < 5) {
          passedHeadings.push(h)
        } else {
          break;
        }
      }
      if (passedHeadings.length > 0) {
        newActiveHeading = passedHeadings[passedHeadings.length - 1];
      } else {
        newActiveHeading = headings[0];
      }
      if (activeHeading != newActiveHeading) {
        getLinkByHeading(activeHeading).classList.remove(activeClass);
        activeHeading = newActiveHeading;
        getLinkByHeading(activeHeading).classList.add(activeClass);
      }
    }

    let timer = null;
    const scrollListener = () => {
      if (timer !== null) {
        clearTimeout(timer)
      }
      timer = setTimeout(onScroll, 50)
    }
    window.addEventListener('scroll', scrollListener, false);
    scrollListeners.push(scrollListener)

    function getLinkByHeading(heading) {
      const id = encodeURI(heading.getAttribute('id')).toLowerCase();
      return document.querySelector(`.toc ul li a[href="#${id}"]`);
    }

    function getOffsetTop(heading) {
      if (!heading.getClientRects().length) {
        return 0;
      }
      let rect = heading.getBoundingClientRect();
      return rect.top
    }
  })();
  </script>

<script src="/js/instantclick.min.js" data-no-instant
></script>
<script data-no-instant>
  
  
  
  
  
  
  InstantClick.init();
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.6.0/mermaid.min.js" crossorigin="anonymous"></script>
<script>
    mermaid.init(undefined, '.language-mermaid');
</script>
</body>

</html>
