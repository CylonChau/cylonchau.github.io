<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>使用cephadm纯离线安装Ceph集群 | Cylon's Collection</title><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NP3JNCPR" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><meta name=keywords content="Install Ceph with cephadm on Centos7,在Centos7上使用cephadm安装ceph集群,cephadm,ceph"><meta name=description content="开篇常例 - 概述 Ceph 是一个广泛使用的开源存储平台。 它提供高性能、可靠性和可扩展性。 Ceph 分布式存储系统提供了对象存储、块存储和文件级存储。 Ceph 旨在提供无单点故障的分布式存储系统。
在本教程中，将通过 ceph-adm 方式在 CentOS 7 上安装和构建 Ceph 集群。该实验的 Ceph 集群需要以下 Ceph 组件：
Ceph OSD (ceph-osd) - 处理数据存储、数据复制和恢复；通常一个Ceph集群至少需要两台 OSD 服务器 。 Ceph Monitor (ceph-mon) - 监视集群状态、OSD 映射和 CRUSH 映射，我们在这里与 cephadm 或 OSD 公用一个节点 Ceph 元数据服务器 (ceph-mds) - 这是使用 CephFS 所需的组件。 有了上面的条件，我们实验环境所需要的节点如下：
三台服务器节点，CentOS 7 注：CentOS 7 可安装最高级别的 ceph 版本就是 O 版
本教程中的服务器将使用以下主机名和 IP 地址：
主机名 IP地址 作用 cephadmin 10.0.0.20 作为 ceph 管理节点，以管理与部署 ceph 集群 osd01 10."><meta name=author content="cylon"><link rel=canonical href=https://www.oomkill.com/2023/07/02-1-install-ceph-with-cephadm/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://www.oomkill.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://www.oomkill.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://www.oomkill.com/favicon-32x32.png><link rel=apple-touch-icon href=https://www.oomkill.com/favicon.ico><link rel=mask-icon href=https://www.oomkill.com/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://www.oomkill.com/2023/07/02-1-install-ceph-with-cephadm/><noscript><style>#theme-toggle,#top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link crossorigin=anonymous href=/assets/css/pe.min.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/pe.min.js></script><link rel=stylesheet href=https://cdn.staticfile.net/font-awesome/6.5.1/css/all.min.css><link rel=stylesheet href=https://cdn.staticfile.net/font-awesome/6.5.1/css/v4-shims.min.css><script id=MathJax-script async src=https://cdn.staticfile.net/mathjax/3.2.2/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["$$","$$"]],inlineMath:[["\\$","\\$"]]}}</script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"><script>(function(e,t,n,s,o){e[s]=e[s]||[],e[s].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var a=t.getElementsByTagName(n)[0],i=t.createElement(n),r=s!="dataLayer"?"&l="+s:"";i.async=!0,i.src="https://www.googletagmanager.com/gtm.js?id="+o+r,a.parentNode.insertBefore(i,a)})(window,document,"script","dataLayer","GTM-NP3JNCPR")</script><meta property="og:title" content="使用cephadm纯离线安装Ceph集群"><meta property="og:description" content="开篇常例 - 概述 Ceph 是一个广泛使用的开源存储平台。 它提供高性能、可靠性和可扩展性。 Ceph 分布式存储系统提供了对象存储、块存储和文件级存储。 Ceph 旨在提供无单点故障的分布式存储系统。
在本教程中，将通过 ceph-adm 方式在 CentOS 7 上安装和构建 Ceph 集群。该实验的 Ceph 集群需要以下 Ceph 组件：
Ceph OSD (ceph-osd) - 处理数据存储、数据复制和恢复；通常一个Ceph集群至少需要两台 OSD 服务器 。 Ceph Monitor (ceph-mon) - 监视集群状态、OSD 映射和 CRUSH 映射，我们在这里与 cephadm 或 OSD 公用一个节点 Ceph 元数据服务器 (ceph-mds) - 这是使用 CephFS 所需的组件。 有了上面的条件，我们实验环境所需要的节点如下：
三台服务器节点，CentOS 7 注：CentOS 7 可安装最高级别的 ceph 版本就是 O 版
本教程中的服务器将使用以下主机名和 IP 地址：
主机名 IP地址 作用 cephadmin 10.0.0.20 作为 ceph 管理节点，以管理与部署 ceph 集群 osd01 10."><meta property="og:type" content="article"><meta property="og:url" content="https://www.oomkill.com/2023/07/02-1-install-ceph-with-cephadm/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-07-30T00:00:00+00:00"><meta property="article:modified_time" content="2023-08-25T23:10:36+08:00"><meta property="og:site_name" content="Cylon's Collection"><meta name=twitter:card content="summary"><meta name=twitter:title content="使用cephadm纯离线安装Ceph集群"><meta name=twitter:description content="开篇常例 - 概述 Ceph 是一个广泛使用的开源存储平台。 它提供高性能、可靠性和可扩展性。 Ceph 分布式存储系统提供了对象存储、块存储和文件级存储。 Ceph 旨在提供无单点故障的分布式存储系统。
在本教程中，将通过 ceph-adm 方式在 CentOS 7 上安装和构建 Ceph 集群。该实验的 Ceph 集群需要以下 Ceph 组件：
Ceph OSD (ceph-osd) - 处理数据存储、数据复制和恢复；通常一个Ceph集群至少需要两台 OSD 服务器 。 Ceph Monitor (ceph-mon) - 监视集群状态、OSD 映射和 CRUSH 映射，我们在这里与 cephadm 或 OSD 公用一个节点 Ceph 元数据服务器 (ceph-mds) - 这是使用 CephFS 所需的组件。 有了上面的条件，我们实验环境所需要的节点如下：
三台服务器节点，CentOS 7 注：CentOS 7 可安装最高级别的 ceph 版本就是 O 版
本教程中的服务器将使用以下主机名和 IP 地址：
主机名 IP地址 作用 cephadmin 10.0.0.20 作为 ceph 管理节点，以管理与部署 ceph 集群 osd01 10."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://www.oomkill.com/posts/"},{"@type":"ListItem","position":2,"name":"使用cephadm纯离线安装Ceph集群","item":"https://www.oomkill.com/2023/07/02-1-install-ceph-with-cephadm/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"使用cephadm纯离线安装Ceph集群","name":"使用cephadm纯离线安装Ceph集群","description":"开篇常例 - 概述 Ceph 是一个广泛使用的开源存储平台。 它提供高性能、可靠性和可扩展性。 Ceph 分布式存储系统提供了对象存储、块存储和文件级存储。 Ceph 旨在提供无单点故障的分布式存储系统。\n在本教程中，将通过 ceph-adm 方式在 CentOS 7 上安装和构建 Ceph 集群。该实验的 Ceph 集群需要以下 Ceph 组件：\nCeph OSD (ceph-osd) - 处理数据存储、数据复制和恢复；通常一个Ceph集群至少需要两台 OSD 服务器 。 Ceph Monitor (ceph-mon) - 监视集群状态、OSD 映射和 CRUSH 映射，我们在这里与 cephadm 或 OSD 公用一个节点 Ceph 元数据服务器 (ceph-mds) - 这是使用 CephFS 所需的组件。 有了上面的条件，我们实验环境所需要的节点如下：\n三台服务器节点，CentOS 7 注：CentOS 7 可安装最高级别的 ceph 版本就是 O 版\n本教程中的服务器将使用以下主机名和 IP 地址：\n主机名 IP地址 作用 cephadmin 10.0.0.20 作为 ceph 管理节点，以管理与部署 ceph 集群 osd01 10.","keywords":["Install Ceph with cephadm on Centos7","在Centos7上使用cephadm安装ceph集群","cephadm","ceph"],"articleBody":"开篇常例 - 概述 Ceph 是一个广泛使用的开源存储平台。 它提供高性能、可靠性和可扩展性。 Ceph 分布式存储系统提供了对象存储、块存储和文件级存储。 Ceph 旨在提供无单点故障的分布式存储系统。\n在本教程中，将通过 ceph-adm 方式在 CentOS 7 上安装和构建 Ceph 集群。该实验的 Ceph 集群需要以下 Ceph 组件：\nCeph OSD (ceph-osd) - 处理数据存储、数据复制和恢复；通常一个Ceph集群至少需要两台 OSD 服务器 。 Ceph Monitor (ceph-mon) - 监视集群状态、OSD 映射和 CRUSH 映射，我们在这里与 cephadm 或 OSD 公用一个节点 Ceph 元数据服务器 (ceph-mds) - 这是使用 CephFS 所需的组件。 有了上面的条件，我们实验环境所需要的节点如下：\n三台服务器节点，CentOS 7 注：CentOS 7 可安装最高级别的 ceph 版本就是 O 版\n本教程中的服务器将使用以下主机名和 IP 地址：\n主机名 IP地址 作用 cephadmin 10.0.0.20 作为 ceph 管理节点，以管理与部署 ceph 集群 osd01 10.0.0.21 osd02 10.0.0.22 any any 作为 Ceph Client 的角色 注：所有 OSD 节点都需要两个分区，一个根（/）分区和一个空分区，稍后用作 Ceph 数据存储。\nREQUIREMENTS 使用 cephadm 安装 ceph 集群，所需要的先决条件如下:\n必要条件：\nPython 3，因为 cephadm 是一个 python3 脚本，所以需要每个节点都需要安装 python3 Systemd Podman or Docker：cephadm 安装的集群是一种以 “容器方式” 运行在对应的 ceph node 之上 LVM2：ceph OSD 是通过 LVM 来使用的，所以需要在每个 OSD 节点之上安装 LVM2 非必要条件：\nchrony or NTP：ceph 强依赖每个节点之上的时间 Internet 域名解析：ceph 集群对于 ceph node 来说是通过 hostname.random_str 识别的的 Step 1 配置节点 此步骤，将配置所有 3 个节点，为安装 Ceph 集群做好准备。 建议在所有节点上按照并运行以下所有命令。 并确保所有节点上都安装了 ssh-server。\n创建ceph用户(可选) bash 1 2 useradd -d /home/cephuser -m cephuser echo 1|passwd cephuser --stdin 创建新用户后，我们需要为“cephuser” 配置 sudo。 他必须能够以 root 身份运行命令并无需密码即可获得 root 权限。\n运行以下命令为用户创建 sudoers 文件并使用 sed 编辑 /etc/sudoers 文件。\nbash 1 2 3 echo \"cephuser ALL = (root) NOPASSWD:ALL\" | sudo tee /etc/sudoers.d/cephuser chmod 0440 /etc/sudoers.d/cephuser sed -i s'/Defaults requiretty/#Defaults requiretty'/g /etc/sudoers Note：上述 通过 ceph-deploy 需要配置，cephadm 中没有强制\n安装配置 NTP 服务(可选) 因为分布式存储需要依赖时间，所以需要对所有 OSD 节点的时间保持一致，这里时间同步的软件可以随意选择，\nbash 1 2 3 4 5 yum install -y ntp ntpdate ntp-doc ntpdate 0.us.pool.ntp.org hwclock --systohc systemctl enable ntpd.service systemctl start ntpd.service 可以不准备，随意启动一个服务即可，否则安装会出现如下提示\nbash 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 $ cephadm bootstrap --mon-ip cephadmin Verifying podman|docker is present... Verifying lvm2 is present... Verifying time synchronization is in place... No time sync service is running; checked for ['chrony.service', 'chronyd.service', 'systemd-timesyncd.service', 'ntpd.service', 'ntp.service', 'ntpsec.service', 'openntpd.service'] Installing packages ['chrony']... Enabling unit chronyd.service No time sync service is running; checked for ['chrony.service', 'chronyd.service', 'systemd-timesyncd.service', 'ntpd.service', 'ntp.service', 'ntpsec.service', 'openntpd.service'] Repeating the final host check... docker (/usr/bin/docker) is present systemctl is present lvcreate is present Unit chronyd.service is enabled and running Host looks OK Cluster fsid: 19c90bda-2fb8-11ee-9128-000c293e5d57 Address: cephadmin is not a valid IP address Verifying IP cephadmin port 3300 ... Address: cephadmin is not a valid IP address Verifying IP cephadmin port 6789 ... Address: cephadmin is not a valid IP address Cannot infer CIDR network for mon IP `cephadmin` : 'cephadmin' does not appear to be an IPv4 or IPv6 address Cannot infer CIDR network for mon IP `cephadmin` : 'cephadmin' does not appear to be an IPv4 or IPv6 address ERROR: Cannot infer CIDR network. Pass --skip-mon-network to configure it later 关闭 SELInux 在所有 Ceph Node 节点上关闭 SELInux，可以根据下面命令使用 sed 操作\nbash 1 sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config 配置 Hosts 文件 这里主机名可以根据自己选择进行，如果你有 DNS 服务，那么也可以通过注册在 DNS 内的服务进行\nbash 1 2 3 4 5 $ tee \u003e\u003e /etc/hosts \u003c\u003c EOF 10.0.0.20 ceph-octopus-cephadm 10.0.0.21 ceph-octopus-01 10.0.0.22 ceph-octopus-02 EOF 安装依赖 bash 1 2 3 4 # centos 7 yum install -y python3 lvm2 docker-ce # centos 8 dnf install -y python3 lvm2 podman Step2 下载 cephadm 并 修改 cephadm 镜像地址 获取 cephadm 脚本 步骤参考了 ceph 官方安装手册 [1] ，需要注意的是 cephadm 脚本也是需要按照版本来的\nbash 1 2 curl --silent --remote-name --location https://github.com/ceph/ceph/raw/octopus/src/cephadm/cephadm chmod +x cephadm 这个步骤主要是为了使 cephadm 可以正常的拉去 ceph 镜像，你可以通过 docker load 方式导入到 ceph node 之上，但是 ceph 镜像必须通过私有镜像进行拉取（存在 reposig 认证）其他 ceph 组件（prometheus, node-exporter..）可以通过 docker load 导入\ncephadm 最上面几行写明了要拉去镜像的镜像仓库地址，可以在有互联网机器上下载好，push 到私有镜像仓库中，如果没有私有镜像仓库，可以 run 一个 docker registry ，这个步骤是强制的；其他组件是可以通过 docker load 方式获得\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 $ head -20 cephadm #!/usr/bin/python3 # Default container images ----------------------------------------------------- DEFAULT_IMAGE = 'quay.io/ceph/ceph:v15' DEFAULT_IMAGE_IS_MASTER = False DEFAULT_PROMETHEUS_IMAGE = 'quay.io/prometheus/prometheus:v2.18.1' DEFAULT_NODE_EXPORTER_IMAGE = 'quay.io/prometheus/node-exporter:v0.18.1' DEFAULT_ALERT_MANAGER_IMAGE = 'quay.io/prometheus/alertmanager:v0.20.0' DEFAULT_GRAFANA_IMAGE = 'quay.io/ceph/ceph-grafana:6.7.4' # ------------------------------------------------------------------------------ LATEST_STABLE_RELEASE = 'octopus' DATA_DIR = '/var/lib/ceph' LOG_DIR = '/var/log/ceph' LOCK_DIR = '/run/cephadm' LOGROTATE_DIR = '/etc/logrotate.d' UNIT_DIR = '/etc/systemd/system' LOG_DIR_MODE = 0o770 DATA_DIR_MODE = 0o700 CONTAINER_INIT=False Run docker registry 拉去 docker registry\nbash 1 docker pull registry 镜像保存路径放置在当前工作目录中\nNote: 如果你没有独立的私有镜像仓库，那么请保留 docker registry，直到你不对 ceph 集群进行扩展\n执行下面命令，运行 docker registry\nbash 1 2 3 4 5 6 7 8 docker run \\ --detach \\ --name registry \\ --hostname registry \\ --volume $(pwd)/registry:/var/lib/registry/docker/registry \\ --publish 5000:5000 \\ --restart unless-stopped \\ registry:latest 在所有 ceph node 之上执行下面命令，需要自行替换 registry_host 部分\n现象：https://xxx:5000/v2/: http: server gave HTTP response to HTTPS client\nbash 1 2 3 4 5 tee /etc/docker/daemon.json \u003c\u003c EOF { \"insecure-registries\": [\"registry_host:5000\"] } EOF Step 3 引导一个新集群 在上面步骤都完成后，可以直接去引导一个新集群了\n可以选择性执行下面步骤\n这里是安装 ceph 客户端时需要用到的，例如 ceph-common, ceph-fuse 都会用到这些\nbash 1 $ ./cephadm add-repo --release octopus cephadm 命令能够：\n引导一个新集群 使用 ceph cli 启动容器化的 shell 用于调试容器化的 ceph daemon O 版的安装命令是通过 github 下载，要注意的是，每个版本号的 cephadm 命令不通用\nbash 1 2 3 4 5 # curl --silent --remote-name --location https://github.com/ceph/ceph/raw/pacific/src/cephadm/cephadm # chmod +x cephadm # ./cephadm add-repo --release octopus # install命令旨在将 cephadm 安装到环境变量中 # ./cephadm install 开始引导一个新的 ceph 集群 创建 Ceph 集群的第一步是在 Ceph 集群的管理几点上执行命令 cephadm bootstrap，这个命令的行为会创建 Ceph 集群中的第一个 “monitor” 守护进程，这需要提供一个 “IP地址” 而不可以是 “域名”。\n这里将 ceph monitor 部署在管理节点上了，以节省 Node 数量\nbash 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 $ cephadm bootstrap --mon-ip 10.0.0.20 Verifying podman|docker is present... Verifying lvm2 is present... Verifying time synchronization is in place... Unit chronyd.service is enabled and running Repeating the final host check... docker (/usr/bin/docker) is present systemctl is present lvcreate is present Unit chronyd.service is enabled and running Host looks OK Cluster fsid: 420ccab4-2fb8-11ee-9f5c-000c293e5d57 Verifying IP 10.0.0.20 port 3300 ... Verifying IP 10.0.0.20 port 6789 ... Mon IP `10.0.0.20` is in CIDR network `10.0.0.0/24` Mon IP `10.0.0.20` is in CIDR network `10.0.0.0/24` Internal network (--cluster-network) has not been provided, OSD replication will default to the public_network Pulling container image quay.io/ceph/ceph:v17... Non-zero exit code 1 from /usr/bin/docker pull quay.io/ceph/ceph:v17 /usr/bin/docker: stderr Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? ERROR: Failed command: /usr/bin/docker pull quay.io/ceph/ceph:v17 [root@cephadmin ~]# systemctl start docker [root@cephadmin ~]# cephadm bootstrap --mon-ip 10.0.0.20 Verifying podman|docker is present... Verifying lvm2 is present... Verifying time synchronization is in place... Unit chronyd.service is enabled and running Repeating the final host check... docker (/usr/bin/docker) is present systemctl is present lvcreate is present Unit chronyd.service is enabled and running Host looks OK Cluster fsid: 4d128cbe-2fb8-11ee-8326-000c293e5d57 Verifying IP 10.0.0.20 port 3300 ... Verifying IP 10.0.0.20 port 6789 ... Mon IP `10.0.0.20` is in CIDR network `10.0.0.0/24` Mon IP `10.0.0.20` is in CIDR network `10.0.0.0/24` Internal network (--cluster-network) has not been provided, OSD replication will default to the public_network Pulling container image quay.io/ceph/ceph:v17... Ceph version: ceph version 17.2.6 (d7ff0d10654d2280e08f1ab989c7cdf3064446a5) quincy (stable) Extracting ceph user uid/gid from container image... Creating initial keys... Creating initial monmap... Creating mon... Waiting for mon to start... Waiting for mon... mon is available Assimilating anything we can from ceph.conf... Generating new minimal ceph.conf... Restarting the monitor... Setting mon public_network to 10.0.0.0/24 Wrote config to /etc/ceph/ceph.conf Wrote keyring to /etc/ceph/ceph.client.admin.keyring Creating mgr... Verifying port 9283 ... Waiting for mgr to start... Waiting for mgr... mgr not available, waiting (1/15)... mgr not available, waiting (2/15)... mgr not available, waiting (3/15)... mgr not available, waiting (4/15)... mgr is available Enabling cephadm module... Waiting for the mgr to restart... Waiting for mgr epoch 5... mgr epoch 5 is available Setting orchestrator backend to cephadm... Generating ssh key... Wrote public SSH key to /etc/ceph/ceph.pub Adding key to root@localhost authorized_keys... Adding host cephadmin... Deploying mon service with default placement... Deploying mgr service with default placement... Deploying crash service with default placement... Deploying prometheus service with default placement... Deploying grafana service with default placement... Deploying node-exporter service with default placement... Deploying alertmanager service with default placement... Enabling the dashboard module... Waiting for the mgr to restart... Waiting for mgr epoch 9... mgr epoch 9 is available Generating a dashboard self-signed certificate... Creating initial admin user... Fetching dashboard port number... Ceph Dashboard is now available at: URL: https://cephadmin:8443/ User: admin Password: eqlf3jh1i1 Enabling client.admin keyring and conf on hosts with \"admin\" label Saving cluster configuration to /var/lib/ceph/4d128cbe-2fb8-11ee-8326-000c293e5d57/config directory Enabling autotune for osd_memory_target You can access the Ceph CLI as following in case of multi-cluster or non-default config: sudo /usr/local/bin/cephadm shell --fsid 4d128cbe-2fb8-11ee-8326-000c293e5d57 -c /etc/ceph/ceph.conf -k /etc/ceph/ceph.client.admin.keyring Or, if you are only running a single cluster on this host: sudo /usr/local/bin/cephadm shell Please consider enabling telemetry to help improve Ceph: ceph telemetry on For more information see: https://docs.ceph.com/docs/master/mgr/telemetry/ Bootstrap complete. 成功后会看到 ceph dashboard 的界面，默认密码会输出到控制台，第一次登陆会要求修改默认密码\n在安装将生成一个最小的 ceph.conf 仅适用于引导阶段的配置文件，通过进入 mon 容器查看\nbash 1 $ docker exec -it ceph-350494de-d23f-11ea-be85-525400d32681-mon.mon0 cat /etc/ceph/ceph.conf # 向 ceph 集群导入 osd node 向每个 node 导入 ssh key，下面的操作是通过进入管理容器执行的\nbash 1 ssh-copy-id -f -i /etc/ceph/ceph.pub root@** 添加一个主机到 ceph 集群\nbash 1 ceph orch host add *newhost* 部署一个新的 mon，你可以给新加入的主机打上标签\nbash 1 2 # ceph orch host label add ** mon ceph orch apply mon ** 向集群部署新的组件\nbash 1 2 ceph orch apply mon ** ceph orch apply mon ** 部署 osd damon 在新的主机之上\nbash 1 2 ceph orch daemon add osd **:** ceph orch daemon add osd host1:/dev/sdb 这是可以列出正在管理的服务器 cephadm 使用 host ls 命令：\nbash 1 ceph orch host ls 到此，如果你只使用 RDB 块存储，这里已经部署完成了，如果需要选择使用 文件存储 CephFS，或者对象存储 RGW，可以在另外部署相应的组件，部署的组件是根据按需使用进行部署\nosd device 命令也可以列出对应的设备\nbash 1 ceph orch device ls 在 Ceph 中一切存储的基础都是基于 RADOS 集群\nTroubleshooting TypeError: init() missing 2 required positional arguments: ‘hostname’ and ‘addr’ 现象：实际上输入了 hostname 和 addr 也是出现这个问题\nbash 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 $ ceph orch host add ceph-octopus-01 Error EINVAL: Traceback (most recent call last): File \"/usr/share/ceph/mgr/mgr_module.py\", line 1756, in _handle_command return self.handle_command(inbuf, cmd) File \"/usr/share/ceph/mgr/orchestrator/_interface.py\", line 171, in handle_command return dispatch[cmd['prefix']].call(self, cmd, inbuf) File \"/usr/share/ceph/mgr/mgr_module.py\", line 462, in call return self.func(mgr, **kwargs) File \"/usr/share/ceph/mgr/orchestrator/_interface.py\", line 107, in wrapper_copy = lambda *l_args, **l_kwargs: wrapper(*l_args, **l_kwargs) # noqa: E731 File \"/usr/share/ceph/mgr/orchestrator/_interface.py\", line 96, in wrapper return func(*args, **kwargs) File \"/usr/share/ceph/mgr/orchestrator/module.py\", line 356, in _add_host return self._apply_misc([s], False, Format.plain) File \"/usr/share/ceph/mgr/orchestrator/module.py\", line 1092, in _apply_misc raise_if_exception(completion) File \"/usr/share/ceph/mgr/orchestrator/_interface.py\", line 225, in raise_if_exception e = pickle.loads(c.serialized_exception) TypeError: __init__() missing 2 required positional arguments: 'hostname' and 'addr' 首先先将公钥分发到对应的 CEPH NODE 之上\nbash 1 2 3 4 5 6 7 8 9 10 11 12 export CEPH_HOSTNAME=root@ceph-octopus-01 # 获取公钥 ceph cephadm get-pub-key \u003e /etc/ceph/ceph.pub # 分发公钥到对应 ceph node ssh-copy-id -f -i /etc/ceph/ceph.pub ${CEPH_HOSTNAME} # 尝试使用私钥是否可以连接到 ceph node ceph cephadm get-ssh-config \u003e ssh_config ceph config-key get mgr/cephadm/ssh_identity_key \u003e ~/cephadm_private_key chmod 0600 ~/cephadm_private_key ssh -F ssh_config -i ~/cephadm_private_key ${CEPH_HOSTNAME} 我解决的方式：实际上版本不对，更新版本就恢复了\nReference [1] install-cephadm\n[2] Object Request Broker Architecture\n[3] Cooperation for Open Systems Interconnection Networking in Europe\n","wordCount":"1783","inLanguage":"zh","datePublished":"2023-07-30T00:00:00Z","dateModified":"2023-08-25T23:10:36+08:00","author":{"@type":"Person","name":"cylon"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.oomkill.com/2023/07/02-1-install-ceph-with-cephadm/"},"publisher":{"@type":"Organization","name":"Cylon's Collection","logo":{"@type":"ImageObject","url":"https://www.oomkill.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://www.oomkill.com/><img src=https://www.oomkill.com/favicon.ico alt aria-label=logo height=20>Cylon's Collection</a><div class=logo-switches><button id=theme-toggle><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://www.oomkill.com/archives><span>归档</span></a></li><li><a href=https://www.oomkill.com/tags><span>标签</span></a></li><li><a href=https://www.oomkill.com/search><span>搜索</span></a></li><li><a href=https://www.oomkill.com/about accesskey=/><span>关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">使用cephadm纯离线安装Ceph集群</h1><div class=post-meta><span class=pe-post-meta-item><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select:text"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select:text"/><line x1="16" y1="2" x2="16" y2="6" style="user-select:text"/><line x1="8" y1="2" x2="8" y2="6" style="user-select:text"/><line x1="3" y1="10" x2="21" y2="10" style="user-select:text"/></svg><span>2023-07-30</span></span>&nbsp;·&nbsp;<span class=pe-post-meta-item><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text" style="user-select:text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z" style="user-select:text"/><polyline points="14 2 14 8 20 8" style="user-select:text"/><line x1="16" y1="13" x2="8" y2="13" style="user-select:text"/><line x1="16" y1="17" x2="8" y2="17" style="user-select:text"/><polyline points="10 9 9 9 8 9" style="user-select:text"/></svg><span>1783 字</span></span>&nbsp;·&nbsp;<span class=pe-post-meta-item><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><span>9 分钟</span></span>
<span class=pe-post-meta-item>&nbsp;·&nbsp;<svg t="1714036239378" fill="currentcolor" class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" p-id="6659" width="256" height="256"><path d="M690 78.2c-18.6-18.8-49-19-67.8-.4s-19 49-.4 67.8l255.4 258.6c67.8 68.6 67.8 178.8.0 247.4L653.4 878.2c-18.6 18.8-18.4 49.2.4 67.8s49.2 18.4 67.8-.4l224-226.4c104.8-106 104.8-276.4.0-382.4L690 78.2zM485.4 101.4c-24-24-56.6-37.4-90.6-37.4H96C43 64 0 107 0 160v299c0 34 13.4 66.6 37.4 90.6l336 336c50 50 131 50 181 0l267-267c50-50 50-131 0-181l-336-336zM96 160h299c8.4.0 16.6 3.4 22.6 9.4l336 336c12.4 12.4 12.4 32.8.0 45.2l-267 267c-12.4 12.4-32.8 12.4-45.2.0l-336-336c-6-6-9.4-14.2-9.4-22.6V160zm192 128a64 64 0 10-128 0 64 64 0 10128 0z" p-id="6660"/></svg></span><ul class=pe-post-meta-item><a href=https://www.oomkill.com/tags/storage/>#Storage</a></ul></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details><summary><span class=details>目录</span></summary><div class=inner><ul><li><a href=#%e5%bc%80%e7%af%87%e5%b8%b8%e4%be%8b---%e6%a6%82%e8%bf%b0 aria-label="开篇常例 - 概述">开篇常例 - 概述</a><li><a href=#requirements aria-label=REQUIREMENTS>REQUIREMENTS</a><li><a href=#step-1-%e9%85%8d%e7%bd%ae%e8%8a%82%e7%82%b9 aria-label="Step 1 配置节点">Step 1 配置节点</a><ul><li><a href=#%e5%88%9b%e5%bb%baceph%e7%94%a8%e6%88%b7%e5%8f%af%e9%80%89 aria-label=创建ceph用户(可选)>创建ceph用户(可选)</a><li><a href=#%e5%ae%89%e8%a3%85%e9%85%8d%e7%bd%ae-ntp-%e6%9c%8d%e5%8a%a1%e5%8f%af%e9%80%89 aria-label="安装配置 NTP 服务(可选)">安装配置 NTP 服务(可选)</a><li><a href=#%e5%85%b3%e9%97%ad-selinux aria-label="关闭 SELInux">关闭 SELInux</a><li><a href=#%e9%85%8d%e7%bd%ae-hosts-%e6%96%87%e4%bb%b6 aria-label="配置 Hosts 文件">配置 Hosts 文件</a><li><a href=#%e5%ae%89%e8%a3%85%e4%be%9d%e8%b5%96 aria-label=安装依赖>安装依赖</a></ul><li><a href=#step2-%e4%b8%8b%e8%bd%bd-cephadm-%e5%b9%b6-%e4%bf%ae%e6%94%b9-cephadm-%e9%95%9c%e5%83%8f%e5%9c%b0%e5%9d%80 aria-label="Step2 下载 cephadm 并 修改 cephadm 镜像地址">Step2 下载 cephadm 并 修改 cephadm 镜像地址</a><ul><li><a href=#%e8%8e%b7%e5%8f%96-cephadm-%e8%84%9a%e6%9c%ac aria-label="获取 cephadm 脚本">获取 cephadm 脚本</a><li><a href=#run-docker-registry aria-label="Run docker registry">Run docker registry</a></ul><li><a href=#step-3-%e5%bc%95%e5%af%bc%e4%b8%80%e4%b8%aa%e6%96%b0%e9%9b%86%e7%be%a4 aria-label="Step 3 引导一个新集群">Step 3 引导一个新集群</a><li><a href=#%e5%bc%80%e5%a7%8b%e5%bc%95%e5%af%bc%e4%b8%80%e4%b8%aa%e6%96%b0%e7%9a%84-ceph-%e9%9b%86%e7%be%a4 aria-label="开始引导一个新的 ceph 集群">开始引导一个新的 ceph 集群</a><li><a href=#%e5%90%91-ceph-%e9%9b%86%e7%be%a4%e5%af%bc%e5%85%a5-osd-node aria-label="向 ceph 集群导入 osd node">向 ceph 集群导入 osd node</a><li><a href=#troubleshooting aria-label=Troubleshooting>Troubleshooting</a><ul><li><a href=#typeerror-__init__-missing-2-required-positional-arguments-hostname-and-addr aria-label="TypeError: init() missing 2 required positional arguments: &amp;lsquo;hostname&amp;rsquo; and &amp;lsquo;addr&amp;rsquo;">TypeError: <strong>init</strong>() missing 2 required positional arguments: &lsquo;hostname&rsquo; and &lsquo;addr&rsquo;</a></ul><li><a href=#reference aria-label=Reference>Reference</a></li></div></details></div></aside><script src=/js/pe-toc.min.445eb1bfc5e85dd13b9519fcc2a806522e9629b6224a2974052789ba00ab78af.js integrity="sha256-RF6xv8XoXdE7lRn8wqgGUi6WKbYiSil0BSeJugCreK8="></script><div class=post-content><h2 id=开篇常例---概述>开篇常例 - 概述<a hidden class=anchor aria-hidden=true href=#开篇常例---概述>#</a></h2><p>Ceph 是一个广泛使用的开源存储平台。 它提供高性能、可靠性和可扩展性。 Ceph 分布式存储系统提供了对象存储、块存储和文件级存储。 Ceph 旨在提供无单点故障的分布式存储系统。</p><p>在本教程中，将通过 ceph-adm 方式在 CentOS 7 上安装和构建 Ceph 集群。该实验的 Ceph 集群需要以下 Ceph 组件：</p><ul><li><strong>Ceph OSD (ceph-osd)</strong> - 处理数据存储、数据复制和恢复；通常一个Ceph集群至少需要两台 OSD 服务器 。</li><li><strong>Ceph Monitor (ceph-mon)</strong> - 监视集群状态、OSD 映射和 CRUSH 映射，我们在这里与 cephadm 或 OSD 公用一个节点</li><li><strong>Ceph 元数据服务器 (ceph-mds)</strong> - 这是使用 CephFS 所需的组件。</li></ul><p>有了上面的条件，我们实验环境所需要的节点如下：</p><ul><li>三台服务器节点，CentOS 7</li></ul><blockquote><p>注：CentOS 7 可安装最高级别的 ceph 版本就是 O 版</p></blockquote><p>本教程中的服务器将使用以下主机名和 IP 地址：</p><table><thead><tr><th>主机名</th><th>IP地址</th><th>作用</th></tr></thead><tbody><tr><td>cephadmin</td><td>10.0.0.20</td><td>作为 ceph 管理节点，以管理与部署 ceph 集群</td></tr><tr><td>osd01</td><td>10.0.0.21</td><td></td></tr><tr><td>osd02</td><td>10.0.0.22</td><td></td></tr><tr><td><em>any</em></td><td><em>any</em></td><td>作为 Ceph Client 的角色</td></tr></tbody></table><blockquote><p>注：所有 OSD 节点都需要两个分区，一个根（/）分区和一个空分区，稍后用作 Ceph 数据存储。</p></blockquote><h2 id=requirements>REQUIREMENTS<a hidden class=anchor aria-hidden=true href=#requirements>#</a></h2><p>使用 <em>cephadm</em> 安装 ceph 集群，所需要的先决条件如下:</p><p>必要条件：</p><ul><li>Python 3，因为 cephadm 是一个 python3 脚本，所以需要每个节点都需要安装 python3</li><li>Systemd</li><li>Podman or Docker：cephadm 安装的集群是一种以 “容器方式” 运行在对应的 ceph node 之上</li><li>LVM2：ceph OSD 是通过 LVM 来使用的，所以需要在每个 OSD 节点之上安装 LVM2</li></ul><p>非必要条件：</p><ul><li>chrony or NTP：ceph 强依赖每个节点之上的时间</li><li>Internet</li><li>域名解析：ceph 集群对于 ceph node 来说是通过 <code>hostname.random_str</code> 识别的的</li></ul><h2 id=step-1-配置节点>Step 1 配置节点<a hidden class=anchor aria-hidden=true href=#step-1-配置节点>#</a></h2><p>此步骤，将配置所有 3 个节点，为安装 Ceph 集群做好准备。 建议在所有节点上按照并运行以下所有命令。 并确保所有节点上都安装了 ssh-server。</p><h3 id=创建ceph用户可选>创建ceph用户(可选)<a hidden class=anchor aria-hidden=true href=#创建ceph用户可选>#</a></h3><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>useradd -d /home/cephuser -m cephuser 
</span></span><span class=line><span class=cl><span class=nb>echo</span> 1<span class=p>|</span>passwd cephuser --stdin</span></span></code></pre></td></tr></table></div></div></div></div><p>创建新用户后，我们需要为“cephuser” 配置 sudo。 他必须能够以 root 身份运行命令并无需密码即可获得 root 权限。</p><p>运行以下命令为用户创建 sudoers 文件并使用 sed 编辑 /etc/sudoers 文件。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;cephuser ALL = (root) NOPASSWD:ALL&#34;</span> <span class=p>|</span> sudo tee /etc/sudoers.d/cephuser
</span></span><span class=line><span class=cl>chmod <span class=m>0440</span> /etc/sudoers.d/cephuser
</span></span><span class=line><span class=cl>sed -i s<span class=s1>&#39;/Defaults requiretty/#Defaults requiretty&#39;</span>/g /etc/sudoers</span></span></code></pre></td></tr></table></div></div></div></div><blockquote><p>Note：上述 通过 ceph-deploy 需要配置，cephadm 中没有强制</p></blockquote><h3 id=安装配置-ntp-服务可选>安装配置 NTP 服务(可选)<a hidden class=anchor aria-hidden=true href=#安装配置-ntp-服务可选>#</a></h3><p>因为分布式存储需要依赖时间，所以需要对所有 OSD 节点的时间保持一致，这里时间同步的软件可以随意选择，</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>yum install -y ntp ntpdate ntp-doc
</span></span><span class=line><span class=cl>ntpdate 0.us.pool.ntp.org
</span></span><span class=line><span class=cl>hwclock --systohc
</span></span><span class=line><span class=cl>systemctl <span class=nb>enable</span> ntpd.service
</span></span><span class=line><span class=cl>systemctl start ntpd.service</span></span></code></pre></td></tr></table></div></div></div></div><blockquote><p>可以不准备，随意启动一个服务即可，否则安装会出现如下提示</p></blockquote><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ cephadm bootstrap --mon-ip cephadmin
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Verifying podman<span class=p>|</span>docker is present...
</span></span><span class=line><span class=cl>Verifying lvm2 is present...
</span></span><span class=line><span class=cl>Verifying <span class=nb>time</span> synchronization is in place...
</span></span><span class=line><span class=cl>No <span class=nb>time</span> sync service is running<span class=p>;</span> checked <span class=k>for</span> <span class=o>[</span><span class=s1>&#39;chrony.service&#39;</span>, <span class=s1>&#39;chronyd.service&#39;</span>, <span class=s1>&#39;systemd-timesyncd.service&#39;</span>, <span class=s1>&#39;ntpd.service&#39;</span>, <span class=s1>&#39;ntp.service&#39;</span>, <span class=s1>&#39;ntpsec.service&#39;</span>, <span class=s1>&#39;openntpd.service&#39;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>Installing packages <span class=o>[</span><span class=s1>&#39;chrony&#39;</span><span class=o>]</span>...
</span></span><span class=line><span class=cl>Enabling unit chronyd.service
</span></span><span class=line><span class=cl>No <span class=nb>time</span> sync service is running<span class=p>;</span> checked <span class=k>for</span> <span class=o>[</span><span class=s1>&#39;chrony.service&#39;</span>, <span class=s1>&#39;chronyd.service&#39;</span>, <span class=s1>&#39;systemd-timesyncd.service&#39;</span>, <span class=s1>&#39;ntpd.service&#39;</span>, <span class=s1>&#39;ntp.service&#39;</span>, <span class=s1>&#39;ntpsec.service&#39;</span>, <span class=s1>&#39;openntpd.service&#39;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>Repeating the final host check...
</span></span><span class=line><span class=cl>docker <span class=o>(</span>/usr/bin/docker<span class=o>)</span> is present
</span></span><span class=line><span class=cl>systemctl is present
</span></span><span class=line><span class=cl>lvcreate is present
</span></span><span class=line><span class=cl>Unit chronyd.service is enabled and running
</span></span><span class=line><span class=cl>Host looks OK
</span></span><span class=line><span class=cl>Cluster fsid: 19c90bda-2fb8-11ee-9128-000c293e5d57
</span></span><span class=line><span class=cl>Address: cephadmin is not a valid IP address
</span></span><span class=line><span class=cl>Verifying IP cephadmin port <span class=m>3300</span> ...
</span></span><span class=line><span class=cl>Address: cephadmin is not a valid IP address
</span></span><span class=line><span class=cl>Verifying IP cephadmin port <span class=m>6789</span> ...
</span></span><span class=line><span class=cl>Address: cephadmin is not a valid IP address
</span></span><span class=line><span class=cl>Cannot infer CIDR network <span class=k>for</span> mon IP <span class=sb>`</span>cephadmin<span class=sb>`</span> : <span class=s1>&#39;cephadmin&#39;</span> does not appear to be an IPv4 or IPv6 address
</span></span><span class=line><span class=cl>Cannot infer CIDR network <span class=k>for</span> mon IP <span class=sb>`</span>cephadmin<span class=sb>`</span> : <span class=s1>&#39;cephadmin&#39;</span> does not appear to be an IPv4 or IPv6 address
</span></span><span class=line><span class=cl>ERROR: Cannot infer CIDR network. Pass --skip-mon-network to configure it later</span></span></code></pre></td></tr></table></div></div></div></div><h3 id=关闭-selinux>关闭 SELInux<a hidden class=anchor aria-hidden=true href=#关闭-selinux>#</a></h3><p>在所有 Ceph Node 节点上关闭 SELInux，可以根据下面命令使用 sed 操作</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sed -i <span class=s1>&#39;s/SELINUX=enforcing/SELINUX=disabled/g&#39;</span> /etc/selinux/config</span></span></code></pre></td></tr></table></div></div></div></div><h3 id=配置-hosts-文件>配置 Hosts 文件<a hidden class=anchor aria-hidden=true href=#配置-hosts-文件>#</a></h3><p>这里主机名可以根据自己选择进行，如果你有 DNS 服务，那么也可以通过注册在 DNS 内的服务进行</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ tee &gt;&gt; /etc/hosts <span class=s>&lt;&lt; EOF
</span></span></span><span class=line><span class=cl><span class=s>10.0.0.20        ceph-octopus-cephadm
</span></span></span><span class=line><span class=cl><span class=s>10.0.0.21        ceph-octopus-01
</span></span></span><span class=line><span class=cl><span class=s>10.0.0.22        ceph-octopus-02
</span></span></span><span class=line><span class=cl><span class=s>EOF</span></span></span></code></pre></td></tr></table></div></div></div></div><h3 id=安装依赖>安装依赖<a hidden class=anchor aria-hidden=true href=#安装依赖>#</a></h3><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># centos 7</span>
</span></span><span class=line><span class=cl>yum install -y python3 lvm2 docker-ce
</span></span><span class=line><span class=cl><span class=c1># centos 8</span>
</span></span><span class=line><span class=cl>dnf install -y python3 lvm2 podman</span></span></code></pre></td></tr></table></div></div></div></div><h2 id=step2-下载-cephadm-并-修改-cephadm-镜像地址>Step2 下载 cephadm 并 修改 cephadm 镜像地址<a hidden class=anchor aria-hidden=true href=#step2-下载-cephadm-并-修改-cephadm-镜像地址>#</a></h2><h3 id=获取-cephadm-脚本>获取 cephadm 脚本<a hidden class=anchor aria-hidden=true href=#获取-cephadm-脚本>#</a></h3><p>步骤参考了 ceph 官方安装手册 <sup><a href=#1>[1]</a></sup> ，需要注意的是 <em>cephadm</em> 脚本也是需要按照版本来的</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl --silent --remote-name --location https://github.com/ceph/ceph/raw/octopus/src/cephadm/cephadm
</span></span><span class=line><span class=cl>chmod +x cephadm</span></span></code></pre></td></tr></table></div></div></div></div><p>这个步骤主要是为了使 cephadm 可以正常的拉去 ceph 镜像，你可以通过 <code>docker load</code> 方式导入到 ceph node 之上，但是 ceph 镜像必须通过私有镜像进行拉取（存在 reposig 认证）其他 ceph 组件（prometheus, node-exporter..）可以通过 <code>docker load</code> 导入</p><p>cephadm 最上面几行写明了要拉去镜像的镜像仓库地址，可以在有互联网机器上下载好，push 到私有镜像仓库中，如果没有私有镜像仓库，可以 run 一个 docker registry ，这个步骤是强制的；其他组件是可以通过 <code>docker load</code> 方式获得</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=err>$</span> <span class=n>head</span> <span class=o>-</span><span class=mi>20</span> <span class=n>cephadm</span> 
</span></span><span class=line><span class=cl><span class=c1>#!/usr/bin/python3</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Default container images -----------------------------------------------------</span>
</span></span><span class=line><span class=cl><span class=n>DEFAULT_IMAGE</span> <span class=o>=</span> <span class=s1>&#39;quay.io/ceph/ceph:v15&#39;</span>
</span></span><span class=line><span class=cl><span class=n>DEFAULT_IMAGE_IS_MASTER</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=n>DEFAULT_PROMETHEUS_IMAGE</span> <span class=o>=</span> <span class=s1>&#39;quay.io/prometheus/prometheus:v2.18.1&#39;</span>
</span></span><span class=line><span class=cl><span class=n>DEFAULT_NODE_EXPORTER_IMAGE</span> <span class=o>=</span> <span class=s1>&#39;quay.io/prometheus/node-exporter:v0.18.1&#39;</span>
</span></span><span class=line><span class=cl><span class=n>DEFAULT_ALERT_MANAGER_IMAGE</span> <span class=o>=</span> <span class=s1>&#39;quay.io/prometheus/alertmanager:v0.20.0&#39;</span>
</span></span><span class=line><span class=cl><span class=n>DEFAULT_GRAFANA_IMAGE</span> <span class=o>=</span> <span class=s1>&#39;quay.io/ceph/ceph-grafana:6.7.4&#39;</span>
</span></span><span class=line><span class=cl><span class=c1># ------------------------------------------------------------------------------</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>LATEST_STABLE_RELEASE</span> <span class=o>=</span> <span class=s1>&#39;octopus&#39;</span>
</span></span><span class=line><span class=cl><span class=n>DATA_DIR</span> <span class=o>=</span> <span class=s1>&#39;/var/lib/ceph&#39;</span>
</span></span><span class=line><span class=cl><span class=n>LOG_DIR</span> <span class=o>=</span> <span class=s1>&#39;/var/log/ceph&#39;</span>
</span></span><span class=line><span class=cl><span class=n>LOCK_DIR</span> <span class=o>=</span> <span class=s1>&#39;/run/cephadm&#39;</span>
</span></span><span class=line><span class=cl><span class=n>LOGROTATE_DIR</span> <span class=o>=</span> <span class=s1>&#39;/etc/logrotate.d&#39;</span>
</span></span><span class=line><span class=cl><span class=n>UNIT_DIR</span> <span class=o>=</span> <span class=s1>&#39;/etc/systemd/system&#39;</span>
</span></span><span class=line><span class=cl><span class=n>LOG_DIR_MODE</span> <span class=o>=</span> <span class=mo>0o770</span>
</span></span><span class=line><span class=cl><span class=n>DATA_DIR_MODE</span> <span class=o>=</span> <span class=mo>0o700</span>
</span></span><span class=line><span class=cl><span class=n>CONTAINER_INIT</span><span class=o>=</span><span class=kc>False</span></span></span></code></pre></td></tr></table></div></div></div></div><h3 id=run-docker-registry>Run docker registry<a hidden class=anchor aria-hidden=true href=#run-docker-registry>#</a></h3><p>拉去 docker registry</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker pull registry</span></span></code></pre></td></tr></table></div></div></div></div><p>镜像保存路径放置在当前工作目录中</p><blockquote><p>Note: 如果你没有独立的私有镜像仓库，那么请保留 docker registry，直到你不对 ceph 集群进行扩展</p></blockquote><p>执行下面命令，运行 docker registry</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker run <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --detach <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --name registry <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --hostname registry <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --volume <span class=k>$(</span><span class=nb>pwd</span><span class=k>)</span>/registry:/var/lib/registry/docker/registry <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --publish 5000:5000 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --restart unless-stopped <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  registry:latest</span></span></code></pre></td></tr></table></div></div></div></div><p>在所有 ceph node 之上执行下面命令，需要自行替换 <code>registry_host</code> 部分</p><blockquote><p>现象：https://xxx:5000/v2/: http: server gave HTTP response to HTTPS client</p></blockquote><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>tee /etc/docker/daemon.json <span class=s>&lt;&lt; EOF
</span></span></span><span class=line><span class=cl><span class=s>{
</span></span></span><span class=line><span class=cl><span class=s>    &#34;insecure-registries&#34;: [&#34;registry_host:5000&#34;]
</span></span></span><span class=line><span class=cl><span class=s>}
</span></span></span><span class=line><span class=cl><span class=s>EOF</span></span></span></code></pre></td></tr></table></div></div></div></div><h2 id=step-3-引导一个新集群>Step 3 引导一个新集群<a hidden class=anchor aria-hidden=true href=#step-3-引导一个新集群>#</a></h2><p>在上面步骤都完成后，可以直接去引导一个新集群了</p><p>可以选择性执行下面步骤</p><blockquote><p>这里是安装 ceph 客户端时需要用到的，例如 ceph-common, ceph-fuse 都会用到这些</p></blockquote><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ ./cephadm add-repo --release octopus</span></span></code></pre></td></tr></table></div></div></div></div><p>cephadm 命令能够：</p><ul><li>引导一个新集群</li><li>使用 ceph cli 启动容器化的 shell</li><li>用于调试容器化的 ceph daemon</li></ul><p>O 版的安装命令是通过 github 下载，要注意的是，每个版本号的 cephadm 命令不通用</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># curl --silent --remote-name --location https://github.com/ceph/ceph/raw/pacific/src/cephadm/cephadm</span>
</span></span><span class=line><span class=cl><span class=c1># chmod +x cephadm</span>
</span></span><span class=line><span class=cl><span class=c1># ./cephadm add-repo --release octopus</span>
</span></span><span class=line><span class=cl><span class=c1># install命令旨在将 cephadm 安装到环境变量中</span>
</span></span><span class=line><span class=cl><span class=c1># ./cephadm install </span></span></span></code></pre></td></tr></table></div></div></div></div><h2 id=开始引导一个新的-ceph-集群>开始引导一个新的 ceph 集群<a hidden class=anchor aria-hidden=true href=#开始引导一个新的-ceph-集群>#</a></h2><p>创建 Ceph 集群的第一步是在 Ceph 集群的管理几点上执行命令 <code>cephadm bootstrap</code>，这个命令的行为会创建 Ceph 集群中的第一个 &ldquo;monitor&rdquo; 守护进程，这需要提供一个 “IP地址” 而不可以是 “域名”。</p><p>这里将 ceph monitor 部署在管理节点上了，以节省 Node 数量</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ cephadm bootstrap --mon-ip 10.0.0.20
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Verifying podman<span class=p>|</span>docker is present...
</span></span><span class=line><span class=cl>Verifying lvm2 is present...
</span></span><span class=line><span class=cl>Verifying <span class=nb>time</span> synchronization is in place...
</span></span><span class=line><span class=cl>Unit chronyd.service is enabled and running
</span></span><span class=line><span class=cl>Repeating the final host check...
</span></span><span class=line><span class=cl>docker <span class=o>(</span>/usr/bin/docker<span class=o>)</span> is present
</span></span><span class=line><span class=cl>systemctl is present
</span></span><span class=line><span class=cl>lvcreate is present
</span></span><span class=line><span class=cl>Unit chronyd.service is enabled and running
</span></span><span class=line><span class=cl>Host looks OK
</span></span><span class=line><span class=cl>Cluster fsid: 420ccab4-2fb8-11ee-9f5c-000c293e5d57
</span></span><span class=line><span class=cl>Verifying IP 10.0.0.20 port <span class=m>3300</span> ...
</span></span><span class=line><span class=cl>Verifying IP 10.0.0.20 port <span class=m>6789</span> ...
</span></span><span class=line><span class=cl>Mon IP <span class=sb>`</span>10.0.0.20<span class=sb>`</span> is in CIDR network <span class=sb>`</span>10.0.0.0/24<span class=sb>`</span>
</span></span><span class=line><span class=cl>Mon IP <span class=sb>`</span>10.0.0.20<span class=sb>`</span> is in CIDR network <span class=sb>`</span>10.0.0.0/24<span class=sb>`</span>
</span></span><span class=line><span class=cl>Internal network <span class=o>(</span>--cluster-network<span class=o>)</span> has not been provided, OSD replication will default to the public_network
</span></span><span class=line><span class=cl>Pulling container image quay.io/ceph/ceph:v17...
</span></span><span class=line><span class=cl>Non-zero <span class=nb>exit</span> code <span class=m>1</span> from /usr/bin/docker pull quay.io/ceph/ceph:v17
</span></span><span class=line><span class=cl>/usr/bin/docker: stderr Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?
</span></span><span class=line><span class=cl>ERROR: Failed command: /usr/bin/docker pull quay.io/ceph/ceph:v17
</span></span><span class=line><span class=cl><span class=o>[</span>root@cephadmin ~<span class=o>]</span><span class=c1># systemctl start docker </span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@cephadmin ~<span class=o>]</span><span class=c1># cephadm bootstrap --mon-ip 10.0.0.20</span>
</span></span><span class=line><span class=cl>Verifying podman<span class=p>|</span>docker is present...
</span></span><span class=line><span class=cl>Verifying lvm2 is present...
</span></span><span class=line><span class=cl>Verifying <span class=nb>time</span> synchronization is in place...
</span></span><span class=line><span class=cl>Unit chronyd.service is enabled and running
</span></span><span class=line><span class=cl>Repeating the final host check...
</span></span><span class=line><span class=cl>docker <span class=o>(</span>/usr/bin/docker<span class=o>)</span> is present
</span></span><span class=line><span class=cl>systemctl is present
</span></span><span class=line><span class=cl>lvcreate is present
</span></span><span class=line><span class=cl>Unit chronyd.service is enabled and running
</span></span><span class=line><span class=cl>Host looks OK
</span></span><span class=line><span class=cl>Cluster fsid: 4d128cbe-2fb8-11ee-8326-000c293e5d57
</span></span><span class=line><span class=cl>Verifying IP 10.0.0.20 port <span class=m>3300</span> ...
</span></span><span class=line><span class=cl>Verifying IP 10.0.0.20 port <span class=m>6789</span> ...
</span></span><span class=line><span class=cl>Mon IP <span class=sb>`</span>10.0.0.20<span class=sb>`</span> is in CIDR network <span class=sb>`</span>10.0.0.0/24<span class=sb>`</span>
</span></span><span class=line><span class=cl>Mon IP <span class=sb>`</span>10.0.0.20<span class=sb>`</span> is in CIDR network <span class=sb>`</span>10.0.0.0/24<span class=sb>`</span>
</span></span><span class=line><span class=cl>Internal network <span class=o>(</span>--cluster-network<span class=o>)</span> has not been provided, OSD replication will default to the public_network
</span></span><span class=line><span class=cl>Pulling container image quay.io/ceph/ceph:v17...
</span></span><span class=line><span class=cl>Ceph version: ceph version 17.2.6 <span class=o>(</span>d7ff0d10654d2280e08f1ab989c7cdf3064446a5<span class=o>)</span> quincy <span class=o>(</span>stable<span class=o>)</span>
</span></span><span class=line><span class=cl>Extracting ceph user uid/gid from container image...
</span></span><span class=line><span class=cl>Creating initial keys...
</span></span><span class=line><span class=cl>Creating initial monmap...
</span></span><span class=line><span class=cl>Creating mon...
</span></span><span class=line><span class=cl>Waiting <span class=k>for</span> mon to start...
</span></span><span class=line><span class=cl>Waiting <span class=k>for</span> mon...
</span></span><span class=line><span class=cl>mon is available
</span></span><span class=line><span class=cl>Assimilating anything we can from ceph.conf...
</span></span><span class=line><span class=cl>Generating new minimal ceph.conf...
</span></span><span class=line><span class=cl>Restarting the monitor...
</span></span><span class=line><span class=cl>Setting mon public_network to 10.0.0.0/24
</span></span><span class=line><span class=cl>Wrote config to /etc/ceph/ceph.conf
</span></span><span class=line><span class=cl>Wrote keyring to /etc/ceph/ceph.client.admin.keyring
</span></span><span class=line><span class=cl>Creating mgr...
</span></span><span class=line><span class=cl>Verifying port <span class=m>9283</span> ...
</span></span><span class=line><span class=cl>Waiting <span class=k>for</span> mgr to start...
</span></span><span class=line><span class=cl>Waiting <span class=k>for</span> mgr...
</span></span><span class=line><span class=cl>mgr not available, waiting <span class=o>(</span>1/15<span class=o>)</span>...
</span></span><span class=line><span class=cl>mgr not available, waiting <span class=o>(</span>2/15<span class=o>)</span>...
</span></span><span class=line><span class=cl>mgr not available, waiting <span class=o>(</span>3/15<span class=o>)</span>...
</span></span><span class=line><span class=cl>mgr not available, waiting <span class=o>(</span>4/15<span class=o>)</span>...
</span></span><span class=line><span class=cl>mgr is available
</span></span><span class=line><span class=cl>Enabling cephadm module...
</span></span><span class=line><span class=cl>Waiting <span class=k>for</span> the mgr to restart...
</span></span><span class=line><span class=cl>Waiting <span class=k>for</span> mgr epoch 5...
</span></span><span class=line><span class=cl>mgr epoch <span class=m>5</span> is available
</span></span><span class=line><span class=cl>Setting orchestrator backend to cephadm...
</span></span><span class=line><span class=cl>Generating ssh key...
</span></span><span class=line><span class=cl>Wrote public SSH key to /etc/ceph/ceph.pub
</span></span><span class=line><span class=cl>Adding key to root@localhost authorized_keys...
</span></span><span class=line><span class=cl>Adding host cephadmin...
</span></span><span class=line><span class=cl>Deploying mon service with default placement...
</span></span><span class=line><span class=cl>Deploying mgr service with default placement...
</span></span><span class=line><span class=cl>Deploying crash service with default placement...
</span></span><span class=line><span class=cl>Deploying prometheus service with default placement...
</span></span><span class=line><span class=cl>Deploying grafana service with default placement...
</span></span><span class=line><span class=cl>Deploying node-exporter service with default placement...
</span></span><span class=line><span class=cl>Deploying alertmanager service with default placement...
</span></span><span class=line><span class=cl>Enabling the dashboard module...
</span></span><span class=line><span class=cl>Waiting <span class=k>for</span> the mgr to restart...
</span></span><span class=line><span class=cl>Waiting <span class=k>for</span> mgr epoch 9...
</span></span><span class=line><span class=cl>mgr epoch <span class=m>9</span> is available
</span></span><span class=line><span class=cl>Generating a dashboard self-signed certificate...
</span></span><span class=line><span class=cl>Creating initial admin user...
</span></span><span class=line><span class=cl>Fetching dashboard port number...
</span></span><span class=line><span class=cl>Ceph Dashboard is now available at:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	     URL: https://cephadmin:8443/
</span></span><span class=line><span class=cl>	    User: admin
</span></span><span class=line><span class=cl>	Password: eqlf3jh1i1
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Enabling client.admin keyring and conf on hosts with <span class=s2>&#34;admin&#34;</span> label
</span></span><span class=line><span class=cl>Saving cluster configuration to /var/lib/ceph/4d128cbe-2fb8-11ee-8326-000c293e5d57/config directory
</span></span><span class=line><span class=cl>Enabling autotune <span class=k>for</span> osd_memory_target
</span></span><span class=line><span class=cl>You can access the Ceph CLI as following in <span class=k>case</span> of multi-cluster or non-default config:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	sudo /usr/local/bin/cephadm shell --fsid 4d128cbe-2fb8-11ee-8326-000c293e5d57 -c /etc/ceph/ceph.conf -k /etc/ceph/ceph.client.admin.keyring
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Or, <span class=k>if</span> you are only running a single cluster on this host:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	sudo /usr/local/bin/cephadm shell 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Please consider enabling telemetry to <span class=nb>help</span> improve Ceph:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	ceph telemetry on
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>For more information see:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	https://docs.ceph.com/docs/master/mgr/telemetry/
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Bootstrap complete.</span></span></code></pre></td></tr></table></div></div></div></div><p>成功后会看到 ceph dashboard 的界面，默认密码会输出到控制台，第一次登陆会要求修改默认密码</p><p>在安装将生成一个最小的 <code>ceph.conf</code> 仅适用于引导阶段的配置文件，通过进入 mon 容器查看</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ docker <span class=nb>exec</span> -it ceph-350494de-d23f-11ea-be85-525400d32681-mon.mon0 cat /etc/ceph/ceph.conf <span class=c1># </span></span></span></code></pre></td></tr></table></div></div></div></div><h2 id=向-ceph-集群导入-osd-node>向 ceph 集群导入 osd node<a hidden class=anchor aria-hidden=true href=#向-ceph-集群导入-osd-node>#</a></h2><p>向每个 node 导入 ssh key，下面的操作是通过进入管理容器执行的</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ssh-copy-id -f -i /etc/ceph/ceph.pub root@*&lt;new-host&gt;*</span></span></code></pre></td></tr></table></div></div></div></div><p>添加一个主机到 ceph 集群</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ceph orch host add *newhost*</span></span></code></pre></td></tr></table></div></div></div></div><p>部署一个新的 mon，你可以给新加入的主机打上标签</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># ceph orch host label add *&lt;hostname&gt;* mon</span>
</span></span><span class=line><span class=cl>ceph orch apply mon *&lt;number-of-monitors&gt;*</span></span></code></pre></td></tr></table></div></div></div></div><p>向集群部署新的组件</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ceph orch apply mon *&lt;number-of-monitors&gt;*
</span></span><span class=line><span class=cl>ceph orch apply mon *&lt;host1,host2,host3,...&gt;*</span></span></code></pre></td></tr></table></div></div></div></div><p>部署 osd damon 在新的主机之上</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ceph orch daemon add osd *&lt;host&gt;*:*&lt;device-path&gt;*
</span></span><span class=line><span class=cl>ceph orch daemon add osd host1:/dev/sdb</span></span></code></pre></td></tr></table></div></div></div></div><p>这是可以列出正在管理的服务器 <code>cephadm</code> 使用 <code>host ls</code> 命令：</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ceph orch host ls </span></span></code></pre></td></tr></table></div></div></div></div><p>到此，如果你只使用 RDB 块存储，这里已经部署完成了，如果需要选择使用 文件存储 CephFS，或者对象存储 RGW，可以在另外部署相应的组件，部署的组件是根据按需使用进行部署</p><p>osd device 命令也可以列出对应的设备</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ceph orch device ls </span></span></code></pre></td></tr></table></div></div></div></div><p>在 Ceph 中一切存储的基础都是基于 RADOS 集群</p><h2 id=troubleshooting>Troubleshooting<a hidden class=anchor aria-hidden=true href=#troubleshooting>#</a></h2><h3 id=typeerror-__init__-missing-2-required-positional-arguments-hostname-and-addr>TypeError: <strong>init</strong>() missing 2 required positional arguments: &lsquo;hostname&rsquo; and &lsquo;addr&rsquo;<a hidden class=anchor aria-hidden=true href=#typeerror-__init__-missing-2-required-positional-arguments-hostname-and-addr>#</a></h3><p>现象：实际上输入了 <em>hostname</em> 和 <em>addr</em> 也是出现这个问题</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ ceph orch host add ceph-octopus-01
</span></span><span class=line><span class=cl>Error EINVAL: Traceback <span class=o>(</span>most recent call last<span class=o>)</span>:
</span></span><span class=line><span class=cl>  File <span class=s2>&#34;/usr/share/ceph/mgr/mgr_module.py&#34;</span>, line 1756, in _handle_command
</span></span><span class=line><span class=cl>    <span class=k>return</span> self.handle_command<span class=o>(</span>inbuf, cmd<span class=o>)</span>
</span></span><span class=line><span class=cl>  File <span class=s2>&#34;/usr/share/ceph/mgr/orchestrator/_interface.py&#34;</span>, line 171, in handle_command
</span></span><span class=line><span class=cl>    <span class=k>return</span> dispatch<span class=o>[</span>cmd<span class=o>[</span><span class=s1>&#39;prefix&#39;</span><span class=o>]]</span>.call<span class=o>(</span>self, cmd, inbuf<span class=o>)</span>
</span></span><span class=line><span class=cl>  File <span class=s2>&#34;/usr/share/ceph/mgr/mgr_module.py&#34;</span>, line 462, in call
</span></span><span class=line><span class=cl>    <span class=k>return</span> self.func<span class=o>(</span>mgr, **kwargs<span class=o>)</span>
</span></span><span class=line><span class=cl>  File <span class=s2>&#34;/usr/share/ceph/mgr/orchestrator/_interface.py&#34;</span>, line 107, in &lt;lambda&gt;
</span></span><span class=line><span class=cl>    <span class=nv>wrapper_copy</span> <span class=o>=</span> lambda *l_args, **l_kwargs: wrapper<span class=o>(</span>*l_args, **l_kwargs<span class=o>)</span>  <span class=c1># noqa: E731</span>
</span></span><span class=line><span class=cl>  File <span class=s2>&#34;/usr/share/ceph/mgr/orchestrator/_interface.py&#34;</span>, line 96, in wrapper
</span></span><span class=line><span class=cl>    <span class=k>return</span> func<span class=o>(</span>*args, **kwargs<span class=o>)</span>
</span></span><span class=line><span class=cl>  File <span class=s2>&#34;/usr/share/ceph/mgr/orchestrator/module.py&#34;</span>, line 356, in _add_host
</span></span><span class=line><span class=cl>    <span class=k>return</span> self._apply_misc<span class=o>([</span>s<span class=o>]</span>, False, Format.plain<span class=o>)</span>
</span></span><span class=line><span class=cl>  File <span class=s2>&#34;/usr/share/ceph/mgr/orchestrator/module.py&#34;</span>, line 1092, in _apply_misc
</span></span><span class=line><span class=cl>    raise_if_exception<span class=o>(</span>completion<span class=o>)</span>
</span></span><span class=line><span class=cl>  File <span class=s2>&#34;/usr/share/ceph/mgr/orchestrator/_interface.py&#34;</span>, line 225, in raise_if_exception
</span></span><span class=line><span class=cl>    <span class=nv>e</span> <span class=o>=</span> pickle.loads<span class=o>(</span>c.serialized_exception<span class=o>)</span>
</span></span><span class=line><span class=cl>TypeError: __init__<span class=o>()</span> missing <span class=m>2</span> required positional arguments: <span class=s1>&#39;hostname&#39;</span> and <span class=s1>&#39;addr&#39;</span></span></span></code></pre></td></tr></table></div></div></div></div><p>首先先将公钥分发到对应的 CEPH NODE 之上</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>CEPH_HOSTNAME</span><span class=o>=</span>root@ceph-octopus-01
</span></span><span class=line><span class=cl><span class=c1># 获取公钥</span>
</span></span><span class=line><span class=cl>ceph cephadm get-pub-key &gt; /etc/ceph/ceph.pub
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 分发公钥到对应 ceph node</span>
</span></span><span class=line><span class=cl>ssh-copy-id -f -i /etc/ceph/ceph.pub <span class=si>${</span><span class=nv>CEPH_HOSTNAME</span><span class=si>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 尝试使用私钥是否可以连接到 ceph node</span>
</span></span><span class=line><span class=cl>ceph cephadm get-ssh-config &gt; ssh_config
</span></span><span class=line><span class=cl>ceph config-key get mgr/cephadm/ssh_identity_key &gt; ~/cephadm_private_key
</span></span><span class=line><span class=cl>chmod <span class=m>0600</span> ~/cephadm_private_key
</span></span><span class=line><span class=cl>ssh -F ssh_config -i ~/cephadm_private_key <span class=si>${</span><span class=nv>CEPH_HOSTNAME</span><span class=si>}</span></span></span></code></pre></td></tr></table></div></div></div></div><p>我解决的方式：实际上版本不对，更新版本就恢复了</p><h2 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h2><blockquote><p><sup id=1>[1]</sup> <a href=https://docs.ceph.com/en/octopus/cephadm/install/#install-cephadm target=_blank rel="noopener nofollow noreferrer"><em><strong>install-cephadm</strong></em></a></p><p><sup id=2>[2]</sup> <a href=https://ldapwiki.com/wiki/Common%20Object%20Request%20Broker%20Architecture target=_blank rel="noopener nofollow noreferrer"><em><strong>Object Request Broker Architecture</strong></em></a></p><p><sup id=3>[3]</sup> <a href=https://ldapwiki.com/wiki/Cooperation%20for%20Open%20Systems%20Interconnection%20Networking%20in%20Europe target=_blank rel="noopener nofollow noreferrer"><em><strong>Cooperation for Open Systems Interconnection Networking in Europe</strong></em></a></p></blockquote></div><div class=pe-copyright><hr><blockquote><p>本文为原创内容，版权归作者所有。如需转载，请在文章中声明本文标题及链接。</p><p>文章标题：使用cephadm纯离线安装Ceph集群</p><p>文章链接：<a href=https://www.oomkill.com/2023/07/02-1-install-ceph-with-cephadm/ target=_blank>https://www.oomkill.com/2023/07/02-1-install-ceph-with-cephadm/</a></p><p>许可协议：<a href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></p></blockquote></div><div class=comments-separator></div><h3 class=relatedContentTitle>相关阅读</h3><ul class=relatedContent><li><a href=/2019/06/07-1-cephx/><span>Ceph安全 - CephX</span></a></li><li><a href=/2019/06/01-1-ceph-acquaintance/><span>Ceph概念 - 初识Ceph</span></a></li><li><a href=/2019/06/08-1-ceph-crush/><span>Ceph算法 - crush</span></a></li><li><a href=/2019/06/01-2-cloud-base/><span>Cloud基础设施 - 初识Ceph</span></a></li><li><a href=/2019/11/02-2-install-ceph-with-ceph-deploy/><span>Ceph集群安装 - ceph-deploy</span></a></li></ul><div class=comments-separator></div><footer class=post-footer><ul class=post-tags><li><a href=https://www.oomkill.com/tags/storage/>Storage</a></li></ul><nav class=paginav><a class=prev href=https://www.oomkill.com/2023/08/picgo-configure/><span class=title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left" style="user-select:text"><line x1="19" y1="12" x2="5" y2="12" style="user-select:text"/><polyline points="12 19 5 12 12 5" style="user-select:text"/></polyline></svg>&nbsp;</span>
<span>picgo + github 给 typora做图床</span>
</a><a class=next href=https://www.oomkill.com/2023/07/blackbox_exporter-in-k8s/><span class=title></span>
<span>在 Kubernetes 集群中使用 blackbox exporter监控外部IP&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right" style="user-select:text"><line x1="5" y1="12" x2="19" y2="12" style="user-select:text"/><polyline points="12 5 19 12 12 19" style="user-select:text"/></svg></span></a></nav></footer><div class=pe-comments-decoration><p class=pe-comments-title></p><p class=pe-comments-subtitle></p></div><div id=pe-comments></div><script src=/js/pe-go-comment.min.86a214102576ba5f9b7bdc29eed8d58dd56e34aef80b3c65c73ea9cc88443696.js integrity="sha256-hqIUECV2ul+be9wp7tjVjdVuNK74Czxlxz6pzIhENpY="></script><script>const getStoredTheme=()=>localStorage.getItem("pref-theme")==="dark"?"dark":"light",setGiscusTheme=()=>{const e=e=>{const t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:e},"https://giscus.app")};e({setConfig:{theme:getStoredTheme()}})};document.addEventListener("DOMContentLoaded",()=>{const s={src:"https://giscus.app/client.js","data-repo":"cylonchau/cylonchau.github.io","data-repo-id":"R_kgDOIRlNSQ","data-category":"Announcements","data-category-id":"DIC_kwDOIRlNSc4CXy1U","data-mapping":"pathname","data-term":"posts/02-1 install ceph with cephadm","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"top","data-theme":getStoredTheme(),"data-lang":"zh-TW","data-loading":"lazy",crossorigin:"anonymous",async:""},e=document.createElement("script");Object.entries(s).forEach(([t,n])=>e.setAttribute(t,n)),document.querySelector("#pe-comments").appendChild(e);const t=document.querySelector("#theme-toggle");t&&t.addEventListener("click",setGiscusTheme);const n=document.querySelector("#theme-toggle-float");n&&n.addEventListener("click",setGiscusTheme)})</script></article></main><footer class=footer><span>&copy; 2024 <a href=https://www.oomkill.com/>Cylon's Collection</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> on
<a href=https://pages.github.com/ rel=noopener target=_blank>GitHub Pages</a> & Theme
        <a href=https://github.com/tofuwine/PaperMod-PE rel=noopener target=_blank>PaperMod-PE</a></span></footer><div class=pe-right-sidebar><a href=javascript:void(0); id=theme-toggle-float class=pe-float-btn><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</a><a href=#top class=pe-float-btn id=top-link><span id=pe-read-progress></span></a></div><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>