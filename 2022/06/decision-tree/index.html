<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>决策树 | Cylon's Collection</title><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NP3JNCPR" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><meta name=keywords content="MachineLearning,algorithm,CS"><meta name=description content='熵和基尼指数 信息增益 信息增益 information gain 是用于训练决策树的指标。具体来说，是指这些指标衡量拆分的质量。通俗来说是通过根据随机变量的给定值拆分数据集来衡量熵。
通过描述一个事件是否"惊讶"，通常低概率事件更令人惊讶，因此具有更大的信息量。而具有相同可能性的事件的概率分布更"惊讶"并且具有更大的熵。
定义：熵 entropy是一组例子中杂质、无序或不确定性的度量。熵控制决策树如何决定拆分数据。它实际上影响了决策树如何绘制边界。
熵 熵的计算公式为：$E=-\sum^i_{i=1}(p_i\times\log_2(p_i))$ ；$P_i$ 是类别 $i$ 的概率。我们来举一个例子来更好地理解熵及其计算。假设有一个由三种颜色组成的数据集，红色、紫色和黄色。如果我们的集合中有一个红色、三个紫色和四个黄色的观测值，我们的方程变为：$E=-(p_r \times \log_2(p_r) + p_p \times \log_2(p_p) + p_y \times \log_2(p_y)$
其中 $p_r$ 、$p_p$ 和 $p_y$ 分别是选择红色、紫色和黄色的概率。假设 $p_r=\frac{1}{8}$，$p_p=\frac{3}{8}$ ，$p_y=\frac{4}{8}$ 现在等式变为变为：
$E=-(\frac{1}{8} \times \log_2(\frac{1}{8}) + \frac{3}{8} \times \log_2(\frac{3}{8}) + \frac{4}{8} \times \log_2(\frac{4}{8}))$ $0.125 \times log_2(0.125) + 0.375 \times log_2(0.375) + 0.5 \times log_2(0.375)$ $0.125 \times -3 + 0.375 \times -1.415 + 0.5 \times -1 = -0.375+-0.425 +-0.5 = 1.'><meta name=author content="cylon"><link rel=canonical href=https://www.oomkill.com/2022/06/decision-tree/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://www.oomkill.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://www.oomkill.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://www.oomkill.com/favicon-32x32.png><link rel=apple-touch-icon href=https://www.oomkill.com/favicon.ico><link rel=mask-icon href=https://www.oomkill.com/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://www.oomkill.com/2022/06/decision-tree/><noscript><style>#theme-toggle,#top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link crossorigin=anonymous href=/assets/css/pe.min.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/pe.min.js></script><link rel=stylesheet href=https://cdn.staticfile.net/font-awesome/6.5.1/css/all.min.css><link rel=stylesheet href=https://cdn.staticfile.net/font-awesome/6.5.1/css/v4-shims.min.css><script defer src=https://cdn.staticfile.net/jquery/3.5.1/jquery.min.js></script><link rel=stylesheet href=https://cdn.staticfile.net/fancybox/3.5.7/jquery.fancybox.min.css><script defer src=https://cdn.staticfile.net/fancybox/3.5.7/jquery.fancybox.min.js></script><script id=MathJax-script async src=https://cdn.staticfile.net/mathjax/3.2.2/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["$$","$$"]],inlineMath:[["\\$","\\$"]]}}</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-H94HZ5S19Y"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-H94HZ5S19Y")</script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"><meta property="og:title" content="决策树"><meta property="og:description" content='熵和基尼指数 信息增益 信息增益 information gain 是用于训练决策树的指标。具体来说，是指这些指标衡量拆分的质量。通俗来说是通过根据随机变量的给定值拆分数据集来衡量熵。
通过描述一个事件是否"惊讶"，通常低概率事件更令人惊讶，因此具有更大的信息量。而具有相同可能性的事件的概率分布更"惊讶"并且具有更大的熵。
定义：熵 entropy是一组例子中杂质、无序或不确定性的度量。熵控制决策树如何决定拆分数据。它实际上影响了决策树如何绘制边界。
熵 熵的计算公式为：$E=-\sum^i_{i=1}(p_i\times\log_2(p_i))$ ；$P_i$ 是类别 $i$ 的概率。我们来举一个例子来更好地理解熵及其计算。假设有一个由三种颜色组成的数据集，红色、紫色和黄色。如果我们的集合中有一个红色、三个紫色和四个黄色的观测值，我们的方程变为：$E=-(p_r \times \log_2(p_r) + p_p \times \log_2(p_p) + p_y \times \log_2(p_y)$
其中 $p_r$ 、$p_p$ 和 $p_y$ 分别是选择红色、紫色和黄色的概率。假设 $p_r=\frac{1}{8}$，$p_p=\frac{3}{8}$ ，$p_y=\frac{4}{8}$ 现在等式变为变为：
$E=-(\frac{1}{8} \times \log_2(\frac{1}{8}) + \frac{3}{8} \times \log_2(\frac{3}{8}) + \frac{4}{8} \times \log_2(\frac{4}{8}))$ $0.125 \times log_2(0.125) + 0.375 \times log_2(0.375) + 0.5 \times log_2(0.375)$ $0.125 \times -3 + 0.375 \times -1.415 + 0.5 \times -1 = -0.375+-0.425 +-0.5 = 1.'><meta property="og:type" content="article"><meta property="og:url" content="https://www.oomkill.com/2022/06/decision-tree/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-06-01T00:00:00+00:00"><meta property="article:modified_time" content="2023-03-22T23:00:36+08:00"><meta property="og:site_name" content="Cylon's Collection"><meta name=twitter:card content="summary"><meta name=twitter:title content="决策树"><meta name=twitter:description content='熵和基尼指数 信息增益 信息增益 information gain 是用于训练决策树的指标。具体来说，是指这些指标衡量拆分的质量。通俗来说是通过根据随机变量的给定值拆分数据集来衡量熵。
通过描述一个事件是否"惊讶"，通常低概率事件更令人惊讶，因此具有更大的信息量。而具有相同可能性的事件的概率分布更"惊讶"并且具有更大的熵。
定义：熵 entropy是一组例子中杂质、无序或不确定性的度量。熵控制决策树如何决定拆分数据。它实际上影响了决策树如何绘制边界。
熵 熵的计算公式为：$E=-\sum^i_{i=1}(p_i\times\log_2(p_i))$ ；$P_i$ 是类别 $i$ 的概率。我们来举一个例子来更好地理解熵及其计算。假设有一个由三种颜色组成的数据集，红色、紫色和黄色。如果我们的集合中有一个红色、三个紫色和四个黄色的观测值，我们的方程变为：$E=-(p_r \times \log_2(p_r) + p_p \times \log_2(p_p) + p_y \times \log_2(p_y)$
其中 $p_r$ 、$p_p$ 和 $p_y$ 分别是选择红色、紫色和黄色的概率。假设 $p_r=\frac{1}{8}$，$p_p=\frac{3}{8}$ ，$p_y=\frac{4}{8}$ 现在等式变为变为：
$E=-(\frac{1}{8} \times \log_2(\frac{1}{8}) + \frac{3}{8} \times \log_2(\frac{3}{8}) + \frac{4}{8} \times \log_2(\frac{4}{8}))$ $0.125 \times log_2(0.125) + 0.375 \times log_2(0.375) + 0.5 \times log_2(0.375)$ $0.125 \times -3 + 0.375 \times -1.415 + 0.5 \times -1 = -0.375+-0.425 +-0.5 = 1.'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://www.oomkill.com/posts/"},{"@type":"ListItem","position":2,"name":"决策树","item":"https://www.oomkill.com/2022/06/decision-tree/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"决策树","name":"决策树","description":"熵和基尼指数 信息增益 信息增益 information gain 是用于训练决策树的指标。具体来说，是指这些指标衡量拆分的质量。通俗来说是通过根据随机变量的给定值拆分数据集来衡量熵。\n通过描述一个事件是否\u0026quot;惊讶\u0026quot;，通常低概率事件更令人惊讶，因此具有更大的信息量。而具有相同可能性的事件的概率分布更\u0026quot;惊讶\u0026quot;并且具有更大的熵。\n定义：熵 entropy是一组例子中杂质、无序或不确定性的度量。熵控制决策树如何决定拆分数据。它实际上影响了决策树如何绘制边界。\n熵 熵的计算公式为：$E=-\\sum^i_{i=1}(p_i\\times\\log_2(p_i))$ ；$P_i$ 是类别 $i$ 的概率。我们来举一个例子来更好地理解熵及其计算。假设有一个由三种颜色组成的数据集，红色、紫色和黄色。如果我们的集合中有一个红色、三个紫色和四个黄色的观测值，我们的方程变为：$E=-(p_r \\times \\log_2(p_r) + p_p \\times \\log_2(p_p) + p_y \\times \\log_2(p_y)$\n其中 $p_r$ 、$p_p$ 和 $p_y$ 分别是选择红色、紫色和黄色的概率。假设 $p_r=\\frac{1}{8}$，$p_p=\\frac{3}{8}$ ，$p_y=\\frac{4}{8}$ 现在等式变为变为：\n$E=-(\\frac{1}{8} \\times \\log_2(\\frac{1}{8}) + \\frac{3}{8} \\times \\log_2(\\frac{3}{8}) + \\frac{4}{8} \\times \\log_2(\\frac{4}{8}))$ $0.125 \\times log_2(0.125) + 0.375 \\times log_2(0.375) + 0.5 \\times log_2(0.375)$ $0.125 \\times -3 + 0.375 \\times -1.415 + 0.5 \\times -1 = -0.375+-0.425 +-0.5 = 1.","keywords":["MachineLearning","algorithm","CS"],"articleBody":"熵和基尼指数 信息增益 信息增益 information gain 是用于训练决策树的指标。具体来说，是指这些指标衡量拆分的质量。通俗来说是通过根据随机变量的给定值拆分数据集来衡量熵。\n通过描述一个事件是否\"惊讶\"，通常低概率事件更令人惊讶，因此具有更大的信息量。而具有相同可能性的事件的概率分布更\"惊讶\"并且具有更大的熵。\n定义：熵 entropy是一组例子中杂质、无序或不确定性的度量。熵控制决策树如何决定拆分数据。它实际上影响了决策树如何绘制边界。\n熵 熵的计算公式为：$E=-\\sum^i_{i=1}(p_i\\times\\log_2(p_i))$ ；$P_i$ 是类别 $i$ 的概率。我们来举一个例子来更好地理解熵及其计算。假设有一个由三种颜色组成的数据集，红色、紫色和黄色。如果我们的集合中有一个红色、三个紫色和四个黄色的观测值，我们的方程变为：$E=-(p_r \\times \\log_2(p_r) + p_p \\times \\log_2(p_p) + p_y \\times \\log_2(p_y)$\n其中 $p_r$ 、$p_p$ 和 $p_y$ 分别是选择红色、紫色和黄色的概率。假设 $p_r=\\frac{1}{8}$，$p_p=\\frac{3}{8}$ ，$p_y=\\frac{4}{8}$ 现在等式变为变为：\n$E=-(\\frac{1}{8} \\times \\log_2(\\frac{1}{8}) + \\frac{3}{8} \\times \\log_2(\\frac{3}{8}) + \\frac{4}{8} \\times \\log_2(\\frac{4}{8}))$ $0.125 \\times log_2(0.125) + 0.375 \\times log_2(0.375) + 0.5 \\times log_2(0.375)$ $0.125 \\times -3 + 0.375 \\times -1.415 + 0.5 \\times -1 = -0.375+-0.425 +-0.5 = 1.41$ ==当所有观测值都属于同一类时会发生什么？== 在这种情况下，熵将始终为零。$E=-(1log_21)=0$ ；这种情况下的数据集没有杂质，这就意味着没有数据集没有意义。又如果有两类数据集，一半是黄色，一半是紫色，那么熵为1，推导过程是：$E=−(\\ (0.5\\log_2(0.5))+(0.5\\times \\log_2(0.5))\\ ) = 1$\n基尼指数 基尼指数 Gini index 和熵 entropy 是计算信息增益的标准。决策树算法使用信息增益来拆分节点。\n基尼指数计算特定变量在随机选择时被错误分类的概率程度以及基尼系数的变化。它适用于分类变量，提供“成功”或“失败”的结果，因此仅进行二元拆分（二叉树结构）。基尼指数在 0 和 1 之间变化，其中，1 表示元素在各个类别中的随机分布。基尼指数为 0.5 表示元素在某些类别中分布均匀。：\n0 表示为所有元素都与某个类相关联，或只存在一个类。 1 表示所有元素随机分布在各个类中，并且0.5 表示元素均匀分布到某些类中 基尼指数公式：$1− \\sum_n^{i=1}(p_i)^2$ ； $P_i$ 为分类到特定类别的概率。在构建决策树时，更愿意选择具有最小基尼指数的属性作为根节点。\n通过实例了解公式\nPast Trend Open Interest Trading Volume Return Positive Low High Up Negative High Low Down Positive Low High Up Positive High High Up Negative Low High Down Positive Low Low Down Negative High High Down Negative Low High Down Positive Low Low Down Positive High High Up 计算基尼指数\n已知条件\n$P(Past\\ Trend=Positive) = \\frac{6}{10}$\n$P(Past\\ Trend=Negative) = \\frac{4}{10}$\n过去趋势基尼指数计算\n如果过去趋势为正面，回报为上涨，概率为：$P(Past\\ Trend=Positive\\ \u0026\\ Return=Up) = \\frac{4}{6}$\n如果过去趋势为正面，回报为下降，概率为：$P(Past\\ Trend=Positive\\ \u0026\\ Return=Down) = \\frac{2}{6}$\n那么这个基尼指数为：$gini(Past\\ Trend) = 1-(\\frac{4}{6}^2+\\frac{2}{6}^2) = 0.45$ 如果过去趋势为负面，回报为上涨，概率为：$P(Past\\ Trend=Negative\\ \u0026\\ Return=Up) = 0$\n如果过去趋势为负面，回报为下降，概率为：$P(Past\\ Trend=Negative\\ \u0026\\ Return=Down) = \\frac{4}{4}$\n那么这个基尼指数为：$gini(Past\\ Trend=Negative) = 1-(0^2+\\frac{4}{4}^2) = 1-(0+1)=0$ 那么过去交易量的的基尼指数加权 = $\\frac{6}{10} \\times 0.45 + \\frac{4}{10}\\times 0 = 0.27$\n未平仓量基尼指数计算\n已知条件\n$P(Open\\ Interest=High): \\frac{4}{10}$ $P(Open\\ Interest=Low): \\frac{6}{10}$ 如果未平仓量为 high 并且回报为上涨，概率为：$P(Open\\ Interest = High\\ \u0026\\ Return\\ = Up)=\\frac{2}{4}$\n如果未平仓量为 high 并且回报为下降，概率为：$P(Open\\ Interest = High\\ \u0026\\ Return\\ = Down)=\\frac{2}{4}$\n那么这个基尼指数为：$gini(Open\\ Interest=High) = 1-(\\frac{2}{4}^2+\\frac{2}{4}^2) = 0.5$ 如果未平仓量为 low 并且回报为上涨，概率为：$P(Open\\ Interest = High\\ \u0026\\ Return\\ = Up)=\\frac{2}{6}$\n如果未平仓量为 low 并且回报为下降，概率为：$P(Open\\ Interest = High\\ \u0026\\ Return\\ = Down)=\\frac{4}{6}$\n那么这个基尼指数为：$gini(Open\\ Interest=Low) = 1-(\\frac{2}{6}^2+\\frac{4}{6}^2) = 0.45$ 那么未平仓量基尼指数加权 = $\\frac{4}{10} \\times 0.5 + \\frac{6}{10}\\times 0.45 = 0.47$\n计算交易量基尼指数\n已知条件\n$P(Trading\\ Volume=High): \\frac{7}{10}$ $P(Trading\\ Volume=Low): \\frac{3}{10}$ 如果交易量为 high 并且回报为上涨，概率为：$P(Trading\\ Volume=High\\ \u0026\\ Return\\ = Up)=\\frac{4}{7}$\n如果交易量为 high 并且回报为下降，概率为：$P(Trading\\ Volume = High\\ \u0026\\ Return\\ = Down)=\\frac{3}{7}$\n那么这个基尼指数为：$gini(Trading\\ Volume=High) = 1-(\\frac{4}{7}^2+\\frac{3}{7}^2) = 0.49$ 如果交易量为 low 并且回报为上涨，概率为：$P(Trading\\ Volume = Low\\ \u0026\\ Return\\ = Up)=0$\n如果交易量为 low 并且回报为下降，概率为：$P(Trading\\ Volume = Low\\ \u0026\\ Return\\ = Down)=\\frac{3}{3}$\n那么这个基尼指数为：$gini(Trading\\ Volume=Low) = 1-(0^2+1^2) = 0$ 那么交易量基尼指数加权 = $\\frac{7}{10} \\times 0.49 + \\frac{3}{10}\\times 0 = 0.34$\n最终计算出的基尼指数列表如下，在表中可以观察到“Past Trend”的基尼指数最低，因此它将被选为决策树的根节点。\nAttributes Gini Index Past Trend 0.27 Open Interest 0.47 Trading Volume 0.34 这里将重复的过程来确定决策树的子节点或分支。将通过计算”Past Trend“的“Positive”分支的基尼指数如下：\nPast Trend Open Interest Trading Volume Return Positive Low High Up Positive Low High Up Positive High High Up Positive Low Low Down Positive Low Low Down Positive High High Up 针对过去正面趋势计算未平仓量的基尼指数\n已知条件\n$P(Open\\ Interest=High): \\frac{2}{6}$ $P(Open\\ Interest=Low): \\frac{4}{6}$ 如果未平仓量为 high 并且回报为上涨，概率为：$P(Open\\ Interest = High\\ \u0026\\ Return\\ = Up)=\\frac{2}{2}$\n如果未平仓量为 high 并且回报为下降，概率为：$P(Open\\ Interest = High\\ \u0026\\ Return\\ = Down)=0$\n那么这个基尼指数为：$gini(Open\\ Interest=High) = 1-(\\frac{2}{2}^2+0^2) = 0$ 如果未平仓量为 low 并且回报为上涨，概率为：$P(Open\\ Interest = Low\\ \u0026\\ Return\\ = Up)=\\frac{2}{4}$\n如果未平仓量为 low 并且回报为下降，概率为：$P(Open\\ Interest = Low\\ \u0026\\ Return\\ = Down)=\\frac{2}{4}$\n那么这个基尼指数为：$gini(Open\\ Interest=Low) = 1-(\\frac{2}{4}^2+\\frac{2}{4}^2) = 0.5$ 那么未平仓量基尼指数加权 = $\\frac{2}{6} \\times 0 + \\frac{4}{6}\\times 0.5 = 0.33$\n计算交易量基尼指数\n已知条件\n$P(Trading\\ Volume=High): \\frac{4}{6}$ $P(Trading\\ Volume=Low): \\frac{2}{6}$ 如果交易量为 high 并且回报为上涨，概率为：$P(Trading\\ Volume=High\\ \u0026\\ Return\\ = Up)=\\frac{4}{4}$\n如果交易量为 high 并且回报为下降，概率为：$P(Trading\\ Volume = High\\ \u0026\\ Return\\ = Down)=0$\n那么这个基尼指数为：$gini(Trading\\ Volume=High) = 1-(\\frac{4}{4}^2+0^2) = 0$ 如果交易量为 low 并且回报为上涨，概率为：$P(Trading\\ Volume = Low\\ \u0026\\ Return\\ = Up)=0$\n如果交易量为 low 并且回报为下降，概率为：$P(Trading\\ Volume = Low\\ \u0026\\ Return\\ = Down)=\\frac{2}{2}$\n那么这个基尼指数为：$gini(Trading\\ Volume=Low) = 1-(0^2+\\frac{2}{2}^2) = 0$ 那么交易量基尼指数加权 = $\\frac{4}{6} \\times 0 + \\frac{2}{6}\\times 0 = 0$\n最终计算出的基尼指数列表如下，这里将使用“Trading Volume”进一步拆分节点，因为它具有最小的基尼指数。\nAttributes/Features Gini Index Open Interest 0.33 Trading Volume 0 最终的模型就如图所示\n计算信息增益示例 我们可以根据属于一类数据的概率分布来考虑数据集的熵，例如，在二进制分类数据集的情况下为两个类。计算样本的熵如 $Entropy = -(P_0 \\times log(P_0) + P_1 \\times log(P_1)$ 。\n两类的样本拆分为 50/50 的数据集将具最大熵（最惊讶），而拆分为 10/90 的不平衡数据集将具有较小的熵。可以通过在 Python 中计算这个不平衡数据集的熵的例子来证明这一点。\npython 1 2 3 4 5 6 7 8 from math import log2 # 概率 class0 = 10/100 class1 = 90/100 # entropy formula entropy = -(class0 * log2(class0) + class1 * log2(class1)) # print the result print('entropy: %.3f bits' % entropy) 运行示例，可以看到用于二分类的数据集的熵小于 1 。也就是说，对来自数据集中的任意示例类进行编码所需的信息不到1。通过这种方式，熵可以用作数据集纯度的计算，例如类别分布的平衡程度。\n熵为 0 位表示数据集包含一个类；1或更大位的熵表示平衡数据集的最大熵（取决于类别的数量），介于两者之间的值表示这些极端之间的水平。\n计算信息增益示例 要求：定义一个函数来根据属于 0 类和 1 类的样本的比率来计算一组样本的熵。\n假设有一个20 个示例的数据集，13 个为0 类，7 个为1 类。我们可以计算该数据集的熵，它的熵小于 1 位。\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 from math import log2 # calculate the entropy for the split in the dataset def entropy(class0, class1): return -(class0 * log2(class0) + class1 * log2(class1)) # split of the main dataset class0 = 13 / 20 class1 = 7 / 20 # calculate entropy before the change s_entropy = entropy(class0, class1) print('Dataset Entropy: %.3f bits' % s_entropy) # Dataset Entropy: 0.934 bits 假设按照 value1 分割数据集，有一组 8 个样本的数据集，7 个为第 0 类，1 个用于第 1 类。然后我们可以计算这组样本的熵。\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 from math import log2 # calculate the entropy for the split in the dataset def entropy(class0, class1): return -(class0 * log2(class0) + class1 * log2(class1)) # split of the main dataset s1_class0 = 7 / 8 s1_class1 = 1 / 8 # calculate entropy before the change s_entropy = entropy(s1_class0, s1_class1) print('Dataset Entropy: %.3f bits' % s_entropy) # Dataset Entropy: 0.544 bits 假设现在按 value2 分割数据集；一组 12 个样本数据集，每组 6 个。我们希望这个组的熵为 1。\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 from math import log2 # calculate the entropy for the split in the dataset def entropy(class0, class1): return -(class0 * log2(class0) + class1 * log2(class1)) # split of the main dataset s1_class0 = 6 / 12 s1_class1 = 6 / 12 # calculate entropy before the change s_entropy = entropy(s1_class0, s1_class1) print('Dataset Entropy: %.3f bits' % s_entropy) # Dataset Entropy: 1.000 bits 最后，可以根据为变量的每个值创建的组和计算的熵来计算该变量的信息增益。例如：\n第一个变量从数据集中产生一组 8 个样本，第二组在数据集中有12 个样本。在这种情况下，信息增益计算：\n$Entropy(Dataset) – (\\frac{(Count(Group1)}{Count(Dataset)} \\times Entropy(Group1) + \\frac{Count(Group2)}{Count(Dataset)} \\times Entropy(Group2)))$ 这里是因为在每个子节点重复这个分裂过程直到空叶节点。这意味着每个节点的样本都属于同一类。但是，这种情况下会导致具有许多节点使非常深的树，这很容易导致过度拟合。因此，我们通常希望通过设置树的最大深度来修剪树。IG就是我们想确定给定训练特征向的量集中的哪个属性最有用，那么上面的公式推理就为：\n$IG(D_p) = I(D_p) − \\frac{N_{left}}{N_p}I(D_{left})−\\frac{N_{right}}{N_p}I(D_{right})$ $IG(D_P)$：数据集的信息增益 $I(D)$：叶子的熵或基尼指数 $\\frac{N}{N_P}$ ：页数据集占总数据集的比例 我们将使用它来决定决策树 节点中属性的顺序。该行为在python中表示为：\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 from math import log2 # calculate the entropy for the split in the dataset def entropy(class0, class1): return -(class0 * log2(class0) + class1 * log2(class1)) # split of the main dataset class0 = 13 / 20 class1 = 7 / 20 # calculate entropy before the change s_entropy = entropy(class0, class1) print('Dataset Entropy: %.3f bits' % s_entropy) # split 1 (split via value1) s1_class0 = 7 / 8 s1_class1 = 1 / 8 # calculate the entropy of the first group s1_entropy = entropy(s1_class0, s1_class1) print('Group1 Entropy: %.3f bits' % s1_entropy) # split 2 (split via value2) s2_class0 = 6 / 12 s2_class1 = 6 / 12 # calculate the entropy of the second group s2_entropy = entropy(s2_class0, s2_class1) print('Group2 Entropy: %.3f bits' % s2_entropy) # calculate the information gain gain = s_entropy - (8/20 * s1_entropy + 12/20 * s2_entropy) print('Information Gain: %.3f bits' % gain) # Dataset Entropy: 0.934 bits # Group1 Entropy: 0.544 bits # Group2 Entropy: 1.000 bits # Information Gain: 0.117 bits 通过实例，就可以很清楚的明白了，信息增益的概念：信息熵-条件熵，换句话来说就是==信息增益代表了在一个条件下，信息复杂度（不确定性）减少的程度==。\npython计算决策树实例 基于基尼指数的决策树 钞票数据集涉及根据从照片中采取的一系列措施来预测给定钞票是否是真实的。数据是取自真钞和伪钞样样本的图像中提取的。对于数字化，使用了通常用于印刷检查的工业相机，从图像中提取特征。\n该数据集包含 1372 行和 5 个数值变量。这是一个二元分类的问题。\n基尼指数 假设有两组数据，每组有 2 行。第一组的行都属于 0 类，第二组的行都属于 1 类，所以这是一个完美的拆分。\n首先需要计算每个组中类的比例。\npython 1 proportion = count(class_value) / count(rows) 这个比例是\npython 1 2 3 4 group_1_class_0 = 2 / 2 = 1 group_1_class_1 = 0 / 2 = 0 group_2_class_0 = 0 / 2 = 0 group_2_class_1 = 2 / 2 = 1 为每个子节点计算 Gini index\npython 1 2 gini_index = sum(proportion * (1.0 - proportion)) gini_index = 1.0 - sum(proportion * proportion) 然后对每组的基尼指数按组的大小加权，例如当前正在分组的所有样本。我们可以将此权重添加到组的基尼指数计算中，如下所示：\npython 1 gini_index = (1.0 - sum(proportion * proportion)) * (group_size/total_samples) 在该案例中，每个组的基尼指数为：\npython 1 2 3 4 5 6 Gini(group_1) = (1 - (1*1 + 0*0)) * 2/4 Gini(group_1) = 0.0 * 0.5 Gini(group_1) = 0.0 # 分类1的基尼指数 Gini(group_2) = (1 - (0*0 + 1*1)) * 2/4 Gini(group_2) = 0.0 * 0.5 Gini(group_2) = 0.0 # 分类2的基尼指数 然后在分割点的每个子节点上添加分数，以给出分割点的最终 Gini 分数，该分数可以与其他候选分割点进行比较。如该分割点的基尼系数为 $0.0 + 0.0$ 或完美的基尼系数 0.0。\n编写一个 gini_index() 的函数，用于计算组列表和已知类值列表的基尼指数。\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def gini_index(groups, classes): print(\"------------\") # 计算所有样本的分割点，计算样本的总长度 n_instances = float(sum([len(group) for group in groups])) # 计算每个组的总基尼指数 gini = 0.0 for group in groups: size = float(len(group)) if size == 0: # avoid divide by zero continue score = 0.0 # score the group based on the score for each class for class_val in classes: # row[-1] 代表每个样本的最后一个值，是否存在分类 class_val p = [row[-1] for row in group] p1 = p.count(class_val) / size score += p1 * p1 # 按照对应的样本分割点，加权重 gini += (1.0 - score) * (size / n_instances) return gini print(gini_index([[[1, 1], [1, 0]], [[1, 1], [1, 0]]], [0, 1])) print(gini_index([[[1, 0], [1, 0]], [[1, 1], [1, 1]]], [0, 1])) 运行该示例会打印两组的Gini index，最差情况的为 0.5，最少情况的指数为 0.0。\n拆分 数据拆分 拆分是由数据集中的一个属性和一个值组成。可以将其总结为要拆分的属性的索引和拆分该属性上的行的值。这只是索引数据行的有用简写。\n创建拆分涉及三个部分，我们已经看过的第一个部分是计算基尼分数。剩下的两部分是：\n拆分数据集。 评估所有拆分。 拆分数据是给定数据集索引和拆分值，将数据集拆分为两个行列表形成一个分类。具体是拆分数据集涉及遍历每一行，检查属性值是否低于或高于拆分值，并将其分别分配给左组或右组。当存在两个组时，可以按照基尼指数进行评估\n编写一个**test_split()**函数，它实现了拆分。\npython 1 2 3 4 5 6 7 8 def test_split(index, value, dataset): left, right = list(), list() for row in dataset: if row[index] \u003c value: left.append(row) else: right.append(row) return left, right 评估拆分的数据 给定一个数据集，必须检查每个属性上的每个值作为候选拆分，评估拆分的成本并找到我们可以进行的最佳拆分。一旦找到最佳值，就可以将其用作决策树中的节点。\n这里使用 dict 作为决策树中的节点，因为这样可以按名称存储数据。选择最佳基尼指数并将其用作树的新节点。\n每组数据都是其小数据集，其中仅包含通过拆分过程分配给左组或右组的那些行。可以想象我们如何在构建决策树时递归地再次拆分每个组。\npython 1 2 3 4 5 6 7 8 9 10 def get_split(dataset): class_values = list(set(row[-1] for row in dataset)) b_index, b_value, b_score, b_groups = 999, 999, 999, None for index in range(len(dataset[0])-1): for row in dataset: groups = test_split(index, row[index], dataset) gini = gini_index(groups, class_values) if gini \u003c b_score: b_index, b_value, b_score, b_groups = index, row[index], gini, groups return {'index':b_index, 'value':b_value, 'groups':b_groups} 之后准备一些测试数据集进行测试，其中 $Y$ 是测试集的分类\ntext 1 2 3 4 5 6 7 8 9 10 11 X1\tX2\tY 2.771244718\t1.784783929\t0 1.728571309\t1.169761413\t0 3.678319846\t2.81281357\t0 3.961043357\t2.61995032\t0 2.999208922\t2.209014212\t0 7.497545867\t3.162953546\t1 9.00220326\t3.339047188\t1 7.444542326\t0.476683375\t1 10.12493903\t3.234550982\t1 6.642287351\t3.319983761\t1 将上述代码整合为一起，运行该代码后会打印所有基尼指数，基尼指数为 0.0 或完美分割。\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 # Split a dataset based on an attribute and an attribute value def test_split(index, value, dataset): left, right = list(), list() for row in dataset: if row[index] \u003c value: left.append(row) else: right.append(row) return left, right # Calculate the Gini index for a split dataset def gini_index(groups, classes): # 计算两组数据集的总数每个种类的列表数量和 n_instances = float(sum([len(group) for group in groups])) # 计算每组的基尼值 gini = 0.0 for group in groups: size = float(len(group)) # avoid divide by zero if size == 0: continue score = 0.0 # score the group based on the score for each class for class_val in classes: # 拿出数据集中每行的类型，拆开是为了更好的了解结构 p = [row[-1] for row in group] # print(\"%f / %f = %f\" % (p.count(class_val), size, p.count(class_val) / size )) # 这里计算的是当前的分类在总数据集中占比 p1 = p.count(class_val) / size score += p1 * p1 # gini index formula = 1 - sum(p_i^2) # 计算总的基尼指数，权重：当前分组占总数据集中的数量 gini += (1.0 - score) * (size / n_instances) return gini # Select the best split point for a dataset def get_split(dataset): class_values = list(set(row[-1] for row in dataset)) b_index, b_value, b_score, b_groups = 999, 999, 999, None for index in range(len(dataset[0])-1): # 最后分类不计算 for row in dataset: # 根据每个值分类计算出最优基尼值，这个值就作为决策树的节点 groups = test_split(index, row[index], dataset) gini = gini_index(groups, class_values) print('X%d \u003c %.3f Gini=%.3f' % ((index+1), row[index], gini)) if gini \u003c b_score: b_index, b_value, b_score, b_groups = index, row[index], gini, groups return {'index':b_index, 'value':b_value, 'groups':b_groups} dataset = [ [2.771244718,1.784783929,0], [1.728571309,1.169761413,0], [3.678319846,2.81281357,0], [3.961043357,2.61995032,0], [2.999208922,2.209014212,0], [7.497545867,3.162953546,1], [9.00220326,3.339047188,1], [7.444542326,0.476683375,1], [10.12493903,3.234550982,1], [6.642287351,3.319983761,1] ] split = get_split(dataset) print('Split: [X%d \u003c %.3f]' % ((split['index']+1), split['value'])) 通过执行结果可以看出，X1 \u003c 6.642 Gini=0.000 基尼指数为 0.0 为完美分割。\n如何构建树 构建树主要分为 3 个部分\n终端节点 Terminal Nodes 零度节点称为终端节点或叶节点 递归拆分 建造一棵树 终端节点 需要决定何时停止种植树，这里可以使用节点在训练数据集中负责的深度和行数来做到。\n树的最大深度：从树的根节点开始的最大节点数。一旦达到树的最大深度，停止拆分新节点。 最小节点：对一个节点的要训练的最小值。一旦达到或低于此最小值，则停止拆分和添加新节点。 这两种方法将是构建树的过程时用户的指定参数。当在给定点停止增长时，该节点称为终端节点，用于进行最终预测。\n编写一个函数to_terminal()，这个函数将为一组行选择一类。它返回行列表中最常见的输出值。\npython 1 2 3 def to_terminal(group): outcomes = [row[-1] for row in group] return max(set(outcomes), key=outcomes.count) 递归拆分 构建决策树会在为每个节点创建的组上一遍又一遍地调用 get_split() 函数。\n添加到现有节点的新节点称为子节点。一个节点可能有零个子节点（一个终端节点）、一个子节点或两个子节点，这里将在给定节点的字典表示中将子节点称为左和右。当一旦创建出一个节点，则通过再次调用相同的函数来递归地从拆分的每组数据以创建子节点。\n下面需要实现这个过程（递归函数）。函数接受一个节点作为参数，以及节点中的最大深度、最小模式数、节点的当前深度。\n调用的过程分步为。设置，传入根节点和深度1：\n首先，将拆分后的两组数据提取出来使用，当处理过这些组时，节点不再需要访问这些数据。 接下来，我们检查左或右两组是否为空，如果是，则使用我们拥有的记录创建一个终端节点。 不为空的情况下，检查是否达到了最大深度，如果是，则创建一个终端节点。 然后我们处理左子节点，如果行组太小，则创建一个终端节点，否则以深度优先的方式创建并添加左节点，直到在该分支上到达树的底部。最后再以相同的方式处理右侧。 python 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 创建子拆分或者终端节点 def split(node, max_depth, min_size, depth): \"\"\" :param node: {},分割好的的{'index':b_index, 'value':b_value, 'groups':b_groups} :param max_depth: int, 最大深度 :param min_size:int，最小模式数 :param depth:int， 当前深度 :return: None \"\"\" left, right = node['groups'] del(node['groups']) # 检查两边的分割问题 if not left or not right: node['left'] = node['right'] = to_terminal(left + right) return # 检查最大的深度 if depth \u003e= max_depth: node['left'], node['right'] = to_terminal(left), to_terminal(right) return # 处理左分支，数量要小于最小模式数为terminal node if len(left) \u003c= min_size: node['left'] = to_terminal(left) else: node['left'] = get_split(left) split(node['left'], max_depth, min_size, depth+1) # 否则递归 # 处理左右支，数量要小于最小模式数为terminal node if len(right) \u003c= min_size: node['right'] = to_terminal(right) else: node['right'] = get_split(right) split(node['right'], max_depth, min_size, depth+1) 创建树 构建一个树就是一个上面的步骤的合并，通过**split()**函数打分并确定树的根节点，然后通过递归来构建出整个树；下面代码是实现此过程的函数 build_tree()。\npython 1 2 3 4 5 6 7 8 9 10 11 # Build a decision tree def build_tree(train, max_depth, min_size): \"\"\" :param train: list, 数据集，可以是训练集 :param max_depth: int, 最大深度 :param min_size:int，最小模式数 :return: None \"\"\" root = get_split(train) # 对整个数据集进行打分 split(root, max_depth, min_size, 1) return root 整合 将全部代码整合为一个\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 # Split a dataset based on an attribute and an attribute value def test_split(index, value, dataset): left, right = list(), list() for row in dataset: if row[index] \u003c value: left.append(row) else: right.append(row) return left, right # Calculate the Gini index for a split dataset def gini_index(groups, classes): # 计算两组数据集的总数每个种类的列表数量和 n_instances = float(sum([len(group) for group in groups])) # 计算每组的基尼值 gini = 0.0 for group in groups: size = float(len(group)) # avoid divide by zero if size == 0: continue score = 0.0 # score the group based on the score for each class for class_val in classes: # 拿出数据集中每行的类型，拆开是为了更好的了解结构 p = [row[-1] for row in group] # print(\"%f / %f = %f\" % (p.count(class_val), size, p.count(class_val) / size )) # 这里计算的是当前的分类在总数据集中占比 p1 = p.count(class_val) / size score += p1 * p1 # gini index formula = 1 - sum(p_i^2) # 计算总的基尼指数，权重：当前分组占总数据集中的数量 gini += (1.0 - score) * (size / n_instances) return gini # Select the best split point for a dataset def get_split(dataset): class_values = list(set(row[-1] for row in dataset)) b_index, b_value, b_score, b_groups = 999, 999, 999, None for index in range(len(dataset[0])-1): # 最后分类不计算 for row in dataset: # 根据每个值分类计算出最优基尼值，这个值就作为决策树的节点 groups = test_split(index, row[index], dataset) gini = gini_index(groups, class_values) # print('X%d \u003c %.3f Gini=%.3f' % ((index+1), row[index], gini)) if gini \u003c b_score: # 拿到最小的gini index那列 b_index, b_value, b_score, b_groups = index, row[index], gini, groups return {'index':b_index, 'value':b_value, 'groups':b_groups} # 创建子拆分或者终端节点 def split(node, max_depth, min_size, depth): \"\"\" :param node: {},分割好的的{'index':b_index, 'value':b_value, 'groups':b_groups} :param max_depth: int, 最大深度 :param min_size:int，最小模式数 :param depth:int， 当前深度 :return: None \"\"\" left, right = node['groups'] del(node['groups']) # 检查两边的分割问题 if not left or not right: node['left'] = node['right'] = to_terminal(left + right) return # 检查最大的深度 if depth \u003e= max_depth: node['left'], node['right'] = to_terminal(left), to_terminal(right) return # 处理左分支，数量要小于最小模式数为terminal node if len(left) \u003c= min_size: node['left'] = to_terminal(left) else: node['left'] = get_split(left) split(node['left'], max_depth, min_size, depth+1) # 否则递归 # 处理左右支，数量要小于最小模式数为terminal node if len(right) \u003c= min_size: node['right'] = to_terminal(right) else: node['right'] = get_split(right) split(node['right'], max_depth, min_size, depth+1) # Build a decision tree def build_tree(train, max_depth, min_size): \"\"\" :param train: list, 数据集，可以是训练集 :param max_depth: int, 最大深度 :param min_size:int，最小模式数 :return: None \"\"\" root = get_split(train) # 对整个数据集进行打分 split(root, max_depth, min_size, 1) return root # 打印树 def print_tree(node, depth=0): if isinstance(node, dict): print('%s[X%d \u003c %.3f]' % ( (depth*' ', (node['index']+1), node['value']) )) print_tree(node['left'], depth+1) # 递归打印左右 print_tree(node['right'], depth+1) else: print('%s[%s]' % ((depth*' ', node))) # 不是对象就是terminal node # 创建一个terminal node def to_terminal(group): outcomes = [row[-1] for row in group] return max(set(outcomes), key=outcomes.count) dataset = [ [2.771244718,1.784783929,0], [1.728571309,1.169761413,0], [3.678319846,2.81281357,0], [3.961043357,2.61995032,0], [2.999208922,2.209014212,0], [7.497545867,3.162953546,1], [9.00220326,3.339047188,1], [7.444542326,0.476683375,1], [10.12493903,3.234550982,1], [6.642287351,3.319983761,1] ] if __name__=='__main__': tree = build_tree(dataset, 4, 2) print_tree(tree) 可以看到打印结果是一个类似二叉树的\ntext 1 2 3 4 5 6 7 8 9 10 11 12 13 [X1 \u003c 6.642] [X1 \u003c 2.771] [0] [X1 \u003c 2.771] [0] [0] [X1 \u003c 7.498] [X1 \u003c 7.445] [1] [1] [X1 \u003c 7.498] [1] [1] 预测 预测是预测数据是该向右还是向左，是作为对数据进行导航的方式。这里可以使用递归来实现，其中使用左侧或右侧子节点再次调用相同的预测，具体取决于拆分如何影响提供的数据。\n我们必须检查子节点是否是要作为预测返回的终端值，或者它是否是包含要考虑的树的另一个级别的字典节点。\n下面是实现此过程的函数 predict()。\npython 1 2 3 4 5 6 7 8 9 10 11 12 # Make a prediction with a decision tree def predict(node, row): if row[node['index']] \u003c node['value']: if isinstance(node['left'], dict): return predict(node['left'], row) else: return node['left'] else: if isinstance(node['right'], dict): return predict(node['right'], row) else: return node['right'] 下面是一个使用硬编码决策树的示例，该决策树具有一个最好地分割数据的节点（决策树桩，这个就是gini index的最优质值）。通过对上面的测试数据集例来对每一行进行预测。\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def predict(node, row): # 如果gini index与对应属性的值小于则向左， if row[node['index']] \u003c node['value']: if isinstance(node['left'], dict): return predict(node['left'], row) # 递归处理完整个树 else: return node['left'] else: # 否则的话，则为右 if isinstance(node['right'], dict): return predict(node['right'], row) else: return node['right'] dataset = [[2.771244718,1.784783929,0], [1.728571309,1.169761413,0], [3.678319846,2.81281357,0], [3.961043357,2.61995032,0], [2.999208922,2.209014212,0], [7.497545867,3.162953546,1], [9.00220326,3.339047188,1], [7.444542326,0.476683375,1], [10.12493903,3.234550982,1], [6.642287351,3.319983761,1]] # 这是之前用于计算出最优的gini index stump = {'index': 0, 'right': 1, 'value': 6.642287351, 'left': 0} for row in dataset: prediction = predict(stump, row) print('Expected=%d, Got=%d' % (row[-1], prediction)) 通过观察可以看出预测结果和实际结果一样\npython 1 2 3 4 5 6 7 8 9 10 Expected=0, Got=0 Expected=0, Got=0 Expected=0, Got=0 Expected=0, Got=0 Expected=0, Got=0 Expected=1, Got=1 Expected=1, Got=1 Expected=1, Got=1 Expected=1, Got=1 Expected=1, Got=1 套用真实数据集来测试 这里将使用 CART 算法对银行钞票数据集进行预测。大概的流程为：\n加载数据集并转换格式。 编写拆分算法与准确度计算算法；这里使用 5折的k折交叉验证（k-fold cross validation）用于评估算法 编写 CART 算法，从训练数据集，创建树，对测试数据集进行预测操作 什么是 K折交叉验证 K折较差验证（K-Fold CV）是将给定的数据集分成K个部分，其中每个折叠在某时用作测试集。以 5 折（K=5）为例。这种情况下，数据集被分成5份。在第一次迭代中，第一份用于测试模型，其余用于训练模型。在第二次迭代中，第 2 份用作测试集，其余用作训练集。重复这个过程，直到 5 个折叠中的每个折叠都被用作测试集。\n下面来开始编写函数，函数的整个过程为\nevaluate_algorithm() 作为最外层调用 使用五折交叉进行评估 cross_validation_split() 使用决策树算法作为算法根据 decision_tree() 构建树：build_tree() 拿到最优基尼指数作为叶子 get_split() python 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 from random import seed from random import randrange from csv import reader # 加载csv文件 def load_csv(filename): file = open(filename, \"rt\") lines = reader(file) dataset = list(lines) return dataset # 将所有字段转换为float类型便于计算 def str_column_to_float(dataset, column): for row in dataset: row[column] = float(row[column].strip()) # k-folds CV函数 def cross_validation_split(dataset, n_folds): dataset_split = list() dataset_copy = list(dataset) # 平均分位折数n_folds fold_size = int(len(dataset) / n_folds) for i in range(n_folds): fold = list() while len(fold) \u003c fold_size: index = randrange(len(dataset_copy)) # 随机 fold.append(dataset_copy.pop(index)) dataset_split.append(fold) return dataset_split # 计算精确度 def accuracy_metric(actual, predicted): correct = 0 for i in range(len(actual)): if actual[i] == predicted[i]: correct += 1 return correct / float(len(actual)) * 100.0 # Evaluate an algorithm using a cross validation split def evaluate_algorithm(dataset, algorithm, n_folds, *args): folds = cross_validation_split(dataset, n_folds) scores = list() for fold in folds: train_set = list(folds) train_set.remove(fold) train_set = sum(train_set, []) test_set = list() for row in fold: row_copy = list(row) test_set.append(row_copy) row_copy[-1] = None predicted = algorithm(train_set, test_set, *args) actual = [row[-1] for row in fold] accuracy = accuracy_metric(actual, predicted) scores.append(accuracy) return scores # 根据基尼指数划分value是应该在树的哪边？ def test_split(index, value, dataset): left, right = list(), list() for row in dataset: if row[index] \u003c value: left.append(row) else: right.append(row) return left, right # 基尼指数打分 def gini_index(groups, classes): # 计算数据集中的多组数据的总个数 n_instances = float(sum([len(group) for group in groups])) # 计算每组中的最优基尼指数 gini = 0.0 for group in groups: size = float(len(group)) if size == 0: continue score = 0.0 # 总基尼指数 for class_val in classes: # 拿出数据集中每行的类型，拆开是为了更好的了解结构 # 计算的是当前的分类在总数据集中占比 p = [row[-1] for row in group] p1 = p.count(class_val) / size score += p1 * p1 # 计算总的基尼指数，并根据相应大小增加权重。权重：当前分组占总数据集中的数量 gini += (1.0 - score) * (size / n_instances) return gini # 从数据集中获得基尼指数最佳的值 def get_split(dataset): class_values = list(set(row[-1] for row in dataset)) b_index, b_value, b_score, b_groups = 999, 999, 999, None for index in range(len(dataset[0])-1): for row in dataset: groups = test_split(index, row[index], dataset) gini = gini_index(groups, class_values) if gini \u003c b_score: b_index, b_value, b_score, b_groups = index, row[index], gini, groups return {'index':b_index, 'value':b_value, 'groups':b_groups} # 创建终端节点 def to_terminal(group): outcomes = [row[-1] for row in group] return max(set(outcomes), key=outcomes.count) # 创建子节点，为终端节点或子节点 def split(node, max_depth, min_size, depth): \"\"\" :param node: {},分割好的的{'index':b_index, 'value':b_value, 'groups':b_groups} :param max_depth: int, 最大深度 :param min_size:int，最小模式数 :param depth:int， 当前深度 :return: None \"\"\" left, right = node['groups'] del(node['groups']) # check for a no split if not left or not right: node['left'] = node['right'] = to_terminal(left + right) return # check for max depth if depth \u003e= max_depth: node['left'], node['right'] = to_terminal(left), to_terminal(right) return # process left child if len(left) \u003c= min_size: node['left'] = to_terminal(left) else: node['left'] = get_split(left) split(node['left'], max_depth, min_size, depth+1) # process right child if len(right) \u003c= min_size: node['right'] = to_terminal(right) else: node['right'] = get_split(right) split(node['right'], max_depth, min_size, depth+1) # 构建树 def build_tree(train, max_depth, min_size): \"\"\" :param train: list, 数据集，可以是训练集 :param max_depth: int, 最大深度 :param min_size:int，最小模式数 :ret \"\"\" root = get_split(train) split(root, max_depth, min_size, 1) return root # 打印树 def print_tree(node, depth=0): if isinstance(node, dict): print('%s[X%d \u003c %.3f]' % ( (depth*' ', (node['index']+1), node['value']) )) print_tree(node['left'], depth+1) # 递归打印左右 print_tree(node['right'], depth+1) else: print('%s[%s]' % ((depth*' ', node))) # 不是对象就是terminal node # 预测，预测方式为当前基尼指数与最优基尼指数相比较，然后放入树两侧 def predict(node, row): \"\"\" :param node: {} 叶子值 :param row: {}, 需要预测值 :ret \"\"\" if row[node['index']] \u003c node['value']: if isinstance(node['left'], dict): return predict(node['left'], row) else: return node['left'] else: if isinstance(node['right'], dict): return predict(node['right'], row) else: return node['right'] def decision_tree(train, test, max_depth, min_size): tree = build_tree(train, max_depth, min_size) predictions = list() for row in test: prediction = predict(tree, row) predictions.append(prediction) return(predictions) # Test CART on Bank Note dataset seed(1) # 加载数据 filename = 'data_banknote_authentication.csv' dataset = load_csv(filename) # 转换格式 for i in range(len(dataset[0])): str_column_to_float(dataset, i) # 评估算法 n_folds = 5 max_depth = 5 min_size = 10 scores = evaluate_algorithm(dataset, decision_tree, n_folds, max_depth, min_size) print('Scores: %s' % scores) print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores)))) Reference Informatioin Gain\nimplement decision tree algorithm\ninplement information gain\n","wordCount":"3725","inLanguage":"zh","datePublished":"2022-06-01T00:00:00Z","dateModified":"2023-03-22T23:00:36+08:00","author":{"@type":"Person","name":"cylon"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.oomkill.com/2022/06/decision-tree/"},"publisher":{"@type":"Organization","name":"Cylon's Collection","logo":{"@type":"ImageObject","url":"https://www.oomkill.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://www.oomkill.com/><img src=https://www.oomkill.com/favicon.ico alt aria-label=logo height=20>Cylon's Collection</a><div class=logo-switches><button id=theme-toggle><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://www.oomkill.com/archives><span>归档</span></a></li><li><a href=https://www.oomkill.com/tags><span>标签</span></a></li><li><a href=https://www.oomkill.com/search><span>搜索</span></a></li><li><a href=https://www.oomkill.com/about accesskey=/><span>关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">决策树</h1><div class=post-meta><span class=pe-post-meta-item><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select:text"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select:text"/><line x1="16" y1="2" x2="16" y2="6" style="user-select:text"/><line x1="8" y1="2" x2="8" y2="6" style="user-select:text"/><line x1="3" y1="10" x2="21" y2="10" style="user-select:text"/></svg><span>2022-06-01</span></span>&nbsp;·&nbsp;<span class=pe-post-meta-item><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text" style="user-select:text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z" style="user-select:text"/><polyline points="14 2 14 8 20 8" style="user-select:text"/><line x1="16" y1="13" x2="8" y2="13" style="user-select:text"/><line x1="16" y1="17" x2="8" y2="17" style="user-select:text"/><polyline points="10 9 9 9 8 9" style="user-select:text"/></svg><span>3725 字</span></span>&nbsp;·&nbsp;<span class=pe-post-meta-item><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><span>18 分钟</span></span>
<span class=pe-post-meta-item>&nbsp;·&nbsp;<svg t="1714036239378" fill="currentcolor" class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" p-id="6659" width="256" height="256"><path d="M690 78.2c-18.6-18.8-49-19-67.8-.4s-19 49-.4 67.8l255.4 258.6c67.8 68.6 67.8 178.8.0 247.4L653.4 878.2c-18.6 18.8-18.4 49.2.4 67.8s49.2 18.4 67.8-.4l224-226.4c104.8-106 104.8-276.4.0-382.4L690 78.2zM485.4 101.4c-24-24-56.6-37.4-90.6-37.4H96C43 64 0 107 0 160v299c0 34 13.4 66.6 37.4 90.6l336 336c50 50 131 50 181 0l267-267c50-50 50-131 0-181l-336-336zM96 160h299c8.4.0 16.6 3.4 22.6 9.4l336 336c12.4 12.4 12.4 32.8.0 45.2l-267 267c-12.4 12.4-32.8 12.4-45.2.0l-336-336c-6-6-9.4-14.2-9.4-22.6V160zm192 128a64 64 0 10-128 0 64 64 0 10128 0z" p-id="6660"/></svg></span><ul class=pe-post-meta-item><a href=https://www.oomkill.com/tags/machinelearning/>#MachineLearning</a>
<a href=https://www.oomkill.com/tags/algorithm/>#Algorithm</a>
<a href=https://www.oomkill.com/tags/cs/>#CS</a></ul></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details><summary><span class=details>目录</span></summary><div class=inner><ul><li><a href=#%e7%86%b5%e5%92%8c%e5%9f%ba%e5%b0%bc%e6%8c%87%e6%95%b0 aria-label=熵和基尼指数>熵和基尼指数</a><ul><li><a href=#%e4%bf%a1%e6%81%af%e5%a2%9e%e7%9b%8a aria-label=信息增益>信息增益</a><li><a href=#%e7%86%b5 aria-label=熵>熵</a><li><a href=#%e5%9f%ba%e5%b0%bc%e6%8c%87%e6%95%b0 aria-label=基尼指数>基尼指数</a><ul><li><a href=#%e8%ae%a1%e7%ae%97%e4%bf%a1%e6%81%af%e5%a2%9e%e7%9b%8a%e7%a4%ba%e4%be%8b aria-label=计算信息增益示例>计算信息增益示例</a></ul><li><a href=#%e8%ae%a1%e7%ae%97%e4%bf%a1%e6%81%af%e5%a2%9e%e7%9b%8a%e7%a4%ba%e4%be%8b-1 aria-label=计算信息增益示例>计算信息增益示例</a></ul><li><a href=#python%e8%ae%a1%e7%ae%97%e5%86%b3%e7%ad%96%e6%a0%91%e5%ae%9e%e4%be%8b aria-label=python计算决策树实例>python计算决策树实例</a><ul><li><a href=#%e5%9f%ba%e4%ba%8e%e5%9f%ba%e5%b0%bc%e6%8c%87%e6%95%b0%e7%9a%84%e5%86%b3%e7%ad%96%e6%a0%91 aria-label=基于基尼指数的决策树>基于基尼指数的决策树</a><ul><li><a href=#%e5%9f%ba%e5%b0%bc%e6%8c%87%e6%95%b0-1 aria-label=基尼指数>基尼指数</a><li><a href=#%e6%8b%86%e5%88%86 aria-label=拆分>拆分</a><ul><li><a href=#%e6%95%b0%e6%8d%ae%e6%8b%86%e5%88%86 aria-label=数据拆分>数据拆分</a><li><a href=#%e8%af%84%e4%bc%b0%e6%8b%86%e5%88%86%e7%9a%84%e6%95%b0%e6%8d%ae aria-label=评估拆分的数据>评估拆分的数据</a></ul><li><a href=#%e5%a6%82%e4%bd%95%e6%9e%84%e5%bb%ba%e6%a0%91 aria-label=如何构建树>如何构建树</a><ul><li><a href=#%e7%bb%88%e7%ab%af%e8%8a%82%e7%82%b9 aria-label=终端节点>终端节点</a><li><a href=#%e9%80%92%e5%bd%92%e6%8b%86%e5%88%86 aria-label=递归拆分>递归拆分</a><li><a href=#%e5%88%9b%e5%bb%ba%e6%a0%91 aria-label=创建树>创建树</a><li><a href=#%e6%95%b4%e5%90%88 aria-label=整合>整合</a><li><a href=#%e9%a2%84%e6%b5%8b aria-label=预测>预测</a></ul><li><a href=#%e5%a5%97%e7%94%a8%e7%9c%9f%e5%ae%9e%e6%95%b0%e6%8d%ae%e9%9b%86%e6%9d%a5%e6%b5%8b%e8%af%95 aria-label=套用真实数据集来测试>套用真实数据集来测试</a><ul><li><a href=#%e4%bb%80%e4%b9%88%e6%98%af-k%e6%8a%98%e4%ba%a4%e5%8f%89%e9%aa%8c%e8%af%81 aria-label="什么是 K折交叉验证">什么是 K折交叉验证</a></ul></ul></ul><li><a href=#reference aria-label=Reference>Reference</a></li></div></details></div></aside><script src=/js/pe-toc.min.445eb1bfc5e85dd13b9519fcc2a806522e9629b6224a2974052789ba00ab78af.js integrity="sha256-RF6xv8XoXdE7lRn8wqgGUi6WKbYiSil0BSeJugCreK8="></script><div class=post-content><h2 id=熵和基尼指数>熵和基尼指数<a hidden class=anchor aria-hidden=true href=#熵和基尼指数>#</a></h2><h3 id=信息增益>信息增益<a hidden class=anchor aria-hidden=true href=#信息增益>#</a></h3><p>信息增益 <code>information gain</code> 是用于训练决策树的指标。具体来说，是指这些指标衡量<strong>拆分的质量</strong>。通俗来说是通过根据随机变量的给定值拆分数据集来衡量熵。</p><p>通过描述一个事件是否"惊讶"，通常低概率事件更令人惊讶，因此具有更大的信息量。而具有相同可能性的事件的概率分布更"惊讶"并且具有更大的熵。</p><p><strong>定义</strong>：熵 <strong>entropy</strong>是一组例子中<strong>杂质</strong>、<strong>无序</strong>或<strong>不确定性</strong>的度量。熵控制决策树如何决定<strong>拆分</strong>数据。它实际上影响了决策树如何绘制边界。</p><h3 id=熵>熵<a hidden class=anchor aria-hidden=true href=#熵>#</a></h3><p>熵的计算公式为：$E=-\sum^i_{i=1}(p_i\times\log_2(p_i))$ ；$P_i$ 是类别 $i$ 的概率。我们来举一个例子来更好地理解熵及其计算。假设有一个由三种颜色组成的数据集，红色、紫色和黄色。如果我们的集合中有一个红色、三个紫色和四个黄色的观测值，我们的方程变为：$E=-(p_r \times \log_2(p_r) + p_p \times \log_2(p_p) + p_y \times \log_2(p_y)$</p><p>其中 $p_r$ 、$p_p$ 和 $p_y$ 分别是选择红色、紫色和黄色的概率。假设 $p_r=\frac{1}{8}$，$p_p=\frac{3}{8}$ ，$p_y=\frac{4}{8}$ 现在等式变为变为：</p><ul><li>$E=-(\frac{1}{8} \times \log_2(\frac{1}{8}) + \frac{3}{8} \times \log_2(\frac{3}{8}) + \frac{4}{8} \times \log_2(\frac{4}{8}))$</li><li>$0.125 \times log_2(0.125) + 0.375 \times log_2(0.375) + 0.5 \times log_2(0.375)$</li><li>$0.125 \times -3 + 0.375 \times -1.415 + 0.5 \times -1 = -0.375+-0.425 +-0.5 = 1.41$</li></ul><p>==当所有观测值都属于同一类时会发生什么？== 在这种情况下，熵将始终为零。$E=-(1log_21)=0$ ；这种情况下的数据集没有杂质，这就意味着没有数据集没有意义。又如果有两类数据集，一半是黄色，一半是紫色，那么熵为1，推导过程是：$E=−(\ (0.5\log_2(0.5))+(0.5\times \log_2(0.5))\ ) = 1$</p><h3 id=基尼指数>基尼指数<a hidden class=anchor aria-hidden=true href=#基尼指数>#</a></h3><p>基尼指数 <code>Gini index</code> 和熵 <code>entropy </code>是计算信息增益的标准。决策树算法使用信息增益来拆分节点。</p><p>基尼指数计算特定变量在随机选择时被错误分类的概率程度以及基尼系数的变化。它适用于分类变量，提供“成功”或“失败”的结果，因此仅进行二元拆分（二叉树结构）。基尼指数在 0 和 1 之间变化，其中，1 表示元素在各个类别中的随机分布。基尼指数为 0.5 表示元素在某些类别中分布均匀。：</p><ul><li>0 表示为所有元素都与某个类相关联，或只存在一个类。</li><li>1 表示所有元素随机分布在各个类中，并且0.5 表示元素均匀分布到某些类中</li></ul><p>基尼指数公式：$1− \sum_n^{i=1}(p_i)^2$ ； $P_i$ 为分类到特定类别的概率。在构建决策树时，更愿意选择具有最小基尼指数的属性作为根节点。</p><p>通过实例了解公式</p><table><thead><tr><th><strong>Past Trend</strong></th><th><strong>Open Interest</strong></th><th><strong>Trading Volume</strong></th><th><strong>Return</strong></th></tr></thead><tbody><tr><td>Positive</td><td>Low</td><td>High</td><td>Up</td></tr><tr><td>Negative</td><td>High</td><td>Low</td><td>Down</td></tr><tr><td>Positive</td><td>Low</td><td>High</td><td>Up</td></tr><tr><td>Positive</td><td>High</td><td>High</td><td>Up</td></tr><tr><td>Negative</td><td>Low</td><td>High</td><td>Down</td></tr><tr><td>Positive</td><td>Low</td><td>Low</td><td>Down</td></tr><tr><td>Negative</td><td>High</td><td>High</td><td>Down</td></tr><tr><td>Negative</td><td>Low</td><td>High</td><td>Down</td></tr><tr><td>Positive</td><td>Low</td><td>Low</td><td>Down</td></tr><tr><td>Positive</td><td>High</td><td>High</td><td>Up</td></tr></tbody></table><p>计算基尼指数</p><p>已知条件</p><ul><li><p>$P(Past\ Trend=Positive) = \frac{6}{10}$</p></li><li><p>$P(Past\ Trend=Negative) = \frac{4}{10}$</p></li></ul><p>过去趋势基尼指数计算</p><p>如果过去趋势为正面，回报为上涨，概率为：$P(Past\ Trend=Positive\ &\ Return=Up) = \frac{4}{6}$</p><p>如果过去趋势为正面，回报为下降，概率为：$P(Past\ Trend=Positive\ &\ Return=Down) = \frac{2}{6}$</p><ul><li>那么这个基尼指数为：$gini(Past\ Trend) = 1-(\frac{4}{6}^2+\frac{2}{6}^2) = 0.45$</li></ul><p>如果过去趋势为负面，回报为上涨，概率为：$P(Past\ Trend=Negative\ &\ Return=Up) = 0$</p><p>如果过去趋势为负面，回报为下降，概率为：$P(Past\ Trend=Negative\ &\ Return=Down) = \frac{4}{4}$</p><ul><li>那么这个基尼指数为：$gini(Past\ Trend=Negative) = 1-(0^2+\frac{4}{4}^2) = 1-(0+1)=0$</li></ul><p>那么过去交易量的的基尼指数加权 = $\frac{6}{10} \times 0.45 + \frac{4}{10}\times 0 = 0.27$</p><p>未平仓量基尼指数计算</p><p>已知条件</p><ul><li>$P(Open\ Interest=High): \frac{4}{10}$</li><li>$P(Open\ Interest=Low): \frac{6}{10}$</li></ul><p>如果未平仓量为 <code>high</code> 并且回报为上涨，概率为：$P(Open\ Interest = High\ &\ Return\ = Up)=\frac{2}{4}$</p><p>如果未平仓量为 <code>high</code> 并且回报为下降，概率为：$P(Open\ Interest = High\ &\ Return\ = Down)=\frac{2}{4}$</p><ul><li>那么这个基尼指数为：$gini(Open\ Interest=High) = 1-(\frac{2}{4}^2+\frac{2}{4}^2) = 0.5$</li></ul><p>如果未平仓量为 <code>low</code> 并且回报为上涨，概率为：$P(Open\ Interest = High\ &\ Return\ = Up)=\frac{2}{6}$</p><p>如果未平仓量为 <code>low</code> 并且回报为下降，概率为：$P(Open\ Interest = High\ &\ Return\ = Down)=\frac{4}{6}$</p><ul><li>那么这个基尼指数为：$gini(Open\ Interest=Low) = 1-(\frac{2}{6}^2+\frac{4}{6}^2) = 0.45$</li></ul><p>那么未平仓量基尼指数加权 = $\frac{4}{10} \times 0.5 + \frac{6}{10}\times 0.45 = 0.47$</p><p>计算交易量基尼指数</p><p>已知条件</p><ul><li>$P(Trading\ Volume=High): \frac{7}{10}$</li><li>$P(Trading\ Volume=Low): \frac{3}{10}$</li></ul><p>如果交易量为 <code>high</code> 并且回报为上涨，概率为：$P(Trading\ Volume=High\ &\ Return\ = Up)=\frac{4}{7}$</p><p>如果交易量为 <code>high</code> 并且回报为下降，概率为：$P(Trading\ Volume = High\ &\ Return\ = Down)=\frac{3}{7}$</p><ul><li>那么这个基尼指数为：$gini(Trading\ Volume=High) = 1-(\frac{4}{7}^2+\frac{3}{7}^2) = 0.49$</li></ul><p>如果交易量为 <code>low</code> 并且回报为上涨，概率为：$P(Trading\ Volume = Low\ &\ Return\ = Up)=0$</p><p>如果交易量为 <code>low</code> 并且回报为下降，概率为：$P(Trading\ Volume = Low\ &\ Return\ = Down)=\frac{3}{3}$</p><ul><li>那么这个基尼指数为：$gini(Trading\ Volume=Low) = 1-(0^2+1^2) = 0$</li></ul><p>那么交易量基尼指数加权 = $\frac{7}{10} \times 0.49 + \frac{3}{10}\times 0 = 0.34$</p><p>最终计算出的基尼指数列表如下，在表中可以观察到“<strong>Past Trend</strong>”的基尼指数最低，因此它将被选为决策树的根节点。</p><table><thead><tr><th><strong>Attributes</strong></th><th><strong>Gini Index</strong></th></tr></thead><tbody><tr><td>Past Trend</td><td>0.27</td></tr><tr><td>Open Interest</td><td>0.47</td></tr><tr><td>Trading Volume</td><td>0.34</td></tr></tbody></table><p>这里将重复的过程来确定决策树的子节点或分支。将通过计算”<strong>Past Trend</strong>“的“<strong>Positive</strong>”分支的基尼指数如下：</p><table><thead><tr><th><strong>Past Trend</strong></th><th><strong>Open Interest</strong></th><th><strong>Trading Volume</strong></th><th><strong>Return</strong></th></tr></thead><tbody><tr><td>Positive</td><td>Low</td><td>High</td><td>Up</td></tr><tr><td>Positive</td><td>Low</td><td>High</td><td>Up</td></tr><tr><td>Positive</td><td>High</td><td>High</td><td>Up</td></tr><tr><td>Positive</td><td>Low</td><td>Low</td><td>Down</td></tr><tr><td>Positive</td><td>Low</td><td>Low</td><td>Down</td></tr><tr><td>Positive</td><td>High</td><td>High</td><td>Up</td></tr></tbody></table><p>针对过去正面趋势计算未平仓量的基尼指数</p><p>已知条件</p><ul><li>$P(Open\ Interest=High): \frac{2}{6}$</li><li>$P(Open\ Interest=Low): \frac{4}{6}$</li></ul><p>如果未平仓量为 <code>high</code> 并且回报为上涨，概率为：$P(Open\ Interest = High\ &\ Return\ = Up)=\frac{2}{2}$</p><p>如果未平仓量为 <code>high</code> 并且回报为下降，概率为：$P(Open\ Interest = High\ &\ Return\ = Down)=0$</p><ul><li>那么这个基尼指数为：$gini(Open\ Interest=High) = 1-(\frac{2}{2}^2+0^2) = 0$</li></ul><p>如果未平仓量为 <code>low</code> 并且回报为上涨，概率为：$P(Open\ Interest = Low\ &\ Return\ = Up)=\frac{2}{4}$</p><p>如果未平仓量为 <code>low</code> 并且回报为下降，概率为：$P(Open\ Interest = Low\ &\ Return\ = Down)=\frac{2}{4}$</p><ul><li>那么这个基尼指数为：$gini(Open\ Interest=Low) = 1-(\frac{2}{4}^2+\frac{2}{4}^2) = 0.5$</li></ul><p>那么未平仓量基尼指数加权 = $\frac{2}{6} \times 0 + \frac{4}{6}\times 0.5 = 0.33$</p><p>计算交易量基尼指数</p><p>已知条件</p><ul><li>$P(Trading\ Volume=High): \frac{4}{6}$</li><li>$P(Trading\ Volume=Low): \frac{2}{6}$</li></ul><p>如果交易量为 <code>high</code> 并且回报为上涨，概率为：$P(Trading\ Volume=High\ &\ Return\ = Up)=\frac{4}{4}$</p><p>如果交易量为 <code>high</code> 并且回报为下降，概率为：$P(Trading\ Volume = High\ &\ Return\ = Down)=0$</p><ul><li>那么这个基尼指数为：$gini(Trading\ Volume=High) = 1-(\frac{4}{4}^2+0^2) = 0$</li></ul><p>如果交易量为 <code>low</code> 并且回报为上涨，概率为：$P(Trading\ Volume = Low\ &\ Return\ = Up)=0$</p><p>如果交易量为 <code>low</code> 并且回报为下降，概率为：$P(Trading\ Volume = Low\ &\ Return\ = Down)=\frac{2}{2}$</p><ul><li>那么这个基尼指数为：$gini(Trading\ Volume=Low) = 1-(0^2+\frac{2}{2}^2) = 0$</li></ul><p>那么交易量基尼指数加权 = $\frac{4}{6} \times 0 + \frac{2}{6}\times 0 = 0$</p><p>最终计算出的基尼指数列表如下，这里将使用“<strong>Trading Volume</strong>”进一步拆分节点，因为它具有最小的基尼指数。</p><table><thead><tr><th><strong>Attributes/Features</strong></th><th><strong>Gini Index</strong></th></tr></thead><tbody><tr><td>Open Interest</td><td>0.33</td></tr><tr><td>Trading Volume</td><td>0</td></tr></tbody></table><p>最终的模型就如图所示</p><p><div class=pe-fancybox><a data-fancybox=gallery href=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/image-20220602000050768.png><img src=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/image-20220602000050768.png#center alt=image-20220602000050768 onerror='this.onerror=null,this.src="/placeholder.svg",this.className="pe-image-placeholder"'></a></div></p><h4 id=计算信息增益示例>计算信息增益示例<a hidden class=anchor aria-hidden=true href=#计算信息增益示例>#</a></h4><p>我们可以根据属于一类数据的概率分布来考虑数据集的熵，例如，在二进制分类数据集的情况下为两个类。计算样本的熵如 $Entropy = -(P_0 \times log(P_0) + P_1 \times log(P_1)$ 。</p><p>两类的样本拆分为 <code>50/50</code> 的数据集将具最大熵（最惊讶），而拆分为 <code>10/90</code> 的不平衡数据集将具有较小的熵。可以通过在 Python 中计算这个不平衡数据集的熵的例子来证明这一点。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>math</span> <span class=kn>import</span> <span class=n>log2</span>
</span></span><span class=line><span class=cl><span class=c1># 概率</span>
</span></span><span class=line><span class=cl><span class=n>class0</span> <span class=o>=</span> <span class=mi>10</span><span class=o>/</span><span class=mi>100</span>
</span></span><span class=line><span class=cl><span class=n>class1</span> <span class=o>=</span> <span class=mi>90</span><span class=o>/</span><span class=mi>100</span>
</span></span><span class=line><span class=cl><span class=c1># entropy formula</span>
</span></span><span class=line><span class=cl><span class=n>entropy</span> <span class=o>=</span> <span class=o>-</span><span class=p>(</span><span class=n>class0</span> <span class=o>*</span> <span class=n>log2</span><span class=p>(</span><span class=n>class0</span><span class=p>)</span> <span class=o>+</span> <span class=n>class1</span> <span class=o>*</span> <span class=n>log2</span><span class=p>(</span><span class=n>class1</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=c1># print the result</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;entropy: </span><span class=si>%.3f</span><span class=s1> bits&#39;</span> <span class=o>%</span> <span class=n>entropy</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div></div></div><p>运行示例，可以看到用于二分类的数据集的熵小于 1 。也就是说，对来自数据集中的任意示例类进行编码所需的信息不到1。通过这种方式，熵可以用作数据集纯度的计算，例如类别分布的平衡程度。</p><p>熵为 0 位表示数据集包含一个类；1或更大位的熵表示平衡数据集的最大熵（取决于类别的数量），介于两者之间的值表示这些极端之间的水平。</p><h3 id=计算信息增益示例-1>计算信息增益示例<a hidden class=anchor aria-hidden=true href=#计算信息增益示例-1>#</a></h3><p>要求：定义一个函数来根据属于 0 类和 1 类的样本的比率来计算一组样本的熵。</p><p>假设有一个20 个示例的数据集，13 个为0 类，7 个为1 类。我们可以计算该数据集的熵，它的熵小于 1 位。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>math</span> <span class=kn>import</span> <span class=n>log2</span>
</span></span><span class=line><span class=cl><span class=c1># calculate the entropy for the split in the dataset</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>entropy</span><span class=p>(</span><span class=n>class0</span><span class=p>,</span> <span class=n>class1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=o>-</span><span class=p>(</span><span class=n>class0</span> <span class=o>*</span> <span class=n>log2</span><span class=p>(</span><span class=n>class0</span><span class=p>)</span> <span class=o>+</span> <span class=n>class1</span> <span class=o>*</span> <span class=n>log2</span><span class=p>(</span><span class=n>class1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># split of the main dataset</span>
</span></span><span class=line><span class=cl><span class=n>class0</span> <span class=o>=</span> <span class=mi>13</span> <span class=o>/</span> <span class=mi>20</span>
</span></span><span class=line><span class=cl><span class=n>class1</span> <span class=o>=</span> <span class=mi>7</span> <span class=o>/</span> <span class=mi>20</span>
</span></span><span class=line><span class=cl><span class=c1># calculate entropy before the change</span>
</span></span><span class=line><span class=cl><span class=n>s_entropy</span> <span class=o>=</span> <span class=n>entropy</span><span class=p>(</span><span class=n>class0</span><span class=p>,</span> <span class=n>class1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Dataset Entropy: </span><span class=si>%.3f</span><span class=s1> bits&#39;</span> <span class=o>%</span> <span class=n>s_entropy</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Dataset Entropy: 0.934 bits</span></span></span></code></pre></td></tr></table></div></div></div></div><p>假设按照 value1 分割数据集，有一组 8 个样本的数据集，7 个为第 0 类，1 个用于第 1 类。然后我们可以计算这组样本的熵。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>math</span> <span class=kn>import</span> <span class=n>log2</span>
</span></span><span class=line><span class=cl><span class=c1># calculate the entropy for the split in the dataset</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>entropy</span><span class=p>(</span><span class=n>class0</span><span class=p>,</span> <span class=n>class1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=o>-</span><span class=p>(</span><span class=n>class0</span> <span class=o>*</span> <span class=n>log2</span><span class=p>(</span><span class=n>class0</span><span class=p>)</span> <span class=o>+</span> <span class=n>class1</span> <span class=o>*</span> <span class=n>log2</span><span class=p>(</span><span class=n>class1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># split of the main dataset</span>
</span></span><span class=line><span class=cl><span class=n>s1_class0</span> <span class=o>=</span> <span class=mi>7</span> <span class=o>/</span> <span class=mi>8</span>
</span></span><span class=line><span class=cl><span class=n>s1_class1</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=mi>8</span>
</span></span><span class=line><span class=cl><span class=c1># calculate entropy before the change</span>
</span></span><span class=line><span class=cl><span class=n>s_entropy</span> <span class=o>=</span> <span class=n>entropy</span><span class=p>(</span><span class=n>s1_class0</span><span class=p>,</span> <span class=n>s1_class1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Dataset Entropy: </span><span class=si>%.3f</span><span class=s1> bits&#39;</span> <span class=o>%</span> <span class=n>s_entropy</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Dataset Entropy: 0.544 bits</span></span></span></code></pre></td></tr></table></div></div></div></div><p>假设现在按 value2 分割数据集；一组 12 个样本数据集，每组 6 个。我们希望这个组的熵为 1。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>math</span> <span class=kn>import</span> <span class=n>log2</span>
</span></span><span class=line><span class=cl><span class=c1># calculate the entropy for the split in the dataset</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>entropy</span><span class=p>(</span><span class=n>class0</span><span class=p>,</span> <span class=n>class1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=o>-</span><span class=p>(</span><span class=n>class0</span> <span class=o>*</span> <span class=n>log2</span><span class=p>(</span><span class=n>class0</span><span class=p>)</span> <span class=o>+</span> <span class=n>class1</span> <span class=o>*</span> <span class=n>log2</span><span class=p>(</span><span class=n>class1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># split of the main dataset</span>
</span></span><span class=line><span class=cl><span class=n>s1_class0</span> <span class=o>=</span> <span class=mi>6</span> <span class=o>/</span> <span class=mi>12</span>
</span></span><span class=line><span class=cl><span class=n>s1_class1</span> <span class=o>=</span> <span class=mi>6</span> <span class=o>/</span> <span class=mi>12</span>
</span></span><span class=line><span class=cl><span class=c1># calculate entropy before the change</span>
</span></span><span class=line><span class=cl><span class=n>s_entropy</span> <span class=o>=</span> <span class=n>entropy</span><span class=p>(</span><span class=n>s1_class0</span><span class=p>,</span> <span class=n>s1_class1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Dataset Entropy: </span><span class=si>%.3f</span><span class=s1> bits&#39;</span> <span class=o>%</span> <span class=n>s_entropy</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Dataset Entropy: 1.000 bits</span></span></span></code></pre></td></tr></table></div></div></div></div><p>最后，可以根据为变量的每个值创建的组和计算的熵来计算该变量的信息增益。例如：</p><p>第一个变量从数据集中产生一组 8 个样本，第二组在数据集中有12 个样本。在这种情况下，信息增益计算：</p><ul><li>$Entropy(Dataset) – (\frac{(Count(Group1)}{Count(Dataset)} \times Entropy(Group1) + \frac{Count(Group2)}{Count(Dataset)} \times Entropy(Group2)))$</li></ul><p>这里是因为在每个子节点重复这个分裂过程直到空叶节点。这意味着每个节点的样本都属于同一类。但是，这种情况下会导致具有许多节点使非常<strong>深的树</strong>，这很容易导致过度拟合。因此，我们通常希望通过设置树的最大深度来修剪树。IG就是我们想确定给定训练特征向的量集中的<strong>哪个属性最有用</strong>，那么上面的公式推理就为：</p><ul><li>$IG(D_p) = I(D_p) − \frac{N_{left}}{N_p}I(D_{left})−\frac{N_{right}}{N_p}I(D_{right})$<ul><li>$IG(D_P)$：数据集的信息增益</li><li>$I(D)$：叶子的熵或基尼指数</li><li>$\frac{N}{N_P}$ ：页数据集占总数据集的比例</li></ul></li></ul><p>我们将使用它来决定<strong>决策树</strong> 节点中<strong>属性的顺序</strong>。该行为在python中表示为：</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>math</span> <span class=kn>import</span> <span class=n>log2</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># calculate the entropy for the split in the dataset</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>entropy</span><span class=p>(</span><span class=n>class0</span><span class=p>,</span> <span class=n>class1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=o>-</span><span class=p>(</span><span class=n>class0</span> <span class=o>*</span> <span class=n>log2</span><span class=p>(</span><span class=n>class0</span><span class=p>)</span> <span class=o>+</span> <span class=n>class1</span> <span class=o>*</span> <span class=n>log2</span><span class=p>(</span><span class=n>class1</span><span class=p>))</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># split of the main dataset</span>
</span></span><span class=line><span class=cl><span class=n>class0</span> <span class=o>=</span> <span class=mi>13</span> <span class=o>/</span> <span class=mi>20</span>
</span></span><span class=line><span class=cl><span class=n>class1</span> <span class=o>=</span> <span class=mi>7</span> <span class=o>/</span> <span class=mi>20</span>
</span></span><span class=line><span class=cl><span class=c1># calculate entropy before the change</span>
</span></span><span class=line><span class=cl><span class=n>s_entropy</span> <span class=o>=</span> <span class=n>entropy</span><span class=p>(</span><span class=n>class0</span><span class=p>,</span> <span class=n>class1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Dataset Entropy: </span><span class=si>%.3f</span><span class=s1> bits&#39;</span> <span class=o>%</span> <span class=n>s_entropy</span><span class=p>)</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># split 1 (split via value1)</span>
</span></span><span class=line><span class=cl><span class=n>s1_class0</span> <span class=o>=</span> <span class=mi>7</span> <span class=o>/</span> <span class=mi>8</span>
</span></span><span class=line><span class=cl><span class=n>s1_class1</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=mi>8</span>
</span></span><span class=line><span class=cl><span class=c1># calculate the entropy of the first group</span>
</span></span><span class=line><span class=cl><span class=n>s1_entropy</span> <span class=o>=</span> <span class=n>entropy</span><span class=p>(</span><span class=n>s1_class0</span><span class=p>,</span> <span class=n>s1_class1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Group1 Entropy: </span><span class=si>%.3f</span><span class=s1> bits&#39;</span> <span class=o>%</span> <span class=n>s1_entropy</span><span class=p>)</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># split 2  (split via value2)</span>
</span></span><span class=line><span class=cl><span class=n>s2_class0</span> <span class=o>=</span> <span class=mi>6</span> <span class=o>/</span> <span class=mi>12</span>
</span></span><span class=line><span class=cl><span class=n>s2_class1</span> <span class=o>=</span> <span class=mi>6</span> <span class=o>/</span> <span class=mi>12</span>
</span></span><span class=line><span class=cl><span class=c1># calculate the entropy of the second group</span>
</span></span><span class=line><span class=cl><span class=n>s2_entropy</span> <span class=o>=</span> <span class=n>entropy</span><span class=p>(</span><span class=n>s2_class0</span><span class=p>,</span> <span class=n>s2_class1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Group2 Entropy: </span><span class=si>%.3f</span><span class=s1> bits&#39;</span> <span class=o>%</span> <span class=n>s2_entropy</span><span class=p>)</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># calculate the information gain</span>
</span></span><span class=line><span class=cl><span class=n>gain</span> <span class=o>=</span> <span class=n>s_entropy</span> <span class=o>-</span> <span class=p>(</span><span class=mi>8</span><span class=o>/</span><span class=mi>20</span> <span class=o>*</span> <span class=n>s1_entropy</span> <span class=o>+</span> <span class=mi>12</span><span class=o>/</span><span class=mi>20</span> <span class=o>*</span> <span class=n>s2_entropy</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Information Gain: </span><span class=si>%.3f</span><span class=s1> bits&#39;</span> <span class=o>%</span> <span class=n>gain</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Dataset Entropy: 0.934 bits</span>
</span></span><span class=line><span class=cl><span class=c1># Group1 Entropy: 0.544 bits</span>
</span></span><span class=line><span class=cl><span class=c1># Group2 Entropy: 1.000 bits</span>
</span></span><span class=line><span class=cl><span class=c1># Information Gain: 0.117 bits</span></span></span></code></pre></td></tr></table></div></div></div></div><p>通过实例，就可以很清楚的明白了，信息增益的概念：<strong>信息熵-条件熵</strong>，换句话来说就是==信息增益代表了在一个条件下，信息复杂度（不确定性）减少的程度==。</p><h2 id=python计算决策树实例>python计算决策树实例<a hidden class=anchor aria-hidden=true href=#python计算决策树实例>#</a></h2><h3 id=基于基尼指数的决策树>基于基尼指数的决策树<a hidden class=anchor aria-hidden=true href=#基于基尼指数的决策树>#</a></h3><p>钞票数据集涉及根据从照片中采取的一系列措施来预测给定钞票是否是真实的。数据是取自真钞和伪钞样样本的图像中提取的。对于数字化，使用了通常用于印刷检查的工业相机，从图像中提取特征。</p><p>该数据集包含 1372 行和 5 个数值变量。这是一个二元分类的问题。</p><h4 id=基尼指数-1>基尼指数<a hidden class=anchor aria-hidden=true href=#基尼指数-1>#</a></h4><p>假设有两组数据，每组有 2 行。第一组的行都属于 0 类，第二组的行都属于 1 类，所以这是一个完美的拆分。</p><p>首先需要计算每个组中类的比例。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>proportion</span> <span class=o>=</span> <span class=n>count</span><span class=p>(</span><span class=n>class_value</span><span class=p>)</span> <span class=o>/</span> <span class=n>count</span><span class=p>(</span><span class=n>rows</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div></div></div><p>这个比例是</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>group_1_class_0</span> <span class=o>=</span> <span class=mi>2</span> <span class=o>/</span> <span class=mi>2</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=n>group_1_class_1</span> <span class=o>=</span> <span class=mi>0</span> <span class=o>/</span> <span class=mi>2</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=n>group_2_class_0</span> <span class=o>=</span> <span class=mi>0</span> <span class=o>/</span> <span class=mi>2</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=n>group_2_class_1</span> <span class=o>=</span> <span class=mi>2</span> <span class=o>/</span> <span class=mi>2</span> <span class=o>=</span> <span class=mi>1</span></span></span></code></pre></td></tr></table></div></div></div></div><p>为每个子节点计算 Gini index</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>gini_index</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>proportion</span> <span class=o>*</span> <span class=p>(</span><span class=mf>1.0</span> <span class=o>-</span> <span class=n>proportion</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>gini_index</span> <span class=o>=</span> <span class=mf>1.0</span> <span class=o>-</span> <span class=nb>sum</span><span class=p>(</span><span class=n>proportion</span> <span class=o>*</span> <span class=n>proportion</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div></div></div><p>然后对每组的基尼指数按组的大小加权，例如当前正在分组的所有样本。我们可以将此权重添加到组的基尼指数计算中，如下所示：</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>gini_index</span> <span class=o>=</span> <span class=p>(</span><span class=mf>1.0</span> <span class=o>-</span> <span class=nb>sum</span><span class=p>(</span><span class=n>proportion</span> <span class=o>*</span> <span class=n>proportion</span><span class=p>))</span> <span class=o>*</span> <span class=p>(</span><span class=n>group_size</span><span class=o>/</span><span class=n>total_samples</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div></div></div><p>在该案例中，每个组的基尼指数为：</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>Gini</span><span class=p>(</span><span class=n>group_1</span><span class=p>)</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=p>(</span><span class=mi>1</span><span class=o>*</span><span class=mi>1</span> <span class=o>+</span> <span class=mi>0</span><span class=o>*</span><span class=mi>0</span><span class=p>))</span> <span class=o>*</span> <span class=mi>2</span><span class=o>/</span><span class=mi>4</span>
</span></span><span class=line><span class=cl><span class=n>Gini</span><span class=p>(</span><span class=n>group_1</span><span class=p>)</span> <span class=o>=</span> <span class=mf>0.0</span> <span class=o>*</span> <span class=mf>0.5</span> 
</span></span><span class=line><span class=cl><span class=n>Gini</span><span class=p>(</span><span class=n>group_1</span><span class=p>)</span> <span class=o>=</span> <span class=mf>0.0</span> <span class=c1># 分类1的基尼指数</span>
</span></span><span class=line><span class=cl><span class=n>Gini</span><span class=p>(</span><span class=n>group_2</span><span class=p>)</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=p>(</span><span class=mi>0</span><span class=o>*</span><span class=mi>0</span> <span class=o>+</span> <span class=mi>1</span><span class=o>*</span><span class=mi>1</span><span class=p>))</span> <span class=o>*</span> <span class=mi>2</span><span class=o>/</span><span class=mi>4</span>
</span></span><span class=line><span class=cl><span class=n>Gini</span><span class=p>(</span><span class=n>group_2</span><span class=p>)</span> <span class=o>=</span> <span class=mf>0.0</span> <span class=o>*</span> <span class=mf>0.5</span> 
</span></span><span class=line><span class=cl><span class=n>Gini</span><span class=p>(</span><span class=n>group_2</span><span class=p>)</span> <span class=o>=</span> <span class=mf>0.0</span> <span class=c1># 分类2的基尼指数</span></span></span></code></pre></td></tr></table></div></div></div></div><p>然后在分割点的每个子节点上添加分数，以给出分割点的最终 Gini 分数，该分数可以与其他候选分割点进行比较。如该分割点的基尼系数为 $0.0 + 0.0$ 或完美的基尼系数 0.0。</p><p>编写一个 <code>gini_index()</code> 的函数，用于计算组列表和已知类值列表的基尼指数。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>gini_index</span><span class=p>(</span><span class=n>groups</span><span class=p>,</span> <span class=n>classes</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;------------&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算所有样本的分割点，计算样本的总长度</span>
</span></span><span class=line><span class=cl>    <span class=n>n_instances</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=nb>sum</span><span class=p>([</span><span class=nb>len</span><span class=p>(</span><span class=n>group</span><span class=p>)</span> <span class=k>for</span> <span class=n>group</span> <span class=ow>in</span> <span class=n>groups</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算每个组的总基尼指数</span>
</span></span><span class=line><span class=cl>    <span class=n>gini</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>group</span> <span class=ow>in</span> <span class=n>groups</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>size</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>group</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>size</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span> <span class=c1># avoid divide by zero</span>
</span></span><span class=line><span class=cl>            <span class=k>continue</span>
</span></span><span class=line><span class=cl>        <span class=n>score</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>        <span class=c1># score the group based on the score for each class</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>class_val</span> <span class=ow>in</span> <span class=n>classes</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># row[-1] 代表每个样本的最后一个值，是否存在分类 class_val</span>
</span></span><span class=line><span class=cl>            <span class=n>p</span> <span class=o>=</span> <span class=p>[</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>group</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>p1</span> <span class=o>=</span> <span class=n>p</span><span class=o>.</span><span class=n>count</span><span class=p>(</span><span class=n>class_val</span><span class=p>)</span> <span class=o>/</span> <span class=n>size</span>
</span></span><span class=line><span class=cl>            <span class=n>score</span> <span class=o>+=</span> <span class=n>p1</span> <span class=o>*</span> <span class=n>p1</span>
</span></span><span class=line><span class=cl>        <span class=c1># 按照对应的样本分割点，加权重</span>
</span></span><span class=line><span class=cl>        <span class=n>gini</span> <span class=o>+=</span> <span class=p>(</span><span class=mf>1.0</span> <span class=o>-</span> <span class=n>score</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=n>size</span> <span class=o>/</span> <span class=n>n_instances</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>gini</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>gini_index</span><span class=p>([[[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>]],</span> <span class=p>[[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>]]],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>gini_index</span><span class=p>([[[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>]],</span> <span class=p>[[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>]]],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]))</span></span></span></code></pre></td></tr></table></div></div></div></div><p>运行该示例会打印两组的Gini index，最差情况的为 0.5，最少情况的指数为 0.0。</p><p><div class=pe-fancybox><a data-fancybox=gallery href=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/image-20220602215655808.png><img src=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/image-20220602215655808.png#center alt=image-20220602215655808 onerror='this.onerror=null,this.src="/placeholder.svg",this.className="pe-image-placeholder"'></a></div></p><h4 id=拆分>拆分<a hidden class=anchor aria-hidden=true href=#拆分>#</a></h4><h5 id=数据拆分>数据拆分<a hidden class=anchor aria-hidden=true href=#数据拆分>#</a></h5><p>拆分是由数据集中的一个属性和一个值组成。可以将其总结为要拆分的属性的索引和拆分该属性上的行的值。这只是索引数据行的有用简写。</p><p>创建拆分涉及三个部分，我们已经看过的第一个部分是计算基尼分数。剩下的两部分是：</p><ul><li>拆分数据集。</li><li>评估所有拆分。</li></ul><p>拆分数据是给定数据集索引和拆分值，将数据集拆分为两个行列表形成一个分类。具体是拆分数据集涉及遍历每一行，检查属性值是否低于或高于拆分值，并将其分别分配给左组或右组。当存在两个组时，可以按照基尼指数进行评估</p><p>编写一个**test_split()**函数，它实现了拆分。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_split</span><span class=p>(</span><span class=n>index</span><span class=p>,</span> <span class=n>value</span><span class=p>,</span> <span class=n>dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=n>left</span><span class=p>,</span> <span class=n>right</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(),</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=n>row</span><span class=p>[</span><span class=n>index</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>value</span><span class=p>:</span>
</span></span><span class=line><span class=cl>			<span class=n>left</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>			<span class=n>right</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=n>left</span><span class=p>,</span> <span class=n>right</span></span></span></code></pre></td></tr></table></div></div></div></div><h5 id=评估拆分的数据>评估拆分的数据<a hidden class=anchor aria-hidden=true href=#评估拆分的数据>#</a></h5><p>给定一个数据集，必须检查每个属性上的每个值作为候选拆分，评估拆分的成本并找到我们可以进行的最佳拆分。一旦找到最佳值，就可以将其用作决策树中的节点。</p><p>这里使用 <code>dict</code> 作为决策树中的节点，因为这样可以按名称存储数据。选择最佳基尼指数并将其用作树的新节点。</p><p>每组数据都是其小数据集，其中仅包含通过拆分过程分配给左组或右组的那些行。可以想象我们如何在构建决策树时递归地再次拆分每个组。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_split</span><span class=p>(</span><span class=n>dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=n>class_values</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>))</span>
</span></span><span class=line><span class=cl>	<span class=n>b_index</span><span class=p>,</span> <span class=n>b_value</span><span class=p>,</span> <span class=n>b_score</span><span class=p>,</span> <span class=n>b_groups</span> <span class=o>=</span> <span class=mi>999</span><span class=p>,</span> <span class=mi>999</span><span class=p>,</span> <span class=mi>999</span><span class=p>,</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>index</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span><span class=o>-</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>		<span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>			<span class=n>groups</span> <span class=o>=</span> <span class=n>test_split</span><span class=p>(</span><span class=n>index</span><span class=p>,</span> <span class=n>row</span><span class=p>[</span><span class=n>index</span><span class=p>],</span> <span class=n>dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>			<span class=n>gini</span> <span class=o>=</span> <span class=n>gini_index</span><span class=p>(</span><span class=n>groups</span><span class=p>,</span> <span class=n>class_values</span><span class=p>)</span>
</span></span><span class=line><span class=cl>			<span class=k>if</span> <span class=n>gini</span> <span class=o>&lt;</span> <span class=n>b_score</span><span class=p>:</span>
</span></span><span class=line><span class=cl>				<span class=n>b_index</span><span class=p>,</span> <span class=n>b_value</span><span class=p>,</span> <span class=n>b_score</span><span class=p>,</span> <span class=n>b_groups</span> <span class=o>=</span> <span class=n>index</span><span class=p>,</span> <span class=n>row</span><span class=p>[</span><span class=n>index</span><span class=p>],</span> <span class=n>gini</span><span class=p>,</span> <span class=n>groups</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=p>{</span><span class=s1>&#39;index&#39;</span><span class=p>:</span><span class=n>b_index</span><span class=p>,</span> <span class=s1>&#39;value&#39;</span><span class=p>:</span><span class=n>b_value</span><span class=p>,</span> <span class=s1>&#39;groups&#39;</span><span class=p>:</span><span class=n>b_groups</span><span class=p>}</span></span></span></code></pre></td></tr></table></div></div></div></div><p>之后准备一些测试数据集进行测试，其中 $Y$ 是测试集的分类</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>text</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>X1				X2				Y
</span></span><span class=line><span class=cl>2.771244718		1.784783929		0
</span></span><span class=line><span class=cl>1.728571309		1.169761413		0
</span></span><span class=line><span class=cl>3.678319846		2.81281357		0
</span></span><span class=line><span class=cl>3.961043357		2.61995032		0
</span></span><span class=line><span class=cl>2.999208922		2.209014212		0
</span></span><span class=line><span class=cl>7.497545867		3.162953546		1
</span></span><span class=line><span class=cl>9.00220326		3.339047188		1
</span></span><span class=line><span class=cl>7.444542326		0.476683375		1
</span></span><span class=line><span class=cl>10.12493903		3.234550982		1
</span></span><span class=line><span class=cl>6.642287351		3.319983761		1</span></span></code></pre></td></tr></table></div></div></div></div><p>将上述代码整合为一起，运行该代码后会打印所有基尼指数，基尼指数为 0.0 或完美分割。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Split a dataset based on an attribute and an attribute value</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_split</span><span class=p>(</span><span class=n>index</span><span class=p>,</span> <span class=n>value</span><span class=p>,</span> <span class=n>dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>left</span><span class=p>,</span> <span class=n>right</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(),</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>row</span><span class=p>[</span><span class=n>index</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>value</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>left</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>right</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>left</span><span class=p>,</span> <span class=n>right</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Calculate the Gini index for a split dataset</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>gini_index</span><span class=p>(</span><span class=n>groups</span><span class=p>,</span> <span class=n>classes</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算两组数据集的总数每个种类的列表数量和</span>
</span></span><span class=line><span class=cl>    <span class=n>n_instances</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=nb>sum</span><span class=p>([</span><span class=nb>len</span><span class=p>(</span><span class=n>group</span><span class=p>)</span> <span class=k>for</span> <span class=n>group</span> <span class=ow>in</span> <span class=n>groups</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算每组的基尼值</span>
</span></span><span class=line><span class=cl>    <span class=n>gini</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>group</span> <span class=ow>in</span> <span class=n>groups</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>size</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>group</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=c1># avoid divide by zero</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>size</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>continue</span>
</span></span><span class=line><span class=cl>        <span class=n>score</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>        <span class=c1># score the group based on the score for each class</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>class_val</span> <span class=ow>in</span> <span class=n>classes</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 拿出数据集中每行的类型，拆开是为了更好的了解结构</span>
</span></span><span class=line><span class=cl>            <span class=n>p</span> <span class=o>=</span> <span class=p>[</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>group</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=c1># print(&#34;%f / %f = %f&#34; % (p.count(class_val), size, p.count(class_val) / size ))</span>
</span></span><span class=line><span class=cl>            <span class=c1># 这里计算的是当前的分类在总数据集中占比</span>
</span></span><span class=line><span class=cl>            <span class=n>p1</span> <span class=o>=</span> <span class=n>p</span><span class=o>.</span><span class=n>count</span><span class=p>(</span><span class=n>class_val</span><span class=p>)</span> <span class=o>/</span> <span class=n>size</span>
</span></span><span class=line><span class=cl>            <span class=n>score</span> <span class=o>+=</span> <span class=n>p1</span> <span class=o>*</span> <span class=n>p1</span> <span class=c1># gini index formula = 1 - sum(p_i^2)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 计算总的基尼指数，权重：当前分组占总数据集中的数量</span>
</span></span><span class=line><span class=cl>        <span class=n>gini</span> <span class=o>+=</span> <span class=p>(</span><span class=mf>1.0</span> <span class=o>-</span> <span class=n>score</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=n>size</span> <span class=o>/</span> <span class=n>n_instances</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>gini</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Select the best split point for a dataset</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_split</span><span class=p>(</span><span class=n>dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>class_values</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>b_index</span><span class=p>,</span> <span class=n>b_value</span><span class=p>,</span> <span class=n>b_score</span><span class=p>,</span> <span class=n>b_groups</span> <span class=o>=</span> <span class=mi>999</span><span class=p>,</span> <span class=mi>999</span><span class=p>,</span> <span class=mi>999</span><span class=p>,</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>index</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span><span class=o>-</span><span class=mi>1</span><span class=p>):</span> <span class=c1># 最后分类不计算</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 根据每个值分类计算出最优基尼值，这个值就作为决策树的节点</span>
</span></span><span class=line><span class=cl>            <span class=n>groups</span> <span class=o>=</span> <span class=n>test_split</span><span class=p>(</span><span class=n>index</span><span class=p>,</span> <span class=n>row</span><span class=p>[</span><span class=n>index</span><span class=p>],</span> <span class=n>dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>gini</span> <span class=o>=</span> <span class=n>gini_index</span><span class=p>(</span><span class=n>groups</span><span class=p>,</span> <span class=n>class_values</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;X</span><span class=si>%d</span><span class=s1> &lt; </span><span class=si>%.3f</span><span class=s1> Gini=</span><span class=si>%.3f</span><span class=s1>&#39;</span> <span class=o>%</span> <span class=p>((</span><span class=n>index</span><span class=o>+</span><span class=mi>1</span><span class=p>),</span> <span class=n>row</span><span class=p>[</span><span class=n>index</span><span class=p>],</span> <span class=n>gini</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>gini</span> <span class=o>&lt;</span> <span class=n>b_score</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>b_index</span><span class=p>,</span> <span class=n>b_value</span><span class=p>,</span> <span class=n>b_score</span><span class=p>,</span> <span class=n>b_groups</span> <span class=o>=</span> <span class=n>index</span><span class=p>,</span> <span class=n>row</span><span class=p>[</span><span class=n>index</span><span class=p>],</span> <span class=n>gini</span><span class=p>,</span> <span class=n>groups</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span><span class=s1>&#39;index&#39;</span><span class=p>:</span><span class=n>b_index</span><span class=p>,</span> <span class=s1>&#39;value&#39;</span><span class=p>:</span><span class=n>b_value</span><span class=p>,</span> <span class=s1>&#39;groups&#39;</span><span class=p>:</span><span class=n>b_groups</span><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>dataset</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>2.771244718</span><span class=p>,</span><span class=mf>1.784783929</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>1.728571309</span><span class=p>,</span><span class=mf>1.169761413</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>3.678319846</span><span class=p>,</span><span class=mf>2.81281357</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>3.961043357</span><span class=p>,</span><span class=mf>2.61995032</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>2.999208922</span><span class=p>,</span><span class=mf>2.209014212</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>7.497545867</span><span class=p>,</span><span class=mf>3.162953546</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>9.00220326</span><span class=p>,</span><span class=mf>3.339047188</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>7.444542326</span><span class=p>,</span><span class=mf>0.476683375</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>10.12493903</span><span class=p>,</span><span class=mf>3.234550982</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>6.642287351</span><span class=p>,</span><span class=mf>3.319983761</span><span class=p>,</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>split</span> <span class=o>=</span> <span class=n>get_split</span><span class=p>(</span><span class=n>dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Split: [X</span><span class=si>%d</span><span class=s1> &lt; </span><span class=si>%.3f</span><span class=s1>]&#39;</span> <span class=o>%</span> <span class=p>((</span><span class=n>split</span><span class=p>[</span><span class=s1>&#39;index&#39;</span><span class=p>]</span><span class=o>+</span><span class=mi>1</span><span class=p>),</span> <span class=n>split</span><span class=p>[</span><span class=s1>&#39;value&#39;</span><span class=p>]))</span></span></span></code></pre></td></tr></table></div></div></div></div><p>通过执行结果可以看出，<code>X1 &lt; 6.642 Gini=0.000 </code>基尼指数为 0.0 为完美分割。</p><h4 id=如何构建树>如何构建树<a hidden class=anchor aria-hidden=true href=#如何构建树>#</a></h4><p>构建树主要分为 3 个部分</p><ul><li>终端节点 <code>Terminal Nodes</code> 零度节点称为终端节点或叶节点</li><li>递归拆分</li><li>建造一棵树</li></ul><h5 id=终端节点>终端节点<a hidden class=anchor aria-hidden=true href=#终端节点>#</a></h5><p>需要决定何时停止种植树，这里可以使用节点在训练数据集中负责的<strong>深度</strong>和<strong>行数</strong>来做到。</p><ul><li><strong>树的最大深度</strong>：从树的根节点开始的最大节点数。一旦达到树的最大深度，停止拆分新节点。</li><li><strong>最小节点</strong>：对一个节点的要训练的最小值。一旦达到或低于此最小值，则停止拆分和添加新节点。</li></ul><p>这两种方法将是构建树的过程时用户的指定参数。当在给定点停止增长时，该节点称为终端节点，用于进行最终预测。</p><p>编写一个函数<strong>to_terminal()</strong>，这个函数将为一组行选择一类。它返回行列表中最常见的输出值。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>to_terminal</span><span class=p>(</span><span class=n>group</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=n>outcomes</span> <span class=o>=</span> <span class=p>[</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>group</span><span class=p>]</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nb>max</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>outcomes</span><span class=p>),</span> <span class=n>key</span><span class=o>=</span><span class=n>outcomes</span><span class=o>.</span><span class=n>count</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div></div></div><h5 id=递归拆分>递归拆分<a hidden class=anchor aria-hidden=true href=#递归拆分>#</a></h5><p>构建决策树会在为每个节点创建的组上一遍又一遍地调用 <code>get_split()</code> 函数。</p><p>添加到现有节点的新节点称为子节点。一个节点可能有零个子节点（一个终端节点）、一个子节点或两个子节点，这里将在给定节点的字典表示中将子节点称为左和右。当一旦创建出一个节点，则通过再次调用相同的函数来递归地从拆分的每组数据以创建子节点。</p><p>下面需要实现这个过程（递归函数）。函数接受一个节点作为参数，以及节点中的最大深度、最小模式数、节点的当前深度。</p><p>调用的过程分步为。设置，传入根节点和深度1：</p><ul><li>首先，将拆分后的两组数据提取出来使用，当处理过这些组时，节点不再需要访问这些数据。</li><li>接下来，我们检查左或右两组是否为空，如果是，则使用我们拥有的记录创建一个终端节点。</li><li>不为空的情况下，检查是否达到了最大深度，如果是，则创建一个终端节点。</li><li>然后我们处理左子节点，如果行组太小，则创建一个终端节点，否则以深度优先的方式创建并添加左节点，直到在该分支上到达树的底部。最后再以相同的方式处理右侧。</li></ul><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 创建子拆分或者终端节点</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>split</span><span class=p>(</span><span class=n>node</span><span class=p>,</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>,</span> <span class=n>depth</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    :param node: </span><span class=si>{}</span><span class=s2>,分割好的的{&#39;index&#39;:b_index, &#39;value&#39;:b_value, &#39;groups&#39;:b_groups}
</span></span></span><span class=line><span class=cl><span class=s2>    :param max_depth: int, 最大深度
</span></span></span><span class=line><span class=cl><span class=s2>    :param min_size:int，最小模式数
</span></span></span><span class=line><span class=cl><span class=s2>    :param depth:int， 当前深度
</span></span></span><span class=line><span class=cl><span class=s2>    :return: None
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>left</span><span class=p>,</span> <span class=n>right</span> <span class=o>=</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;groups&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>del</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;groups&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=c1># 检查两边的分割问题</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=n>left</span> <span class=ow>or</span> <span class=ow>not</span> <span class=n>right</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>to_terminal</span><span class=p>(</span><span class=n>left</span> <span class=o>+</span> <span class=n>right</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span>
</span></span><span class=line><span class=cl>    <span class=c1># 检查最大的深度</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>depth</span> <span class=o>&gt;=</span> <span class=n>max_depth</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>],</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>to_terminal</span><span class=p>(</span><span class=n>left</span><span class=p>),</span> <span class=n>to_terminal</span><span class=p>(</span><span class=n>right</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span>
</span></span><span class=line><span class=cl>    <span class=c1># 处理左分支，数量要小于最小模式数为terminal node</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>left</span><span class=p>)</span> <span class=o>&lt;=</span> <span class=n>min_size</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>to_terminal</span><span class=p>(</span><span class=n>left</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>get_split</span><span class=p>(</span><span class=n>left</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>split</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>],</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>,</span> <span class=n>depth</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=c1># 否则递归</span>
</span></span><span class=line><span class=cl>    <span class=c1># 处理左右支，数量要小于最小模式数为terminal node</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>right</span><span class=p>)</span> <span class=o>&lt;=</span> <span class=n>min_size</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>to_terminal</span><span class=p>(</span><span class=n>right</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>get_split</span><span class=p>(</span><span class=n>right</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>split</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>],</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>,</span> <span class=n>depth</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div></div></div><h5 id=创建树>创建树<a hidden class=anchor aria-hidden=true href=#创建树>#</a></h5><p>构建一个树就是一个上面的步骤的合并，通过**split()**函数打分并确定树的根节点，然后通过递归来构建出整个树；下面代码是实现此过程的函数 <strong>build_tree()</strong>。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Build a decision tree</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>build_tree</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    :param train: list, 数据集，可以是训练集
</span></span></span><span class=line><span class=cl><span class=s2>    :param max_depth: int, 最大深度
</span></span></span><span class=line><span class=cl><span class=s2>    :param min_size:int，最小模式数
</span></span></span><span class=line><span class=cl><span class=s2>    :return: None
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>root</span> <span class=o>=</span> <span class=n>get_split</span><span class=p>(</span><span class=n>train</span><span class=p>)</span> <span class=c1># 对整个数据集进行打分</span>
</span></span><span class=line><span class=cl>    <span class=n>split</span><span class=p>(</span><span class=n>root</span><span class=p>,</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>root</span></span></span></code></pre></td></tr></table></div></div></div></div><h5 id=整合>整合<a hidden class=anchor aria-hidden=true href=#整合>#</a></h5><p>将全部代码整合为一个</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Split a dataset based on an attribute and an attribute value</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_split</span><span class=p>(</span><span class=n>index</span><span class=p>,</span> <span class=n>value</span><span class=p>,</span> <span class=n>dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>left</span><span class=p>,</span> <span class=n>right</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(),</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>row</span><span class=p>[</span><span class=n>index</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>value</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>left</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>right</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>left</span><span class=p>,</span> <span class=n>right</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Calculate the Gini index for a split dataset</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>gini_index</span><span class=p>(</span><span class=n>groups</span><span class=p>,</span> <span class=n>classes</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算两组数据集的总数每个种类的列表数量和</span>
</span></span><span class=line><span class=cl>    <span class=n>n_instances</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=nb>sum</span><span class=p>([</span><span class=nb>len</span><span class=p>(</span><span class=n>group</span><span class=p>)</span> <span class=k>for</span> <span class=n>group</span> <span class=ow>in</span> <span class=n>groups</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算每组的基尼值</span>
</span></span><span class=line><span class=cl>    <span class=n>gini</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>group</span> <span class=ow>in</span> <span class=n>groups</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>size</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>group</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=c1># avoid divide by zero</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>size</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>continue</span>
</span></span><span class=line><span class=cl>        <span class=n>score</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>        <span class=c1># score the group based on the score for each class</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>class_val</span> <span class=ow>in</span> <span class=n>classes</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 拿出数据集中每行的类型，拆开是为了更好的了解结构</span>
</span></span><span class=line><span class=cl>            <span class=n>p</span> <span class=o>=</span> <span class=p>[</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>group</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=c1># print(&#34;%f / %f = %f&#34; % (p.count(class_val), size, p.count(class_val) / size ))</span>
</span></span><span class=line><span class=cl>            <span class=c1># 这里计算的是当前的分类在总数据集中占比</span>
</span></span><span class=line><span class=cl>            <span class=n>p1</span> <span class=o>=</span> <span class=n>p</span><span class=o>.</span><span class=n>count</span><span class=p>(</span><span class=n>class_val</span><span class=p>)</span> <span class=o>/</span> <span class=n>size</span>
</span></span><span class=line><span class=cl>            <span class=n>score</span> <span class=o>+=</span> <span class=n>p1</span> <span class=o>*</span> <span class=n>p1</span> <span class=c1># gini index formula = 1 - sum(p_i^2)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 计算总的基尼指数，权重：当前分组占总数据集中的数量</span>
</span></span><span class=line><span class=cl>        <span class=n>gini</span> <span class=o>+=</span> <span class=p>(</span><span class=mf>1.0</span> <span class=o>-</span> <span class=n>score</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=n>size</span> <span class=o>/</span> <span class=n>n_instances</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>gini</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Select the best split point for a dataset</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_split</span><span class=p>(</span><span class=n>dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>class_values</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>b_index</span><span class=p>,</span> <span class=n>b_value</span><span class=p>,</span> <span class=n>b_score</span><span class=p>,</span> <span class=n>b_groups</span> <span class=o>=</span> <span class=mi>999</span><span class=p>,</span> <span class=mi>999</span><span class=p>,</span> <span class=mi>999</span><span class=p>,</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>index</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span><span class=o>-</span><span class=mi>1</span><span class=p>):</span> <span class=c1># 最后分类不计算</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 根据每个值分类计算出最优基尼值，这个值就作为决策树的节点</span>
</span></span><span class=line><span class=cl>            <span class=n>groups</span> <span class=o>=</span> <span class=n>test_split</span><span class=p>(</span><span class=n>index</span><span class=p>,</span> <span class=n>row</span><span class=p>[</span><span class=n>index</span><span class=p>],</span> <span class=n>dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>gini</span> <span class=o>=</span> <span class=n>gini_index</span><span class=p>(</span><span class=n>groups</span><span class=p>,</span> <span class=n>class_values</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># print(&#39;X%d &lt; %.3f Gini=%.3f&#39; % ((index+1), row[index], gini))</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>gini</span> <span class=o>&lt;</span> <span class=n>b_score</span><span class=p>:</span> <span class=c1># 拿到最小的gini index那列</span>
</span></span><span class=line><span class=cl>                <span class=n>b_index</span><span class=p>,</span> <span class=n>b_value</span><span class=p>,</span> <span class=n>b_score</span><span class=p>,</span> <span class=n>b_groups</span> <span class=o>=</span> <span class=n>index</span><span class=p>,</span> <span class=n>row</span><span class=p>[</span><span class=n>index</span><span class=p>],</span> <span class=n>gini</span><span class=p>,</span> <span class=n>groups</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span><span class=s1>&#39;index&#39;</span><span class=p>:</span><span class=n>b_index</span><span class=p>,</span> <span class=s1>&#39;value&#39;</span><span class=p>:</span><span class=n>b_value</span><span class=p>,</span> <span class=s1>&#39;groups&#39;</span><span class=p>:</span><span class=n>b_groups</span><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 创建子拆分或者终端节点</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>split</span><span class=p>(</span><span class=n>node</span><span class=p>,</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>,</span> <span class=n>depth</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    :param node: </span><span class=si>{}</span><span class=s2>,分割好的的{&#39;index&#39;:b_index, &#39;value&#39;:b_value, &#39;groups&#39;:b_groups}
</span></span></span><span class=line><span class=cl><span class=s2>    :param max_depth: int, 最大深度
</span></span></span><span class=line><span class=cl><span class=s2>    :param min_size:int，最小模式数
</span></span></span><span class=line><span class=cl><span class=s2>    :param depth:int， 当前深度
</span></span></span><span class=line><span class=cl><span class=s2>    :return: None
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>left</span><span class=p>,</span> <span class=n>right</span> <span class=o>=</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;groups&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>del</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;groups&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=c1># 检查两边的分割问题</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=n>left</span> <span class=ow>or</span> <span class=ow>not</span> <span class=n>right</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>to_terminal</span><span class=p>(</span><span class=n>left</span> <span class=o>+</span> <span class=n>right</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span>
</span></span><span class=line><span class=cl>    <span class=c1># 检查最大的深度</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>depth</span> <span class=o>&gt;=</span> <span class=n>max_depth</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>],</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>to_terminal</span><span class=p>(</span><span class=n>left</span><span class=p>),</span> <span class=n>to_terminal</span><span class=p>(</span><span class=n>right</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span>
</span></span><span class=line><span class=cl>    <span class=c1># 处理左分支，数量要小于最小模式数为terminal node</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>left</span><span class=p>)</span> <span class=o>&lt;=</span> <span class=n>min_size</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>to_terminal</span><span class=p>(</span><span class=n>left</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>get_split</span><span class=p>(</span><span class=n>left</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>split</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>],</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>,</span> <span class=n>depth</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=c1># 否则递归</span>
</span></span><span class=line><span class=cl>    <span class=c1># 处理左右支，数量要小于最小模式数为terminal node</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>right</span><span class=p>)</span> <span class=o>&lt;=</span> <span class=n>min_size</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>to_terminal</span><span class=p>(</span><span class=n>right</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>get_split</span><span class=p>(</span><span class=n>right</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>split</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>],</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>,</span> <span class=n>depth</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Build a decision tree</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>build_tree</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    :param train: list, 数据集，可以是训练集
</span></span></span><span class=line><span class=cl><span class=s2>    :param max_depth: int, 最大深度
</span></span></span><span class=line><span class=cl><span class=s2>    :param min_size:int，最小模式数
</span></span></span><span class=line><span class=cl><span class=s2>    :return: None
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>root</span> <span class=o>=</span> <span class=n>get_split</span><span class=p>(</span><span class=n>train</span><span class=p>)</span> <span class=c1># 对整个数据集进行打分</span>
</span></span><span class=line><span class=cl>    <span class=n>split</span><span class=p>(</span><span class=n>root</span><span class=p>,</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>root</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 打印树</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>print_tree</span><span class=p>(</span><span class=n>node</span><span class=p>,</span> <span class=n>depth</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>node</span><span class=p>,</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;</span><span class=si>%s</span><span class=s1>[X</span><span class=si>%d</span><span class=s1> &lt; </span><span class=si>%.3f</span><span class=s1>]&#39;</span> <span class=o>%</span> <span class=p>(</span> <span class=p>(</span><span class=n>depth</span><span class=o>*</span><span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;index&#39;</span><span class=p>]</span><span class=o>+</span><span class=mi>1</span><span class=p>),</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;value&#39;</span><span class=p>])</span> <span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>print_tree</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>],</span> <span class=n>depth</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=c1># 递归打印左右</span>
</span></span><span class=line><span class=cl>        <span class=n>print_tree</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>],</span> <span class=n>depth</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;</span><span class=si>%s</span><span class=s1>[</span><span class=si>%s</span><span class=s1>]&#39;</span> <span class=o>%</span> <span class=p>((</span><span class=n>depth</span><span class=o>*</span><span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>node</span><span class=p>)))</span> <span class=c1># 不是对象就是terminal node</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 创建一个terminal node</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>to_terminal</span><span class=p>(</span><span class=n>group</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>outcomes</span> <span class=o>=</span> <span class=p>[</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>group</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nb>max</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>outcomes</span><span class=p>),</span> <span class=n>key</span><span class=o>=</span><span class=n>outcomes</span><span class=o>.</span><span class=n>count</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>dataset</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>2.771244718</span><span class=p>,</span><span class=mf>1.784783929</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>1.728571309</span><span class=p>,</span><span class=mf>1.169761413</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>3.678319846</span><span class=p>,</span><span class=mf>2.81281357</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>3.961043357</span><span class=p>,</span><span class=mf>2.61995032</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>2.999208922</span><span class=p>,</span><span class=mf>2.209014212</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>7.497545867</span><span class=p>,</span><span class=mf>3.162953546</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>9.00220326</span><span class=p>,</span><span class=mf>3.339047188</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>7.444542326</span><span class=p>,</span><span class=mf>0.476683375</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>10.12493903</span><span class=p>,</span><span class=mf>3.234550982</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>6.642287351</span><span class=p>,</span><span class=mf>3.319983761</span><span class=p>,</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span><span class=o>==</span><span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>tree</span> <span class=o>=</span> <span class=n>build_tree</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>print_tree</span><span class=p>(</span><span class=n>tree</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div></div></div><p>可以看到打印结果是一个类似二叉树的</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>text</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>[X1 &lt; 6.642]
</span></span><span class=line><span class=cl> [X1 &lt; 2.771]
</span></span><span class=line><span class=cl>  [0]
</span></span><span class=line><span class=cl>  [X1 &lt; 2.771]
</span></span><span class=line><span class=cl>   [0]
</span></span><span class=line><span class=cl>   [0]
</span></span><span class=line><span class=cl> [X1 &lt; 7.498]
</span></span><span class=line><span class=cl>  [X1 &lt; 7.445]
</span></span><span class=line><span class=cl>   [1]
</span></span><span class=line><span class=cl>   [1]
</span></span><span class=line><span class=cl>  [X1 &lt; 7.498]
</span></span><span class=line><span class=cl>   [1]
</span></span><span class=line><span class=cl>   [1]</span></span></code></pre></td></tr></table></div></div></div></div><h5 id=预测>预测<a hidden class=anchor aria-hidden=true href=#预测>#</a></h5><p>预测是预测数据是该向右还是向左，是作为对数据进行导航的方式。这里可以使用递归来实现，其中使用左侧或右侧子节点再次调用相同的预测，具体取决于拆分如何影响提供的数据。</p><p>我们必须检查子节点是否是要作为预测返回的终端值，或者它是否是包含要考虑的树的另一个级别的字典节点。</p><p>下面是实现此过程的函数 <strong>predict()</strong>。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Make a prediction with a decision tree</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>predict</span><span class=p>(</span><span class=n>node</span><span class=p>,</span> <span class=n>row</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=n>row</span><span class=p>[</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;index&#39;</span><span class=p>]]</span> <span class=o>&lt;</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;value&#39;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>],</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>			<span class=k>return</span> <span class=n>predict</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>],</span> <span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>			<span class=k>return</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>	<span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>],</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>			<span class=k>return</span> <span class=n>predict</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>],</span> <span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>			<span class=k>return</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span></span></span></code></pre></td></tr></table></div></div></div></div><p>下面是一个使用硬编码决策树的示例，该决策树具有一个最好地分割数据的节点（决策树桩，这个就是gini index的最优质值）。通过对上面的测试数据集例来对每一行进行预测。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>predict</span><span class=p>(</span><span class=n>node</span><span class=p>,</span> <span class=n>row</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 如果gini index与对应属性的值小于则向左，</span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=n>row</span><span class=p>[</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;index&#39;</span><span class=p>]]</span> <span class=o>&lt;</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;value&#39;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>],</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>			<span class=k>return</span> <span class=n>predict</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>],</span> <span class=n>row</span><span class=p>)</span> <span class=c1># 递归处理完整个树</span>
</span></span><span class=line><span class=cl>		<span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>			<span class=k>return</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>	<span class=k>else</span><span class=p>:</span> <span class=c1># 否则的话，则为右</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>],</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>			<span class=k>return</span> <span class=n>predict</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>],</span> <span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>			<span class=k>return</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=n>dataset</span> <span class=o>=</span> <span class=p>[[</span><span class=mf>2.771244718</span><span class=p>,</span><span class=mf>1.784783929</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>1.728571309</span><span class=p>,</span><span class=mf>1.169761413</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>3.678319846</span><span class=p>,</span><span class=mf>2.81281357</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>3.961043357</span><span class=p>,</span><span class=mf>2.61995032</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>2.999208922</span><span class=p>,</span><span class=mf>2.209014212</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>7.497545867</span><span class=p>,</span><span class=mf>3.162953546</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>9.00220326</span><span class=p>,</span><span class=mf>3.339047188</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>7.444542326</span><span class=p>,</span><span class=mf>0.476683375</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>10.12493903</span><span class=p>,</span><span class=mf>3.234550982</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>6.642287351</span><span class=p>,</span><span class=mf>3.319983761</span><span class=p>,</span><span class=mi>1</span><span class=p>]]</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1>#  这是之前用于计算出最优的gini index</span>
</span></span><span class=line><span class=cl><span class=n>stump</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;index&#39;</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span> <span class=s1>&#39;right&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;value&#39;</span><span class=p>:</span> <span class=mf>6.642287351</span><span class=p>,</span> <span class=s1>&#39;left&#39;</span><span class=p>:</span> <span class=mi>0</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>	<span class=n>prediction</span> <span class=o>=</span> <span class=n>predict</span><span class=p>(</span><span class=n>stump</span><span class=p>,</span> <span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Expected=</span><span class=si>%d</span><span class=s1>, Got=</span><span class=si>%d</span><span class=s1>&#39;</span> <span class=o>%</span> <span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>],</span> <span class=n>prediction</span><span class=p>))</span></span></span></code></pre></td></tr></table></div></div></div></div><p>通过观察可以看出预测结果和实际结果一样</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>Expected</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>Got</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=n>Expected</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>Got</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=n>Expected</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>Got</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=n>Expected</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>Got</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=n>Expected</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>Got</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=n>Expected</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>Got</span><span class=o>=</span><span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=n>Expected</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>Got</span><span class=o>=</span><span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=n>Expected</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>Got</span><span class=o>=</span><span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=n>Expected</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>Got</span><span class=o>=</span><span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=n>Expected</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>Got</span><span class=o>=</span><span class=mi>1</span></span></span></code></pre></td></tr></table></div></div></div></div><h4 id=套用真实数据集来测试>套用真实数据集来测试<a hidden class=anchor aria-hidden=true href=#套用真实数据集来测试>#</a></h4><p>这里将使用 <code>CART</code> 算法对<a href=https://archive.ics.uci.edu/ml/datasets/banknote+authentication target=_blank rel="noopener nofollow noreferrer">银行钞票数据集</a>进行预测。大概的流程为：</p><ul><li>加载数据集并转换格式。</li><li>编写拆分算法与准确度计算算法；这里使用 5折的k折交叉验证（<code>k-fold cross validation</code>）用于评估算法</li><li>编写 CART 算法，从训练数据集，创建树，对测试数据集进行预测操作</li></ul><h5 id=什么是-k折交叉验证>什么是 K折交叉验证<a hidden class=anchor aria-hidden=true href=#什么是-k折交叉验证>#</a></h5><p>K折较差验证（<strong>K-Fold CV</strong>）是将给定的数据集分成<strong>K</strong>个部分，其中每个折叠在某时用作测试集。以 5 折（K=5）为例。这种情况下，数据集被分成5份。在第一次迭代中，第一份用于测试模型，其余用于训练模型。在第二次迭代中，第 2 份用作测试集，其余用作训练集。重复这个过程，直到 5 个折叠中的每个折叠都被用作测试集。</p><p><div class=pe-fancybox><a data-fancybox=gallery href=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/1IjKy-Zc9zVOHFzMw2GXaQw.png><img src=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/1IjKy-Zc9zVOHFzMw2GXaQw.png#center alt="K-Fold CV" onerror='this.onerror=null,this.src="/placeholder.svg",this.className="pe-image-placeholder"'></a></div></p><p>下面来开始编写函数，函数的整个过程为</p><ul><li><code>evaluate_algorithm()</code> 作为最外层调用<ul><li>使用五折交叉进行评估 <code>cross_validation_split()</code></li><li>使用决策树算法作为算法根据 <code>decision_tree()</code></li><li>构建树：<code>build_tree()</code><ul><li>拿到最优基尼指数作为叶子 <code>get_split()</code></li></ul></li></ul></li></ul><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span><span class=lnt>129
</span><span class=lnt>130
</span><span class=lnt>131
</span><span class=lnt>132
</span><span class=lnt>133
</span><span class=lnt>134
</span><span class=lnt>135
</span><span class=lnt>136
</span><span class=lnt>137
</span><span class=lnt>138
</span><span class=lnt>139
</span><span class=lnt>140
</span><span class=lnt>141
</span><span class=lnt>142
</span><span class=lnt>143
</span><span class=lnt>144
</span><span class=lnt>145
</span><span class=lnt>146
</span><span class=lnt>147
</span><span class=lnt>148
</span><span class=lnt>149
</span><span class=lnt>150
</span><span class=lnt>151
</span><span class=lnt>152
</span><span class=lnt>153
</span><span class=lnt>154
</span><span class=lnt>155
</span><span class=lnt>156
</span><span class=lnt>157
</span><span class=lnt>158
</span><span class=lnt>159
</span><span class=lnt>160
</span><span class=lnt>161
</span><span class=lnt>162
</span><span class=lnt>163
</span><span class=lnt>164
</span><span class=lnt>165
</span><span class=lnt>166
</span><span class=lnt>167
</span><span class=lnt>168
</span><span class=lnt>169
</span><span class=lnt>170
</span><span class=lnt>171
</span><span class=lnt>172
</span><span class=lnt>173
</span><span class=lnt>174
</span><span class=lnt>175
</span><span class=lnt>176
</span><span class=lnt>177
</span><span class=lnt>178
</span><span class=lnt>179
</span><span class=lnt>180
</span><span class=lnt>181
</span><span class=lnt>182
</span><span class=lnt>183
</span><span class=lnt>184
</span><span class=lnt>185
</span><span class=lnt>186
</span><span class=lnt>187
</span><span class=lnt>188
</span><span class=lnt>189
</span><span class=lnt>190
</span><span class=lnt>191
</span><span class=lnt>192
</span><span class=lnt>193
</span><span class=lnt>194
</span><span class=lnt>195
</span><span class=lnt>196
</span><span class=lnt>197
</span><span class=lnt>198
</span><span class=lnt>199
</span><span class=lnt>200
</span><span class=lnt>201
</span><span class=lnt>202
</span><span class=lnt>203
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>random</span> <span class=kn>import</span> <span class=n>seed</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>random</span> <span class=kn>import</span> <span class=n>randrange</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>csv</span> <span class=kn>import</span> <span class=n>reader</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 加载csv文件</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_csv</span><span class=p>(</span><span class=n>filename</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=n>file</span> <span class=o>=</span> <span class=nb>open</span><span class=p>(</span><span class=n>filename</span><span class=p>,</span> <span class=s2>&#34;rt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=n>lines</span> <span class=o>=</span> <span class=n>reader</span><span class=p>(</span><span class=n>file</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=n>dataset</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>lines</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=n>dataset</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 将所有字段转换为float类型便于计算</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>str_column_to_float</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>column</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=n>row</span><span class=p>[</span><span class=n>column</span><span class=p>]</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=n>column</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>())</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># k-folds CV函数</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>cross_validation_split</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>n_folds</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=n>dataset_split</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=n>dataset_copy</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 平均分位折数n_folds</span>
</span></span><span class=line><span class=cl>	<span class=n>fold_size</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>)</span> <span class=o>/</span> <span class=n>n_folds</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_folds</span><span class=p>):</span>
</span></span><span class=line><span class=cl>		<span class=n>fold</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>		<span class=k>while</span> <span class=nb>len</span><span class=p>(</span><span class=n>fold</span><span class=p>)</span> <span class=o>&lt;</span> <span class=n>fold_size</span><span class=p>:</span>
</span></span><span class=line><span class=cl>			<span class=n>index</span> <span class=o>=</span> <span class=n>randrange</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset_copy</span><span class=p>))</span> <span class=c1># 随机</span>
</span></span><span class=line><span class=cl>			<span class=n>fold</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>dataset_copy</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=n>index</span><span class=p>))</span>
</span></span><span class=line><span class=cl>		<span class=n>dataset_split</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>fold</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=n>dataset_split</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 计算精确度</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>accuracy_metric</span><span class=p>(</span><span class=n>actual</span><span class=p>,</span> <span class=n>predicted</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>actual</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=n>actual</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>==</span> <span class=n>predicted</span><span class=p>[</span><span class=n>i</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>			<span class=n>correct</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=n>correct</span> <span class=o>/</span> <span class=nb>float</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>actual</span><span class=p>))</span> <span class=o>*</span> <span class=mf>100.0</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># Evaluate an algorithm using a cross validation split</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>evaluate_algorithm</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>algorithm</span><span class=p>,</span> <span class=n>n_folds</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=n>folds</span> <span class=o>=</span> <span class=n>cross_validation_split</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>n_folds</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=n>scores</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>fold</span> <span class=ow>in</span> <span class=n>folds</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=n>train_set</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>folds</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>train_set</span><span class=o>.</span><span class=n>remove</span><span class=p>(</span><span class=n>fold</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>train_set</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>train_set</span><span class=p>,</span> <span class=p>[])</span>
</span></span><span class=line><span class=cl>		<span class=n>test_set</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>		<span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>fold</span><span class=p>:</span>
</span></span><span class=line><span class=cl>			<span class=n>row_copy</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>			<span class=n>test_set</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>row_copy</span><span class=p>)</span>
</span></span><span class=line><span class=cl>			<span class=n>row_copy</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>		<span class=n>predicted</span> <span class=o>=</span> <span class=n>algorithm</span><span class=p>(</span><span class=n>train_set</span><span class=p>,</span> <span class=n>test_set</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>actual</span> <span class=o>=</span> <span class=p>[</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>fold</span><span class=p>]</span>
</span></span><span class=line><span class=cl>		<span class=n>accuracy</span> <span class=o>=</span> <span class=n>accuracy_metric</span><span class=p>(</span><span class=n>actual</span><span class=p>,</span> <span class=n>predicted</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>accuracy</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=n>scores</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 根据基尼指数划分value是应该在树的哪边？</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_split</span><span class=p>(</span><span class=n>index</span><span class=p>,</span> <span class=n>value</span><span class=p>,</span> <span class=n>dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=n>left</span><span class=p>,</span> <span class=n>right</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(),</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=n>row</span><span class=p>[</span><span class=n>index</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>value</span><span class=p>:</span>
</span></span><span class=line><span class=cl>			<span class=n>left</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>			<span class=n>right</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=n>left</span><span class=p>,</span> <span class=n>right</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 基尼指数打分</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>gini_index</span><span class=p>(</span><span class=n>groups</span><span class=p>,</span> <span class=n>classes</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算数据集中的多组数据的总个数</span>
</span></span><span class=line><span class=cl>    <span class=n>n_instances</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=nb>sum</span><span class=p>([</span><span class=nb>len</span><span class=p>(</span><span class=n>group</span><span class=p>)</span> <span class=k>for</span> <span class=n>group</span> <span class=ow>in</span> <span class=n>groups</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算每组中的最优基尼指数</span>
</span></span><span class=line><span class=cl>    <span class=n>gini</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>group</span> <span class=ow>in</span> <span class=n>groups</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>size</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>group</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>size</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>continue</span>
</span></span><span class=line><span class=cl>        <span class=n>score</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>        <span class=c1># 总基尼指数</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>class_val</span> <span class=ow>in</span> <span class=n>classes</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 拿出数据集中每行的类型，拆开是为了更好的了解结构</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 计算的是当前的分类在总数据集中占比</span>
</span></span><span class=line><span class=cl>            <span class=n>p</span> <span class=o>=</span> <span class=p>[</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>group</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>p1</span> <span class=o>=</span> <span class=n>p</span><span class=o>.</span><span class=n>count</span><span class=p>(</span><span class=n>class_val</span><span class=p>)</span> <span class=o>/</span> <span class=n>size</span>
</span></span><span class=line><span class=cl>            <span class=n>score</span> <span class=o>+=</span> <span class=n>p1</span> <span class=o>*</span> <span class=n>p1</span>
</span></span><span class=line><span class=cl>        <span class=c1># 计算总的基尼指数，并根据相应大小增加权重。权重：当前分组占总数据集中的数量</span>
</span></span><span class=line><span class=cl>        <span class=n>gini</span> <span class=o>+=</span> <span class=p>(</span><span class=mf>1.0</span> <span class=o>-</span> <span class=n>score</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=n>size</span> <span class=o>/</span> <span class=n>n_instances</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>gini</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 从数据集中获得基尼指数最佳的值</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_split</span><span class=p>(</span><span class=n>dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=n>class_values</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>))</span>
</span></span><span class=line><span class=cl>	<span class=n>b_index</span><span class=p>,</span> <span class=n>b_value</span><span class=p>,</span> <span class=n>b_score</span><span class=p>,</span> <span class=n>b_groups</span> <span class=o>=</span> <span class=mi>999</span><span class=p>,</span> <span class=mi>999</span><span class=p>,</span> <span class=mi>999</span><span class=p>,</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>index</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span><span class=o>-</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>		<span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>			<span class=n>groups</span> <span class=o>=</span> <span class=n>test_split</span><span class=p>(</span><span class=n>index</span><span class=p>,</span> <span class=n>row</span><span class=p>[</span><span class=n>index</span><span class=p>],</span> <span class=n>dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>			<span class=n>gini</span> <span class=o>=</span> <span class=n>gini_index</span><span class=p>(</span><span class=n>groups</span><span class=p>,</span> <span class=n>class_values</span><span class=p>)</span>
</span></span><span class=line><span class=cl>			<span class=k>if</span> <span class=n>gini</span> <span class=o>&lt;</span> <span class=n>b_score</span><span class=p>:</span>
</span></span><span class=line><span class=cl>				<span class=n>b_index</span><span class=p>,</span> <span class=n>b_value</span><span class=p>,</span> <span class=n>b_score</span><span class=p>,</span> <span class=n>b_groups</span> <span class=o>=</span> <span class=n>index</span><span class=p>,</span> <span class=n>row</span><span class=p>[</span><span class=n>index</span><span class=p>],</span> <span class=n>gini</span><span class=p>,</span> <span class=n>groups</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=p>{</span><span class=s1>&#39;index&#39;</span><span class=p>:</span><span class=n>b_index</span><span class=p>,</span> <span class=s1>&#39;value&#39;</span><span class=p>:</span><span class=n>b_value</span><span class=p>,</span> <span class=s1>&#39;groups&#39;</span><span class=p>:</span><span class=n>b_groups</span><span class=p>}</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 创建终端节点</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>to_terminal</span><span class=p>(</span><span class=n>group</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=n>outcomes</span> <span class=o>=</span> <span class=p>[</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>group</span><span class=p>]</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nb>max</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>outcomes</span><span class=p>),</span> <span class=n>key</span><span class=o>=</span><span class=n>outcomes</span><span class=o>.</span><span class=n>count</span><span class=p>)</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 创建子节点，为终端节点或子节点</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>split</span><span class=p>(</span><span class=n>node</span><span class=p>,</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>,</span> <span class=n>depth</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    :param node: </span><span class=si>{}</span><span class=s2>,分割好的的{&#39;index&#39;:b_index, &#39;value&#39;:b_value, &#39;groups&#39;:b_groups}
</span></span></span><span class=line><span class=cl><span class=s2>    :param max_depth: int, 最大深度
</span></span></span><span class=line><span class=cl><span class=s2>    :param min_size:int，最小模式数
</span></span></span><span class=line><span class=cl><span class=s2>    :param depth:int， 当前深度
</span></span></span><span class=line><span class=cl><span class=s2>    :return: None
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>left</span><span class=p>,</span> <span class=n>right</span> <span class=o>=</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;groups&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>del</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;groups&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=c1># check for a no split</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=n>left</span> <span class=ow>or</span> <span class=ow>not</span> <span class=n>right</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>to_terminal</span><span class=p>(</span><span class=n>left</span> <span class=o>+</span> <span class=n>right</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span>
</span></span><span class=line><span class=cl>    <span class=c1># check for max depth</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>depth</span> <span class=o>&gt;=</span> <span class=n>max_depth</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>],</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>to_terminal</span><span class=p>(</span><span class=n>left</span><span class=p>),</span> <span class=n>to_terminal</span><span class=p>(</span><span class=n>right</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span>
</span></span><span class=line><span class=cl>    <span class=c1># process left child</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>left</span><span class=p>)</span> <span class=o>&lt;=</span> <span class=n>min_size</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>to_terminal</span><span class=p>(</span><span class=n>left</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>get_split</span><span class=p>(</span><span class=n>left</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>split</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>],</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>,</span> <span class=n>depth</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># process right child</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>right</span><span class=p>)</span> <span class=o>&lt;=</span> <span class=n>min_size</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>to_terminal</span><span class=p>(</span><span class=n>right</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>get_split</span><span class=p>(</span><span class=n>right</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>split</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>],</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>,</span> <span class=n>depth</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 构建树</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>build_tree</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    :param train: list, 数据集，可以是训练集
</span></span></span><span class=line><span class=cl><span class=s2>    :param max_depth: int, 最大深度
</span></span></span><span class=line><span class=cl><span class=s2>    :param min_size:int，最小模式数
</span></span></span><span class=line><span class=cl><span class=s2>    :ret
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>root</span> <span class=o>=</span> <span class=n>get_split</span><span class=p>(</span><span class=n>train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>split</span><span class=p>(</span><span class=n>root</span><span class=p>,</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>root</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 打印树</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>print_tree</span><span class=p>(</span><span class=n>node</span><span class=p>,</span> <span class=n>depth</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>node</span><span class=p>,</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;</span><span class=si>%s</span><span class=s1>[X</span><span class=si>%d</span><span class=s1> &lt; </span><span class=si>%.3f</span><span class=s1>]&#39;</span> <span class=o>%</span> <span class=p>(</span> <span class=p>(</span><span class=n>depth</span><span class=o>*</span><span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;index&#39;</span><span class=p>]</span><span class=o>+</span><span class=mi>1</span><span class=p>),</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;value&#39;</span><span class=p>])</span> <span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>print_tree</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>],</span> <span class=n>depth</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=c1># 递归打印左右</span>
</span></span><span class=line><span class=cl>        <span class=n>print_tree</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>],</span> <span class=n>depth</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;</span><span class=si>%s</span><span class=s1>[</span><span class=si>%s</span><span class=s1>]&#39;</span> <span class=o>%</span> <span class=p>((</span><span class=n>depth</span><span class=o>*</span><span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>node</span><span class=p>)))</span> <span class=c1># 不是对象就是terminal node</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 预测，预测方式为当前基尼指数与最优基尼指数相比较，然后放入树两侧</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>predict</span><span class=p>(</span><span class=n>node</span><span class=p>,</span> <span class=n>row</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    :param node: </span><span class=si>{}</span><span class=s2> 叶子值
</span></span></span><span class=line><span class=cl><span class=s2>    :param row: </span><span class=si>{}</span><span class=s2>, 需要预测值
</span></span></span><span class=line><span class=cl><span class=s2>    :ret
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>row</span><span class=p>[</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;index&#39;</span><span class=p>]]</span> <span class=o>&lt;</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;value&#39;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>],</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>predict</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>],</span> <span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;left&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>],</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>predict</span><span class=p>(</span><span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>],</span> <span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>node</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>decision_tree</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>test</span><span class=p>,</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=n>tree</span> <span class=o>=</span> <span class=n>build_tree</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=n>predictions</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>test</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=n>prediction</span> <span class=o>=</span> <span class=n>predict</span><span class=p>(</span><span class=n>tree</span><span class=p>,</span> <span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>predictions</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>prediction</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span><span class=p>(</span><span class=n>predictions</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Test CART on Bank Note dataset</span>
</span></span><span class=line><span class=cl><span class=n>seed</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 加载数据</span>
</span></span><span class=line><span class=cl><span class=n>filename</span> <span class=o>=</span> <span class=s1>&#39;data_banknote_authentication.csv&#39;</span>
</span></span><span class=line><span class=cl><span class=n>dataset</span> <span class=o>=</span> <span class=n>load_csv</span><span class=p>(</span><span class=n>filename</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 转换格式</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>[</span><span class=mi>0</span><span class=p>])):</span>
</span></span><span class=line><span class=cl>	<span class=n>str_column_to_float</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 评估算法</span>
</span></span><span class=line><span class=cl><span class=n>n_folds</span> <span class=o>=</span> <span class=mi>5</span>
</span></span><span class=line><span class=cl><span class=n>max_depth</span> <span class=o>=</span> <span class=mi>5</span>
</span></span><span class=line><span class=cl><span class=n>min_size</span> <span class=o>=</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl><span class=n>scores</span> <span class=o>=</span> <span class=n>evaluate_algorithm</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>decision_tree</span><span class=p>,</span> <span class=n>n_folds</span><span class=p>,</span> <span class=n>max_depth</span><span class=p>,</span> <span class=n>min_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Scores: </span><span class=si>%s</span><span class=s1>&#39;</span> <span class=o>%</span> <span class=n>scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Mean Accuracy: </span><span class=si>%.3f%%</span><span class=s1>&#39;</span> <span class=o>%</span> <span class=p>(</span><span class=nb>sum</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span><span class=o>/</span><span class=nb>float</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>scores</span><span class=p>))))</span></span></span></code></pre></td></tr></table></div></div></div></div><h2 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h2><blockquote><p><a href=https://www.bogotobogo.com/python/scikit-learn/scikt_machine_learning_Decision_Tree_Learning_Informatioin_Gain_IG_Impurity_Entropy_Gini_Classification_Error.php target=_blank rel="noopener nofollow noreferrer">Informatioin Gain</a></p><p><a href=https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/ target=_blank rel="noopener nofollow noreferrer">implement decision tree algorithm</a></p><p><a href=https://machinelearningmastery.com/information-gain-and-mutual-information/ target=_blank rel="noopener nofollow noreferrer">inplement information gain</a></p></blockquote></div><div class=pe-copyright><hr><blockquote><p>本文为原创内容，版权归作者所有。如需转载，请在文章中声明本文标题及链接。</p><p>文章标题：决策树</p><p>文章链接：<a href=https://www.oomkill.com/2022/06/decision-tree/ target=_blank>https://www.oomkill.com/2022/06/decision-tree/</a></p><p>许可协议：<a href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></p></blockquote></div><div class=comments-separator></div><h3 class=relatedContentTitle>相关阅读</h3><ul class=relatedContent><li><a href=/2022/06/knn/><span>KNN算法</span></a></li><li><a href=/2022/06/decision-boundary/><span>决策边界算法</span></a></li><li><a href=/2022/06/naive-bayes/><span>朴素贝叶斯算法</span></a></li><li><a href=/2022/06/logistic-regression/><span>逻辑回归</span></a></li><li><a href=/2016/09/consistent-hash/><span>一致性hash在memcache中的应用</span></a></li></ul><div class=comments-separator></div><footer class=post-footer><ul class=post-tags><li><a href=https://www.oomkill.com/tags/machinelearning/>MachineLearning</a></li><li><a href=https://www.oomkill.com/tags/algorithm/>Algorithm</a></li><li><a href=https://www.oomkill.com/tags/cs/>CS</a></li></ul><nav class=paginav><a class=prev href=https://www.oomkill.com/2022/06/decision-boundary/><span class=title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left" style="user-select:text"><line x1="19" y1="12" x2="5" y2="12" style="user-select:text"/><polyline points="12 19 5 12 12 5" style="user-select:text"/></polyline></svg>&nbsp;</span>
<span>决策边界算法</span>
</a><a class=next href=https://www.oomkill.com/2022/06/logistic-regression/><span class=title></span>
<span>逻辑回归&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right" style="user-select:text"><line x1="5" y1="12" x2="19" y2="12" style="user-select:text"/><polyline points="12 5 19 12 12 19" style="user-select:text"/></svg></span></a></nav></footer><div class=pe-comments-decoration><p class=pe-comments-title></p><p class=pe-comments-subtitle></p></div><div id=pe-comments></div><script src=/js/pe-go-comment.min.86a214102576ba5f9b7bdc29eed8d58dd56e34aef80b3c65c73ea9cc88443696.js integrity="sha256-hqIUECV2ul+be9wp7tjVjdVuNK74Czxlxz6pzIhENpY="></script><script>const getStoredTheme=()=>localStorage.getItem("pref-theme")==="dark"?"dark":"light",setGiscusTheme=()=>{const e=e=>{const t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:e},"https://giscus.app")};e({setConfig:{theme:getStoredTheme()}})};document.addEventListener("DOMContentLoaded",()=>{const s={src:"https://giscus.app/client.js","data-repo":"cylonchau/blogs","data-repo-id":"R_kgDOIRlNSQ","data-category":"Announcements","data-category-id":"DIC_kwDOIRlNSc4CXy1U","data-mapping":"pathname","data-term":"posts/decision-tree","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":getStoredTheme(),"data-lang":"zh-TW","data-loading":"lazy",crossorigin:"anonymous",async:""},e=document.createElement("script");Object.entries(s).forEach(([t,n])=>e.setAttribute(t,n)),document.querySelector("#pe-comments").appendChild(e);const t=document.querySelector("#theme-toggle");t&&t.addEventListener("click",setGiscusTheme);const n=document.querySelector("#theme-toggle-float");n&&n.addEventListener("click",setGiscusTheme)})</script></article></main><footer class=footer><span>&copy; 2025 <a href=https://www.oomkill.com/>Cylon's Collection</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> on
<a href=https://pages.github.com/ rel=noopener target=_blank>GitHub Pages</a> & Theme
        <a href=https://github.com/tofuwine/PaperMod-PE rel=noopener target=_blank>PaperMod-PE</a></span></footer><div class=pe-right-sidebar><a href=javascript:void(0); id=theme-toggle-float class=pe-float-btn><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</a><a href=#top class=pe-float-btn id=top-link><span id=pe-read-progress></span></a></div><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>