<!doctype html><html lang=zh dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>KNN算法 | Cylon's Collection</title><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NP3JNCPR" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><meta name=keywords content="MachineLearning,algorithm,CS"><meta name=description content="Overview K近邻值算法 KNN (K — Nearest Neighbors) 是一种机器学习中的分类算法；K-NN是一种非参数的惰性学习算法。非参数意味着没有对基础数据分布的假设，即模型结构是从数据集确定的。
它被称为惰性算法的原因是，因为它**不需要任何训练数据点来生成模型。**所有训练数据都用于测试阶段，这使得训练更快，测试阶段更慢且成本更高。
如何工作 KNN 算法是通过计算新对象与训练数据集中所有对象之间的距离，对新实例进行分类或回归预测。然后选择训练数据集中距离最小的 K 个示例，并通过平均结果进行预测。
如图所示：一个未分类的数据（红色）和所有其他已分类的数据（黄色和紫色），每个数据都属于一个类别。因此，计算未分类数据与所有其他数据的距离，以了解哪些距离最小，因此当K= 3 （或K= 6 ）最接近的数据并检查出现最多的类，如下图所示，与新数据最接近的数据是在第一个圆圈内（圆圈内）的数据，在这个圆圈内还有 3 个其他数据（已经用黄色分类），我们将检查其中的主要类别，会被归类为紫色，因为有2个紫色球，1个黄色球。
KNN算法要执行的步骤 将数据分为训练数据和测试数据 选择一个值 K 确定要使用的距离算法 从需要分类的测试数据中选择一个样本，计算到它的 n 个训练样本的距离。 对获得的距离进行排序并取 k最近的数据样本。 根据 k 个邻居的多数票将测试类分配给该类。 影响KNN算法性能的因素 用于确定最近邻居的距离的算法
用于从 K 近邻派生分类的决策规则
用于对新示例进行分类的邻居数
如何计算距离 测量距离是KNN算法的核心，总结了问题域中两个对象之间的相对差异。比较常见的是，这两个对象是描述主题（例如人、汽车或房屋）或事件（例如购买、索赔或诊断）的数据行。
汉明距离 汉明距离（Hamming Distance）计算两个二进制向量之间的距离，也简称为二进制串 binary strings 或位串 bitstrings ；换句话说，汉明距离是将一个字符串更改为另一个字符串所需的最小替换次数，或将一个字符串转换为另一个字符串的最小错误数。
示例：如一列具有类别 “红色”、“绿色” 和 “蓝色”，您可以将每个示例独热编码为一个位串，每列一个位。
注：独热编码 one-hot encoding：将分类数据，转换成二进制向量表示，这个二进制向量用来表示一种特殊的bit（二进制位）组合，该字节里，仅容许单一bit为1，其他bit都必须为0
如：
apple banana pineapple 1 0 0 0 1 0 0 0 1 100 表示苹果，100就是苹果的二进制向量 010 表示香蕉，010就是香蕉的二进制向量"><meta name=author content="cylon"><link rel=canonical href=http://localhost:1313/2022/06/knn/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/favicon.ico><link rel=mask-icon href=http://localhost:1313/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=http://localhost:1313/2022/06/knn/><noscript><style>#theme-toggle,#top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link crossorigin=anonymous href=/assets/css/pe.min.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/pe.min.js></script><link rel=stylesheet href=https://cdn.staticfile.net/font-awesome/6.5.1/css/all.min.css><link rel=stylesheet href=https://cdn.staticfile.net/font-awesome/6.5.1/css/v4-shims.min.css><script defer src=https://cdn.staticfile.net/jquery/3.5.1/jquery.min.js></script><link rel=stylesheet href=https://cdn.staticfile.net/fancybox/3.5.7/jquery.fancybox.min.css><script defer src=https://cdn.staticfile.net/fancybox/3.5.7/jquery.fancybox.min.js></script><script id=MathJax-script async src=https://cdn.staticfile.net/mathjax/3.2.2/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["$$","$$"]],inlineMath:[["\\$","\\$"]]}}</script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"><script>(function(e,t,n,s,o){e[s]=e[s]||[],e[s].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var a=t.getElementsByTagName(n)[0],i=t.createElement(n),r=s!="dataLayer"?"&l="+s:"";i.async=!0,i.src="https://www.googletagmanager.com/gtm.js?id="+o+r,a.parentNode.insertBefore(i,a)})(window,document,"script","dataLayer","GTM-NP3JNCPR")</script><meta property="og:title" content="KNN算法"><meta property="og:description" content="Overview K近邻值算法 KNN (K — Nearest Neighbors) 是一种机器学习中的分类算法；K-NN是一种非参数的惰性学习算法。非参数意味着没有对基础数据分布的假设，即模型结构是从数据集确定的。
它被称为惰性算法的原因是，因为它**不需要任何训练数据点来生成模型。**所有训练数据都用于测试阶段，这使得训练更快，测试阶段更慢且成本更高。
如何工作 KNN 算法是通过计算新对象与训练数据集中所有对象之间的距离，对新实例进行分类或回归预测。然后选择训练数据集中距离最小的 K 个示例，并通过平均结果进行预测。
如图所示：一个未分类的数据（红色）和所有其他已分类的数据（黄色和紫色），每个数据都属于一个类别。因此，计算未分类数据与所有其他数据的距离，以了解哪些距离最小，因此当K= 3 （或K= 6 ）最接近的数据并检查出现最多的类，如下图所示，与新数据最接近的数据是在第一个圆圈内（圆圈内）的数据，在这个圆圈内还有 3 个其他数据（已经用黄色分类），我们将检查其中的主要类别，会被归类为紫色，因为有2个紫色球，1个黄色球。
KNN算法要执行的步骤 将数据分为训练数据和测试数据 选择一个值 K 确定要使用的距离算法 从需要分类的测试数据中选择一个样本，计算到它的 n 个训练样本的距离。 对获得的距离进行排序并取 k最近的数据样本。 根据 k 个邻居的多数票将测试类分配给该类。 影响KNN算法性能的因素 用于确定最近邻居的距离的算法
用于从 K 近邻派生分类的决策规则
用于对新示例进行分类的邻居数
如何计算距离 测量距离是KNN算法的核心，总结了问题域中两个对象之间的相对差异。比较常见的是，这两个对象是描述主题（例如人、汽车或房屋）或事件（例如购买、索赔或诊断）的数据行。
汉明距离 汉明距离（Hamming Distance）计算两个二进制向量之间的距离，也简称为二进制串 binary strings 或位串 bitstrings ；换句话说，汉明距离是将一个字符串更改为另一个字符串所需的最小替换次数，或将一个字符串转换为另一个字符串的最小错误数。
示例：如一列具有类别 “红色”、“绿色” 和 “蓝色”，您可以将每个示例独热编码为一个位串，每列一个位。
注：独热编码 one-hot encoding：将分类数据，转换成二进制向量表示，这个二进制向量用来表示一种特殊的bit（二进制位）组合，该字节里，仅容许单一bit为1，其他bit都必须为0
如：
apple banana pineapple 1 0 0 0 1 0 0 0 1 100 表示苹果，100就是苹果的二进制向量 010 表示香蕉，010就是香蕉的二进制向量"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/2022/06/knn/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-06-01T00:00:00+00:00"><meta property="article:modified_time" content="2023-03-22T23:00:36+08:00"><meta property="og:site_name" content="Cylon's Collection"><meta name=twitter:card content="summary"><meta name=twitter:title content="KNN算法"><meta name=twitter:description content="Overview K近邻值算法 KNN (K — Nearest Neighbors) 是一种机器学习中的分类算法；K-NN是一种非参数的惰性学习算法。非参数意味着没有对基础数据分布的假设，即模型结构是从数据集确定的。
它被称为惰性算法的原因是，因为它**不需要任何训练数据点来生成模型。**所有训练数据都用于测试阶段，这使得训练更快，测试阶段更慢且成本更高。
如何工作 KNN 算法是通过计算新对象与训练数据集中所有对象之间的距离，对新实例进行分类或回归预测。然后选择训练数据集中距离最小的 K 个示例，并通过平均结果进行预测。
如图所示：一个未分类的数据（红色）和所有其他已分类的数据（黄色和紫色），每个数据都属于一个类别。因此，计算未分类数据与所有其他数据的距离，以了解哪些距离最小，因此当K= 3 （或K= 6 ）最接近的数据并检查出现最多的类，如下图所示，与新数据最接近的数据是在第一个圆圈内（圆圈内）的数据，在这个圆圈内还有 3 个其他数据（已经用黄色分类），我们将检查其中的主要类别，会被归类为紫色，因为有2个紫色球，1个黄色球。
KNN算法要执行的步骤 将数据分为训练数据和测试数据 选择一个值 K 确定要使用的距离算法 从需要分类的测试数据中选择一个样本，计算到它的 n 个训练样本的距离。 对获得的距离进行排序并取 k最近的数据样本。 根据 k 个邻居的多数票将测试类分配给该类。 影响KNN算法性能的因素 用于确定最近邻居的距离的算法
用于从 K 近邻派生分类的决策规则
用于对新示例进行分类的邻居数
如何计算距离 测量距离是KNN算法的核心，总结了问题域中两个对象之间的相对差异。比较常见的是，这两个对象是描述主题（例如人、汽车或房屋）或事件（例如购买、索赔或诊断）的数据行。
汉明距离 汉明距离（Hamming Distance）计算两个二进制向量之间的距离，也简称为二进制串 binary strings 或位串 bitstrings ；换句话说，汉明距离是将一个字符串更改为另一个字符串所需的最小替换次数，或将一个字符串转换为另一个字符串的最小错误数。
示例：如一列具有类别 “红色”、“绿色” 和 “蓝色”，您可以将每个示例独热编码为一个位串，每列一个位。
注：独热编码 one-hot encoding：将分类数据，转换成二进制向量表示，这个二进制向量用来表示一种特殊的bit（二进制位）组合，该字节里，仅容许单一bit为1，其他bit都必须为0
如：
apple banana pineapple 1 0 0 0 1 0 0 0 1 100 表示苹果，100就是苹果的二进制向量 010 表示香蕉，010就是香蕉的二进制向量"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"KNN算法","item":"http://localhost:1313/2022/06/knn/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"KNN算法","name":"KNN算法","description":"Overview K近邻值算法 KNN (K — Nearest Neighbors) 是一种机器学习中的分类算法；K-NN是一种非参数的惰性学习算法。非参数意味着没有对基础数据分布的假设，即模型结构是从数据集确定的。\n它被称为惰性算法的原因是，因为它**不需要任何训练数据点来生成模型。**所有训练数据都用于测试阶段，这使得训练更快，测试阶段更慢且成本更高。\n如何工作 KNN 算法是通过计算新对象与训练数据集中所有对象之间的距离，对新实例进行分类或回归预测。然后选择训练数据集中距离最小的 K 个示例，并通过平均结果进行预测。\n如图所示：一个未分类的数据（红色）和所有其他已分类的数据（黄色和紫色），每个数据都属于一个类别。因此，计算未分类数据与所有其他数据的距离，以了解哪些距离最小，因此当K= 3 （或K= 6 ）最接近的数据并检查出现最多的类，如下图所示，与新数据最接近的数据是在第一个圆圈内（圆圈内）的数据，在这个圆圈内还有 3 个其他数据（已经用黄色分类），我们将检查其中的主要类别，会被归类为紫色，因为有2个紫色球，1个黄色球。\nKNN算法要执行的步骤 将数据分为训练数据和测试数据 选择一个值 K 确定要使用的距离算法 从需要分类的测试数据中选择一个样本，计算到它的 n 个训练样本的距离。 对获得的距离进行排序并取 k最近的数据样本。 根据 k 个邻居的多数票将测试类分配给该类。 影响KNN算法性能的因素 用于确定最近邻居的距离的算法\n用于从 K 近邻派生分类的决策规则\n用于对新示例进行分类的邻居数\n如何计算距离 测量距离是KNN算法的核心，总结了问题域中两个对象之间的相对差异。比较常见的是，这两个对象是描述主题（例如人、汽车或房屋）或事件（例如购买、索赔或诊断）的数据行。\n汉明距离 汉明距离（Hamming Distance）计算两个二进制向量之间的距离，也简称为二进制串 binary strings 或位串 bitstrings ；换句话说，汉明距离是将一个字符串更改为另一个字符串所需的最小替换次数，或将一个字符串转换为另一个字符串的最小错误数。\n示例：如一列具有类别 “红色”、“绿色” 和 “蓝色”，您可以将每个示例独热编码为一个位串，每列一个位。\n注：独热编码 one-hot encoding：将分类数据，转换成二进制向量表示，这个二进制向量用来表示一种特殊的bit（二进制位）组合，该字节里，仅容许单一bit为1，其他bit都必须为0\n如：\napple banana pineapple 1 0 0 0 1 0 0 0 1 100 表示苹果，100就是苹果的二进制向量 010 表示香蕉，010就是香蕉的二进制向量","keywords":["MachineLearning","algorithm","CS"],"articleBody":"Overview K近邻值算法 KNN (K — Nearest Neighbors) 是一种机器学习中的分类算法；K-NN是一种非参数的惰性学习算法。非参数意味着没有对基础数据分布的假设，即模型结构是从数据集确定的。\n它被称为惰性算法的原因是，因为它**不需要任何训练数据点来生成模型。**所有训练数据都用于测试阶段，这使得训练更快，测试阶段更慢且成本更高。\n如何工作 KNN 算法是通过计算新对象与训练数据集中所有对象之间的距离，对新实例进行分类或回归预测。然后选择训练数据集中距离最小的 K 个示例，并通过平均结果进行预测。\n如图所示：一个未分类的数据（红色）和所有其他已分类的数据（黄色和紫色），每个数据都属于一个类别。因此，计算未分类数据与所有其他数据的距离，以了解哪些距离最小，因此当K= 3 （或K= 6 ）最接近的数据并检查出现最多的类，如下图所示，与新数据最接近的数据是在第一个圆圈内（圆圈内）的数据，在这个圆圈内还有 3 个其他数据（已经用黄色分类），我们将检查其中的主要类别，会被归类为紫色，因为有2个紫色球，1个黄色球。\nKNN算法要执行的步骤 将数据分为训练数据和测试数据 选择一个值 K 确定要使用的距离算法 从需要分类的测试数据中选择一个样本，计算到它的 n 个训练样本的距离。 对获得的距离进行排序并取 k最近的数据样本。 根据 k 个邻居的多数票将测试类分配给该类。 影响KNN算法性能的因素 用于确定最近邻居的距离的算法\n用于从 K 近邻派生分类的决策规则\n用于对新示例进行分类的邻居数\n如何计算距离 测量距离是KNN算法的核心，总结了问题域中两个对象之间的相对差异。比较常见的是，这两个对象是描述主题（例如人、汽车或房屋）或事件（例如购买、索赔或诊断）的数据行。\n汉明距离 汉明距离（Hamming Distance）计算两个二进制向量之间的距离，也简称为二进制串 binary strings 或位串 bitstrings ；换句话说，汉明距离是将一个字符串更改为另一个字符串所需的最小替换次数，或将一个字符串转换为另一个字符串的最小错误数。\n示例：如一列具有类别 “红色”、“绿色” 和 “蓝色”，您可以将每个示例独热编码为一个位串，每列一个位。\n注：独热编码 one-hot encoding：将分类数据，转换成二进制向量表示，这个二进制向量用来表示一种特殊的bit（二进制位）组合，该字节里，仅容许单一bit为1，其他bit都必须为0\n如：\napple banana pineapple 1 0 0 0 1 0 0 0 1 100 表示苹果，100就是苹果的二进制向量 010 表示香蕉，010就是香蕉的二进制向量\ntext 1 2 3 red = [1, 0, 0] green = [0, 1, 0] blue = [0, 0, 1] 而red和green之间的距离就是两个等长bitstrings之间bit差（对应符号不同的位置）的总和或平均数，这就是汉明距离\n$Hamming Distance d(a, b)\\ =\\ sum(xi\\ !=\\ yi\\ for\\ xi,\\ yi\\ in\\ zip(x, y))$ 上述的实现为：\npython 1 2 3 4 5 6 7 8 9 10 def hammingDistance(a, b): if len(a) != len(b): raise ValueError(\"Undefined for sequences of unequal length.\") return sum(abs(e1 - e2) for e1, e2 in zip(a, b)) row1 = [0, 0, 0, 0, 0, 1] row2 = [0, 0, 0, 0, 1, 0] dist = hammingDistance(row1, row2) print(dist) 可以看到字符串之间有两个差异，或者 6 个位位置中有 2 个不同，平均 (2/6) 约为 1/3 或 0.333。\npython 1 2 3 4 5 6 7 8 9 from scipy.spatial.distance import hamming # define data row1 = [0, 0, 0, 0, 0, 1] row2 = [0, 0, 0, 0, 1, 0] # calculate distance dist = hamming(row1, row2) print(dist) 欧几里得距离 欧几里得距离（Euclidean distance） 是计算两个点之间的距离。在计算具体的数值（例如浮点数或整数）的两行数据之间的距离时，您最有可能使用欧几里得距离。\n欧几里得距离计算公式为两个向量之间的平方差之和的平方根。\n$EuclideanDistance=\\sqrt[]{\\sum(a-b)^2}$\n如果要执行数千或数百万次距离计算，通常会去除平方根运算以加快计算速度。修改后的结果分数将具有相同的相对比例，并且仍然可以在机器学习算法中有效地用于查找最相似的示例。\n$EuclideanDistance = sum\\ for\\ i\\ to\\ N\\ (v1[i]\\ –\\ v2[i])^2$\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # calculating euclidean distance between vectors from math import sqrt from scipy.spatial.distance import euclidean # calculate euclidean distance def euclidean_distance(a, b): return sqrt(sum((e1-e2)**2 for e1, e2 in zip(a,b))) # define data row1 = [10, 20, 15, 10, 5] row2 = [12, 24, 18, 8, 7] # calculate distance dist = euclidean_distance(row1, row2) print(dist) print(euclidean(row1, row2)) 曼哈顿距离 曼哈顿距离（ Manhattan distance ）又被称作出租车几何学 Taxicab geometry；用于计算两个向量之间的距离。\n对于描述网格上的对象（如棋盘或城市街区）的向量可能更有用。出租车在城市街区之间采取的最短路径（网格上的坐标）。\n粗略地说，欧几里得几何是中学常用的平面几何和立体几何 Plane geometry\n曼哈顿距离可以理解为：欧几里得空间的固定直角坐标系上两点所形成的线段对轴产生的投影的距离总和。\n图中： 红、蓝与黄线分别表示所有曼哈顿距离都拥有一样长度（12），绿线表示欧几里得距离 $6×\\sqrt2 ≈ 8.48$\n对于整数特征空间中的两个向量，应该计算曼哈顿距离而不是欧几里得距离\n曼哈顿距离在二维平面的计算公式是，在X轴的亮点\n$Manhattandistance\\ d(x,y)=\\left|x_{1}-x_{2}\\right|+\\left|y_{1}-y_{2}\\right|$\n如果所示，描述格子和格子之间的距离可以用曼哈顿距离，如国王移动到右下角的距离是？\n$King=|6-8|+|6-1| = 7$\n两个向量间的距离可以表示为 $MD\\ =\\ Σ|Ai – Bi|$\npython中的公式可以表示为 ：sum(abs(val1-val2) for val1, val2 in zip(a,b))\npython 1 2 3 4 5 6 7 8 9 10 11 12 from scipy.spatial.distance import cityblock # calculate manhattan distance def manhattan_distance(a, b): return sum(abs(e1-e2) for e1, e2 in zip(a,b)) # define data row1 = [10, 20, 15, 10, 5] row2 = [12, 24, 18, 8, 7] # calculate distance dist = manhattan_distance(row1, row2) print(dist) print(cityblock(row1, row2)) 闵可夫斯基距离 闵可夫斯基距离（Minkowski distance）并不是一种距离而是对是欧几里得距离和曼哈顿距离的概括，用来计算两个向量之间的距离。\n闵可夫斯基增并添加了一个参数，称为“阶数”或 p：$d(x,y) = (\\sum(|x-y|)^p)^\\frac{1}{p}$\n在python中的公式：\npython 1 (sum for i to N (abs(v1[i] – v2[i]))^p)^(1/p) p 是一个有序的参数，当 $p=1$ 时，计算的是曼哈顿距离。当 $p=2$ 时，计算的是欧几里得距离。\n在实现使用距离度量的机器学习算法时，通常会使用闵可夫斯基距离，因为可以通过调整参数“ p ”控制用于向量的距离度量算法的类型。\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # calculating minkowski distance between vectors from scipy.spatial import minkowski_distance # calculate minkowski distance def minkowski_distance(a, b, p): return sum(abs(e1-e2)**p for e1, e2 in zip(a,b))**(1/p) # define data row1 = [10, 20, 15, 10, 5] row2 = [12, 24, 18, 8, 7] # 手动实现的算法用来使用闵可夫斯基计算距离 dist = minkowski_distance(row1, row2, 1) # 1为曼哈顿 print(dist) # 1为欧几里得 dist = minkowski_distance(row1, row2, 2) print(dist) # 使用包 scipy.spatial来计算 print(minkowski_distance(row1, row2, 1)) print(minkowski_distance(row1, row2, 2)) KNN算法实现 Prerequisite 首先会用示例来实现KNN算法的每个步骤，并加以分析，然后将所有步骤关联在在一起，形成一个适用于真实数据集的实现。\nKNN在实现起来主要有三个步骤：\n计算距离（这里选择欧几里得距离） 获得临近邻居 做出预测 这三个步骤是KNN算法用以解决分类和回归预测建模问题的基础知识\n计算距离 第一步计算数据集中两行之间的距离。在数据集中的数据行主要由数字组成，计算两行或数字向量之间的距离的一种简单方法是画一条直线。这在 2D 或 3D 平面中都是很好地选择，并且可以很好地扩展到更高的维度。\n这里使用的是比较流行的计算距离的算法，欧几里得距离来计算两个向量之间的直线距离。欧几里得距离的公式是，两个向量的平方差的平方根，$Euclidean\\ Distance=\\sqrt[]{\\sum(a-b)^2}$ ；在python中可以表示为：sqrt(sum i to N (x1 – x2)^2) ；其中 x1 是第一行数据，x2 是第二行数据，i 表示特定列的索引，因为可能需要对所有行进行计算。\n在欧几里得距离中，值越小，两条记录就越相似； 0 表示两条记录之间没有差异。\n那么使用python实现一个计算欧几里得距离的算法\npython 1 2 3 4 5 def euclidean_distance(row1, row2): distance = 0.0 for i in range(len(row1)-1): distance += (row1[i] - row2[i])**2 return sqrt(distance) 准备一部分测试数据，来对测试距离算法\npython 1 2 3 4 5 6 7 8 9 10 11 X1\tX2\tY 2.7810836\t2.550537003\t0 1.465489372\t2.362125076\t0 3.396561688\t4.400293529\t0 1.38807019\t1.850220317\t0 3.06407232\t3.005305973\t0 7.627531214\t2.759262235\t1 5.332441248\t2.088626775\t1 6.922596716\t1.77106367\t1 8.675418651\t-0.242068655\t1 7.673756466\t3.508563011\t1 那么来测试这些数据，需要做到的是第一行与所有行之间的距离，对于第一行与自己的距离应该为0\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from math import sqrt # 欧几里得距离，计算两个向量间距离的算法 def euclidean_distance(row1, row2): distance = 0.0 for i in range(len(row1)-1): distance += (row1[i] - row2[i])**2 # 平方差 return sqrt(distance) # 平方根 # 测试数据集 dataset = [ [2.7810836,2.550537003,0], [1.465489372,2.362125076,0], [3.396561688,4.400293529,0], [1.38807019,1.850220317,0], [3.06407232,3.005305973,0], [7.627531214,2.759262235,1], [5.332441248,2.088626775,1], [6.922596716,1.77106367,1], [8.675418651,-0.242068655,1], [7.673756466,3.508563011,1] ] row0 = dataset[0] for row in dataset: distance = euclidean_distance(row0, row) print(distance) # 0.0 # 1.3290173915275787 # 1.9494646655653247 # 1.5591439385540549 # 0.5356280721938492 # 4.850940186986411 # 2.592833759950511 # 4.214227042632867 # 6.522409988228337 # 4.985585382449795 获取最近邻居 数据集中新数据的邻居是k个最接近的实例（行），这个实例由距离定义。现在诞生的问题：如何找到最近的邻居？以及怎么找到最近的邻居？\n为了在数据集中找到 K 的邻居，首先必须计算数据集中每条记录与新数据之间的距离。\n有了距离之后，必须按照 K 的距离对训练集中的所有实例排序。然后选择前 k 个作为最近的邻居。\n这里实现起来是通过将数据集中每条记录的距离作为一个元组来跟踪，通过对元组列表进行排序（距离降序），然后检索最近邻居。下面是一个实现这些步骤的函数\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 找到最近的邻居 def get_neighbors(train, test_row, num_neighbors): \"\"\" 计算训练集train中所有元素到test_row的距离 :param train: list, 数据集，可以是训练集 :param test_row: list, 新的实例，也就是K :param num_neighbors:int，需要多少个邻居 :return: None \"\"\" distances = list() for train_row in train: # 计算出每一行的距离，把他添加到元组中 dist = euclidean_distance(test_row, train_row) distances.append((train_row, dist)) distances.sort(key=lambda knn: knn[1]) # 根据元素哪个字段进行排序 neighbors = list() for i in range(num_neighbors): neighbors.append(distances[i][0]) return neighbors 下面是完整的示例\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 from math import sqrt # 欧几里得距离，计算两个向量间距离的算法 def euclidean_distance(row1, row2): distance = 0.0 for i in range(len(row1)-1): distance += (row1[i] - row2[i])**2 # 平方差 return sqrt(distance) # 平方根 # 找到最近的邻居 def get_neighbors(train, test_row, num_neighbors): \"\"\" 计算训练集train中所有元素到test_row的距离 :param train: list, 数据集，可以是训练集 :param test_row: list, 新的实例，也就是K :param num_neighbors:int，需要多少个邻居 :return: None \"\"\" distances = list() for train_row in train: # 计算出每一行的距离，把他添加到元组中 dist = euclidean_distance(test_row, train_row) distances.append((train_row, dist)) distances.sort(key=lambda knn: knn[1]) # 根据元素哪个字段进行排序 neighbors = list() for i in range(num_neighbors): neighbors.append(distances[i][0]) return neighbors # 测试数据集 dataset = [ [2.7810836,2.550537003,0], [1.465489372,2.362125076,0], [3.396561688,4.400293529,0], [1.38807019,1.850220317,0], [3.06407232,3.005305973,0], [7.627531214,2.759262235,1], [5.332441248,2.088626775,1], [6.922596716,1.77106367,1], [8.675418651,-0.242068655,1], [7.673756466,3.508563011,1] ] neighbors = get_neighbors(dataset, dataset[0], 3) for neighbor in neighbors: print(neighbor) # [2.7810836, 2.550537003, 0] # [3.06407232, 3.005305973, 0] # [1.465489372, 2.362125076, 0] 可以看到，运行后会将数据集中最相似的 3 条记录按相似度顺序打印。和预测的一样，第一个记录与其本身最相似，并且位于列表的顶部。\n预测结果 预测结果在这里指定是，通过分类拿到了最近的邻居的实例，对邻居进行分类，找到邻居中最大类别的一类，作为预测值。这里使用的是对邻居值执行 max() 来实现这一点，下面是实现方式\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 # 预测值 def predict_classification(train, test_row, num_neighbors): \"\"\" 计算训练集train中所有元素到test_row的距离 :param train: list, 数据集，可以是训练集 :param test_row: list, 新的实例，也就是K :param num_neighbors:int，需要多少个邻居 :return: None \"\"\" neighbors = get_neighbors(train, test_row, num_neighbors) output_values = [row[-1] for row in neighbors] # 拿到所属类的真实类别 prediction = max(set(output_values), key=output_values.count) #算出邻居类别最大的数量 return prediction 下面是完整的示例\npython 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 from math import sqrt # 欧几里得距离，计算两个向量间距离的算法 def euclidean_distance(row1, row2): distance = 0.0 for i in range(len(row1)-1): distance += (row1[i] - row2[i])**2 # 平方差 return sqrt(distance) # 平方根 # 找到最近的邻居 def get_neighbors(train, test_row, num_neighbors): \"\"\" 计算训练集train中所有元素到test_row的距离 :param train: list, 数据集，可以是训练集 :param test_row: list, 新的实例，也就是K :param num_neighbors:int，需要多少个邻居 :return: None \"\"\" distances = list() for train_row in train: # 计算出每一行的距离，把他添加到元组中 dist = euclidean_distance(test_row, train_row) distances.append((train_row, dist)) distances.sort(key=lambda knn: knn[1]) # 根据元素哪个字段进行排序 neighbors = list() for i in range(num_neighbors): neighbors.append(distances[i][0]) return neighbors # 预测值 def predict_classification(train, test_row, num_neighbors): \"\"\" 计算训练集train中所有元素到test_row的距离 :param train: list, 数据集，可以是训练集 :param test_row: list, 新的实例，也就是K :param num_neighbors:int，需要多少个邻居 :return: None \"\"\" neighbors = get_neighbors(train, test_row, num_neighbors) output_values = [row[-1] for row in neighbors] # 拿到所属类的真实类别 prediction = max(set(output_values), key=output_values.count) #算出邻居类别最大的数量 return prediction # 测试数据集 dataset = [ [2.7810836,2.550537003,0], [1.465489372,2.362125076,0], [3.396561688,4.400293529,0], [1.38807019,1.850220317,0], [3.06407232,3.005305973,0], [7.627531214,2.759262235,1], [5.332441248,2.088626775,1], [6.922596716,1.77106367,1], [8.675418651,-0.242068655,1], [7.673756466,3.508563011,1] ] for n in range(len(dataset)): prediction = predict_classification(dataset, dataset[n], 5) print('Expected %d, Got %d.' % (dataset[n][-1], prediction)) # Expected 0, Got 0. # Expected 0, Got 0. # Expected 0, Got 0. # Expected 0, Got 0. # Expected 0, Got 0. # Expected 1, Got 1. # Expected 1, Got 1. # Expected 1, Got 1. # Expected 1, Got 1. # Expected 1, Got 1. 运行结果打印了预期分类与从数据集中 3 个相进邻居预测结果是一直的。\n鸢尾花种实例 这里使用的是 Iris Flower Species 数据集。\n鸢尾花数据集是根据鸢尾花的测量值预测花卉种类。这是一个多类分类问题。每个类的观察数量是平衡的。有 150 个观测值，有 4 个输入变量和 1 个输出变量。变量名称如下：\n萼片长度以厘米为单位。 萼片宽度以厘米为单位。 花瓣长度以厘米为单位。 花瓣宽度以厘米为单位。 真实类型 更多的关于数据集的说明可以参考：Iris-databases数据集的说明\nPrerequisite 实验的步骤大概分为如下：\n加载数据集并将数据转换为可用于均值和标准差计算的数字。将属性转为float，将类别转换为int。 使 5折的K折较差验证（K-Fold CV）评估该算法。 Start python 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 from random import seed from random import randrange from csv import reader from math import sqrt # 加载CSV def load_csv(filename): dataset = list() with open(filename, 'r') as file: csv_reader = reader(file) for row in csv_reader: if not row: continue dataset.append(row) return dataset # 转换所有的值为float方便运算 def str_column_to_float(dataset, column): for row in dataset: row[column] = float(row[column].strip()) # 转换所有的类型为int def str_column_to_int(dataset, column): class_values = [row[column] for row in dataset] unique = set(class_values) lookup = dict() for i, value in enumerate(unique): lookup[value] = i for row in dataset: row[column] = lookup[row[column]] return lookup # # k-folds CV函数进行划分 def cross_validation_split(dataset, n_folds): dataset_split = list() dataset_copy = list(dataset) # 平均分成n_folds折数 fold_size = int(len(dataset) / n_folds) for _ in range(n_folds): fold = list() while len(fold) \u003c fold_size: index = randrange(len(dataset_copy)) fold.append(dataset_copy.pop(index)) dataset_split.append(fold) return dataset_split # 计算精确度 def accuracy_metric(actual, predicted): correct = 0 for i in range(len(actual)): if actual[i] == predicted[i]: correct += 1 return correct / float(len(actual)) * 100.0 # 评估算法 def evaluate_algorithm(dataset, algorithm, n_folds, *args): \"\"\" 评估算法，计算算法的精确度 :param dataset: list, 数据集 :param algorithm: function, 算法名 :param n_folds: int，折数 :param args: 用于algorithm的参数 :return: None \"\"\" folds = cross_validation_split(dataset, n_folds) # 分成5折 scores = list() for fold in folds: train_set = list(folds) train_set.remove(fold) # 训练集不包含本身 train_set = sum(train_set, []) test_set = list() # 测试集 for row in fold: row_copy = list(row) test_set.append(row_copy) row_copy[-1] = None predicted = algorithm(train_set, test_set, *args) actual = [row[-1] for row in fold] accuracy = accuracy_metric(actual, predicted) scores.append(accuracy) return scores # 欧几里得距离，计算两个向量间距离的算法 def euclidean_distance(row1, row2): distance = 0.0 for i in range(len(row1)-1): distance += (row1[i] - row2[i])**2 return sqrt(distance) # 确定最邻近的邻居 def get_neighbors(train, test_row, num_neighbors): \"\"\" 计算训练集train中所有元素到test_row的距离 :param train: list, 数据集，可以是训练集 :param test_row: list, 新的实例，也就是K :param num_neighbors:int，需要多少个邻居 :return: None \"\"\" distances = list() for train_row in train: dist = euclidean_distance(test_row, train_row) distances.append((train_row, dist)) distances.sort(key=lambda tup: tup[1]) neighbors = list() for i in range(num_neighbors): neighbors.append(distances[i][0]) return neighbors # 与临近值进行比较并预测 def predict_classification(train, test_row, num_neighbors): \"\"\" 计算训练集train中所有元素到test_row的距离 :param train: list, 数据集，可以是训练集 :param test_row: list, 新的实例，也就是K :param num_neighbors:int，需要多少个邻居 :return: None \"\"\" neighbors = get_neighbors(train, test_row, num_neighbors) output_values = [row[-1] for row in neighbors] prediction = max(set(output_values), key=output_values.count) return prediction # kNN Algorithm def k_nearest_neighbors(train, test, num_neighbors): predictions = list() for row in test: output = predict_classification(train, row, num_neighbors) predictions.append(output) return(predictions) # 使用KNN算法计算鸢尾花数据集 seed(1) filename = 'iris.csv' dataset = load_csv(filename) for i in range(len(dataset[0])-1): str_column_to_float(dataset, i) # 转换类型为int str_column_to_int(dataset, len(dataset[0])-1) # 评估算法 n_folds = 5 # 5折 num_neighbors = 5 #取5个邻居 scores = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors) print('Scores: %s' % scores) print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores)))) # Scores: [96.66666666666667, 96.66666666666667, 100.0, 90.0, 100.0] # Mean Accuracy: 96.667% 上述是对整个数据集的预测百分比，也可以对对应的类的信息进行输出\n首先在类别转换函数 str_column_to_int 中增加打印方法\npython 1 2 3 for i, value in enumerate(unique): lookup[value] = i print('[%s] =\u003e %d' % (value, i)) 然后在定义一个新的实例，这个实例是用于预测的信息 row = [5.7,2.9,4.2,1.3] ; 然后修改需要预测的数据，进行预测\npython 1 2 3 4 5 6 7 8 9 10 11 12 # 原来的整个数据集打分不需要了 # scores = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors) # print('Scores: %s' % scores) # print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores)))) # 定义一个新数据 row = [5.7,2.9,4.2,1.3] label = predict_classification(dataset, row, num_neighbors) print('Data=%s, Predicted: %s' % (row, label)) # Data=[5.7, 2.9, 4.2, 1.3], Predicted: 1 通过预测，可以看出预测结果属于第 1 类，就知道该花为 Iris-setosa 。\nReference distance measures k nearest neighbors implement\n","wordCount":"2014","inLanguage":"zh","datePublished":"2022-06-01T00:00:00Z","dateModified":"2023-03-22T23:00:36+08:00","author":{"@type":"Person","name":"cylon"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/2022/06/knn/"},"publisher":{"@type":"Organization","name":"Cylon's Collection","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/><img src=http://localhost:1313/favicon.ico alt aria-label=logo height=20>Cylon's Collection</a><div class=logo-switches><button id=theme-toggle><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/archives><span>归档</span></a></li><li><a href=http://localhost:1313/tags><span>标签</span></a></li><li><a href=http://localhost:1313/search><span>搜索</span></a></li><li><a href=http://localhost:1313/about accesskey=/><span>关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">KNN算法</h1><div class=post-meta><span class=pe-post-meta-item><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select:text"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select:text"/><line x1="16" y1="2" x2="16" y2="6" style="user-select:text"/><line x1="8" y1="2" x2="8" y2="6" style="user-select:text"/><line x1="3" y1="10" x2="21" y2="10" style="user-select:text"/></svg><span>2022-06-01</span></span>&nbsp;·&nbsp;<span class=pe-post-meta-item><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text" style="user-select:text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z" style="user-select:text"/><polyline points="14 2 14 8 20 8" style="user-select:text"/><line x1="16" y1="13" x2="8" y2="13" style="user-select:text"/><line x1="16" y1="17" x2="8" y2="17" style="user-select:text"/><polyline points="10 9 9 9 8 9" style="user-select:text"/></svg><span>2014 字</span></span>&nbsp;·&nbsp;<span class=pe-post-meta-item><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><span>10 分钟</span></span>
<span class=pe-post-meta-item>&nbsp;·&nbsp;<svg t="1714036239378" fill="currentcolor" class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" p-id="6659" width="256" height="256"><path d="M690 78.2c-18.6-18.8-49-19-67.8-.4s-19 49-.4 67.8l255.4 258.6c67.8 68.6 67.8 178.8.0 247.4L653.4 878.2c-18.6 18.8-18.4 49.2.4 67.8s49.2 18.4 67.8-.4l224-226.4c104.8-106 104.8-276.4.0-382.4L690 78.2zM485.4 101.4c-24-24-56.6-37.4-90.6-37.4H96C43 64 0 107 0 160v299c0 34 13.4 66.6 37.4 90.6l336 336c50 50 131 50 181 0l267-267c50-50 50-131 0-181l-336-336zM96 160h299c8.4.0 16.6 3.4 22.6 9.4l336 336c12.4 12.4 12.4 32.8.0 45.2l-267 267c-12.4 12.4-32.8 12.4-45.2.0l-336-336c-6-6-9.4-14.2-9.4-22.6V160zm192 128a64 64 0 10-128 0 64 64 0 10128 0z" p-id="6660"/></svg></span><ul class=pe-post-meta-item><a href=http://localhost:1313/tags/machinelearning/>#MachineLearning</a>
<a href=http://localhost:1313/tags/algorithm/>#Algorithm</a>
<a href=http://localhost:1313/tags/cs/>#CS</a></ul></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details><summary><span class=details>目录</span></summary><div class=inner><ul><li><a href=#overview aria-label=Overview>Overview</a><li><a href=#%e5%a6%82%e4%bd%95%e5%b7%a5%e4%bd%9c aria-label=如何工作>如何工作</a><ul><li><a href=#knn%e7%ae%97%e6%b3%95%e8%a6%81%e6%89%a7%e8%a1%8c%e7%9a%84%e6%ad%a5%e9%aa%a4 aria-label=KNN算法要执行的步骤>KNN算法要执行的步骤</a><li><a href=#%e5%bd%b1%e5%93%8dknn%e7%ae%97%e6%b3%95%e6%80%a7%e8%83%bd%e7%9a%84%e5%9b%a0%e7%b4%a0 aria-label=影响KNN算法性能的因素>影响KNN算法性能的因素</a></ul><li><a href=#%e5%a6%82%e4%bd%95%e8%ae%a1%e7%ae%97%e8%b7%9d%e7%a6%bb aria-label=如何计算距离>如何计算距离</a><ul><li><a href=#%e6%b1%89%e6%98%8e%e8%b7%9d%e7%a6%bb aria-label=汉明距离>汉明距离</a><li><a href=#%e6%ac%a7%e5%87%a0%e9%87%8c%e5%be%97%e8%b7%9d%e7%a6%bb aria-label=欧几里得距离>欧几里得距离</a><li><a href=#%e6%9b%bc%e5%93%88%e9%a1%bf%e8%b7%9d%e7%a6%bb aria-label=曼哈顿距离>曼哈顿距离</a><li><a href=#%e9%97%b5%e5%8f%af%e5%a4%ab%e6%96%af%e5%9f%ba%e8%b7%9d%e7%a6%bb aria-label=闵可夫斯基距离>闵可夫斯基距离</a></ul><li><a href=#knn%e7%ae%97%e6%b3%95%e5%ae%9e%e7%8e%b0 aria-label=KNN算法实现>KNN算法实现</a><ul><li><a href=#prerequisite aria-label=Prerequisite>Prerequisite</a><li><a href=#%e8%ae%a1%e7%ae%97%e8%b7%9d%e7%a6%bb aria-label=计算距离>计算距离</a><li><a href=#%e8%8e%b7%e5%8f%96%e6%9c%80%e8%bf%91%e9%82%bb%e5%b1%85 aria-label=获取最近邻居>获取最近邻居</a><li><a href=#%e9%a2%84%e6%b5%8b%e7%bb%93%e6%9e%9c aria-label=预测结果>预测结果</a></ul><li><a href=#%e9%b8%a2%e5%b0%be%e8%8a%b1%e7%a7%8d%e5%ae%9e%e4%be%8b aria-label=鸢尾花种实例>鸢尾花种实例</a><ul><li><a href=#prerequisite-1 aria-label=Prerequisite>Prerequisite</a><li><a href=#start aria-label=Start>Start</a></ul><li><a href=#reference aria-label=Reference>Reference</a></li></div></details></div></aside><script src=/js/pe-toc.min.445eb1bfc5e85dd13b9519fcc2a806522e9629b6224a2974052789ba00ab78af.js integrity="sha256-RF6xv8XoXdE7lRn8wqgGUi6WKbYiSil0BSeJugCreK8="></script><div class=post-content><h2 id=overview>Overview<a hidden class=anchor aria-hidden=true href=#overview>#</a></h2><p>K近邻值算法 <strong>KNN (K — Nearest Neighbors)</strong> 是一种机器学习中的分类算法；K-NN是一种<strong>非参数</strong>的<strong>惰性学习算法</strong>。非参数意味着没有对基础数据分布的假设，即模型结构是从数据集确定的。</p><p>它被称为<strong>惰性算法</strong>的原因是，因为它**不需要任何训练数据点来生成模型。**所有训练数据都用于测试阶段，这使得训练更快，测试阶段更慢且成本更高。</p><h2 id=如何工作>如何工作<a hidden class=anchor aria-hidden=true href=#如何工作>#</a></h2><p>KNN 算法是通过计算新对象与训练数据集中所有对象之间的距离，对新实例进行分类或回归预测。然后选择训练数据集中距离最小的 K 个示例，并通过平均结果进行预测。</p><p>如图所示：一个未分类的数据（红色）和所有其他已分类的数据（黄色和紫色），每个数据都属于一个类别。因此，计算未分类数据与所有其他数据的距离，以了解哪些距离最小，因此当K= 3 （或K= 6 ）最接近的数据并检查出现最多的类，如下图所示，与新数据最接近的数据是在第一个圆圈内（圆圈内）的数据，在这个圆圈内还有 3 个其他数据（已经用黄色分类），我们将检查其中的主要类别，会被归类为紫色，因为有2个紫色球，1个黄色球。</p><p><div class=pe-fancybox><a data-fancybox=gallery href=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/image-20221021234452066.png><img src=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/image-20221021234452066.png#center alt=image-20221021234452066 onerror='this.onerror=null,this.src="/placeholder.svg",this.className="pe-image-placeholder"'></a></div></p><h3 id=knn算法要执行的步骤>KNN算法要执行的步骤<a hidden class=anchor aria-hidden=true href=#knn算法要执行的步骤>#</a></h3><ul><li>将数据分为训练数据和测试数据</li><li>选择一个值 K</li><li>确定要使用的距离算法</li><li>从需要分类的测试数据中选择一个样本，计算到它的 n 个训练样本的距离。</li><li>对获得的距离进行排序并取 k最近的数据样本。</li><li>根据 k 个邻居的多数票将测试类分配给该类。</li></ul><h3 id=影响knn算法性能的因素>影响KNN算法性能的因素<a hidden class=anchor aria-hidden=true href=#影响knn算法性能的因素>#</a></h3><ul><li><p>用于确定最近邻居的<strong>距离</strong>的算法</p></li><li><p>用于从 K 近邻派生分类的决策规则</p></li><li><p>用于对新示例进行分类的邻居<strong>数</strong></p></li></ul><h2 id=如何计算距离>如何计算距离<a hidden class=anchor aria-hidden=true href=#如何计算距离>#</a></h2><p>测量距离是KNN算法的核心，总结了问题域中两个对象之间的相对差异。比较常见的是，这两个对象是描述主题（例如人、汽车或房屋）或事件（例如购买、索赔或诊断）的数据行。</p><h3 id=汉明距离>汉明距离<a hidden class=anchor aria-hidden=true href=#汉明距离>#</a></h3><p>汉明距离（<code>Hamming Distance</code>）计算两个二进制向量之间的距离，也简称为二进制串 <code>binary strings</code> 或位串 <code>bitstrings </code>；换句话说，汉明距离是将一个字符串更改为另一个字符串所需的最小替换次数，或将一个字符串转换为另一个字符串的最小错误数。</p><p>示例：如一列具有类别 “红色”、“绿色” 和 “蓝色”，您可以将每个示例独热编码为一个位串，每列一个位。</p><blockquote><p>注：独热编码 one-hot encoding：将分类数据，转换成二进制向量表示，这个二进制向量用来表示一种特殊的bit（二进制位）组合，该字节里，仅容许单一bit为1，其他bit都必须为0</p><p>如：</p><table><thead><tr><th>apple</th><th>banana</th><th>pineapple</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>0</td></tr><tr><td>0</td><td>1</td><td>0</td></tr><tr><td>0</td><td>0</td><td>1</td></tr></tbody></table><p>100 表示苹果，100就是苹果的二进制向量
010 表示香蕉，010就是香蕉的二进制向量</p></blockquote><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>text</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>red = [1, 0, 0]
</span></span><span class=line><span class=cl>green = [0, 1, 0]
</span></span><span class=line><span class=cl>blue = [0, 0, 1]</span></span></code></pre></td></tr></table></div></div></div></div><p>而red和green之间的距离就是<strong>两个等长bitstrings之间bit差</strong>（对应符号不同的位置）的总和或平均数，这就是汉明距离</p><ul><li>$Hamming Distance d(a, b)\ =\ sum(xi\ !=\ yi\ for\ xi,\ yi\ in\ zip(x, y))$</li></ul><p>上述的实现为：</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>hammingDistance</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>a</span><span class=p>)</span> <span class=o>!=</span> <span class=nb>len</span><span class=p>(</span><span class=n>b</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&#34;Undefined for sequences of unequal length.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nb>sum</span><span class=p>(</span><span class=nb>abs</span><span class=p>(</span><span class=n>e1</span> <span class=o>-</span> <span class=n>e2</span><span class=p>)</span> <span class=k>for</span> <span class=n>e1</span><span class=p>,</span> <span class=n>e2</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>row1</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>row2</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>dist</span> <span class=o>=</span> <span class=n>hammingDistance</span><span class=p>(</span><span class=n>row1</span><span class=p>,</span> <span class=n>row2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div></div></div><p>可以看到字符串之间有两个差异，或者 6 个位位置中有 2 个不同，平均 (2/6) 约为 1/3 或 0.333。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.spatial.distance</span> <span class=kn>import</span> <span class=n>hamming</span>
</span></span><span class=line><span class=cl><span class=c1># define data</span>
</span></span><span class=line><span class=cl><span class=n>row1</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>row2</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># calculate distance</span>
</span></span><span class=line><span class=cl><span class=n>dist</span> <span class=o>=</span> <span class=n>hamming</span><span class=p>(</span><span class=n>row1</span><span class=p>,</span> <span class=n>row2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div></div></div><h3 id=欧几里得距离>欧几里得距离<a hidden class=anchor aria-hidden=true href=#欧几里得距离>#</a></h3><p>欧几里得距离（<code>Euclidean distance</code>） 是计算两个点之间的距离。在计算具体的数值（例如浮点数或整数）的两行数据之间的距离时，您最有可能使用欧几里得距离。</p><p>欧几里得距离计算公式为两个向量之间的平方差之和的平方根。</p><p>$EuclideanDistance=\sqrt[]{\sum(a-b)^2}$</p><p>如果要执行数千或数百万次距离计算，通常会去除平方根运算以加快计算速度。修改后的结果分数将具有相同的相对比例，并且仍然可以在机器学习算法中有效地用于查找最相似的示例。</p><p>$EuclideanDistance = sum\ for\ i\ to\ N\ (v1[i]\ –\ v2[i])^2$</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># calculating euclidean distance between vectors</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>math</span> <span class=kn>import</span> <span class=n>sqrt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.spatial.distance</span> <span class=kn>import</span> <span class=n>euclidean</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># calculate euclidean distance</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>euclidean_distance</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=n>sqrt</span><span class=p>(</span><span class=nb>sum</span><span class=p>((</span><span class=n>e1</span><span class=o>-</span><span class=n>e2</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span> <span class=k>for</span> <span class=n>e1</span><span class=p>,</span> <span class=n>e2</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>a</span><span class=p>,</span><span class=n>b</span><span class=p>)))</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># define data</span>
</span></span><span class=line><span class=cl><span class=n>row1</span> <span class=o>=</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>5</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>row2</span> <span class=o>=</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>7</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># calculate distance</span>
</span></span><span class=line><span class=cl><span class=n>dist</span> <span class=o>=</span> <span class=n>euclidean_distance</span><span class=p>(</span><span class=n>row1</span><span class=p>,</span> <span class=n>row2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>euclidean</span><span class=p>(</span><span class=n>row1</span><span class=p>,</span> <span class=n>row2</span><span class=p>))</span></span></span></code></pre></td></tr></table></div></div></div></div><h3 id=曼哈顿距离>曼哈顿距离<a hidden class=anchor aria-hidden=true href=#曼哈顿距离>#</a></h3><p>曼哈顿距离（ <code>Manhattan distance</code> ）又被称作出租车几何学 <code>Taxicab geometry</code>；用于计算两个向量之间的距离。</p><p>对于描述网格上的对象（如棋盘或城市街区）的向量可能更有用。出租车在城市街区之间采取的最短路径（网格上的坐标）。</p><blockquote><p>粗略地说，欧几里得几何是中学常用的平面几何和立体几何 <a href=https://www.britannica.com/science/Euclidean-geometry/Plane-geometry target=_blank rel="noopener nofollow noreferrer">Plane geometry</a></p></blockquote><p>曼哈顿距离可以理解为：欧几里得空间的固定直角坐标系上两点所形成的线段对轴产生的投影的距离总和。</p><p><div class=pe-fancybox><a data-fancybox=gallery href=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/image-20221021234505760.png><img src=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/image-20221021234505760.png#center alt=image-20221021234505760 onerror='this.onerror=null,this.src="/placeholder.svg",this.className="pe-image-placeholder"'></a></div></p><p>图中： 红、蓝与黄线分别表示所有曼哈顿距离都拥有一样长度（12），绿线表示欧几里得距离 $6×\sqrt2 ≈ 8.48$</p><p>对于整数特征空间中的两个向量，应该计算曼哈顿距离而不是欧几里得距离</p><p>曼哈顿距离在二维平面的计算公式是，在X轴的亮点</p><p>$Manhattandistance\ d(x,y)=\left|x_{1}-x_{2}\right|+\left|y_{1}-y_{2}\right|$</p><p><div class=pe-fancybox><a data-fancybox=gallery href=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/image-20221021234535889.png><img src=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/image-20221021234535889.png#center alt=image-20221021234535889 onerror='this.onerror=null,this.src="/placeholder.svg",this.className="pe-image-placeholder"'></a></div></p><p>如果所示，描述格子和格子之间的距离可以用曼哈顿距离，如国王移动到右下角的距离是？</p><p>$King=|6-8|+|6-1| = 7$</p><p>两个向量间的距离可以表示为 $MD\ =\ Σ|Ai – Bi|$</p><p>python中的公式可以表示为 ：<code>sum(abs(val1-val2) for val1, val2 in zip(a,b))</code></p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.spatial.distance</span> <span class=kn>import</span> <span class=n>cityblock</span>
</span></span><span class=line><span class=cl><span class=c1># calculate manhattan distance</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>manhattan_distance</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nb>sum</span><span class=p>(</span><span class=nb>abs</span><span class=p>(</span><span class=n>e1</span><span class=o>-</span><span class=n>e2</span><span class=p>)</span> <span class=k>for</span> <span class=n>e1</span><span class=p>,</span> <span class=n>e2</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>a</span><span class=p>,</span><span class=n>b</span><span class=p>))</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># define data</span>
</span></span><span class=line><span class=cl><span class=n>row1</span> <span class=o>=</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>5</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>row2</span> <span class=o>=</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>7</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># calculate distance</span>
</span></span><span class=line><span class=cl><span class=n>dist</span> <span class=o>=</span> <span class=n>manhattan_distance</span><span class=p>(</span><span class=n>row1</span><span class=p>,</span> <span class=n>row2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>cityblock</span><span class=p>(</span><span class=n>row1</span><span class=p>,</span> <span class=n>row2</span><span class=p>))</span></span></span></code></pre></td></tr></table></div></div></div></div><h3 id=闵可夫斯基距离>闵可夫斯基距离<a hidden class=anchor aria-hidden=true href=#闵可夫斯基距离>#</a></h3><p>闵可夫斯基距离（<code>Minkowski distance</code>）并不是一种距离而是对是<strong>欧几里得距离</strong>和<strong>曼哈顿距离</strong>的概括，用来计算两个向量之间的距离。</p><p>闵可夫斯基增并添加了一个参数，称为“<strong>阶数</strong>”或 <code>p</code>：$d(x,y) = (\sum(|x-y|)^p)^\frac{1}{p}$</p><p>在python中的公式：</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=p>(</span><span class=nb>sum</span> <span class=k>for</span> <span class=n>i</span> <span class=n>to</span> <span class=n>N</span> <span class=p>(</span><span class=nb>abs</span><span class=p>(</span><span class=n>v1</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=err>–</span> <span class=n>v2</span><span class=p>[</span><span class=n>i</span><span class=p>]))</span><span class=o>^</span><span class=n>p</span><span class=p>)</span><span class=o>^</span><span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=n>p</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div></div></div><p><code>p</code> 是一个有序的参数，当 $p=1$ 时，计算的是曼哈顿距离。当 $p=2$ 时，计算的是欧几里得距离。</p><p>在实现使用距离度量的机器学习算法时，通常会使用闵可夫斯基距离，因为可以通过调整参数“ <em>p</em> ”控制用于向量的距离度量算法的类型。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># calculating minkowski distance between vectors</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.spatial</span> <span class=kn>import</span> <span class=n>minkowski_distance</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># calculate minkowski distance</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>minkowski_distance</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>,</span> <span class=n>p</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nb>sum</span><span class=p>(</span><span class=nb>abs</span><span class=p>(</span><span class=n>e1</span><span class=o>-</span><span class=n>e2</span><span class=p>)</span><span class=o>**</span><span class=n>p</span> <span class=k>for</span> <span class=n>e1</span><span class=p>,</span> <span class=n>e2</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>a</span><span class=p>,</span><span class=n>b</span><span class=p>))</span><span class=o>**</span><span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=n>p</span><span class=p>)</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># define data</span>
</span></span><span class=line><span class=cl><span class=n>row1</span> <span class=o>=</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>5</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>row2</span> <span class=o>=</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>7</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 手动实现的算法用来使用闵可夫斯基计算距离</span>
</span></span><span class=line><span class=cl><span class=n>dist</span> <span class=o>=</span> <span class=n>minkowski_distance</span><span class=p>(</span><span class=n>row1</span><span class=p>,</span> <span class=n>row2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 1为曼哈顿</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 1为欧几里得</span>
</span></span><span class=line><span class=cl><span class=n>dist</span> <span class=o>=</span> <span class=n>minkowski_distance</span><span class=p>(</span><span class=n>row1</span><span class=p>,</span> <span class=n>row2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dist</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用包 scipy.spatial来计算</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>minkowski_distance</span><span class=p>(</span><span class=n>row1</span><span class=p>,</span> <span class=n>row2</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>minkowski_distance</span><span class=p>(</span><span class=n>row1</span><span class=p>,</span> <span class=n>row2</span><span class=p>,</span> <span class=mi>2</span><span class=p>))</span></span></span></code></pre></td></tr></table></div></div></div></div><h2 id=knn算法实现>KNN算法实现<a hidden class=anchor aria-hidden=true href=#knn算法实现>#</a></h2><h3 id=prerequisite>Prerequisite<a hidden class=anchor aria-hidden=true href=#prerequisite>#</a></h3><p>首先会用示例来实现KNN算法的每个步骤，并加以分析，然后将所有步骤关联在在一起，形成一个适用于真实数据集的实现。</p><p>KNN在实现起来主要有三个步骤：</p><ul><li>计算距离（这里选择欧几里得距离）</li><li>获得临近邻居</li><li>做出预测</li></ul><p>这三个步骤是KNN算法用以解决分类和回归预测建模问题的基础知识</p><h3 id=计算距离>计算距离<a hidden class=anchor aria-hidden=true href=#计算距离>#</a></h3><p>第一步计算数据集中两行之间的距离。在数据集中的数据行主要由数字组成，计算两行或数字向量之间的距离的一种简单方法是画一条直线。这在 2D 或 3D 平面中都是很好地选择，并且可以很好地扩展到更高的维度。</p><p>这里使用的是比较流行的计算距离的算法，<strong>欧几里得距离</strong>来计算两个向量之间的直线距离。欧几里得距离的公式是，两个向量的平方差的平方根，$Euclidean\ Distance=\sqrt[]{\sum(a-b)^2}$ ；在python中可以表示为：<code>sqrt(sum i to N (x1 – x2)^2)</code> ；其中 <code>x1</code> 是第一行数据，<code>x2</code> 是第二行数据，<code>i</code> 表示特定列的索引，因为可能需要对所有行进行计算。</p><p>在欧几里得距离中，值越小，两条记录就越相似； 0 表示两条记录之间没有差异。</p><p>那么使用python实现一个计算欧几里得距离的算法</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>euclidean_distance</span><span class=p>(</span><span class=n>row1</span><span class=p>,</span> <span class=n>row2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=n>distance</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>row1</span><span class=p>)</span><span class=o>-</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>		<span class=n>distance</span> <span class=o>+=</span> <span class=p>(</span><span class=n>row1</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>-</span> <span class=n>row2</span><span class=p>[</span><span class=n>i</span><span class=p>])</span><span class=o>**</span><span class=mi>2</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=n>sqrt</span><span class=p>(</span><span class=n>distance</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div></div></div><p>准备一部分测试数据，来对测试距离算法</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>X1</span>				<span class=n>X2</span>					<span class=n>Y</span>
</span></span><span class=line><span class=cl><span class=mf>2.7810836</span>		<span class=mf>2.550537003</span>			<span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=mf>1.465489372</span>		<span class=mf>2.362125076</span>			<span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=mf>3.396561688</span>		<span class=mf>4.400293529</span>			<span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=mf>1.38807019</span>		<span class=mf>1.850220317</span>			<span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=mf>3.06407232</span>		<span class=mf>3.005305973</span>			<span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=mf>7.627531214</span>		<span class=mf>2.759262235</span>			<span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=mf>5.332441248</span>		<span class=mf>2.088626775</span>			<span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=mf>6.922596716</span>		<span class=mf>1.77106367</span>			<span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=mf>8.675418651</span>		<span class=o>-</span><span class=mf>0.242068655</span>		<span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=mf>7.673756466</span>		<span class=mf>3.508563011</span>			<span class=mi>1</span></span></span></code></pre></td></tr></table></div></div></div></div><p>那么来测试这些数据，需要做到的是第一行与所有行之间的距离，对于第一行与自己的距离应该为<strong>0</strong></p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>math</span> <span class=kn>import</span> <span class=n>sqrt</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 欧几里得距离，计算两个向量间距离的算法</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>euclidean_distance</span><span class=p>(</span><span class=n>row1</span><span class=p>,</span> <span class=n>row2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=n>distance</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>row1</span><span class=p>)</span><span class=o>-</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>		<span class=n>distance</span> <span class=o>+=</span> <span class=p>(</span><span class=n>row1</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>-</span> <span class=n>row2</span><span class=p>[</span><span class=n>i</span><span class=p>])</span><span class=o>**</span><span class=mi>2</span> <span class=c1># 平方差</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=n>sqrt</span><span class=p>(</span><span class=n>distance</span><span class=p>)</span> <span class=c1># 平方根</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 测试数据集</span>
</span></span><span class=line><span class=cl><span class=n>dataset</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>2.7810836</span><span class=p>,</span><span class=mf>2.550537003</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>1.465489372</span><span class=p>,</span><span class=mf>2.362125076</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>3.396561688</span><span class=p>,</span><span class=mf>4.400293529</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>1.38807019</span><span class=p>,</span><span class=mf>1.850220317</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>3.06407232</span><span class=p>,</span><span class=mf>3.005305973</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>7.627531214</span><span class=p>,</span><span class=mf>2.759262235</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>5.332441248</span><span class=p>,</span><span class=mf>2.088626775</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>6.922596716</span><span class=p>,</span><span class=mf>1.77106367</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>8.675418651</span><span class=p>,</span><span class=o>-</span><span class=mf>0.242068655</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>7.673756466</span><span class=p>,</span><span class=mf>3.508563011</span><span class=p>,</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>row0</span> <span class=o>=</span> <span class=n>dataset</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>	<span class=n>distance</span> <span class=o>=</span> <span class=n>euclidean_distance</span><span class=p>(</span><span class=n>row0</span><span class=p>,</span> <span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=nb>print</span><span class=p>(</span><span class=n>distance</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl><span class=c1># 0.0</span>
</span></span><span class=line><span class=cl><span class=c1># 1.3290173915275787</span>
</span></span><span class=line><span class=cl><span class=c1># 1.9494646655653247</span>
</span></span><span class=line><span class=cl><span class=c1># 1.5591439385540549</span>
</span></span><span class=line><span class=cl><span class=c1># 0.5356280721938492</span>
</span></span><span class=line><span class=cl><span class=c1># 4.850940186986411</span>
</span></span><span class=line><span class=cl><span class=c1># 2.592833759950511</span>
</span></span><span class=line><span class=cl><span class=c1># 4.214227042632867</span>
</span></span><span class=line><span class=cl><span class=c1># 6.522409988228337</span>
</span></span><span class=line><span class=cl><span class=c1># 4.985585382449795</span></span></span></code></pre></td></tr></table></div></div></div></div><h3 id=获取最近邻居>获取最近邻居<a hidden class=anchor aria-hidden=true href=#获取最近邻居>#</a></h3><p>数据集中新数据的邻居是k个最接近的实例（行），这个实例由距离定义。现在诞生的问题：<strong>如何找到最近的邻居？以及怎么找到最近的邻居？</strong></p><ul><li><p>为了在数据集中找到 K 的邻居，首先必须计算数据集中每条记录与新数据之间的距离。</p></li><li><p>有了距离之后，必须按照 <strong>K</strong> 的距离对训练集中的所有实例排序。然后选择前 <strong>k</strong> 个作为最近的邻居。</p></li></ul><p>这里实现起来是通过将数据集中每条记录的距离作为一个元组来跟踪，通过对元组列表进行排序（距离降序），然后检索最近邻居。下面是一个实现这些步骤的函数</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 找到最近的邻居</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_neighbors</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>test_row</span><span class=p>,</span> <span class=n>num_neighbors</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    计算训练集train中所有元素到test_row的距离
</span></span></span><span class=line><span class=cl><span class=s2>    :param train: list, 数据集，可以是训练集
</span></span></span><span class=line><span class=cl><span class=s2>    :param test_row: list, 新的实例，也就是K
</span></span></span><span class=line><span class=cl><span class=s2>    :param num_neighbors:int，需要多少个邻居
</span></span></span><span class=line><span class=cl><span class=s2>    :return: None
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>distances</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>train_row</span> <span class=ow>in</span> <span class=n>train</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># 计算出每一行的距离，把他添加到元组中</span>
</span></span><span class=line><span class=cl>        <span class=n>dist</span> <span class=o>=</span> <span class=n>euclidean_distance</span><span class=p>(</span><span class=n>test_row</span><span class=p>,</span> <span class=n>train_row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>distances</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=n>train_row</span><span class=p>,</span> <span class=n>dist</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>distances</span><span class=o>.</span><span class=n>sort</span><span class=p>(</span><span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>knn</span><span class=p>:</span> <span class=n>knn</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span> <span class=c1># 根据元素哪个字段进行排序</span>
</span></span><span class=line><span class=cl>    <span class=n>neighbors</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_neighbors</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>neighbors</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>distances</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>neighbors</span></span></span></code></pre></td></tr></table></div></div></div></div><p>下面是完整的示例</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>math</span> <span class=kn>import</span> <span class=n>sqrt</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 欧几里得距离，计算两个向量间距离的算法</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>euclidean_distance</span><span class=p>(</span><span class=n>row1</span><span class=p>,</span> <span class=n>row2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=n>distance</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>row1</span><span class=p>)</span><span class=o>-</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>		<span class=n>distance</span> <span class=o>+=</span> <span class=p>(</span><span class=n>row1</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>-</span> <span class=n>row2</span><span class=p>[</span><span class=n>i</span><span class=p>])</span><span class=o>**</span><span class=mi>2</span> <span class=c1># 平方差</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=n>sqrt</span><span class=p>(</span><span class=n>distance</span><span class=p>)</span> <span class=c1># 平方根</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 找到最近的邻居</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_neighbors</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>test_row</span><span class=p>,</span> <span class=n>num_neighbors</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    计算训练集train中所有元素到test_row的距离
</span></span></span><span class=line><span class=cl><span class=s2>    :param train: list, 数据集，可以是训练集
</span></span></span><span class=line><span class=cl><span class=s2>    :param test_row: list, 新的实例，也就是K
</span></span></span><span class=line><span class=cl><span class=s2>    :param num_neighbors:int，需要多少个邻居
</span></span></span><span class=line><span class=cl><span class=s2>    :return: None
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>distances</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>train_row</span> <span class=ow>in</span> <span class=n>train</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># 计算出每一行的距离，把他添加到元组中</span>
</span></span><span class=line><span class=cl>        <span class=n>dist</span> <span class=o>=</span> <span class=n>euclidean_distance</span><span class=p>(</span><span class=n>test_row</span><span class=p>,</span> <span class=n>train_row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>distances</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=n>train_row</span><span class=p>,</span> <span class=n>dist</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>distances</span><span class=o>.</span><span class=n>sort</span><span class=p>(</span><span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>knn</span><span class=p>:</span> <span class=n>knn</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span> <span class=c1># 根据元素哪个字段进行排序</span>
</span></span><span class=line><span class=cl>    <span class=n>neighbors</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_neighbors</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>neighbors</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>distances</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>neighbors</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 测试数据集</span>
</span></span><span class=line><span class=cl><span class=n>dataset</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>2.7810836</span><span class=p>,</span><span class=mf>2.550537003</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>1.465489372</span><span class=p>,</span><span class=mf>2.362125076</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>3.396561688</span><span class=p>,</span><span class=mf>4.400293529</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>1.38807019</span><span class=p>,</span><span class=mf>1.850220317</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>3.06407232</span><span class=p>,</span><span class=mf>3.005305973</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>7.627531214</span><span class=p>,</span><span class=mf>2.759262235</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>5.332441248</span><span class=p>,</span><span class=mf>2.088626775</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>6.922596716</span><span class=p>,</span><span class=mf>1.77106367</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>8.675418651</span><span class=p>,</span><span class=o>-</span><span class=mf>0.242068655</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>7.673756466</span><span class=p>,</span><span class=mf>3.508563011</span><span class=p>,</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>neighbors</span> <span class=o>=</span> <span class=n>get_neighbors</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>dataset</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>neighbor</span> <span class=ow>in</span> <span class=n>neighbors</span><span class=p>:</span>
</span></span><span class=line><span class=cl>	<span class=nb>print</span><span class=p>(</span><span class=n>neighbor</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># [2.7810836, 2.550537003, 0]</span>
</span></span><span class=line><span class=cl><span class=c1># [3.06407232, 3.005305973, 0]</span>
</span></span><span class=line><span class=cl><span class=c1># [1.465489372, 2.362125076, 0]</span></span></span></code></pre></td></tr></table></div></div></div></div><p>可以看到，运行后会将数据集中最相似的 3 条记录按相似度顺序打印。和预测的一样，第一个记录与其本身最相似，并且位于列表的顶部。</p><h3 id=预测结果>预测结果<a hidden class=anchor aria-hidden=true href=#预测结果>#</a></h3><p>预测结果在这里指定是，通过分类拿到了最近的邻居的实例，对邻居进行分类，找到邻居中最大类别的一类，作为预测值。这里使用的是对邻居值执行 <code>max()</code> 来实现这一点，下面是实现方式</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 预测值</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>predict_classification</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>test_row</span><span class=p>,</span> <span class=n>num_neighbors</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    计算训练集train中所有元素到test_row的距离
</span></span></span><span class=line><span class=cl><span class=s2>    :param train: list, 数据集，可以是训练集
</span></span></span><span class=line><span class=cl><span class=s2>    :param test_row: list, 新的实例，也就是K
</span></span></span><span class=line><span class=cl><span class=s2>    :param num_neighbors:int，需要多少个邻居
</span></span></span><span class=line><span class=cl><span class=s2>    :return: None
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>neighbors</span> <span class=o>=</span> <span class=n>get_neighbors</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>test_row</span><span class=p>,</span> <span class=n>num_neighbors</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>output_values</span> <span class=o>=</span> <span class=p>[</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>neighbors</span><span class=p>]</span> <span class=c1># 拿到所属类的真实类别</span>
</span></span><span class=line><span class=cl>    <span class=n>prediction</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>output_values</span><span class=p>),</span> <span class=n>key</span><span class=o>=</span><span class=n>output_values</span><span class=o>.</span><span class=n>count</span><span class=p>)</span>  <span class=c1>#算出邻居类别最大的数量</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>prediction</span></span></span></code></pre></td></tr></table></div></div></div></div><p>下面是完整的示例</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>math</span> <span class=kn>import</span> <span class=n>sqrt</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 欧几里得距离，计算两个向量间距离的算法</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>euclidean_distance</span><span class=p>(</span><span class=n>row1</span><span class=p>,</span> <span class=n>row2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>distance</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>row1</span><span class=p>)</span><span class=o>-</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>distance</span> <span class=o>+=</span> <span class=p>(</span><span class=n>row1</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>-</span> <span class=n>row2</span><span class=p>[</span><span class=n>i</span><span class=p>])</span><span class=o>**</span><span class=mi>2</span> <span class=c1># 平方差</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>sqrt</span><span class=p>(</span><span class=n>distance</span><span class=p>)</span> <span class=c1># 平方根</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl><span class=c1># 找到最近的邻居</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_neighbors</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>test_row</span><span class=p>,</span> <span class=n>num_neighbors</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    计算训练集train中所有元素到test_row的距离
</span></span></span><span class=line><span class=cl><span class=s2>    :param train: list, 数据集，可以是训练集
</span></span></span><span class=line><span class=cl><span class=s2>    :param test_row: list, 新的实例，也就是K
</span></span></span><span class=line><span class=cl><span class=s2>    :param num_neighbors:int，需要多少个邻居
</span></span></span><span class=line><span class=cl><span class=s2>    :return: None
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>distances</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>train_row</span> <span class=ow>in</span> <span class=n>train</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># 计算出每一行的距离，把他添加到元组中</span>
</span></span><span class=line><span class=cl>        <span class=n>dist</span> <span class=o>=</span> <span class=n>euclidean_distance</span><span class=p>(</span><span class=n>test_row</span><span class=p>,</span> <span class=n>train_row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>distances</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=n>train_row</span><span class=p>,</span> <span class=n>dist</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>distances</span><span class=o>.</span><span class=n>sort</span><span class=p>(</span><span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>knn</span><span class=p>:</span> <span class=n>knn</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span> <span class=c1># 根据元素哪个字段进行排序</span>
</span></span><span class=line><span class=cl>    <span class=n>neighbors</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_neighbors</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>neighbors</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>distances</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>neighbors</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 预测值</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>predict_classification</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>test_row</span><span class=p>,</span> <span class=n>num_neighbors</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    计算训练集train中所有元素到test_row的距离
</span></span></span><span class=line><span class=cl><span class=s2>    :param train: list, 数据集，可以是训练集
</span></span></span><span class=line><span class=cl><span class=s2>    :param test_row: list, 新的实例，也就是K
</span></span></span><span class=line><span class=cl><span class=s2>    :param num_neighbors:int，需要多少个邻居
</span></span></span><span class=line><span class=cl><span class=s2>    :return: None
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>neighbors</span> <span class=o>=</span> <span class=n>get_neighbors</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>test_row</span><span class=p>,</span> <span class=n>num_neighbors</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>output_values</span> <span class=o>=</span> <span class=p>[</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>neighbors</span><span class=p>]</span> <span class=c1># 拿到所属类的真实类别</span>
</span></span><span class=line><span class=cl>    <span class=n>prediction</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>output_values</span><span class=p>),</span> <span class=n>key</span><span class=o>=</span><span class=n>output_values</span><span class=o>.</span><span class=n>count</span><span class=p>)</span>  <span class=c1>#算出邻居类别最大的数量</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>prediction</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 测试数据集</span>
</span></span><span class=line><span class=cl><span class=n>dataset</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mf>2.7810836</span><span class=p>,</span><span class=mf>2.550537003</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>1.465489372</span><span class=p>,</span><span class=mf>2.362125076</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>3.396561688</span><span class=p>,</span><span class=mf>4.400293529</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>1.38807019</span><span class=p>,</span><span class=mf>1.850220317</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>3.06407232</span><span class=p>,</span><span class=mf>3.005305973</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>7.627531214</span><span class=p>,</span><span class=mf>2.759262235</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>5.332441248</span><span class=p>,</span><span class=mf>2.088626775</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>6.922596716</span><span class=p>,</span><span class=mf>1.77106367</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>8.675418651</span><span class=p>,</span><span class=o>-</span><span class=mf>0.242068655</span><span class=p>,</span><span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=p>[</span><span class=mf>7.673756466</span><span class=p>,</span><span class=mf>3.508563011</span><span class=p>,</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>n</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>    <span class=n>prediction</span> <span class=o>=</span> <span class=n>predict_classification</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>dataset</span><span class=p>[</span><span class=n>n</span><span class=p>],</span> <span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Expected </span><span class=si>%d</span><span class=s1>, Got </span><span class=si>%d</span><span class=s1>.&#39;</span> <span class=o>%</span> <span class=p>(</span><span class=n>dataset</span><span class=p>[</span><span class=n>n</span><span class=p>][</span><span class=o>-</span><span class=mi>1</span><span class=p>],</span> <span class=n>prediction</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Expected 0, Got 0.</span>
</span></span><span class=line><span class=cl><span class=c1># Expected 0, Got 0.</span>
</span></span><span class=line><span class=cl><span class=c1># Expected 0, Got 0.</span>
</span></span><span class=line><span class=cl><span class=c1># Expected 0, Got 0.</span>
</span></span><span class=line><span class=cl><span class=c1># Expected 0, Got 0.</span>
</span></span><span class=line><span class=cl><span class=c1># Expected 1, Got 1.</span>
</span></span><span class=line><span class=cl><span class=c1># Expected 1, Got 1.</span>
</span></span><span class=line><span class=cl><span class=c1># Expected 1, Got 1.</span>
</span></span><span class=line><span class=cl><span class=c1># Expected 1, Got 1.</span>
</span></span><span class=line><span class=cl><span class=c1># Expected 1, Got 1.</span></span></span></code></pre></td></tr></table></div></div></div></div><p>运行结果打印了预期分类与从数据集中 3 个相进邻居预测结果是一直的。</p><h2 id=鸢尾花种实例>鸢尾花种实例<a hidden class=anchor aria-hidden=true href=#鸢尾花种实例>#</a></h2><p>这里使用的是 <a href=https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv target=_blank rel="noopener nofollow noreferrer">Iris Flower Species</a> 数据集。</p><p>鸢尾花数据集是根据鸢尾花的测量值预测花卉种类。这是一个多类分类问题。每个类的观察数量是平衡的。有 150 个观测值，有 4 个输入变量和 1 个输出变量。变量名称如下：</p><ul><li>萼片长度以厘米为单位。</li><li>萼片宽度以厘米为单位。</li><li>花瓣长度以厘米为单位。</li><li>花瓣宽度以厘米为单位。</li><li>真实类型</li></ul><p>更多的关于数据集的说明可以参考：<a href=https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.names target=_blank rel="noopener nofollow noreferrer">Iris-databases数据集的说明</a></p><h3 id=prerequisite-1>Prerequisite<a hidden class=anchor aria-hidden=true href=#prerequisite-1>#</a></h3><p>实验的步骤大概分为如下：</p><ul><li>加载数据集并将数据转换为可用于均值和标准差计算的数字。将属性转为float，将类别转换为int。</li><li>使 5折的<strong>K</strong>折较差验证（<strong>K-Fold CV</strong>）评估该算法。</li></ul><h3 id=start>Start<a hidden class=anchor aria-hidden=true href=#start>#</a></h3><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span><span class=lnt>129
</span><span class=lnt>130
</span><span class=lnt>131
</span><span class=lnt>132
</span><span class=lnt>133
</span><span class=lnt>134
</span><span class=lnt>135
</span><span class=lnt>136
</span><span class=lnt>137
</span><span class=lnt>138
</span><span class=lnt>139
</span><span class=lnt>140
</span><span class=lnt>141
</span><span class=lnt>142
</span><span class=lnt>143
</span><span class=lnt>144
</span><span class=lnt>145
</span><span class=lnt>146
</span><span class=lnt>147
</span><span class=lnt>148
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>random</span> <span class=kn>import</span> <span class=n>seed</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>random</span> <span class=kn>import</span> <span class=n>randrange</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>csv</span> <span class=kn>import</span> <span class=n>reader</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>math</span> <span class=kn>import</span> <span class=n>sqrt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载CSV</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_csv</span><span class=p>(</span><span class=n>filename</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>filename</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>file</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>csv_reader</span> <span class=o>=</span> <span class=n>reader</span><span class=p>(</span><span class=n>file</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>csv_reader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=ow>not</span> <span class=n>row</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>continue</span>
</span></span><span class=line><span class=cl>            <span class=n>dataset</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 转换所有的值为float方便运算</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>str_column_to_float</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>column</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>row</span><span class=p>[</span><span class=n>column</span><span class=p>]</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=n>column</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 转换所有的类型为int</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>str_column_to_int</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>column</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>class_values</span> <span class=o>=</span> <span class=p>[</span><span class=n>row</span><span class=p>[</span><span class=n>column</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>unique</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>class_values</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>lookup</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>value</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>unique</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>lookup</span><span class=p>[</span><span class=n>value</span><span class=p>]</span> <span class=o>=</span> <span class=n>i</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>row</span><span class=p>[</span><span class=n>column</span><span class=p>]</span> <span class=o>=</span> <span class=n>lookup</span><span class=p>[</span><span class=n>row</span><span class=p>[</span><span class=n>column</span><span class=p>]]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>lookup</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># # k-folds CV函数进行划分</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>cross_validation_split</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>n_folds</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset_split</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset_copy</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 平均分成n_folds折数</span>
</span></span><span class=line><span class=cl>    <span class=n>fold_size</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>)</span> <span class=o>/</span> <span class=n>n_folds</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_folds</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>fold</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>while</span> <span class=nb>len</span><span class=p>(</span><span class=n>fold</span><span class=p>)</span> <span class=o>&lt;</span> <span class=n>fold_size</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>index</span> <span class=o>=</span> <span class=n>randrange</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset_copy</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>fold</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>dataset_copy</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=n>index</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>dataset_split</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>fold</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>dataset_split</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 计算精确度</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>accuracy_metric</span><span class=p>(</span><span class=n>actual</span><span class=p>,</span> <span class=n>predicted</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>actual</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>actual</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>==</span> <span class=n>predicted</span><span class=p>[</span><span class=n>i</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=n>correct</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>correct</span> <span class=o>/</span> <span class=nb>float</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>actual</span><span class=p>))</span> <span class=o>*</span> <span class=mf>100.0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 评估算法</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>evaluate_algorithm</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>algorithm</span><span class=p>,</span> <span class=n>n_folds</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    评估算法，计算算法的精确度
</span></span></span><span class=line><span class=cl><span class=s2>    :param dataset: list, 数据集
</span></span></span><span class=line><span class=cl><span class=s2>    :param algorithm: function, 算法名
</span></span></span><span class=line><span class=cl><span class=s2>    :param n_folds: int，折数
</span></span></span><span class=line><span class=cl><span class=s2>    :param args: 用于algorithm的参数
</span></span></span><span class=line><span class=cl><span class=s2>    :return: None
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>folds</span> <span class=o>=</span> <span class=n>cross_validation_split</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>n_folds</span><span class=p>)</span> <span class=c1># 分成5折</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>fold</span> <span class=ow>in</span> <span class=n>folds</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>folds</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=o>.</span><span class=n>remove</span><span class=p>(</span><span class=n>fold</span><span class=p>)</span> <span class=c1># 训练集不包含本身</span>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>train_set</span><span class=p>,</span> <span class=p>[])</span>
</span></span><span class=line><span class=cl>        <span class=n>test_set</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span> <span class=c1># 测试集</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>fold</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>row_copy</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>test_set</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>row_copy</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>row_copy</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=n>predicted</span> <span class=o>=</span> <span class=n>algorithm</span><span class=p>(</span><span class=n>train_set</span><span class=p>,</span> <span class=n>test_set</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>actual</span> <span class=o>=</span> <span class=p>[</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>fold</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>accuracy</span> <span class=o>=</span> <span class=n>accuracy_metric</span><span class=p>(</span><span class=n>actual</span><span class=p>,</span> <span class=n>predicted</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>accuracy</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>scores</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 欧几里得距离，计算两个向量间距离的算法</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>euclidean_distance</span><span class=p>(</span><span class=n>row1</span><span class=p>,</span> <span class=n>row2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>distance</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>row1</span><span class=p>)</span><span class=o>-</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>distance</span> <span class=o>+=</span> <span class=p>(</span><span class=n>row1</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>-</span> <span class=n>row2</span><span class=p>[</span><span class=n>i</span><span class=p>])</span><span class=o>**</span><span class=mi>2</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>sqrt</span><span class=p>(</span><span class=n>distance</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 确定最邻近的邻居</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_neighbors</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>test_row</span><span class=p>,</span> <span class=n>num_neighbors</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    计算训练集train中所有元素到test_row的距离
</span></span></span><span class=line><span class=cl><span class=s2>    :param train: list, 数据集，可以是训练集
</span></span></span><span class=line><span class=cl><span class=s2>    :param test_row: list, 新的实例，也就是K
</span></span></span><span class=line><span class=cl><span class=s2>    :param num_neighbors:int，需要多少个邻居
</span></span></span><span class=line><span class=cl><span class=s2>    :return: None
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>distances</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>train_row</span> <span class=ow>in</span> <span class=n>train</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>dist</span> <span class=o>=</span> <span class=n>euclidean_distance</span><span class=p>(</span><span class=n>test_row</span><span class=p>,</span> <span class=n>train_row</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>distances</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=n>train_row</span><span class=p>,</span> <span class=n>dist</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>distances</span><span class=o>.</span><span class=n>sort</span><span class=p>(</span><span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>tup</span><span class=p>:</span> <span class=n>tup</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>neighbors</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_neighbors</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>neighbors</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>distances</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>neighbors</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 与临近值进行比较并预测</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>predict_classification</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>test_row</span><span class=p>,</span> <span class=n>num_neighbors</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    计算训练集train中所有元素到test_row的距离
</span></span></span><span class=line><span class=cl><span class=s2>    :param train: list, 数据集，可以是训练集
</span></span></span><span class=line><span class=cl><span class=s2>    :param test_row: list, 新的实例，也就是K
</span></span></span><span class=line><span class=cl><span class=s2>    :param num_neighbors:int，需要多少个邻居
</span></span></span><span class=line><span class=cl><span class=s2>    :return: None
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>neighbors</span> <span class=o>=</span> <span class=n>get_neighbors</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>test_row</span><span class=p>,</span> <span class=n>num_neighbors</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>output_values</span> <span class=o>=</span> <span class=p>[</span><span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>neighbors</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>prediction</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>output_values</span><span class=p>),</span> <span class=n>key</span><span class=o>=</span><span class=n>output_values</span><span class=o>.</span><span class=n>count</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>prediction</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># kNN Algorithm</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>k_nearest_neighbors</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>test</span><span class=p>,</span> <span class=n>num_neighbors</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>predictions</span> <span class=o>=</span> <span class=nb>list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>test</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=n>predict_classification</span><span class=p>(</span><span class=n>train</span><span class=p>,</span> <span class=n>row</span><span class=p>,</span> <span class=n>num_neighbors</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>predictions</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span><span class=p>(</span><span class=n>predictions</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用KNN算法计算鸢尾花数据集</span>
</span></span><span class=line><span class=cl><span class=n>seed</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>filename</span> <span class=o>=</span> <span class=s1>&#39;iris.csv&#39;</span>
</span></span><span class=line><span class=cl><span class=n>dataset</span> <span class=o>=</span> <span class=n>load_csv</span><span class=p>(</span><span class=n>filename</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span><span class=o>-</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>str_column_to_float</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 转换类型为int</span>
</span></span><span class=line><span class=cl><span class=n>str_column_to_int</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 评估算法</span>
</span></span><span class=line><span class=cl><span class=n>n_folds</span> <span class=o>=</span> <span class=mi>5</span> <span class=c1># 5折</span>
</span></span><span class=line><span class=cl><span class=n>num_neighbors</span> <span class=o>=</span> <span class=mi>5</span> <span class=c1>#取5个邻居</span>
</span></span><span class=line><span class=cl><span class=n>scores</span> <span class=o>=</span> <span class=n>evaluate_algorithm</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>k_nearest_neighbors</span><span class=p>,</span> <span class=n>n_folds</span><span class=p>,</span> <span class=n>num_neighbors</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Scores: </span><span class=si>%s</span><span class=s1>&#39;</span> <span class=o>%</span> <span class=n>scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Mean Accuracy: </span><span class=si>%.3f%%</span><span class=s1>&#39;</span> <span class=o>%</span> <span class=p>(</span><span class=nb>sum</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span><span class=o>/</span><span class=nb>float</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>scores</span><span class=p>))))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Scores: [96.66666666666667, 96.66666666666667, 100.0, 90.0, 100.0]</span>
</span></span><span class=line><span class=cl><span class=c1># Mean Accuracy: 96.667%</span></span></span></code></pre></td></tr></table></div></div></div></div><p>上述是对整个数据集的预测百分比，也可以对对应的类的信息进行输出</p><p>首先在类别转换函数 <code>str_column_to_int</code> 中增加打印方法</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>value</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>unique</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>lookup</span><span class=p>[</span><span class=n>value</span><span class=p>]</span> <span class=o>=</span> <span class=n>i</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;[</span><span class=si>%s</span><span class=s1>] =&gt; </span><span class=si>%d</span><span class=s1>&#39;</span> <span class=o>%</span> <span class=p>(</span><span class=n>value</span><span class=p>,</span> <span class=n>i</span><span class=p>))</span></span></span></code></pre></td></tr></table></div></div></div></div><p>然后在定义一个新的实例，这个实例是用于预测的信息 <code>row = [5.7,2.9,4.2,1.3]</code> ; 然后修改需要预测的数据，进行预测</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>python</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 原来的整个数据集打分不需要了</span>
</span></span><span class=line><span class=cl><span class=c1># scores = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors)</span>
</span></span><span class=line><span class=cl><span class=c1># print(&#39;Scores: %s&#39; % scores)</span>
</span></span><span class=line><span class=cl><span class=c1># print(&#39;Mean Accuracy: %.3f%%&#39; % (sum(scores)/float(len(scores))))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义一个新数据</span>
</span></span><span class=line><span class=cl><span class=n>row</span> <span class=o>=</span> <span class=p>[</span><span class=mf>5.7</span><span class=p>,</span><span class=mf>2.9</span><span class=p>,</span><span class=mf>4.2</span><span class=p>,</span><span class=mf>1.3</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>label</span> <span class=o>=</span> <span class=n>predict_classification</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>row</span><span class=p>,</span> <span class=n>num_neighbors</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Data=</span><span class=si>%s</span><span class=s1>, Predicted: </span><span class=si>%s</span><span class=s1>&#39;</span> <span class=o>%</span> <span class=p>(</span><span class=n>row</span><span class=p>,</span> <span class=n>label</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Data=[5.7, 2.9, 4.2, 1.3], Predicted: 1</span></span></span></code></pre></td></tr></table></div></div></div></div><p>通过预测，可以看出预测结果属于第 1 类，就知道该花为 <code>Iris-setosa</code> 。</p><h2 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h2><p><a href=https://machinelearningmastery.com/distance-measures-for-machine-learning/ target=_blank rel="noopener nofollow noreferrer">distance measures</a>
<a href=https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/ target=_blank rel="noopener nofollow noreferrer">k nearest neighbors implement</a></p></div><div class=pe-copyright><hr><blockquote><p>本文为原创内容，版权归作者所有。如需转载，请在文章中声明本文标题及链接。</p><p>文章标题：KNN算法</p><p>文章链接：<a href=http://localhost:1313/2022/06/knn/ target=_blank>http://localhost:1313/2022/06/knn/</a></p><p>许可协议：<a href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></p></blockquote></div><div class=comments-separator></div><h3 class=relatedContentTitle>相关阅读</h3><ul class=relatedContent><li><a href=/2022/06/decision-tree/><span>决策树</span></a></li><li><a href=/2022/06/decision-boundary/><span>决策边界算法</span></a></li><li><a href=/2022/06/naive-bayes/><span>朴素贝叶斯算法</span></a></li><li><a href=/2022/06/logistic-regression/><span>逻辑回归</span></a></li><li><a href=/2016/09/consistent-hash/><span>一致性hash在memcache中的应用</span></a></li></ul><div class=comments-separator></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/machinelearning/>MachineLearning</a></li><li><a href=http://localhost:1313/tags/algorithm/>Algorithm</a></li><li><a href=http://localhost:1313/tags/cs/>CS</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/2022/06/ch09-queue/><span class=title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left" style="user-select:text"><line x1="19" y1="12" x2="5" y2="12" style="user-select:text"/><polyline points="12 19 5 12 12 5" style="user-select:text"/></polyline></svg>&nbsp;</span>
<span>源码分析client-go架构 - queue</span>
</a><a class=next href=http://localhost:1313/2022/06/decision-boundary/><span class=title></span>
<span>决策边界算法&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right" style="user-select:text"><line x1="5" y1="12" x2="19" y2="12" style="user-select:text"/><polyline points="12 5 19 12 12 19" style="user-select:text"/></svg></span></a></nav></footer><div class=pe-comments-decoration><p class=pe-comments-title></p><p class=pe-comments-subtitle></p></div><div id=pe-comments></div><script src=/js/pe-go-comment.min.86a214102576ba5f9b7bdc29eed8d58dd56e34aef80b3c65c73ea9cc88443696.js integrity="sha256-hqIUECV2ul+be9wp7tjVjdVuNK74Czxlxz6pzIhENpY="></script><script>const getStoredTheme=()=>localStorage.getItem("pref-theme")==="dark"?"dark":"light",setGiscusTheme=()=>{const e=e=>{const t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:e},"https://giscus.app")};e({setConfig:{theme:getStoredTheme()}})};document.addEventListener("DOMContentLoaded",()=>{const s={src:"https://giscus.app/client.js","data-repo":"cylonchau/cylonchau.github.io","data-repo-id":"R_kgDOIRlNSQ","data-category":"Announcements","data-category-id":"DIC_kwDOIRlNSc4CXy1U","data-mapping":"pathname","data-term":"posts/knn","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"top","data-theme":getStoredTheme(),"data-lang":"zh-TW","data-loading":"lazy",crossorigin:"anonymous",async:""},e=document.createElement("script");Object.entries(s).forEach(([t,n])=>e.setAttribute(t,n)),document.querySelector("#pe-comments").appendChild(e);const t=document.querySelector("#theme-toggle");t&&t.addEventListener("click",setGiscusTheme);const n=document.querySelector("#theme-toggle-float");n&&n.addEventListener("click",setGiscusTheme)})</script></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Cylon's Collection</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> on
<a href=https://pages.github.com/ rel=noopener target=_blank>GitHub Pages</a> & Theme
        <a href=https://github.com/tofuwine/PaperMod-PE rel=noopener target=_blank>PaperMod-PE</a></span></footer><div class=pe-right-sidebar><a href=javascript:void(0); id=theme-toggle-float class=pe-float-btn><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</a><a href=#top class=pe-float-btn id=top-link><span id=pe-read-progress></span></a></div><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>