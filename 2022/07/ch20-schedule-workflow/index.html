<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>kube-scheduler的调度上下文 | Cylon&#39;s Collection</title>
<meta name="keywords" content="kubernetes, develop">
<meta name="description" content="kube-scheduler的调度上下文 - Cylon&#39;s Collection">
<meta name="author" content="cylon">
<link rel="canonical" href="https://www.oomkill.com/2022/07/ch20-schedule-workflow/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.41a8706089174fae1769fc26da4d1d354fa88083db604a95688ff58852dd9006.css" integrity="sha256-QahwYIkXT64Xafwm2k0dNU&#43;ogIPbYEqVaI/1iFLdkAY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://www.oomkill.com/favicon.ico">
<link rel="apple-touch-icon" href="https://www.oomkill.com/apple-touch-icon.png">

<meta name="twitter:title" content="kube-scheduler的调度上下文 | Cylon&#39;s Collection" />
<meta name="twitter:description" content="" />
<meta property="og:title" content="kube-scheduler的调度上下文 | Cylon&#39;s Collection" />
<meta property="og:description" content="" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.oomkill.com/2022/07/ch20-schedule-workflow/" />
<meta property="article:section" content="posts" />
  <meta property="article:published_time" content="2022-07-21T00:00:00&#43;00:00" />
  <meta property="article:modified_time" content="2022-07-21T00:00:00&#43;00:00" />


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://www.oomkill.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "kube-scheduler的调度上下文",
      "item": "https://www.oomkill.com/2022/07/ch20-schedule-workflow/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "kube-scheduler的调度上下文 | Cylon's Collection",
  "name": "kube-scheduler的调度上下文",
  "description": "",
  "keywords": [
    "kubernetes", "develop"
  ],
  "wordCount" : "7452",
  "inLanguage": "zh",
  "datePublished": "2022-07-21T00:00:00Z",
  "dateModified": "2022-07-21T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "cylon"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.oomkill.com/2022/07/ch20-schedule-workflow/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Cylon's Collection",
    "logo": {
      "@type": "ImageObject",
      "url": "https://www.oomkill.com/favicon.ico"
    }
  }
}
</script><script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary-bg: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list-page {
                background: var(--theme);
            }

            .list-page:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list-page:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

</head>

<body class=" type-posts kind-page layout-" id="top"><script data-no-instant>
function switchTheme(theme) {
  switch (theme) {
    case 'light':
      document.body.classList.remove('dark');
      break;
    case 'dark':
      document.body.classList.add('dark');
      break;
    
    default:
      if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
      }
  }
}

function isDarkTheme() {
  return document.body.className.includes("dark");
}

function getPrefTheme() {
  return localStorage.getItem("pref-theme");
}

function setPrefTheme(theme) {
  switchTheme(theme)
  localStorage.setItem("pref-theme", theme);
}

const toggleThemeCallbacks = {}
toggleThemeCallbacks['main'] = (isDark) => {
  
  if (isDark) {
    setPrefTheme('light');
  } else {
    setPrefTheme('dark');
  }
}




window.addEventListener('toggle-theme', function() {
  
  const isDark = isDarkTheme()
  for (const key in toggleThemeCallbacks) {
    toggleThemeCallbacks[key](isDark)
  }
});


function toggleThemeListener() {
  
  window.dispatchEvent(new CustomEvent('toggle-theme'));
}

</script>
<script>
  
  (function() {
    const defaultTheme = 'auto';
    const prefTheme = getPrefTheme();
    const theme = prefTheme ? prefTheme : defaultTheme;

    switchTheme(theme);
  })();
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://www.oomkill.com" accesskey="h" title="Cylon&#39;s Collection (Alt + H)">Cylon&#39;s Collection</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://www.oomkill.com/archives/" title="归档"
                >归档
                </a>
            </li>
            <li>
                <a href="https://www.oomkill.com/tags/" title="标签"
                >标签
                </a>
            </li>
            <li>
                <a href="https://www.oomkill.com/search/" title="搜索 (Alt &#43; /)"data-no-instant accesskey=/
                >搜索
                </a>
            </li>
            <li>
                <a href="https://www.oomkill.com/about/" title="关于"
                >关于
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main post">

<article class="post-single">
  <header class="post-header"><h1 class="post-title">kube-scheduler的调度上下文</h1>
    <div class="post-meta"><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select: text;"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select: text;"></rect><line x1="16" y1="2" x2="16" y2="6" style="user-select: text;"></line><line x1="8" y1="2" x2="8" y2="6" style="user-select: text;"></line><line x1="3" y1="10" x2="21" y2="10" style="user-select: text;"></line></svg>
  <span>2022-07-21</span></span><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select: text;"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select: text;"></rect><line x1="16" y1="2" x2="16" y2="6" style="user-select: text;"></line><line x1="8" y1="2" x2="8" y2="6" style="user-select: text;"></line><line x1="3" y1="10" x2="21" y2="10" style="user-select: text;"></line></svg>
  <span>Edited on 2022-07-21</span></span><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon" style="user-select: text;"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z" style="user-select: text;"></path><line x1="7" y1="7" x2="7" y2="7" style="user-select: text;"></line></svg>
  <span class="post-tags"><a href="https://www.oomkill.com/tags/kubernetes-develop/">kubernetes develop</a><a href="https://www.oomkill.com/tags/kubernetes/">kubernetes</a></span></span><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><circle cx="12" cy="12" r="9"></circle><polyline points="12 7 12 12 15 15"></polyline></svg>
  <span>15 分钟</span></span>

      
      
    </div>
  </header> <div class="toc side right">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">目录</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#scheduler" aria-label="Scheduler">Scheduler</a></li>
                <li>
                    <a href="#schedulingqueue" aria-label="SchedulingQueue">SchedulingQueue</a></li>
                <li>
                    <a href="#%e8%b0%83%e5%ba%a6%e4%b8%8a%e4%b8%8b%e6%96%87" aria-label="调度上下文">调度上下文</a><ul>
                        
                <li>
                    <a href="#sort" aria-label="Sort">Sort</a></li>
                <li>
                    <a href="#prefilter" aria-label="preFilter">preFilter</a></li>
                <li>
                    <a href="#filter" aria-label="filter">filter</a></li>
                <li>
                    <a href="#postfilter" aria-label="Postfilter">Postfilter</a></li>
                <li>
                    <a href="#prescorescore" aria-label="PreScore,Score">PreScore,Score</a></li>
                <li>
                    <a href="#reserve" aria-label="Reserve">Reserve</a></li>
                <li>
                    <a href="#permit" aria-label="permit">permit</a></li>
                <li>
                    <a href="#binding-cycle" aria-label="Binding Cycle">Binding Cycle</a></li></ul>
                </li>
                <li>
                    <a href="#%e8%b0%83%e5%ba%a6%e4%b8%8a%e4%b8%8b%e6%96%87%e4%b8%ad%e7%9a%84%e5%a4%b1%e8%b4%a5%e6%b5%81%e7%a8%8b" aria-label="调度上下文中的失败流程">调度上下文中的失败流程</a></li>
                <li>
                    <a href="#%e6%80%bb%e7%bb%93%e8%b0%83%e5%ba%a6%e4%b8%8a%e4%b8%8b%e6%96%87%e6%b5%81%e7%a8%8b" aria-label="总结调度上下文流程">总结调度上下文流程</a></li>
                <li>
                    <a href="#reference" aria-label="Reference">Reference</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content">
    





<div class="copyrightTopBlock">
    <p>本文发布于<a href="https://www.oomkill.com/about" target="_blank">Cylon的收藏册</a>，转载请著名原文链接~</p>
    <div class="articleSuffix-bg"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 147.78 155.96"> <path d="M10.5,99.81a1.9,1.9,0,0,0-.53-.09,1.66,1.66,0,0,0-1.64,1.65A1.64,1.64,0,0,0,10,103a1.57,1.57,0,0,0,.87-.25l26.76,26.82.45-1.08L11.52,101.91A1.65,1.65,0,0,0,10.5,99.81Zm-.13,2a.57.57,0,0,1-.8,0,.58.58,0,0,1-.17-.41.58.58,0,0,1,.57-.57h0a.57.57,0,0,1,.56.58A.55.55,0,0,1,10.37,101.77Z" style="fill:#c5c9e0"></path><path d="M56.15,117.58H39.06l0-.09a1.65,1.65,0,0,0-1.36-1H37.5a1.65,1.65,0,1,0,1.56,2.19H55.7L92.92,156h41.44v-1.08h-41Zm-18.25.94a.56.56,0,0,1-.79,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.56-.57h0a.58.58,0,0,1,.57.58A.54.54,0,0,1,37.9,118.52Z" style="fill:#c5c9e0"></path><path d="M23.52,50.32a1.65,1.65,0,0,0,1.55-1.11H55.28l48-48.13h31.06V0H102.85l-48,48.13H25.07a1.64,1.64,0,0,0-2.09-1,1.64,1.64,0,0,0,.54,3.2Zm0-2.21a.57.57,0,0,1,0,1.13.57.57,0,1,1,0-1.13Z" style="fill:#c5c9e0"></path><polygon points="102.86 0 102.86 0 102.86 0 102.86 0" style="fill:#c5c9e0"></polygon><path d="M107.72,12.14h26.64V11.07H107.27L57.4,61H3.09a1.66,1.66,0,0,0-1.45-.86H1.52A1.65,1.65,0,1,0,2.81,63a1.59,1.59,0,0,0,.45-.87H57.85ZM2.05,62.23a.57.57,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.56-.57h.09a.57.57,0,0,1,.32,1Z" style="fill:#c5c9e0"></path><path d="M134.36,43.22V42.14h-22.3l-9.62,9.63a1.64,1.64,0,0,0-2.19.77,1.61,1.61,0,0,0-.17.71,1.65,1.65,0,1,0,3.29,0,1.61,1.61,0,0,0-.16-.72l9.3-9.32Zm-32.64,10.6a.57.57,0,0,1,0-1.13.57.57,0,0,1,0,1.13Z" style="fill:#c5c9e0"></path><path d="M147,52.3l-9,9H111.48a1.64,1.64,0,0,0-1.61-1.33h-.14a1.65,1.65,0,1,0,1.6,2.41h27.19l9.26-9.29L147,52.3Zm-37.15,9.85a.56.56,0,0,1-.56-.57h0a.56.56,0,0,1,.56-.56h0a.57.57,0,1,1,0,1.13Z" style="fill:#c5c9e0"></path><path d="M66.79,75.35l11,11.06h56.53V85.33H78.27l-11-11.06H49.49L37.12,86.67a1.64,1.64,0,0,0-2.09,1,1.61,1.61,0,0,0-.09.54,1.65,1.65,0,0,0,3.29,0,1.68,1.68,0,0,0-.26-.89l12-12ZM36.58,88.79a.57.57,0,1,1,.57-.56A.57.57,0,0,1,36.58,88.79Z" style="fill:#c5c9e0"></path><path d="M110.61,95.55,92.8,113.4a1.62,1.62,0,1,0,.77.76l17.49-17.53h23.31V95.55ZM92.49,115.28a.56.56,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.57-.57h0a.58.58,0,0,1,.56.58A.55.55,0,0,1,92.49,115.28Z" style="fill:#c5c9e0"></path><path d="M97.89,122.3H76.62L64.2,109.85a1.65,1.65,0,0,0-.77-2.2,1.77,1.77,0,0,0-.72-.17h-.14a1.65,1.65,0,0,0,.15,3.29,1.58,1.58,0,0,0,.71-.17l12.74,12.77H98.34l17.48-17.52h18.54v-1.08h-19ZM63.12,109.53a.56.56,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,1.14,0A.54.54,0,0,1,63.12,109.53Z" style="fill:#c5c9e0"></path> </svg> </div>
</div>
<br><h2 id="scheduler">Scheduler<a hidden class="anchor" aria-hidden="true" href="#scheduler">¶</a></h2>
<p><a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/pkg/scheduler/scheduler.go#L64-L102" target="_blank"
   rel="noopener nofollow noreferrer" >Scheduler</a> 是整个 <code>kube-scheduler</code> 的一个 structure，提供了 <code>kube-scheduler</code> 运行所需的组件。</p>
<pre><code class="language-go">type Scheduler struct {
	// Cache是一个抽象，会缓存pod的信息，作为scheduler进行查找，操作是基于Pod进行增加
	Cache internalcache.Cache
	// Extenders 算是调度框架中提供的调度插件，会影响kubernetes中的调度策略
	Extenders []framework.Extender

	// NextPod 作为一个函数提供，会阻塞获取下一个ke'diao'du
	NextPod func() *framework.QueuedPodInfo

	// Error is called if there is an error. It is passed the pod in
	// question, and the error
	Error func(*framework.QueuedPodInfo, error)

	// SchedulePod 尝试将给出的pod调度到Node。
	SchedulePod func(ctx context.Context, fwk framework.Framework, state *framework.CycleState, pod *v1.Pod) (ScheduleResult, error)

	// 关闭scheduler的信号
	StopEverything &lt;-chan struct{}

	// SchedulingQueue保存要调度的Pod
	SchedulingQueue internalqueue.SchedulingQueue

	// Profiles中是多个调度框架
	Profiles profile.Map
	client clientset.Interface
	nodeInfoSnapshot *internalcache.Snapshot
	percentageOfNodesToScore int32
	nextStartNodeIndex int
}
</code></pre>
<p>作为实际执行的两个核心，<code>SchedulingQueue</code> ，与 <code>scheduleOne</code> 将会分析到这两个</p>
<h2 id="schedulingqueue">SchedulingQueue<a hidden class="anchor" aria-hidden="true" href="#schedulingqueue">¶</a></h2>
<p>在知道 <code>kube-scheduler</code> 初始化过程后，需要对 <code>kube-scheduler</code> 的整个 <em>structure</em> 和 <em>workflow</em> 进行分析</p>
<p>在 <a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/pkg/scheduler/scheduler.go#L336-L340" target="_blank"
   rel="noopener nofollow noreferrer" >Run</a> 中，运行的是 一个 <code>SchedulingQueue</code> 与 一个 <code>scheduleOne</code> ，从结构上看是属于 <em>Scheduler</em></p>
<pre><code class="language-go">func (sched *Scheduler) Run(ctx context.Context) {
	sched.SchedulingQueue.Run()

	// We need to start scheduleOne loop in a dedicated goroutine,
	// because scheduleOne function hangs on getting the next item
	// from the SchedulingQueue.
	// If there are no new pods to schedule, it will be hanging there
	// and if done in this goroutine it will be blocking closing
	// SchedulingQueue, in effect causing a deadlock on shutdown.
	go wait.UntilWithContext(ctx, sched.scheduleOne, 0)

	&lt;-ctx.Done()
	sched.SchedulingQueue.Close()
}

</code></pre>
<p><a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/pkg/scheduler/internal/queue/scheduling_queue.go#L81-L110" target="_blank"
   rel="noopener nofollow noreferrer" >SchedulingQueue</a> 是一个队列的抽象，用于存储等待调度的Pod。该接口遵循类似于 cache.FIFO 和 cache.Heap 的模式。</p>
<pre><code class="language-go">type SchedulingQueue interface {
	framework.PodNominator
	Add(pod *v1.Pod) error
	// Activate moves the given pods to activeQ iff they're in unschedulablePods or backoffQ.
	// The passed-in pods are originally compiled from plugins that want to activate Pods,
	// by injecting the pods through a reserved CycleState struct (PodsToActivate).
	Activate(pods map[string]*v1.Pod)
	// 将不可调度的Pod重入到队列中
	AddUnschedulableIfNotPresent(pod *framework.QueuedPodInfo, podSchedulingCycle int64) error
	// SchedulingCycle returns the current number of scheduling cycle which is
	// cached by scheduling queue. Normally, incrementing this number whenever
	// a pod is popped (e.g. called Pop()) is enough.
	SchedulingCycle() int64
	// Pop会弹出一个pod，并从head优先级队列中删除
	Pop() (*framework.QueuedPodInfo, error)
	Update(oldPod, newPod *v1.Pod) error
	Delete(pod *v1.Pod) error
	MoveAllToActiveOrBackoffQueue(event framework.ClusterEvent, preCheck PreEnqueueCheck)
	AssignedPodAdded(pod *v1.Pod)
	AssignedPodUpdated(pod *v1.Pod)
	PendingPods() []*v1.Pod
	// Close closes the SchedulingQueue so that the goroutine which is
	// waiting to pop items can exit gracefully.
	Close()
	// Run starts the goroutines managing the queue.
	Run()
}
</code></pre>
<p>而 <a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/pkg/scheduler/internal/queue/scheduling_queue.go#L134-L175" target="_blank"
   rel="noopener nofollow noreferrer" >PriorityQueue</a> 是 <code>SchedulingQueue</code> 的实现，该部分的核心构成是两个子队列与一个数据结构，即 <code>activeQ</code>、<code>backoffQ</code> 和 <code>unschedulablePods</code></p>
<ul>
<li><code>activeQ</code>：是一个 <em>heap</em> 类型的优先级队列，是 <em>sheduler</em> 从中获得优先级最高的Pod进行调度</li>
<li><code>backoffQ</code>：也是一个 <em>heap</em> 类型的优先级队列，存放的是不可调度的Pod</li>
<li><code>unschedulablePods </code>：保存确定不可被调度的Pod</li>
</ul>
<pre><code class="language-GO">type SchedulingQueue interface {
	framework.PodNominator
	Add(pod *v1.Pod) error
	// Activate moves the given pods to activeQ iff they're in unschedulablePods or backoffQ.
	// The passed-in pods are originally compiled from plugins that want to activate Pods,
	// by injecting the pods through a reserved CycleState struct (PodsToActivate).
	Activate(pods map[string]*v1.Pod)
	// AddUnschedulableIfNotPresent adds an unschedulable pod back to scheduling queue.
	// The podSchedulingCycle represents the current scheduling cycle number which can be
	// returned by calling SchedulingCycle().
	AddUnschedulableIfNotPresent(pod *framework.QueuedPodInfo, podSchedulingCycle int64) error
	// SchedulingCycle returns the current number of scheduling cycle which is
	// cached by scheduling queue. Normally, incrementing this number whenever
	// a pod is popped (e.g. called Pop()) is enough.
	SchedulingCycle() int64
	// Pop removes the head of the queue and returns it. It blocks if the
	// queue is empty and waits until a new item is added to the queue.
	Pop() (*framework.QueuedPodInfo, error)
	Update(oldPod, newPod *v1.Pod) error
	Delete(pod *v1.Pod) error
	MoveAllToActiveOrBackoffQueue(event framework.ClusterEvent, preCheck PreEnqueueCheck)
	AssignedPodAdded(pod *v1.Pod)
	AssignedPodUpdated(pod *v1.Pod)
	PendingPods() []*v1.Pod
	// Close closes the SchedulingQueue so that the goroutine which is
	// waiting to pop items can exit gracefully.
	Close()
	// Run starts the goroutines managing the queue.
	Run()
}
</code></pre>
<p>在New <em>scheduler</em> 时可以看到会初始化这个queue</p>
<pre><code class="language-go">podQueue := internalqueue.NewSchedulingQueue(
    // 实现pod对比的一个函数即less
    profiles[options.profiles[0].SchedulerName].QueueSortFunc(),
    informerFactory,
    internalqueue.WithPodInitialBackoffDuration(time.Duration(options.podInitialBackoffSeconds)*time.Second),
    internalqueue.WithPodMaxBackoffDuration(time.Duration(options.podMaxBackoffSeconds)*time.Second),
    internalqueue.WithPodNominator(nominator),
    internalqueue.WithClusterEventMap(clusterEventMap),
    internalqueue.WithPodMaxInUnschedulablePodsDuration(options.podMaxInUnschedulablePodsDuration),
)
</code></pre>
<p>而 <a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/pkg/scheduler/internal/queue/scheduling_queue.go#L252-L289" target="_blank"
   rel="noopener nofollow noreferrer" >NewSchedulingQueue</a> 则是初始化这个 PriorityQueue</p>
<pre><code class="language-go">// NewSchedulingQueue initializes a priority queue as a new scheduling queue.
func NewSchedulingQueue(
	lessFn framework.LessFunc,
	informerFactory informers.SharedInformerFactory,
	opts ...Option) SchedulingQueue {
	return NewPriorityQueue(lessFn, informerFactory, opts...)
}

// NewPriorityQueue creates a PriorityQueue object.
func NewPriorityQueue(
	lessFn framework.LessFunc,
	informerFactory informers.SharedInformerFactory,
	opts ...Option,
) *PriorityQueue {
	options := defaultPriorityQueueOptions
	for _, opt := range opts {
		opt(&amp;options)
	}
	// 这个就是 less函数，作为打分的一部分
	comp := func(podInfo1, podInfo2 interface{}) bool {
		pInfo1 := podInfo1.(*framework.QueuedPodInfo)
		pInfo2 := podInfo2.(*framework.QueuedPodInfo)
		return lessFn(pInfo1, pInfo2)
	}

	if options.podNominator == nil {
		options.podNominator = NewPodNominator(informerFactory.Core().V1().Pods().Lister())
	}

	pq := &amp;PriorityQueue{
		PodNominator:                      options.podNominator,
		clock:                             options.clock,
		stop:                              make(chan struct{}),
		podInitialBackoffDuration:         options.podInitialBackoffDuration,
		podMaxBackoffDuration:             options.podMaxBackoffDuration,
		podMaxInUnschedulablePodsDuration: options.podMaxInUnschedulablePodsDuration,
		activeQ:                           heap.NewWithRecorder(podInfoKeyFunc, comp, metrics.NewActivePodsRecorder()),
		unschedulablePods:                 newUnschedulablePods(metrics.NewUnschedulablePodsRecorder()),
		moveRequestCycle:                  -1,
		clusterEventMap:                   options.clusterEventMap,
	}
	pq.cond.L = &amp;pq.lock
	pq.podBackoffQ = heap.NewWithRecorder(podInfoKeyFunc, pq.podsCompareBackoffCompleted, metrics.NewBackoffPodsRecorder())
	pq.nsLister = informerFactory.Core().V1().Namespaces().Lister()

	return pq
}
</code></pre>
<p>了解了Queue的结构，就需要知道 入队列与出队列是在哪里操作的。在初始化时，需要注册一个 <code>addEventHandlerFuncs</code> 这个时候，会注入三个动作函数，也就是controller中的概念；而在AddFunc中可以看到会入队列。</p>
<p>注入是对 Pod 的<a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/pkg/scheduler/eventhandlers.go#L302-L305" target="_blank"
   rel="noopener nofollow noreferrer" >informer</a>注入的，注入的函数 <a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/pkg/scheduler/eventhandlers.go#L114-L120" target="_blank"
   rel="noopener nofollow noreferrer" >addPodToSchedulingQueue</a>  就是入栈</p>
<pre><code class="language-go">Handler: cache.ResourceEventHandlerFuncs{
    AddFunc:    sched.addPodToSchedulingQueue,
    UpdateFunc: sched.updatePodInSchedulingQueue,
    DeleteFunc: sched.deletePodFromSchedulingQueue,
},

func (sched *Scheduler) addPodToSchedulingQueue(obj interface{}) {
	pod := obj.(*v1.Pod)
	klog.V(3).InfoS(&quot;Add event for unscheduled pod&quot;, &quot;pod&quot;, klog.KObj(pod))
	if err := sched.SchedulingQueue.Add(pod); err != nil {
		utilruntime.HandleError(fmt.Errorf(&quot;unable to queue %T: %v&quot;, obj, err))
	}
}
</code></pre>
<p>而这个 <code>SchedulingQueue</code> 的实现就是 <code>PriorityQueue</code> ，而Add中则对 activeQ进行的操作</p>
<pre><code class="language-go">func (p *PriorityQueue) Add(pod *v1.Pod) error {
	p.lock.Lock()
	defer p.lock.Unlock()
    // 格式化入栈数据，包含podinfo，里会包含v1.Pod
    // 初始化的时间，创建的时间，以及不能被调度时的记录其plugin的名称
	pInfo := p.newQueuedPodInfo(pod)
    // 入栈
	if err := p.activeQ.Add(pInfo); err != nil {
		klog.ErrorS(err, &quot;Error adding pod to the active queue&quot;, &quot;pod&quot;, klog.KObj(pod))
		return err
	}
	if p.unschedulablePods.get(pod) != nil {
		klog.ErrorS(nil, &quot;Error: pod is already in the unschedulable queue&quot;, &quot;pod&quot;, klog.KObj(pod))
		p.unschedulablePods.delete(pod)
	}
	// Delete pod from backoffQ if it is backing off
	if err := p.podBackoffQ.Delete(pInfo); err == nil {
		klog.ErrorS(nil, &quot;Error: pod is already in the podBackoff queue&quot;, &quot;pod&quot;, klog.KObj(pod))
	}
	metrics.SchedulerQueueIncomingPods.WithLabelValues(&quot;active&quot;, PodAdd).Inc()
	p.PodNominator.AddNominatedPod(pInfo.PodInfo, nil)
	p.cond.Broadcast()

	return nil
}
</code></pre>
<p>在上面看 <em>scheduler</em> 结构时，可以看到有一个 nextPod的，nextPod就是从队列中弹出一个pod，这个在<em>scheduler</em> 时会传入 <a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/pkg/scheduler/internal/queue/scheduling_queue.go#L952-L965" target="_blank"
   rel="noopener nofollow noreferrer" >MakeNextPodFunc</a> 就是这个 nextpod</p>
<pre><code class="language-go">func MakeNextPodFunc(queue SchedulingQueue) func() *framework.QueuedPodInfo {
	return func() *framework.QueuedPodInfo {
		podInfo, err := queue.Pop()
		if err == nil {
			klog.V(4).InfoS(&quot;About to try and schedule pod&quot;, &quot;pod&quot;, klog.KObj(podInfo.Pod))
			for plugin := range podInfo.UnschedulablePlugins {
				metrics.UnschedulableReason(plugin, podInfo.Pod.Spec.SchedulerName).Dec()
			}
			return podInfo
		}
		klog.ErrorS(err, &quot;Error while retrieving next pod from scheduling queue&quot;)
		return nil
	}
}
</code></pre>
<p>而这个 <code>queue.Pop()</code> 对应的就是 <code>PriorityQueue</code> 的 <a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/pkg/scheduler/internal/queue/scheduling_queue.go#L483-L503" target="_blank"
   rel="noopener nofollow noreferrer" >Pop()</a> ，在这里会将作为 activeQ 的消费端</p>
<pre><code class="language-go">func (p *PriorityQueue) Pop() (*framework.QueuedPodInfo, error) {
   p.lock.Lock()
   defer p.lock.Unlock()
   for p.activeQ.Len() == 0 {
      // When the queue is empty, invocation of Pop() is blocked until new item is enqueued.
      // When Close() is called, the p.closed is set and the condition is broadcast,
      // which causes this loop to continue and return from the Pop().
      if p.closed {
         return nil, fmt.Errorf(queueClosed)
      }
      p.cond.Wait()
   }
   obj, err := p.activeQ.Pop()
   if err != nil {
      return nil, err
   }
   pInfo := obj.(*framework.QueuedPodInfo)
   pInfo.Attempts++
   p.schedulingCycle++
   return pInfo, nil
}
</code></pre>
<p>在上面入口部分也看到了，scheduleOne 和 scheduler，scheduleOne 就是去消费一个Pod，他会调用 NextPod，NextPod就是在初始化传入的 <code>MakeNextPodFunc</code> ，至此回到对应的 Pop来做消费。</p>
<p>schedulerOne是为一个Pod做调度的流程。</p>
<pre><code class="language-go">func (sched *Scheduler) scheduleOne(ctx context.Context) {
	podInfo := sched.NextPod()
	// pod could be nil when schedulerQueue is closed
	if podInfo == nil || podInfo.Pod == nil {
		return
	}
	pod := podInfo.Pod
	fwk, err := sched.frameworkForPod(pod)
	if err != nil {
		// This shouldn't happen, because we only accept for scheduling the pods
		// which specify a scheduler name that matches one of the profiles.
		klog.ErrorS(err, &quot;Error occurred&quot;)
		return
	}
	if sched.skipPodSchedule(fwk, pod) {
		return
	}
...
</code></pre>
<h2 id="调度上下文">调度上下文<a hidden class="anchor" aria-hidden="true" href="#调度上下文">¶</a></h2>
<p>当了解了scheduler结构后，下面分析下调度上下文的过程。看看扩展点是怎么工作的。这个时候又需要提到官网的调度上下文的图。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/scheduling-framework-extensions.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center class="podsc">图1：Pod的调度上下文</center>
<center><em>Source：</em>https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework</center>
<p>而 <em>scheduler</em> 对于调度上下文来就是这个 <code>scheduleOne </code> ，下面就是看这个调度上下文</p>
<h3 id="sort">Sort<a hidden class="anchor" aria-hidden="true" href="#sort">¶</a></h3>
<p><code>Sort</code> 插件提供了排序功能，用于对在调度队列中待处理 Pod 进行排序。一次只能启用一个队列排序。</p>
<p>在进入 <code>scheduleOne</code> 后，<code>NextPod</code> 从 <code>activeQ</code> 中队列中得到一个Pod，然后的 <code>frameworkForPod</code> 会做打分的动作就是调度上下文的第一个扩展点 <code>sort</code></p>
<pre><code class="language-go">func (sched *Scheduler) scheduleOne(ctx context.Context) {
	podInfo := sched.NextPod()
	// pod could be nil when schedulerQueue is closed
	if podInfo == nil || podInfo.Pod == nil {
		return
	}
	pod := podInfo.Pod
	fwk, err := sched.frameworkForPod(pod)
...
    
func (sched *Scheduler) frameworkForPod(pod *v1.Pod) (framework.Framework, error) {
    // 获取指定的profile
	fwk, ok := sched.Profiles[pod.Spec.SchedulerName]
	if !ok {
		return nil, fmt.Errorf(&quot;profile not found for scheduler name %q&quot;, pod.Spec.SchedulerName)
	}
	return fwk, nil
}
</code></pre>
<p>回顾，因为在New scheduler时会初始化这个 sort 函数</p>
<pre><code class="language-go">podQueue := internalqueue.NewSchedulingQueue(
    profiles[options.profiles[0].SchedulerName].QueueSortFunc(),
    informerFactory,
    internalqueue.WithPodInitialBackoffDuration(time.Duration(options.podInitialBackoffSeconds)*time.Second),
    internalqueue.WithPodMaxBackoffDuration(time.Duration(options.podMaxBackoffSeconds)*time.Second),
    internalqueue.WithPodNominator(nominator),
    internalqueue.WithClusterEventMap(clusterEventMap),
    internalqueue.WithPodMaxInUnschedulablePodsDuration(options.podMaxInUnschedulablePodsDuration),
)
</code></pre>
<h3 id="prefilter">preFilter<a hidden class="anchor" aria-hidden="true" href="#prefilter">¶</a></h3>
<p>preFilter作为第一个扩展点，是用于在过滤之前预处理或检查 Pod 或集群的相关信息。这里会终止调度</p>
<pre><code class="language-go">func (sched *Scheduler) scheduleOne(ctx context.Context) {
	podInfo := sched.NextPod()
	// pod could be nil when schedulerQueue is closed
	if podInfo == nil || podInfo.Pod == nil {
		return
	}
	pod := podInfo.Pod
	fwk, err := sched.frameworkForPod(pod)
	if err != nil {
		// This shouldn't happen, because we only accept for scheduling the pods
		// which specify a scheduler name that matches one of the profiles.
		klog.ErrorS(err, &quot;Error occurred&quot;)
		return
	}
	if sched.skipPodSchedule(fwk, pod) {
		return
	}

	klog.V(3).InfoS(&quot;Attempting to schedule pod&quot;, &quot;pod&quot;, klog.KObj(pod))

	// Synchronously attempt to find a fit for the pod.
	start := time.Now()
	state := framework.NewCycleState()
	state.SetRecordPluginMetrics(rand.Intn(100) &lt; pluginMetricsSamplePercent)
	// Initialize an empty podsToActivate struct, which will be filled up by plugins or stay empty.
	podsToActivate := framework.NewPodsToActivate()
	state.Write(framework.PodsToActivateKey, podsToActivate)

	schedulingCycleCtx, cancel := context.WithCancel(ctx)
	defer cancel()
    // 这里将进入prefilter
	scheduleResult, err := sched.SchedulePod(schedulingCycleCtx, fwk, state, pod)
</code></pre>
<p><a href="https://github.com/kubernetes/kubernetes/blob/32c483ea6ee90a3a81f382563c91034470af8a4a/pkg/scheduler/schedule_one.go#L311-L360" target="_blank"
   rel="noopener nofollow noreferrer" >schedulePod</a> 尝试将给定的 pod 调度到节点列表中的节点之一。如果成功，它将返回节点的名称。</p>
<pre><code class="language-go">func (sched *Scheduler) schedulePod(ctx context.Context, fwk framework.Framework, state *framework.CycleState, pod *v1.Pod) (result ScheduleResult, err error) {
	trace := utiltrace.New(&quot;Scheduling&quot;, utiltrace.Field{Key: &quot;namespace&quot;, Value: pod.Namespace}, utiltrace.Field{Key: &quot;name&quot;, Value: pod.Name})
	defer trace.LogIfLong(100 * time.Millisecond)
	// 用于将cache更新为当前内容
	if err := sched.Cache.UpdateSnapshot(sched.nodeInfoSnapshot); err != nil {
		return result, err
	}
	trace.Step(&quot;Snapshotting scheduler cache and node infos done&quot;)

	if sched.nodeInfoSnapshot.NumNodes() == 0 {
		return result, ErrNoNodesAvailable
	}
	// 找到一个合适的pod时，会执行扩展点
	feasibleNodes, diagnosis, err := sched.findNodesThatFitPod(ctx, fwk, state, pod)
	
    ...
</code></pre>
<p><a href="https://github.com/kubernetes/kubernetes/blob/32c483ea6ee90a3a81f382563c91034470af8a4a/pkg/scheduler/schedule_one.go#L364-L426" target="_blank"
   rel="noopener nofollow noreferrer" >findNodesThatFitPod</a> 会执行对应的过滤插件来找到最适合的Node，包括备注，以及方法名都可以看到，这里运行的插件😁😁，后面会分析算法内容，只对workflow学习。</p>
<pre><code class="language-go">func (sched *Scheduler) findNodesThatFitPod(ctx context.Context, fwk framework.Framework, state *framework.CycleState, pod *v1.Pod) ([]*v1.Node, framework.Diagnosis, error) {
	diagnosis := framework.Diagnosis{
		NodeToStatusMap:      make(framework.NodeToStatusMap),
		UnschedulablePlugins: sets.NewString(),
	}

	// Run &quot;prefilter&quot; plugins.
	preRes, s := fwk.RunPreFilterPlugins(ctx, state, pod)
	allNodes, err := sched.nodeInfoSnapshot.NodeInfos().List()
	if err != nil {
		return nil, diagnosis, err
	}
	if !s.IsSuccess() {
		if !s.IsUnschedulable() {
			return nil, diagnosis, s.AsError()
		}
		// All nodes will have the same status. Some non trivial refactoring is
		// needed to avoid this copy.
		for _, n := range allNodes {
			diagnosis.NodeToStatusMap[n.Node().Name] = s
		}
		// Status satisfying IsUnschedulable() gets injected into diagnosis.UnschedulablePlugins.
		if s.FailedPlugin() != &quot;&quot; {
			diagnosis.UnschedulablePlugins.Insert(s.FailedPlugin())
		}
		return nil, diagnosis, nil
	}

	// &quot;NominatedNodeName&quot; can potentially be set in a previous scheduling cycle as a result of preemption.
	// This node is likely the only candidate that will fit the pod, and hence we try it first before iterating over all nodes.
	if len(pod.Status.NominatedNodeName) &gt; 0 {
		feasibleNodes, err := sched.evaluateNominatedNode(ctx, pod, fwk, state, diagnosis)
		if err != nil {
			klog.ErrorS(err, &quot;Evaluation failed on nominated node&quot;, &quot;pod&quot;, klog.KObj(pod), &quot;node&quot;, pod.Status.NominatedNodeName)
		}
		// Nominated node passes all the filters, scheduler is good to assign this node to the pod.
		if len(feasibleNodes) != 0 {
			return feasibleNodes, diagnosis, nil
		}
	}

	nodes := allNodes
	if !preRes.AllNodes() {
		nodes = make([]*framework.NodeInfo, 0, len(preRes.NodeNames))
		for n := range preRes.NodeNames {
			nInfo, err := sched.nodeInfoSnapshot.NodeInfos().Get(n)
			if err != nil {
				return nil, diagnosis, err
			}
			nodes = append(nodes, nInfo)
		}
	}
	feasibleNodes, err := sched.findNodesThatPassFilters(ctx, fwk, state, pod, diagnosis, nodes)
	if err != nil {
		return nil, diagnosis, err
	}

	feasibleNodes, err = findNodesThatPassExtenders(sched.Extenders, pod, feasibleNodes, diagnosis.NodeToStatusMap)
	if err != nil {
		return nil, diagnosis, err
	}
	return feasibleNodes, diagnosis, nil
}
</code></pre>
<h3 id="filter">filter<a hidden class="anchor" aria-hidden="true" href="#filter">¶</a></h3>
<p>filter插件相当于<em>调度上下文</em>中的 <code>Predicates</code>，用于排除不能运行 Pod 的节点。Filter 会按配置的顺序进行调用。如果有一个filter将节点标记位不可用，则将 Pod 标记为不可调度（即不会向下执行）。</p>
<p>对于代码中来讲，filter还是处于 <a href="https://github.com/kubernetes/kubernetes/blob/32c483ea6ee90a3a81f382563c91034470af8a4a/pkg/scheduler/schedule_one.go#L364-L426" target="_blank"
   rel="noopener nofollow noreferrer" >findNodesThatFitPod</a> 函数中，<code>findNodesThatPassFilters</code> 就是获取到 FN，即可行节点，而这个过程就是 <em>filter</em> 扩展点</p>
<pre><code class="language-go">func (sched *Scheduler) findNodesThatFitPod(ctx context.Context, fwk framework.Framework, state *framework.CycleState, pod *v1.Pod) ([]*v1.Node, framework.Diagnosis, error) {
	...
    
	feasibleNodes, err := sched.findNodesThatPassFilters(ctx, fwk, state, pod, diagnosis, nodes)
	if err != nil {
		return nil, diagnosis, err
	}

	feasibleNodes, err = findNodesThatPassExtenders(sched.Extenders, pod, feasibleNodes, diagnosis.NodeToStatusMap)
	if err != nil {
		return nil, diagnosis, err
	}
	return feasibleNodes, diagnosis, nil
}
</code></pre>
<h3 id="postfilter">Postfilter<a hidden class="anchor" aria-hidden="true" href="#postfilter">¶</a></h3>
<p>当没有为 pod 找到<em>FN</em>时，该插件会按照配置的顺序进行调用。如果任何<code>postFilter</code>插件将 Pod 标记为<em>schedulable</em>，则不会调用其余插件。即 <code>filter</code> 成功后不会进行这步骤，那我们来验证下这里把😊</p>
<p>还是在 scheduleOne 中，当我们运行的 SchedulePod 完成后（成功或失败），这时会返回一个err，而 <code>postfilter</code> 会根据这个 err进行选择执行或不执行，符合官方给出的说法。</p>
<pre><code class="language-go">scheduleResult, err := sched.SchedulePod(schedulingCycleCtx, fwk, state, pod)
	if err != nil {
		// SchedulePod() may have failed because the pod would not fit on any host, so we try to
		// preempt, with the expectation that the next time the pod is tried for scheduling it
		// will fit due to the preemption. It is also possible that a different pod will schedule
		// into the resources that were preempted, but this is harmless.
		var nominatingInfo *framework.NominatingInfo
		if fitError, ok := err.(*framework.FitError); ok {
			if !fwk.HasPostFilterPlugins() {
				klog.V(3).InfoS(&quot;No PostFilter plugins are registered, so no preemption will be performed&quot;)
			} else {
				// Run PostFilter plugins to try to make the pod schedulable in a future scheduling cycle.
				result, status := fwk.RunPostFilterPlugins(ctx, state, pod, fitError.Diagnosis.NodeToStatusMap)
				if status.Code() == framework.Error {
					klog.ErrorS(nil, &quot;Status after running PostFilter plugins for pod&quot;, &quot;pod&quot;, klog.KObj(pod), &quot;status&quot;, status)
				} else {
					fitError.Diagnosis.PostFilterMsg = status.Message()
					klog.V(5).InfoS(&quot;Status after running PostFilter plugins for pod&quot;, &quot;pod&quot;, klog.KObj(pod), &quot;status&quot;, status)
				}
				if result != nil {
					nominatingInfo = result.NominatingInfo
				}
			}
			// Pod did not fit anywhere, so it is counted as a failure. If preemption
			// succeeds, the pod should get counted as a success the next time we try to
			// schedule it. (hopefully)
			metrics.PodUnschedulable(fwk.ProfileName(), metrics.SinceInSeconds(start))
		} else if err == ErrNoNodesAvailable {
			nominatingInfo = clearNominatedNode
			// No nodes available is counted as unschedulable rather than an error.
			metrics.PodUnschedulable(fwk.ProfileName(), metrics.SinceInSeconds(start))
		} else {
			nominatingInfo = clearNominatedNode
			klog.ErrorS(err, &quot;Error selecting node for pod&quot;, &quot;pod&quot;, klog.KObj(pod))
			metrics.PodScheduleError(fwk.ProfileName(), metrics.SinceInSeconds(start))
		}
		sched.handleSchedulingFailure(ctx, fwk, podInfo, err, v1.PodReasonUnschedulable, nominatingInfo)
		return
	}
</code></pre>
<h3 id="prescorescore">PreScore,Score<a hidden class="anchor" aria-hidden="true" href="#prescorescore">¶</a></h3>
<p>可用于进行预Score工作，作为通知性的扩展点，会在在filter完之后直接会关联 preScore 插件进行继续工作，而不是返回，如果配置的这些插件有任何一个返回失败，则Pod将被拒绝。</p>
<pre><code class="language-go">
func (sched *Scheduler) schedulePod(ctx context.Context, fwk framework.Framework, state *framework.CycleState, pod *v1.Pod) (result ScheduleResult, err error) {
	trace := utiltrace.New(&quot;Scheduling&quot;, utiltrace.Field{Key: &quot;namespace&quot;, Value: pod.Namespace}, utiltrace.Field{Key: &quot;name&quot;, Value: pod.Name})
	defer trace.LogIfLong(100 * time.Millisecond)

	if err := sched.Cache.UpdateSnapshot(sched.nodeInfoSnapshot); err != nil {
		return result, err
	}
	trace.Step(&quot;Snapshotting scheduler cache and node infos done&quot;)

	if sched.nodeInfoSnapshot.NumNodes() == 0 {
		return result, ErrNoNodesAvailable
	}

	feasibleNodes, diagnosis, err := sched.findNodesThatFitPod(ctx, fwk, state, pod)
	if err != nil {
		return result, err
	}
	trace.Step(&quot;Computing predicates done&quot;)

	if len(feasibleNodes) == 0 {
		return result, &amp;framework.FitError{
			Pod:         pod,
			NumAllNodes: sched.nodeInfoSnapshot.NumNodes(),
			Diagnosis:   diagnosis,
		}
	}

	// When only one node after predicate, just use it.
	if len(feasibleNodes) == 1 {
		return ScheduleResult{
			SuggestedHost:  feasibleNodes[0].Name,
			EvaluatedNodes: 1 + len(diagnosis.NodeToStatusMap),
			FeasibleNodes:  1,
		}, nil
	}
	// 这里会完成prescore，score
	priorityList, err := prioritizeNodes(ctx, sched.Extenders, fwk, state, pod, feasibleNodes)
	if err != nil {
		return result, err
	}

	host, err := selectHost(priorityList)
	trace.Step(&quot;Prioritizing done&quot;)

	return ScheduleResult{
		SuggestedHost:  host,
		EvaluatedNodes: len(feasibleNodes) + len(diagnosis.NodeToStatusMap),
		FeasibleNodes:  len(feasibleNodes),
	}, err
}
</code></pre>
<p><a href="https://github.com/kubernetes/kubernetes/blob/32c483ea6ee90a3a81f382563c91034470af8a4a/pkg/scheduler/schedule_one.go#L605-L705" target="_blank"
   rel="noopener nofollow noreferrer" >priorityNodes</a> 会通过配置的插件给Node打分，并返回每个Node的分数，将每个插件打分结果计算总和获得Node的分数，最后获得节点的加权总分数。</p>
<pre><code class="language-go">func prioritizeNodes(
	ctx context.Context,
	extenders []framework.Extender,
	fwk framework.Framework,
	state *framework.CycleState,
	pod *v1.Pod,
	nodes []*v1.Node,
) (framework.NodeScoreList, error) {
	// If no priority configs are provided, then all nodes will have a score of one.
	// This is required to generate the priority list in the required format
	if len(extenders) == 0 &amp;&amp; !fwk.HasScorePlugins() {
		result := make(framework.NodeScoreList, 0, len(nodes))
		for i := range nodes {
			result = append(result, framework.NodeScore{
				Name:  nodes[i].Name,
				Score: 1,
			})
		}
		return result, nil
	}

	// Run PreScore plugins.
	preScoreStatus := fwk.RunPreScorePlugins(ctx, state, pod, nodes)
	if !preScoreStatus.IsSuccess() {
		return nil, preScoreStatus.AsError()
	}

	// Run the Score plugins.
	scoresMap, scoreStatus := fwk.RunScorePlugins(ctx, state, pod, nodes)
	if !scoreStatus.IsSuccess() {
		return nil, scoreStatus.AsError()
	}

	// Additional details logged at level 10 if enabled.
	klogV := klog.V(10)
	if klogV.Enabled() {
		for plugin, nodeScoreList := range scoresMap {
			for _, nodeScore := range nodeScoreList {
				klogV.InfoS(&quot;Plugin scored node for pod&quot;, &quot;pod&quot;, klog.KObj(pod), &quot;plugin&quot;, plugin, &quot;node&quot;, nodeScore.Name, &quot;score&quot;, nodeScore.Score)
			}
		}
	}

	// Summarize all scores.
	result := make(framework.NodeScoreList, 0, len(nodes))

	for i := range nodes {
		result = append(result, framework.NodeScore{Name: nodes[i].Name, Score: 0})
		for j := range scoresMap {
			result[i].Score += scoresMap[j][i].Score
		}
	}

	if len(extenders) != 0 &amp;&amp; nodes != nil {
		var mu sync.Mutex
		var wg sync.WaitGroup
		combinedScores := make(map[string]int64, len(nodes))
		for i := range extenders {
			if !extenders[i].IsInterested(pod) {
				continue
			}
			wg.Add(1)
			go func(extIndex int) {
				metrics.SchedulerGoroutines.WithLabelValues(metrics.PrioritizingExtender).Inc()
				defer func() {
					metrics.SchedulerGoroutines.WithLabelValues(metrics.PrioritizingExtender).Dec()
					wg.Done()
				}()
				prioritizedList, weight, err := extenders[extIndex].Prioritize(pod, nodes)
				if err != nil {
					// Prioritization errors from extender can be ignored, let k8s/other extenders determine the priorities
					klog.V(5).InfoS(&quot;Failed to run extender's priority function. No score given by this extender.&quot;, &quot;error&quot;, err, &quot;pod&quot;, klog.KObj(pod), &quot;extender&quot;, extenders[extIndex].Name())
					return
				}
				mu.Lock()
				for i := range *prioritizedList {
					host, score := (*prioritizedList)[i].Host, (*prioritizedList)[i].Score
					if klogV.Enabled() {
						klogV.InfoS(&quot;Extender scored node for pod&quot;, &quot;pod&quot;, klog.KObj(pod), &quot;extender&quot;, extenders[extIndex].Name(), &quot;node&quot;, host, &quot;score&quot;, score)
					}
					combinedScores[host] += score * weight
				}
				mu.Unlock()
			}(i)
		}
		// wait for all go routines to finish
		wg.Wait()
		for i := range result {
			// MaxExtenderPriority may diverge from the max priority used in the scheduler and defined by MaxNodeScore,
			// therefore we need to scale the score returned by extenders to the score range used by the scheduler.
			result[i].Score += combinedScores[result[i].Name] * (framework.MaxNodeScore / extenderv1.MaxExtenderPriority)
		}
	}

	if klogV.Enabled() {
		for i := range result {
			klogV.InfoS(&quot;Calculated node's final score for pod&quot;, &quot;pod&quot;, klog.KObj(pod), &quot;node&quot;, result[i].Name, &quot;score&quot;, result[i].Score)
		}
	}
	return result, nil
}
</code></pre>
<h3 id="reserve">Reserve<a hidden class="anchor" aria-hidden="true" href="#reserve">¶</a></h3>
<p><a href="https://github.com/kubernetes/kubernetes/blob/32c483ea6ee90a3a81f382563c91034470af8a4a/pkg/scheduler/schedule_one.go#L153-L163" target="_blank"
   rel="noopener nofollow noreferrer" >Reserve</a> 因为绑定事件时异步发生的，该插件是为了避免Pod在绑定到节点前时，调度到新的Pod，使节点使用资源超过可用资源情况。如果后续阶段发生错误或失败，将触发 <code>UnReserve</code> 回滚（通知性扩展点）。这也是作为调度周期中最后一个状态，要么成功到 <code>postBind</code> ，要么失败触发 <code>UnReserve</code>。</p>
<pre><code class="language-go">// Run the Reserve method of reserve plugins.
if sts := fwk.RunReservePluginsReserve(schedulingCycleCtx, state, assumedPod, scheduleResult.SuggestedHost); !sts.IsSuccess() { // 当处理不成功时
    metrics.PodScheduleError(fwk.ProfileName(), metrics.SinceInSeconds(start))
    // 触发 un-reserve 来清理相关Pod的状态
    fwk.RunReservePluginsUnreserve(schedulingCycleCtx, state, assumedPod, scheduleResult.SuggestedHost)
    if forgetErr := sched.Cache.ForgetPod(assumedPod); forgetErr != nil {
        klog.ErrorS(forgetErr, &quot;Scheduler cache ForgetPod failed&quot;)
    }
    sched.handleSchedulingFailure(ctx, fwk, assumedPodInfo, sts.AsError(), SchedulerError, clearNominatedNode)
    return
}
</code></pre>
<h3 id="permit">permit<a hidden class="anchor" aria-hidden="true" href="#permit">¶</a></h3>
<p><a href="https://github.com/kubernetes/kubernetes/blob/32c483ea6ee90a3a81f382563c91034470af8a4a/pkg/scheduler/schedule_one.go#L165-L183" target="_blank"
   rel="noopener nofollow noreferrer" >Permit</a> 插件可以阻止或延迟 Pod 的绑定</p>
<pre><code class="language-go">	// Run &quot;permit&quot; plugins.
	runPermitStatus := fwk.RunPermitPlugins(schedulingCycleCtx, state, assumedPod, scheduleResult.SuggestedHost)
	if !runPermitStatus.IsWait() &amp;&amp; !runPermitStatus.IsSuccess() {
		var reason string
		if runPermitStatus.IsUnschedulable() {
			metrics.PodUnschedulable(fwk.ProfileName(), metrics.SinceInSeconds(start))
			reason = v1.PodReasonUnschedulable
		} else {
			metrics.PodScheduleError(fwk.ProfileName(), metrics.SinceInSeconds(start))
			reason = SchedulerError
		}
        // 只要其中一个插件返回的状态不是 success 或者 wait
		fwk.RunReservePluginsUnreserve(schedulingCycleCtx, state, assumedPod, scheduleResult.SuggestedHost)
        // 从cache中忘掉pod
		if forgetErr := sched.Cache.ForgetPod(assumedPod); forgetErr != nil {
			klog.ErrorS(forgetErr, &quot;Scheduler cache ForgetPod failed&quot;)
		}
		sched.handleSchedulingFailure(ctx, fwk, assumedPodInfo, runPermitStatus.AsError(), reason, clearNominatedNode)
		return
	}

</code></pre>
<h3 id="binding-cycle">Binding Cycle<a hidden class="anchor" aria-hidden="true" href="#binding-cycle">¶</a></h3>
<p>在选择好 <em>FN</em> 后则做一个假设绑定，并更新到cache中，接下来回去执行真正的bind操作，也就是 <code>binding cycle</code></p>
<pre><code class="language-go">func (sched *Scheduler) scheduleOne(ctx context.Context) {
	...
    ...
	// binding cycle 是一个异步的操作，这里表现就是go协程
	go func() {
		bindingCycleCtx, cancel := context.WithCancel(ctx)
		defer cancel()
		metrics.SchedulerGoroutines.WithLabelValues(metrics.Binding).Inc()
		defer metrics.SchedulerGoroutines.WithLabelValues(metrics.Binding).Dec()
		// 运行WaitOnPermit插件，如果失败则，unReserve回滚
		waitOnPermitStatus := fwk.WaitOnPermit(bindingCycleCtx, assumedPod)
		if !waitOnPermitStatus.IsSuccess() {
			var reason string
			if waitOnPermitStatus.IsUnschedulable() {
				metrics.PodUnschedulable(fwk.ProfileName(), metrics.SinceInSeconds(start))
				reason = v1.PodReasonUnschedulable
			} else {
				metrics.PodScheduleError(fwk.ProfileName(), metrics.SinceInSeconds(start))
				reason = SchedulerError
			}
			// trigger un-reserve plugins to clean up state associated with the reserved Pod
			fwk.RunReservePluginsUnreserve(bindingCycleCtx, state, assumedPod, scheduleResult.SuggestedHost)
			if forgetErr := sched.Cache.ForgetPod(assumedPod); forgetErr != nil {
				klog.ErrorS(forgetErr, &quot;scheduler cache ForgetPod failed&quot;)
			} else {
				// &quot;Forget&quot;ing an assumed Pod in binding cycle should be treated as a PodDelete event,
				// as the assumed Pod had occupied a certain amount of resources in scheduler cache.
				// TODO(#103853): de-duplicate the logic.
				// Avoid moving the assumed Pod itself as it's always Unschedulable.
				// It's intentional to &quot;defer&quot; this operation; otherwise MoveAllToActiveOrBackoffQueue() would
				// update `q.moveRequest` and thus move the assumed pod to backoffQ anyways.
				defer sched.SchedulingQueue.MoveAllToActiveOrBackoffQueue(internalqueue.AssignedPodDelete, func(pod *v1.Pod) bool {
					return assumedPod.UID != pod.UID
				})
			}
			sched.handleSchedulingFailure(ctx, fwk, assumedPodInfo, waitOnPermitStatus.AsError(), reason, clearNominatedNode)
			return
		}

	// 运行Prebind 插件
		preBindStatus := fwk.RunPreBindPlugins(bindingCycleCtx, state, assumedPod, scheduleResult.SuggestedHost)
		if !preBindStatus.IsSuccess() {
			metrics.PodScheduleError(fwk.ProfileName(), metrics.SinceInSeconds(start))
			// trigger un-reserve plugins to clean up state associated with the reserved Pod
			fwk.RunReservePluginsUnreserve(bindingCycleCtx, state, assumedPod, scheduleResult.SuggestedHost)
			if forgetErr := sched.Cache.ForgetPod(assumedPod); forgetErr != nil {
				klog.ErrorS(forgetErr, &quot;scheduler cache ForgetPod failed&quot;)
			} else {
				// &quot;Forget&quot;ing an assumed Pod in binding cycle should be treated as a PodDelete event,
				// as the assumed Pod had occupied a certain amount of resources in scheduler cache.
				// TODO(#103853): de-duplicate the logic.
				sched.SchedulingQueue.MoveAllToActiveOrBackoffQueue(internalqueue.AssignedPodDelete, nil)
			}
			sched.handleSchedulingFailure(ctx, fwk, assumedPodInfo, preBindStatus.AsError(), SchedulerError, clearNominatedNode)
			return
		}
		// bind是真正的绑定操作
		err := sched.bind(bindingCycleCtx, fwk, assumedPod, scheduleResult.SuggestedHost, state)
		if err != nil {
			metrics.PodScheduleError(fwk.ProfileName(), metrics.SinceInSeconds(start))
			// 如果失败了就触发 un-reserve plugins 
			fwk.RunReservePluginsUnreserve(bindingCycleCtx, state, assumedPod, scheduleResult.SuggestedHost)
			if err := sched.Cache.ForgetPod(assumedPod); err != nil {
				klog.ErrorS(err, &quot;scheduler cache ForgetPod failed&quot;)
			} else {
				// &quot;Forget&quot;ing an assumed Pod in binding cycle should be treated as a PodDelete event,
				// as the assumed Pod had occupied a certain amount of resources in scheduler cache.
				// TODO(#103853): de-duplicate the logic.
				sched.SchedulingQueue.MoveAllToActiveOrBackoffQueue(internalqueue.AssignedPodDelete, nil)
			}
			sched.handleSchedulingFailure(ctx, fwk, assumedPodInfo, fmt.Errorf(&quot;binding rejected: %w&quot;, err), SchedulerError, clearNominatedNode)
			return
		}
		// Calculating nodeResourceString can be heavy. Avoid it if klog verbosity is below 2.
		klog.V(2).InfoS(&quot;Successfully bound pod to node&quot;, &quot;pod&quot;, klog.KObj(pod), &quot;node&quot;, scheduleResult.SuggestedHost, &quot;evaluatedNodes&quot;, scheduleResult.EvaluatedNodes, &quot;feasibleNodes&quot;, scheduleResult.FeasibleNodes)
		metrics.PodScheduled(fwk.ProfileName(), metrics.SinceInSeconds(start))
		metrics.PodSchedulingAttempts.Observe(float64(podInfo.Attempts))
		metrics.PodSchedulingDuration.WithLabelValues(getAttemptsLabel(podInfo)).Observe(metrics.SinceInSeconds(podInfo.InitialAttemptTimestamp))

		// 运行 &quot;postbind&quot; 插件
        // 是通知性的扩展点，该插件在绑定 Pod 后调用，可用于清理相关资源（）。
		fwk.RunPostBindPlugins(bindingCycleCtx, state, assumedPod, scheduleResult.SuggestedHost)

		// At the end of a successful binding cycle, move up Pods if needed.
		if len(podsToActivate.Map) != 0 {
			sched.SchedulingQueue.Activate(podsToActivate.Map)
			// Unlike the logic in scheduling cycle, we don't bother deleting the entries
			// as `podsToActivate.Map` is no longer consumed.
		}
	}()
}
</code></pre>
<h2 id="调度上下文中的失败流程">调度上下文中的失败流程<a hidden class="anchor" aria-hidden="true" href="#调度上下文中的失败流程">¶</a></h2>
<p>上面说到的都是正常的请求，下面会对失败的请求是如何重试的进行分析，而 <em>scheduler</em> 中关于失败处理方面相关的属性会涉及到上面 <em>scheduler</em> 结构中的  <code>backoffQ</code> 与 <code>unschedulablePods </code></p>
<ul>
<li><code>backoffQ</code>：也是一个 <em>heap</em> 类型的优先级队列，存放的是不可调度的Pod</li>
<li><code>unschedulablePods </code>：保存确定不可被调度的Pod，一个map类型</li>
</ul>
<p>backoffQ 与  unschedulablePods 会在初始化 <em>scheduler</em> 时初始化，</p>
<pre><code class="language-go">func NewPriorityQueue(
	lessFn framework.LessFunc,
	informerFactory informers.SharedInformerFactory,
	opts ...Option,
) *PriorityQueue {
	options := defaultPriorityQueueOptions
	for _, opt := range opts {
		opt(&amp;options)
	}

	comp := func(podInfo1, podInfo2 interface{}) bool {
		pInfo1 := podInfo1.(*framework.QueuedPodInfo)
		pInfo2 := podInfo2.(*framework.QueuedPodInfo)
		return lessFn(pInfo1, pInfo2)
	}

	if options.podNominator == nil {
		options.podNominator = NewPodNominator(informerFactory.Core().V1().Pods().Lister())
	}

	pq := &amp;PriorityQueue{
		PodNominator:                      options.podNominator,
		clock:                             options.clock,
		stop:                              make(chan struct{}),
		podInitialBackoffDuration:         options.podInitialBackoffDuration,
		podMaxBackoffDuration:             options.podMaxBackoffDuration,
		podMaxInUnschedulablePodsDuration: options.podMaxInUnschedulablePodsDuration,
		activeQ:                           heap.NewWithRecorder(podInfoKeyFunc, comp, metrics.NewActivePodsRecorder()),
		unschedulablePods:                 newUnschedulablePods(metrics.NewUnschedulablePodsRecorder()),
		moveRequestCycle:                  -1,
		clusterEventMap:                   options.clusterEventMap,
	}
	pq.cond.L = &amp;pq.lock
    // 初始化backoffQ
    // NewWithRecorder作为一个可选的 metricRecorder 的 Heap 对象。
    // podInfoKeyFunc是一个函数，返回错误与字符串
    // pq.podsCompareBackoffCompleted 比较两个pod的回退时间，如果第一个在第二个之前为true，
    // 反之 false
	pq.podBackoffQ = heap.NewWithRecorder(podInfoKeyFunc, pq.podsCompareBackoffCompleted, metrics.NewBackoffPodsRecorder())
	pq.nsLister = informerFactory.Core().V1().Namespaces().Lister()

	return pq
}
</code></pre>
<p>对于初始化 backoffQ 会产生的两个函数，<a href="https://github.com/kubernetes/kubernetes/blob/32c483ea6ee90a3a81f382563c91034470af8a4a/pkg/scheduler/internal/queue/scheduling_queue.go#L757-L761" target="_blank"
   rel="noopener nofollow noreferrer" >getBackoffTime</a> 与 <a href="https://github.com/kubernetes/kubernetes/blob/32c483ea6ee90a3a81f382563c91034470af8a4a/pkg/scheduler/internal/queue/scheduling_queue.go#L765-L775" target="_blank"
   rel="noopener nofollow noreferrer" >calculateBackoffDuration</a></p>
<pre><code class="language-go">// getBackoffTime returns the time that podInfo completes backoff
func (p *PriorityQueue) getBackoffTime(podInfo *framework.QueuedPodInfo) time.Time {
	duration := p.calculateBackoffDuration(podInfo)
	backoffTime := podInfo.Timestamp.Add(duration)
	return backoffTime
}

// calculateBackoffDuration is a helper function for calculating the backoffDuration
// based on the number of attempts the pod has made.
func (p *PriorityQueue) calculateBackoffDuration(podInfo *framework.QueuedPodInfo) time.Duration {
	duration := p.podInitialBackoffDuration
	for i := 1; i &lt; podInfo.Attempts; i++ {
		// Use subtraction instead of addition or multiplication to avoid overflow.
		if duration &gt; p.podMaxBackoffDuration-duration {
			return p.podMaxBackoffDuration
		}
		duration += duration
	}
	return duration
}
</code></pre>
<p>对于整个故障错误会按照如下流程进行，在初始化 <em>scheduler</em> 会注册一个 Error 函数，这个函数用作对不可调度Pod进行处理，实际上被注册的函数是 MakeDefaultErrorFunc。这个函数将作为 Error 函数被调用。</p>
<pre><code class="language-go">sched := newScheduler(
    schedulerCache,
    extenders,
    internalqueue.MakeNextPodFunc(podQueue),
    MakeDefaultErrorFunc(client, podLister, podQueue, schedulerCache),
    stopEverything,
    podQueue,
    profiles,
    client,
    snapshot,
    options.percentageOfNodesToScore,
)
</code></pre>
<p>而在 调度周期中，也就是 <a href="https://github.com/kubernetes/kubernetes/blob/32c483ea6ee90a3a81f382563c91034470af8a4a/pkg/scheduler/schedule_one.go#L66-L132" target="_blank"
   rel="noopener nofollow noreferrer" >scheduleOne</a> 可以看到，每个扩展点操作失败后都会调用 <a href="https://github.com/kubernetes/kubernetes/blob/32c483ea6ee90a3a81f382563c91034470af8a4a/pkg/scheduler/schedule_one.go#L812-L834" target="_blank"
   rel="noopener nofollow noreferrer" >handleSchedulingFailure</a> 而该函数，使用了注册的 <em>Error</em> 函数来处理Pod</p>
<pre><code class="language-go">func (sched *Scheduler) scheduleOne(ctx context.Context) {
	...
	defer cancel()
	scheduleResult, err := sched.SchedulePod(schedulingCycleCtx, fwk, state, pod)
	if err != nil {

		var nominatingInfo *framework.NominatingInfo
		if fitError, ok := err.(*framework.FitError); ok {
			if !fwk.HasPostFilterPlugins() {
				klog.V(3).InfoS(&quot;No PostFilter plugins are registered, so no preemption will be performed&quot;)
			} else {
			
				result, status := fwk.RunPostFilterPlugins(ctx, state, pod, fitError.Diagnosis.NodeToStatusMap)
				if status.Code() == framework.Error {
					klog.ErrorS(nil, &quot;Status after running PostFilter plugins for pod&quot;, &quot;pod&quot;, klog.KObj(pod), &quot;status&quot;, status)
				} else {
					fitError.Diagnosis.PostFilterMsg = status.Message()
					klog.V(5).InfoS(&quot;Status after running PostFilter plugins for pod&quot;, &quot;pod&quot;, klog.KObj(pod), &quot;status&quot;, status)
				}
				if result != nil {
					nominatingInfo = result.NominatingInfo
				}
			}
	
			metrics.PodUnschedulable(fwk.ProfileName(), metrics.SinceInSeconds(start))
		} else if err == ErrNoNodesAvailable {
			nominatingInfo = clearNominatedNode
			// No nodes available is counted as unschedulable rather than an error.
			metrics.PodUnschedulable(fwk.ProfileName(), metrics.SinceInSeconds(start))
		} else {
			nominatingInfo = clearNominatedNode
			klog.ErrorS(err, &quot;Error selecting node for pod&quot;, &quot;pod&quot;, klog.KObj(pod))
			metrics.PodScheduleError(fwk.ProfileName(), metrics.SinceInSeconds(start))
		}
        // 处理不可调度Pod
		sched.handleSchedulingFailure(ctx, fwk, podInfo, err, v1.PodReasonUnschedulable, nominatingInfo)
		return
	}

</code></pre>
<p>来到了注册的 <em>Error</em> 函数 <code>MakeDefaultErrorFunc</code></p>
<pre><code class="language-go">func MakeDefaultErrorFunc(client clientset.Interface, podLister corelisters.PodLister, podQueue internalqueue.SchedulingQueue, schedulerCache internalcache.Cache) func(*framework.QueuedPodInfo, error) {
	return func(podInfo *framework.QueuedPodInfo, err error) {
		pod := podInfo.Pod
		if err == ErrNoNodesAvailable {
			klog.V(2).InfoS(&quot;Unable to schedule pod; no nodes are registered to the cluster; waiting&quot;, &quot;pod&quot;, klog.KObj(pod))
		} else if fitError, ok := err.(*framework.FitError); ok {
			// Inject UnschedulablePlugins to PodInfo, which will be used later for moving Pods between queues efficiently.
			podInfo.UnschedulablePlugins = fitError.Diagnosis.UnschedulablePlugins
			klog.V(2).InfoS(&quot;Unable to schedule pod; no fit; waiting&quot;, &quot;pod&quot;, klog.KObj(pod), &quot;err&quot;, err)
		} else if apierrors.IsNotFound(err) {
			klog.V(2).InfoS(&quot;Unable to schedule pod, possibly due to node not found; waiting&quot;, &quot;pod&quot;, klog.KObj(pod), &quot;err&quot;, err)
			if errStatus, ok := err.(apierrors.APIStatus); ok &amp;&amp; errStatus.Status().Details.Kind == &quot;node&quot; {
				nodeName := errStatus.Status().Details.Name
				// when node is not found, We do not remove the node right away. Trying again to get
				// the node and if the node is still not found, then remove it from the scheduler cache.
				_, err := client.CoreV1().Nodes().Get(context.TODO(), nodeName, metav1.GetOptions{})
				if err != nil &amp;&amp; apierrors.IsNotFound(err) {
					node := v1.Node{ObjectMeta: metav1.ObjectMeta{Name: nodeName}}
					if err := schedulerCache.RemoveNode(&amp;node); err != nil {
						klog.V(4).InfoS(&quot;Node is not found; failed to remove it from the cache&quot;, &quot;node&quot;, node.Name)
					}
				}
			}
		} else {
			klog.ErrorS(err, &quot;Error scheduling pod; retrying&quot;, &quot;pod&quot;, klog.KObj(pod))
		}

		// Check if the Pod exists in informer cache.
		cachedPod, err := podLister.Pods(pod.Namespace).Get(pod.Name)
		if err != nil {
			klog.InfoS(&quot;Pod doesn't exist in informer cache&quot;, &quot;pod&quot;, klog.KObj(pod), &quot;err&quot;, err)
			return
		}

		// In the case of extender, the pod may have been bound successfully, but timed out returning its response to the scheduler.
		// It could result in the live version to carry .spec.nodeName, and that's inconsistent with the internal-queued version.
		if len(cachedPod.Spec.NodeName) != 0 {
			klog.InfoS(&quot;Pod has been assigned to node. Abort adding it back to queue.&quot;, &quot;pod&quot;, klog.KObj(pod), &quot;node&quot;, cachedPod.Spec.NodeName)
			return
		}

		// As &lt;cachedPod&gt; is from SharedInformer, we need to do a DeepCopy() here.
		podInfo.PodInfo = framework.NewPodInfo(cachedPod.DeepCopy())
        // 添加到unschedulable队列中
		if err := podQueue.AddUnschedulableIfNotPresent(podInfo, podQueue.SchedulingCycle()); err != nil {
			klog.ErrorS(err, &quot;Error occurred&quot;)
		}
	}
}
</code></pre>
<p>下面来到 <code>AddUnschedulableIfNotPresent</code> ，这个也是操作 <code>backoffQ</code> 和 <code>unschedulablePods </code> 的真正的动作</p>
<p><code>AddUnschedulableIfNotPresent</code> 函数会吧无法调度的 pod 插入队列，除非它已经在队列中。通常情况下，<code>PriorityQueue</code> 将不可调度的 Pod 放在 <code>unschedulablePods</code> 中。但如果最近有 move request，则将 pod 放入 <code>podBackoffQ</code> 中。</p>
<pre><code class="language-go">func (p *PriorityQueue) AddUnschedulableIfNotPresent(pInfo *framework.QueuedPodInfo, podSchedulingCycle int64) error {
	p.lock.Lock()
	defer p.lock.Unlock()
	pod := pInfo.Pod
    // 如果已经存在则不添加
	if p.unschedulablePods.get(pod) != nil {
		return fmt.Errorf(&quot;Pod %v is already present in unschedulable queue&quot;, klog.KObj(pod))
	}
	// 检查是否在activeQ中
	if _, exists, _ := p.activeQ.Get(pInfo); exists {
		return fmt.Errorf(&quot;Pod %v is already present in the active queue&quot;, klog.KObj(pod))
	}
    // 检查是否在podBackoffQ中
	if _, exists, _ := p.podBackoffQ.Get(pInfo); exists {
		return fmt.Errorf(&quot;Pod %v is already present in the backoff queue&quot;, klog.KObj(pod))
	}

	// 在重新添加时，会刷新 Pod时间为最新操作的时间
	pInfo.Timestamp = p.clock.Now()

	for plugin := range pInfo.UnschedulablePlugins {
		metrics.UnschedulableReason(plugin, pInfo.Pod.Spec.SchedulerName).Inc()
	}
    // 如果接受到move request那么则放入BackoffQ
	if p.moveRequestCycle &gt;= podSchedulingCycle {
		if err := p.podBackoffQ.Add(pInfo); err != nil {
			return fmt.Errorf(&quot;error adding pod %v to the backoff queue: %v&quot;, pod.Name, err)
		}
		metrics.SchedulerQueueIncomingPods.WithLabelValues(&quot;backoff&quot;, ScheduleAttemptFailure).Inc()
	} else {
        // 否则将放入到 unschedulablePods
		p.unschedulablePods.addOrUpdate(pInfo)
		metrics.SchedulerQueueIncomingPods.WithLabelValues(&quot;unschedulable&quot;, ScheduleAttemptFailure).Inc()

	}

	p.PodNominator.AddNominatedPod(pInfo.PodInfo, nil)
	return nil
}
</code></pre>
<p>在启动 <em>scheduler</em> 时，会将这两个队列异步启用两个loop来操作队列。表现在 <a href="https://github.com/kubernetes/kubernetes/blob/32c483ea6ee90a3a81f382563c91034470af8a4a/pkg/scheduler/internal/queue/scheduling_queue.go#L292-L295" target="_blank"
   rel="noopener nofollow noreferrer" >Run()</a></p>
<pre><code class="language-go">func (p *PriorityQueue) Run() {
	go wait.Until(p.flushBackoffQCompleted, 1.0*time.Second, p.stop)
	go wait.Until(p.flushUnschedulablePodsLeftover, 30*time.Second, p.stop)
}
</code></pre>
<p>可以看到 <a href="https://github.com/kubernetes/kubernetes/blob/32c483ea6ee90a3a81f382563c91034470af8a4a/pkg/scheduler/internal/queue/scheduling_queue.go#L431-L458" target="_blank"
   rel="noopener nofollow noreferrer" >flushBackoffQCompleted</a> 作为 <code>BackoffQ</code> 实现；而 <a href="https://github.com/kubernetes/kubernetes/blob/32c483ea6ee90a3a81f382563c91034470af8a4a/pkg/scheduler/internal/queue/scheduling_queue.go#L462-L478" target="_blank"
   rel="noopener nofollow noreferrer" >flushUnschedulablePodsLeftover</a> 作为 <code>UnschedulablePods</code> 实现。</p>
<p><code>flushBackoffQCompleted</code> 是用于将所有已完成回退的 pod 从 <code>backoffQ</code> 移到 <code>activeQ</code> 中</p>
<pre><code class="language-go">func (p *PriorityQueue) flushBackoffQCompleted() {
	p.lock.Lock()
	defer p.lock.Unlock()
	broadcast := false
	for { // 这就是heap实现的方法，窥视下，但不弹出
		rawPodInfo := p.podBackoffQ.Peek()
		if rawPodInfo == nil {
			break
		}
		pod := rawPodInfo.(*framework.QueuedPodInfo).Pod
		boTime := p.getBackoffTime(rawPodInfo.(*framework.QueuedPodInfo))
		if boTime.After(p.clock.Now()) {
			break
		}
		_, err := p.podBackoffQ.Pop() // 弹出一个
		if err != nil {
			klog.ErrorS(err, &quot;Unable to pop pod from backoff queue despite backoff completion&quot;, &quot;pod&quot;, klog.KObj(pod))
			break
		}
		p.activeQ.Add(rawPodInfo) // 放入到活动队列中
		metrics.SchedulerQueueIncomingPods.WithLabelValues(&quot;active&quot;, BackoffComplete).Inc()
		broadcast = true
	}

	if broadcast {
		p.cond.Broadcast()
	}
}
</code></pre>
<p><code>flushUnschedulablePodsLeftover </code> 函数用于将在 <code>unschedulablePods</code> 中的存放时间超过 <code>podMaxInUnschedulablePodsDuration</code> 值的 pod 移动到 <code>backoffQ</code> 或 <code>activeQ</code> 中。</p>
<p><code>podMaxInUnschedulablePodsDuration</code> 会根据配置传入，当没有传入，也就是使用了 <em><a href="https://github.com/kubernetes/kubernetes/blob/32c483ea6ee90a3a81f382563c91034470af8a4a/cmd/kube-scheduler/app/options/options.go#L77-L84" target="_blank"
   rel="noopener nofollow noreferrer" >Deprecated</a></em> 那么会为5分钟。</p>
<pre><code class="language-go">func NewOptions() *Options {
	o := &amp;Options{
		SecureServing:  apiserveroptions.NewSecureServingOptions().WithLoopback(),
		Authentication: apiserveroptions.NewDelegatingAuthenticationOptions(),
		Authorization:  apiserveroptions.NewDelegatingAuthorizationOptions(),
		Deprecated: &amp;DeprecatedOptions{
			PodMaxInUnschedulablePodsDuration: 5 * time.Minute,
		},
</code></pre>
<p>对于 <code>flushUnschedulablePodsLeftover </code> 就是做一个时间对比，然后添加到对应的队列中</p>
<pre><code class="language-go">func (p *PriorityQueue) flushUnschedulablePodsLeftover() {
	p.lock.Lock()
	defer p.lock.Unlock()

	var podsToMove []*framework.QueuedPodInfo
	currentTime := p.clock.Now()
	for _, pInfo := range p.unschedulablePods.podInfoMap {
		lastScheduleTime := pInfo.Timestamp
		if currentTime.Sub(lastScheduleTime) &gt; p.podMaxInUnschedulablePodsDuration {
			podsToMove = append(podsToMove, pInfo)
		}
	}

	if len(podsToMove) &gt; 0 {
		p.movePodsToActiveOrBackoffQueue(podsToMove, UnschedulableTimeout)
	}
}
</code></pre>
<h2 id="总结调度上下文流程">总结调度上下文流程<a hidden class="anchor" aria-hidden="true" href="#总结调度上下文流程">¶</a></h2>
<ul>
<li>在构建一个 <em>scheduler</em> 时经历如下步骤：
<ul>
<li>准备cache，informer，queue，错误处理函数等</li>
<li>添加事件函数，会监听资源（如Pod），当有变动则触发对应事件函数，这是入站 <code>activeQ</code></li>
</ul>
</li>
<li>构建完成后会 run，run时会run一个 <code>SchedulingQueue</code>，这个是作为不可调度队列
<ul>
<li><code>BackoffQ</code></li>
<li><code>UnschedulablePods</code></li>
<li>不可调度队列会根据注册时定期消费队列中Pod将其添加到 <code>activeQ</code> 中</li>
</ul>
</li>
<li>启动一个 <code>scheduleOne</code> 的loop，这个是调度上下文中所有的扩展点的执行，也是 <code>activeQ</code> 的消费端
<ul>
<li><code>scheduleOne</code> 获取 pod</li>
<li>执行各个扩展点，如果出错则 <em>Error</em> 函数 <code>MakeDefaultErrorFunc</code> 将其添加到不可调度队列中</li>
<li>回到不可调度队列中消费部分</li>
</ul>
</li>
</ul>
<h2 id="reference">Reference<a hidden class="anchor" aria-hidden="true" href="#reference">¶</a></h2>
<blockquote>
<p><sup id="1">[1]</sup> <a href="https://www.sobyte.net/post/2022-02/kubernetes-scheduling-framework-and-extender/" target="_blank"
   rel="noopener nofollow noreferrer" >kubernetes scheduler extender</a></p>
</blockquote>


    
    


<div class="copyrightBlock" >
    <div class="articleSuffix-bg"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 147.78 155.96"> <path d="M10.5,99.81a1.9,1.9,0,0,0-.53-.09,1.66,1.66,0,0,0-1.64,1.65A1.64,1.64,0,0,0,10,103a1.57,1.57,0,0,0,.87-.25l26.76,26.82.45-1.08L11.52,101.91A1.65,1.65,0,0,0,10.5,99.81Zm-.13,2a.57.57,0,0,1-.8,0,.58.58,0,0,1-.17-.41.58.58,0,0,1,.57-.57h0a.57.57,0,0,1,.56.58A.55.55,0,0,1,10.37,101.77Z" style="fill:#c5c9e0"></path><path d="M56.15,117.58H39.06l0-.09a1.65,1.65,0,0,0-1.36-1H37.5a1.65,1.65,0,1,0,1.56,2.19H55.7L92.92,156h41.44v-1.08h-41Zm-18.25.94a.56.56,0,0,1-.79,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.56-.57h0a.58.58,0,0,1,.57.58A.54.54,0,0,1,37.9,118.52Z" style="fill:#c5c9e0"></path><path d="M23.52,50.32a1.65,1.65,0,0,0,1.55-1.11H55.28l48-48.13h31.06V0H102.85l-48,48.13H25.07a1.64,1.64,0,0,0-2.09-1,1.64,1.64,0,0,0,.54,3.2Zm0-2.21a.57.57,0,0,1,0,1.13.57.57,0,1,1,0-1.13Z" style="fill:#c5c9e0"></path><polygon points="102.86 0 102.86 0 102.86 0 102.86 0" style="fill:#c5c9e0"></polygon><path d="M107.72,12.14h26.64V11.07H107.27L57.4,61H3.09a1.66,1.66,0,0,0-1.45-.86H1.52A1.65,1.65,0,1,0,2.81,63a1.59,1.59,0,0,0,.45-.87H57.85ZM2.05,62.23a.57.57,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.56-.57h.09a.57.57,0,0,1,.32,1Z" style="fill:#c5c9e0"></path><path d="M134.36,43.22V42.14h-22.3l-9.62,9.63a1.64,1.64,0,0,0-2.19.77,1.61,1.61,0,0,0-.17.71,1.65,1.65,0,1,0,3.29,0,1.61,1.61,0,0,0-.16-.72l9.3-9.32Zm-32.64,10.6a.57.57,0,0,1,0-1.13.57.57,0,0,1,0,1.13Z" style="fill:#c5c9e0"></path><path d="M147,52.3l-9,9H111.48a1.64,1.64,0,0,0-1.61-1.33h-.14a1.65,1.65,0,1,0,1.6,2.41h27.19l9.26-9.29L147,52.3Zm-37.15,9.85a.56.56,0,0,1-.56-.57h0a.56.56,0,0,1,.56-.56h0a.57.57,0,1,1,0,1.13Z" style="fill:#c5c9e0"></path><path d="M66.79,75.35l11,11.06h56.53V85.33H78.27l-11-11.06H49.49L37.12,86.67a1.64,1.64,0,0,0-2.09,1,1.61,1.61,0,0,0-.09.54,1.65,1.65,0,0,0,3.29,0,1.68,1.68,0,0,0-.26-.89l12-12ZM36.58,88.79a.57.57,0,1,1,.57-.56A.57.57,0,0,1,36.58,88.79Z" style="fill:#c5c9e0"></path><path d="M110.61,95.55,92.8,113.4a1.62,1.62,0,1,0,.77.76l17.49-17.53h23.31V95.55ZM92.49,115.28a.56.56,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.57-.57h0a.58.58,0,0,1,.56.58A.55.55,0,0,1,92.49,115.28Z" style="fill:#c5c9e0"></path><path d="M97.89,122.3H76.62L64.2,109.85a1.65,1.65,0,0,0-.77-2.2,1.77,1.77,0,0,0-.72-.17h-.14a1.65,1.65,0,0,0,.15,3.29,1.58,1.58,0,0,0,.71-.17l12.74,12.77H98.34l17.48-17.52h18.54v-1.08h-19ZM63.12,109.53a.56.56,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,1.14,0A.54.54,0,0,1,63.12,109.53Z" style="fill:#c5c9e0"></path> </svg> </div>
    <p>本文发布于<a href="https://www.oomkill.com/about" target="_blank">Cylon的收藏册</a>，转载请著名原文链接~</p>
    <p>链接：<a href="https://www.oomkill.com/2022/07/ch20-schedule-workflow/" target="_blank">https://www.oomkill.com/2022/07/ch20-schedule-workflow/</a></p>
    <p style="margin-bottom: 0px;">版权：本作品采用<a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">「署名-非商业性使用-相同方式共享 4.0 国际」</a> 许可协议进行许可。</p>
    </div>
</div>
  </div>

  <footer class="post-footer">
    
<nav class="paginav">
  <a class="prev" href="https://www.oomkill.com/2022/07/ch21-scheduling-algorithm/">
    <span class="title"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left" style="user-select: text;"><line x1="19" y1="12" x2="5" y2="12" style="user-select: text;"></line><polyline points="12 19 5 12 12 5" style="user-select: text;"></polyline>
      </polyline></svg>&nbsp; </span>
    
    <span>如何理解kubernetes调度框架与插件？</span>
  </a>
  <a class="next" href="https://www.oomkill.com/2022/07/ch16-scheduler/" >
    <span class="title"> </span>
    
    <span>kubernetes的决策组件 - kube-scheduler原理分析&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right" style="user-select: text;"><line x1="5" y1="12" x2="19" y2="12" style="user-select: text;"></line><polyline points="12 5 19 12 12 19" style="user-select: text;"></polyline></svg></span>
  </a>
</nav>

  </footer>

  
  <div class="pagination__title">
    <span class="pagination__title-h"></span>
  </div>
  
  
  
  
    <div class="comments-separator"></div>
    

<h3 class="relatedContentTitle" >相关阅读</h3>
<ul class="relatedContent">
	
	<li><a href="/2022/07/ch16-scheduler/"><span>kubernetes的决策组件 - kube-scheduler原理分析</span></a></li>
	
	<li><a href="/2022/07/ch33-admission-webhook/"><span>深入理解Kubernetes 4A - Admission Control源码解析</span></a></li>
	
	<li><a href="/2022/06/ch27-leader-election/"><span>源码分析Kubernetes HA机制 - leader election</span></a></li>
	
	<li><a href="/2022/06/ch15-controller-runtime/"><span>源码分析Kubernetes controller组件 - controller-runtime</span></a></li>
	
	<li><a href="/2022/06/ch04-apiserver-aggregation/"><span>扩展Kubernetes API的另一种方式 - APIServer aggregation</span></a></li>
	
</ul>

  

  
    
      <div class="comments-separator"></div>
<div class="comments">
    <script>
    function loadComment() {
        let theme = localStorage.getItem('pref-theme') === 'dark' ? 'dark' : 'light';
        let s = document.createElement('script');
        s.src = 'https://giscus.app/client.js';
        s.setAttribute('data-repo', 'cylonchau\/cylonchau.github.io');
        s.setAttribute('data-repo-id', 'R_kgDOIRlNSQ');
        s.setAttribute('data-category', 'Announcements');
        s.setAttribute('data-category-id', 'DIC_kwDOIRlNSc4CXy1U');
        s.setAttribute('data-mapping', 'title');
        s.setAttribute('data-reactions-enabled', '1');
        s.setAttribute('data-emit-metadata', '1');
        s.setAttribute('data-input-position', 'top');
        s.setAttribute('data-lang', 'zh-TW');
        s.setAttribute('data-theme', theme);
        s.setAttribute('crossorigin', 'anonymous');
        s.setAttribute('async', '');
        document.querySelector('div.comments').innerHTML = '';
        document.querySelector('div.comments').appendChild(s);
    }
    loadComment();
    </script>
</div>
</article>
    </main>
    
<footer class="footer">
  <p>
  Copyright
  <span>&copy; 2024 <a href="https://www.oomkill.com">Cylon&#39;s Collection</a></span></p>
  <span style="display: inline-block; margin-left: 1em;">
    Powered by
    <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> on github-page & Theme
    <a href="https://github.com/reorx/hugo-PaperModX/" rel="noopener" target="_blank">PaperModX</a>
  </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
  (function() {
     
    const disableThemeToggle = '' == '1';
    if (disableThemeToggle) {
      return;
    }

    let button = document.getElementById("theme-toggle")
    
    button.removeEventListener('click', toggleThemeListener)
    
    button.addEventListener('click', toggleThemeListener)
  })();
</script>

<script>
  (function () {
    let menu = document.getElementById('menu')
    if (menu) {
      menu.scrollLeft = localStorage.getItem("menu-scroll-position");
      menu.onscroll = function () {
        localStorage.setItem("menu-scroll-position", menu.scrollLeft);
      }
    }

    const disableSmoothScroll = '' == '1';
    const enableInstantClick = '1' == '1';
    
    if (window.matchMedia('(prefers-reduced-motion: reduce)').matches || disableSmoothScroll || enableInstantClick) {
      return;
    }
    
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener("click", function (e) {
        e.preventDefault();
        var id = this.getAttribute("href").substr(1);
        document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
          behavior: "smooth"
        });
        if (id === "top") {
          history.replaceState(null, null, " ");
        } else {
          history.pushState(null, null, `#${id}`);
        }
      });
    });
  })();
</script>

<script>
  document.addEventListener('scroll', function (e) {
      const readProgress = document.getElementById("read_progress");
      const scrollHeight = document.documentElement.scrollHeight;
      const clientHeight = document.documentElement.clientHeight;
      const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
      readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
  })
</script>

<script>
  var menu = document.getElementById('menu')
  if (menu) {
      menu.scrollLeft = localStorage.getItem("menu-scroll-position");
      menu.onscroll = function () {
          localStorage.setItem("menu-scroll-position", menu.scrollLeft);
      }
  }

  document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener("click", function (e) {
          e.preventDefault();
          var id = this.getAttribute("href").substr(1);
          if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
              document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                  behavior: "smooth"
              });
          } else {
              document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
          }
          if (id === "top") {
              history.replaceState(null, null, " ");
          } else {
              history.pushState(null, null, `#${id}`);
          }
      });
  });
</script>
<script>
  var mybutton = document.getElementById("top-link");
  window.onscroll = function () {
      if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
          mybutton.style.visibility = "visible";
          mybutton.style.opacity = "1";
      } else {
          mybutton.style.visibility = "hidden";
          mybutton.style.opacity = "0";
      }
  };
</script>
<script>
  if (window.scrollListeners) {
    
    for (const listener of scrollListeners) {
      window.removeEventListener('scroll', listener)
    }
  }
  window.scrollListeners = []
</script>



<script src="/js/medium-zoom.min.js" data-no-instant
></script>
<script>
  document.querySelectorAll('pre > code').forEach((codeblock) => {
    const container = codeblock.parentNode.parentNode;

    const copybutton = document.createElement('button');
    copybutton.classList.add('copy-code');
    copybutton.innerText = 'copy';

    function copyingDone() {
      copybutton.innerText = 'copied';
      setTimeout(() => {
        copybutton.innerText = 'copy';
      }, 2000);
    }

    copybutton.addEventListener('click', (cb) => {
      if ('clipboard' in navigator) {
        navigator.clipboard.writeText(codeblock.textContent);
        copyingDone();
        return;
      }

      const range = document.createRange();
      range.selectNodeContents(codeblock);
      const selection = window.getSelection();
      selection.removeAllRanges();
      selection.addRange(range);
      try {
        document.execCommand('copy');
        copyingDone();
      } catch (e) { };
      selection.removeRange(range);
    });

    if (container.classList.contains("highlight")) {
      container.appendChild(copybutton);
    } else if (container.parentNode.firstChild == container) {
      
    } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
      
      codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
    } else {
      
      codeblock.parentNode.appendChild(copybutton);
    }
  });
</script>




<script>
  
  
  (function() {
    const enableTocScroll = '1' == '1'
    if (!enableTocScroll) {
      return
    }
    if (!document.querySelector('.toc')) {
      console.log('no toc found, ignore toc scroll')
      return
    }
    

    
    const scrollListeners = window.scrollListeners
    const headings = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id]');
    const activeClass = 'active';

    
    let activeHeading = headings[0];
    getLinkByHeading(activeHeading).classList.add(activeClass);

    const onScroll = () => {
      const passedHeadings = [];
      for (const h of headings) {
        
        if (getOffsetTop(h) < 5) {
          passedHeadings.push(h)
        } else {
          break;
        }
      }
      if (passedHeadings.length > 0) {
        newActiveHeading = passedHeadings[passedHeadings.length - 1];
      } else {
        newActiveHeading = headings[0];
      }
      if (activeHeading != newActiveHeading) {
        getLinkByHeading(activeHeading).classList.remove(activeClass);
        activeHeading = newActiveHeading;
        getLinkByHeading(activeHeading).classList.add(activeClass);
      }
    }

    let timer = null;
    const scrollListener = () => {
      if (timer !== null) {
        clearTimeout(timer)
      }
      timer = setTimeout(onScroll, 50)
    }
    window.addEventListener('scroll', scrollListener, false);
    scrollListeners.push(scrollListener)

    function getLinkByHeading(heading) {
      const id = encodeURI(heading.getAttribute('id')).toLowerCase();
      return document.querySelector(`.toc ul li a[href="#${id}"]`);
    }

    function getOffsetTop(heading) {
      if (!heading.getClientRects().length) {
        return 0;
      }
      let rect = heading.getBoundingClientRect();
      return rect.top
    }
  })();
  </script>

<script src="/js/instantclick.min.js" data-no-instant
></script>
<script data-no-instant>
  
  
  
  
  
  
  InstantClick.init();
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.6.0/mermaid.min.js" crossorigin="anonymous"></script>
<script>
    mermaid.init(undefined, '.language-mermaid');
</script>
</body>

</html>
