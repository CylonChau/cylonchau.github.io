<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>kubernetes的决策组件 - kube-scheduler原理分析 | Cylon&#39;s Collection</title>
<meta name="keywords" content="kubernetes, develop, k8s调度">
<meta name="description" content="kubernetes的决策组件 - kube-scheduler原理分析 - Cylon&#39;s Collection">
<meta name="author" content="cylon">
<link rel="canonical" href="https://www.oomkill.com/2022/07/ch16-scheduler/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.41a8706089174fae1769fc26da4d1d354fa88083db604a95688ff58852dd9006.css" integrity="sha256-QahwYIkXT64Xafwm2k0dNU&#43;ogIPbYEqVaI/1iFLdkAY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://www.oomkill.com/favicon.ico">
<link rel="apple-touch-icon" href="https://www.oomkill.com/apple-touch-icon.png">

<meta name="twitter:title" content="kubernetes的决策组件 - kube-scheduler原理分析 | Cylon&#39;s Collection" />
<meta name="twitter:description" content="" />
<meta property="og:title" content="kubernetes的决策组件 - kube-scheduler原理分析 | Cylon&#39;s Collection" />
<meta property="og:description" content="" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.oomkill.com/2022/07/ch16-scheduler/" />
<meta property="article:section" content="posts" />
  <meta property="article:published_time" content="2022-07-18T00:00:00&#43;00:00" />
  <meta property="article:modified_time" content="2022-07-18T00:00:00&#43;00:00" />


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://www.oomkill.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "kubernetes的决策组件 - kube-scheduler原理分析",
      "item": "https://www.oomkill.com/2022/07/ch16-scheduler/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "kubernetes的决策组件 - kube-scheduler原理分析 | Cylon's Collection",
  "name": "kubernetes的决策组件 - kube-scheduler原理分析",
  "description": "",
  "keywords": [
    "kubernetes", "develop", "k8s调度"
  ],
  "wordCount" : "6916",
  "inLanguage": "zh",
  "datePublished": "2022-07-18T00:00:00Z",
  "dateModified": "2022-07-18T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "cylon"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.oomkill.com/2022/07/ch16-scheduler/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Cylon's Collection",
    "logo": {
      "@type": "ImageObject",
      "url": "https://www.oomkill.com/favicon.ico"
    }
  }
}
</script><script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary-bg: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list-page {
                background: var(--theme);
            }

            .list-page:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list-page:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

</head>

<body class=" type-posts kind-page layout-" id="top"><script data-no-instant>
function switchTheme(theme) {
  switch (theme) {
    case 'light':
      document.body.classList.remove('dark');
      break;
    case 'dark':
      document.body.classList.add('dark');
      break;
    
    default:
      if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
      }
  }
}

function isDarkTheme() {
  return document.body.className.includes("dark");
}

function getPrefTheme() {
  return localStorage.getItem("pref-theme");
}

function setPrefTheme(theme) {
  switchTheme(theme)
  localStorage.setItem("pref-theme", theme);
}

const toggleThemeCallbacks = {}
toggleThemeCallbacks['main'] = (isDark) => {
  
  if (isDark) {
    setPrefTheme('light');
  } else {
    setPrefTheme('dark');
  }
}




window.addEventListener('toggle-theme', function() {
  
  const isDark = isDarkTheme()
  for (const key in toggleThemeCallbacks) {
    toggleThemeCallbacks[key](isDark)
  }
});


function toggleThemeListener() {
  
  window.dispatchEvent(new CustomEvent('toggle-theme'));
}

</script>
<script>
  
  (function() {
    const defaultTheme = 'auto';
    const prefTheme = getPrefTheme();
    const theme = prefTheme ? prefTheme : defaultTheme;

    switchTheme(theme);
  })();
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://www.oomkill.com" accesskey="h" title="Cylon&#39;s Collection (Alt + H)">Cylon&#39;s Collection</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://www.oomkill.com/archives/" title="归档"
                >归档
                </a>
            </li>
            <li>
                <a href="https://www.oomkill.com/tags/" title="标签"
                >标签
                </a>
            </li>
            <li>
                <a href="https://www.oomkill.com/search/" title="搜索 (Alt &#43; /)"data-no-instant accesskey=/
                >搜索
                </a>
            </li>
            <li>
                <a href="https://www.oomkill.com/about/" title="关于"
                >关于
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main post">

<article class="post-single">
  <header class="post-header"><h1 class="post-title">kubernetes的决策组件 - kube-scheduler原理分析</h1>
    <div class="post-meta"><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select: text;"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select: text;"></rect><line x1="16" y1="2" x2="16" y2="6" style="user-select: text;"></line><line x1="8" y1="2" x2="8" y2="6" style="user-select: text;"></line><line x1="3" y1="10" x2="21" y2="10" style="user-select: text;"></line></svg>
  <span>2022-07-18</span></span><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select: text;"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select: text;"></rect><line x1="16" y1="2" x2="16" y2="6" style="user-select: text;"></line><line x1="8" y1="2" x2="8" y2="6" style="user-select: text;"></line><line x1="3" y1="10" x2="21" y2="10" style="user-select: text;"></line></svg>
  <span>Edited on 2022-07-18</span></span><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon" style="user-select: text;"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z" style="user-select: text;"></path><line x1="7" y1="7" x2="7" y2="7" style="user-select: text;"></line></svg>
  <span class="post-tags"><a href="https://www.oomkill.com/tags/kubernetes-develop/">kubernetes develop</a><a href="https://www.oomkill.com/tags/kubernetes/">kubernetes</a></span></span><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><circle cx="12" cy="12" r="9"></circle><polyline points="12 7 12 12 15 15"></polyline></svg>
  <span>14 分钟</span></span>

      
      
    </div>
  </header> <div class="toc side right">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">目录</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#overview-supa-href11asup" aria-label="Overview [1]">Overview <sup><a href="#1">[1]</a></sup></a><ul>
                        
                <li>
                    <a href="#%e5%a6%82%e4%bd%95%e4%b8%bapod%e9%80%89%e6%8b%a9%e8%8a%82%e7%82%b9" aria-label="如何为pod选择节点？">如何为pod选择节点？</a></li></ul>
                </li>
                <li>
                    <a href="#kubernetes%e7%9a%84%e8%b0%83%e5%ba%a6%e7%ad%96%e7%95%a5" aria-label="kubernetes的调度策略">kubernetes的调度策略</a><ul>
                        
                <li>
                    <a href="#%e4%b8%bapod%e9%a2%84%e9%80%89%e8%8a%82%e7%82%b9-supa-href22asup" aria-label="为Pod预选节点 [2]">为Pod预选节点 <sup><a href="#2">[2]</a></sup></a></li>
                <li>
                    <a href="#%e5%af%b9%e9%a2%84%e9%80%89%e8%8a%82%e7%82%b9%e6%89%93%e5%88%86-supa-href22asup" aria-label="对预选节点打分 [2]">对预选节点打分 <sup><a href="#2">[2]</a></sup></a></li>
                <li>
                    <a href="#%e5%9c%a8%e4%bb%a3%e7%a0%81%e4%b8%ad%e6%9f%a5%e7%9c%8b%e4%b8%8a%e8%bf%b0%e7%9a%84%e4%bb%a3%e7%a0%81" aria-label="在代码中查看上述的代码">在代码中查看上述的代码</a></li></ul>
                </li>
                <li>
                    <a href="#%e8%b0%83%e5%ba%a6%e6%a1%86%e6%9e%b6-supa-href33asup" aria-label="调度框架 [3]">调度框架 <sup><a href="#3">[3]</a></sup></a><ul>
                        
                <li>
                    <a href="#%e6%89%a9%e5%b1%95%e7%82%b9-supa-href44asup" aria-label="扩展点 [4]">扩展点 <sup><a href="#4">[4]</a></sup></a></li></ul>
                </li>
                <li>
                    <a href="#kube-scheduler%e5%b7%a5%e4%bd%9c%e6%b5%81%e5%88%86%e6%9e%90" aria-label="kube-scheduler工作流分析">kube-scheduler工作流分析</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content">
    





<div class="copyrightTopBlock">
    <p>本文发布于<a href="https://www.oomkill.com/about" target="_blank">Cylon的收藏册</a>，转载请著名原文链接~</p>
    <div class="articleSuffix-bg"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 147.78 155.96"> <path d="M10.5,99.81a1.9,1.9,0,0,0-.53-.09,1.66,1.66,0,0,0-1.64,1.65A1.64,1.64,0,0,0,10,103a1.57,1.57,0,0,0,.87-.25l26.76,26.82.45-1.08L11.52,101.91A1.65,1.65,0,0,0,10.5,99.81Zm-.13,2a.57.57,0,0,1-.8,0,.58.58,0,0,1-.17-.41.58.58,0,0,1,.57-.57h0a.57.57,0,0,1,.56.58A.55.55,0,0,1,10.37,101.77Z" style="fill:#c5c9e0"></path><path d="M56.15,117.58H39.06l0-.09a1.65,1.65,0,0,0-1.36-1H37.5a1.65,1.65,0,1,0,1.56,2.19H55.7L92.92,156h41.44v-1.08h-41Zm-18.25.94a.56.56,0,0,1-.79,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.56-.57h0a.58.58,0,0,1,.57.58A.54.54,0,0,1,37.9,118.52Z" style="fill:#c5c9e0"></path><path d="M23.52,50.32a1.65,1.65,0,0,0,1.55-1.11H55.28l48-48.13h31.06V0H102.85l-48,48.13H25.07a1.64,1.64,0,0,0-2.09-1,1.64,1.64,0,0,0,.54,3.2Zm0-2.21a.57.57,0,0,1,0,1.13.57.57,0,1,1,0-1.13Z" style="fill:#c5c9e0"></path><polygon points="102.86 0 102.86 0 102.86 0 102.86 0" style="fill:#c5c9e0"></polygon><path d="M107.72,12.14h26.64V11.07H107.27L57.4,61H3.09a1.66,1.66,0,0,0-1.45-.86H1.52A1.65,1.65,0,1,0,2.81,63a1.59,1.59,0,0,0,.45-.87H57.85ZM2.05,62.23a.57.57,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.56-.57h.09a.57.57,0,0,1,.32,1Z" style="fill:#c5c9e0"></path><path d="M134.36,43.22V42.14h-22.3l-9.62,9.63a1.64,1.64,0,0,0-2.19.77,1.61,1.61,0,0,0-.17.71,1.65,1.65,0,1,0,3.29,0,1.61,1.61,0,0,0-.16-.72l9.3-9.32Zm-32.64,10.6a.57.57,0,0,1,0-1.13.57.57,0,0,1,0,1.13Z" style="fill:#c5c9e0"></path><path d="M147,52.3l-9,9H111.48a1.64,1.64,0,0,0-1.61-1.33h-.14a1.65,1.65,0,1,0,1.6,2.41h27.19l9.26-9.29L147,52.3Zm-37.15,9.85a.56.56,0,0,1-.56-.57h0a.56.56,0,0,1,.56-.56h0a.57.57,0,1,1,0,1.13Z" style="fill:#c5c9e0"></path><path d="M66.79,75.35l11,11.06h56.53V85.33H78.27l-11-11.06H49.49L37.12,86.67a1.64,1.64,0,0,0-2.09,1,1.61,1.61,0,0,0-.09.54,1.65,1.65,0,0,0,3.29,0,1.68,1.68,0,0,0-.26-.89l12-12ZM36.58,88.79a.57.57,0,1,1,.57-.56A.57.57,0,0,1,36.58,88.79Z" style="fill:#c5c9e0"></path><path d="M110.61,95.55,92.8,113.4a1.62,1.62,0,1,0,.77.76l17.49-17.53h23.31V95.55ZM92.49,115.28a.56.56,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.57-.57h0a.58.58,0,0,1,.56.58A.55.55,0,0,1,92.49,115.28Z" style="fill:#c5c9e0"></path><path d="M97.89,122.3H76.62L64.2,109.85a1.65,1.65,0,0,0-.77-2.2,1.77,1.77,0,0,0-.72-.17h-.14a1.65,1.65,0,0,0,.15,3.29,1.58,1.58,0,0,0,.71-.17l12.74,12.77H98.34l17.48-17.52h18.54v-1.08h-19ZM63.12,109.53a.56.56,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,1.14,0A.54.54,0,0,1,63.12,109.53Z" style="fill:#c5c9e0"></path> </svg> </div>
</div>
<br><h2 id="overview-supa-href11asup">Overview <sup><a href="#1">[1]</a></sup><a hidden class="anchor" aria-hidden="true" href="#overview-supa-href11asup">¶</a></h2>
<p>kubernetes集群中的调度程序 <code>kube-scheduler</code> 会 <code>watch</code> 未分配节点的新创建的Pod，并未该Pod找到可运行的最佳（特定）节点。那么这些动作或者说这些原理是怎么实现的呢，让我们往下剖析下。</p>
<p>对于新创建的 pod 或其他未调度的 pod来讲，kube-scheduler 选择一个最佳节点供它们运行。但是，Pod 中的每个容器对资源的要求都不同，每个 Pod 也有不同的要求。因此，需要根据具体的调度要求对现有节点进行过滤。</p>
<p>在Kubernetes集群中，满足 Pod 调度要求的节点称为可行节点 （<code> feasible nodes</code> <em>FN</em>） 。如果没有合适的节点，则 pod 将保持未调度状态，直到调度程序能够放置它。也就是说，当我们创建Pod时，如果长期处于 <code>Pending</code> 状态，这个时候应该看你的集群调度器是否因为某些问题没有合适的节点了</p>
<p>调度器为 Pod 找到 FN 后，然后运行一组函数对 FN 进行评分，并在 FN 中找到得分最高的节点来运行 Pod。</p>
<p>调度策略在决策时需要考虑的因素包括个人和集体资源需求、硬件/软件/策略约束 （<code>constraints</code>）、亲和性 (<code>affinity</code>) 和反亲和性（ <code>anti-affinity</code> ）规范、数据局部性、工作负载间干扰等。</p>
<h3 id="如何为pod选择节点">如何为pod选择节点？<a hidden class="anchor" aria-hidden="true" href="#如何为pod选择节点">¶</a></h3>
<p><code>kube-scheduler</code> 为pod选择节点会分位两部：</p>
<ul>
<li>过滤 (<code>Filtering</code>)</li>
<li>打分 (<code>Scoring</code>)</li>
</ul>
<p>过滤也被称为预选 （<code>Predicates</code>），该步骤会找到可调度的节点集，然后通过是否满足特定资源的请求，例如通过 <code>PodFitsResources</code> 过滤器检查候选节点是否有足够的资源来满足 Pod 资源的请求。这个步骤完成后会得到一个包含合适的节点的列表（通常为多个），如果列表为空，则Pod不可调度。</p>
<p>打分也被称为优选（<code>Priorities</code>），在该步骤中，会对上一个步骤的输出进行打分，Scheduer 通过打分的规则为每个通过 <code>Filtering</code> 步骤的节点计算出一个分数。</p>
<p>完成上述两个步骤之后，<code>kube-scheduler</code> 会将Pod分配给分数最高的 Node，如果存在多个相同分数的节点，会随机选择一个。</p>
<h2 id="kubernetes的调度策略">kubernetes的调度策略<a hidden class="anchor" aria-hidden="true" href="#kubernetes的调度策略">¶</a></h2>
<p>Kubernetes 1.21之前版本可以在代码 <a href="https://github.com/kubernetes/kubernetes/blob/release-1.21/pkg/scheduler/algorithmprovider/registry.go" target="_blank"
   rel="noopener nofollow noreferrer" >kubernetes\pkg\scheduler\algorithmprovider\registry.go</a> 中看到对应的注册模式，在1.22 scheduler 更换了其路径，对于registry文件更换到了<a href="https://github.com/kubernetes/kubernetes/blob/release-1.24/pkg/scheduler/framework/plugins/registry.go" target="_blank"
   rel="noopener nofollow noreferrer" >kubernetes\pkg\scheduler\framework\plugins\registry.go</a> ；对于kubernetes官方说法为，<em>调度策略是用于“预选” (<code>Predicates </code>)或 过滤（<code>filtering </code>） 和 用于 优选（<code>Priorities</code>）或 评分 (<code>scoring</code>)的</em></p>
<blockquote>
<p>注：kubernetes官方没有找到预选和优选的概念，而Predicates和filtering 是处于预选阶段的动词，而Priorities和scoring是优选阶段的动词。后面用PF和PS代替这个两个词。</p>
</blockquote>
<h3 id="为pod预选节点-supa-href22asup">为Pod预选节点 <sup><a href="#2">[2]</a></sup><a hidden class="anchor" aria-hidden="true" href="#为pod预选节点-supa-href22asup">¶</a></h3>
<p>上面也提到了，<code>filtering</code> 的目的是为了排除（过滤）掉不满足 Pod 要求的节点。例如，某个节点上的闲置资源小于 Pod 所需资源，则该节点不会被考虑在内，即被过滤掉。在 <em>“Predicates”</em> 阶段实现的 <em>filtering</em> 策略，包括：</p>
<ul>
<li><code>NoDiskConflict</code> ：评估是否有合适Pod请求的卷</li>
<li><code>NoVolumeZoneConflict</code>：在给定zone限制情况下，评估Pod请求所需的卷在Node上是否可用</li>
<li><code>PodFitsResources</code>：检查空闲资源（CPU、内存）是否满足Pod请求</li>
<li><code>PodFitsHostPorts</code>：检查Pod所需端口在Node上是否被占用</li>
<li><code>HostName</code>： 过滤除去，<code>PodSpec</code> 中 <code>NodeName</code> 字段中指定的Node之外的所有Node。</li>
<li><code>MatchNodeSelector</code>：检查Node的 <em>label</em> 是否与 <em>Pod</em> 配置中 <code>nodeSelector</code>字段中指定的 <em>label</em> 匹配，并且从 Kubernetes v1.2 开始， 如果存在 <code>nodeAffinity</code> 也会匹配。</li>
<li><code>CheckNodeMemoryPressure</code>：检查是否可以在已出现内存压力情况节点上调度 Pod。</li>
<li><code>CheckNodeDiskPressure</code>：检查是否可以在报告磁盘压力情况的节点上调度 Pod</li>
</ul>
<p>具体对应得策略可以在 kubernetes\pkg\scheduler\framework\plugins\registry.go 看到</p>
<h3 id="对预选节点打分-supa-href22asup">对预选节点打分 <sup><a href="#2">[2]</a></sup><a hidden class="anchor" aria-hidden="true" href="#对预选节点打分-supa-href22asup">¶</a></h3>
<p>通过上面步骤过滤过得列表则是适合托管的Pod，这个结果通常来说是一个列表，如何选择最优Node进行调度，则是接下来打分的步骤步骤。</p>
<p>例如：Kubernetes对剩余节点进行优先级排序，优先级由一组函数计算；优先级函数将为剩余节点给出从<code>0~10</code> 的分数，10 表示最优，0 表示最差。每个优先级函数由一个正数加权组成，每个Node的得分是通过将所有加权得分相加来计算的。设有两个优先级函数，<code>priorityFunc1</code> 和 <code>priorityFunc2</code> 加上权重因子 <code>weight1</code> 和<code>weight2</code>，那么这个Node的最终得分为：$finalScore = (w1 \times priorityFunc1) + (w2 \times priorityFunc2)$。计算完分数后，选择最高分数的Node做为Pod的宿主机，存在多个相同分数Node情况下会随机选择一个Node。</p>
<p>目前kubernetes提供了一些在打分 <em>Scoring</em> 阶段算法：</p>
<ul>
<li><code>LeastRequestedPriority</code>：Node的优先级基于Node的空闲部分$\frac{capacity\ -\  Node上所有存在的Pod\ -\ 正在调度的Pod请求}{capacity}$，通过计算具有最高分数的Node是FN</li>
<li><code>BalancedResourceAllocation</code> ：该算法会将 Pod 放在一个Node上，使得在Pod 部署后 CPU 和内存的使用率为平衡的</li>
<li><code>SelectorSpreadPriority</code>：通过最小化资源方式，将属于同一种服务、控制器或同一Node上的Replica的 Pod的数量来分布Pod。如果节点上存在Zone，则会调整优先级，以便 pod可以分布在Zone之上。</li>
<li><code>CalculateAntiAffinityPriority</code>：根据label来分布，按照相同service上相同label值的pod进行分配</li>
<li><code>ImageLocalityPriority</code> ：根据Node上镜像进行打分，Node上存在Pod请求所需的镜像优先级较高。</li>
</ul>
<h3 id="在代码中查看上述的代码">在代码中查看上述的代码<a hidden class="anchor" aria-hidden="true" href="#在代码中查看上述的代码">¶</a></h3>
<p>以 <code>PodFitsHostPorts</code> 算法为例，因为是Node类算法，在<a href="https://github.com/kubernetes/kubernetes/tree/release-1.23/pkg/scheduler/framework/plugins/nodeports" target="_blank"
   rel="noopener nofollow noreferrer" >kubernetes\pkg\scheduler\framework\plugins\nodeports</a></p>
<h2 id="调度框架-supa-href33asup">调度框架 <sup><a href="#3">[3]</a></sup><a hidden class="anchor" aria-hidden="true" href="#调度框架-supa-href33asup">¶</a></h2>
<p>调度框架 (<code>scheduling framework</code> <em>SF</em> ) 是kubernetes为 scheduler设计的一个pluggable的架构。SF 将scheduler设计为 <em>Plugin</em> 式的 API，API将上一章中提到的一些列调度策略实现为 <code>Plugin</code>。</p>
<p>在 <em>SF</em> 中，定义了一些扩展点 （<code>extension points</code> <em>EP</em> ），而被实现为Plugin的调度程序将被注册在一个或多个 <em>EP</em> 中，换句话来说，在这些 <em>EP</em> 的执行过程中如果注册在多个 <em>EP</em> 中，将会在多个 <em>EP</em> 被调用。</p>
<p>每次调度都分为两个阶段，调度周期（<code>Scheduling Cycel</code>）与绑定周期（<code>Binding Cycle</code>）。</p>
<ul>
<li><em>SC</em> 表示为，为Pod选择一个节点；<em>SC</em> 是串行运行的。</li>
<li><em>BC</em> 表示为，将 <em>SC</em> 决策结果应用于集群中；<em>BC</em> 可以同时运行。</li>
</ul>
<p>调度周期与绑定周期结合一起，被称为<strong>调度上下文</strong> （<code>Scheduling Context</code>）,下图则是调度上下文的工作流</p>
<blockquote>
<p>注：如果决策结果为Pod的调度结果无可用节点，或存在内部错误，则中止 <em>SC</em> 或 <em>BC</em>。Pod将重入队列重试</p>
</blockquote>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/scheduling-framework-extensions.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center class="podsc">图1：Pod的调度上下文</center>
<center><em>Source：</em>https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework</center>
<h3 id="扩展点-supa-href44asup">扩展点 <sup><a href="#4">[4]</a></sup><a hidden class="anchor" aria-hidden="true" href="#扩展点-supa-href44asup">¶</a></h3>
<p>扩展点（<code>Extension points</code>）是指在<em>调度上下文</em>中的每个可扩展API，通过图提现为<a href="#podsc">[图1]</a>。其中 <code>Filter</code> 相当于 <code>Predicate</code> 而 <code>Scoring</code> 相当于 <code>Priority</code>。</p>
<p>对于调度阶段会通过以下扩展点：</p>
<ul>
<li>
<p><code>Sort</code>：该插件提供了排序功能，用于对在调度队列中待处理 Pod 进行排序。一次只能启用一个队列排序。</p>
</li>
<li>
<p><code>preFilter</code>：该插件用于在过滤之前预处理或检查 Pod 或集群的相关信息。这里会终止调度</p>
</li>
<li>
<p><code>filter</code>：该插件相当于<em>调度上下文</em>中的 <code>Predicates</code>，用于排除不能运行 Pod 的节点。Filter 会按配置的顺序进行调用。如果有一个filter将节点标记位不可用，则将 Pod 标记为不可调度（即不会向下执行）。</p>
</li>
<li>
<p><code>postFilter</code>：当没有为 pod 找到<em>FN</em>时，该插件会按照配置的顺序进行调用。如果任何<code>postFilter</code>插件将 Pod 标记为<em>schedulable</em>，则不会调用其余插件。即 <code>filter</code> 成功后不会进行这步骤</p>
</li>
<li>
<p><code>preScore</code>：可用于进行预Score工作（通知性的扩展点）。</p>
</li>
<li>
<p><code>score</code>：该插件为每个通过 <code>filter</code> 阶段的Node提供打分服务。然后Scheduler将选择具有最高加权分数总和的Node。</p>
</li>
<li>
<p><code>reserve</code>：因为绑定事件时异步发生的，该插件是为了避免Pod在绑定到节点前时，调度到新的Pod，使节点使用资源超过可用资源情况。如果后续阶段发生错误或失败，将触发 <code>UnReserve</code> 回滚（通知性扩展点）。这也是作为调度周期中最后一个状态，要么成功到 <code>postBind</code> ，要么失败触发 <code>UnReserve</code>。</p>
</li>
<li>
<p><code>permit</code>：该插件可以阻止或延迟 Pod 的绑定，一般情况下这步骤会做三件事：</p>
<ul>
<li><code>appove</code> ：调度器继续绑定过程</li>
<li><code>Deny</code>：如果任何一个Premit拒绝了Pod与节点的绑定，那么将触发 <code>UnReserve</code> ，并重入队列</li>
<li><code>Wait</code>： 如果 Permit 插件返回 <code>Wait</code>，该 Pod 将保留在内部 <code>Wait</code> Pod 列表中，直到被 <code>Appove</code>。如果发生超时，<code>wait</code> 变为 <code>deny</code> ，将Pod放回至调度队列中，并触发 <code>Unreserve</code> 回滚 。</li>
</ul>
</li>
<li>
<p><code>preBind</code>：该插件用于在 bind Pod 之前执行所需的前置工作。如，<code>preBind</code> 可能会提供一个网络卷并将其挂载到目标节点上。如果在该步骤中的任意插件返回错误，则Pod 将被 <code>deny</code> 并放置到调度队列中。</p>
</li>
<li>
<p><code>bind</code>：在所有的 <code>preBind</code> 完成后，该插件将用于将Pod绑定到Node，并按顺序调用绑定该步骤的插件。如果有一个插件处理了这个事件，那么则忽略其余所有插件。</p>
</li>
<li>
<p><code>postBind</code>：该插件在绑定 Pod 后调用，可用于清理相关资源（通知性的扩展点）。</p>
</li>
<li>
<p><code>multiPoint</code>：这是一个仅配置字段，允许同时为所有适用的扩展点启用或禁用插件。</p>
</li>
</ul>
<h2 id="kube-scheduler工作流分析">kube-scheduler工作流分析<a hidden class="anchor" aria-hidden="true" href="#kube-scheduler工作流分析">¶</a></h2>
<p>对于 <code>kube-scheduler</code> 组件的分析，包含 <code>kube-scheduler</code> 启动流程，以及scheduler调度流程。这里会主要针对启动流程分析，后面算法及二次开发部分会切入调度分析。</p>
<p>对于我们部署时使用的 <code>kube-scheduler</code> 位于 <a href="https://github.com/kubernetes/kubernetes/tree/release-1.24/cmd/kube-scheduler" target="_blank"
   rel="noopener nofollow noreferrer" >cmd/kube-scheduler</a> ，在 <em>Alpha (1.16)</em> 版本提供了调度框架的模式，到 <em>Stable (1.19)</em> ，从代码结构上是相似的；直到1.22后改变了代码风格。</p>
<p>首先看到的是 <code>kube-scheduler</code> 的入口 <a href="https://github.com/kubernetes/kubernetes/blob/release-1.24/cmd/kube-scheduler/scheduler.go" target="_blank"
   rel="noopener nofollow noreferrer" >cmd/kube-scheduler</a> ，这里主要作为两部分，构建参数与启动<code>server</code> ,这里严格来讲 <code>kube-scheduer</code> 是作为一个server，而调度框架等部分是另外的。</p>
<pre><code class="language-go">func main() {
	command := app.NewSchedulerCommand()
	code := cli.Run(command)
	os.Exit(code)
}
</code></pre>
<p><code>cli.Run</code> 提供了cobra构成的命令行cli，日志将输出为标准输出</p>
<pre><code class="language-go">// 这里是main中执行的Run
func Run(cmd *cobra.Command) int {
	if logsInitialized, err := run(cmd); err != nil {
		if !logsInitialized {
			fmt.Fprintf(os.Stderr, &quot;Error: %v\n&quot;, err)
		} else {
			klog.ErrorS(err, &quot;command failed&quot;)
		}
		return 1
	}
	return 0
}
// 这个run作为
func run(cmd *cobra.Command) (logsInitialized bool, err error) {
	rand.Seed(time.Now().UnixNano())
	defer logs.FlushLogs()

	cmd.SetGlobalNormalizationFunc(cliflag.WordSepNormalizeFunc)

	if !cmd.SilenceUsage {
		cmd.SilenceUsage = true
		cmd.SetFlagErrorFunc(func(c *cobra.Command, err error) error {
			// Re-enable usage printing.
			c.SilenceUsage = false
			return err
		})
	}

	// In all cases error printing is done below.
	cmd.SilenceErrors = true

	// This is idempotent.
	logs.AddFlags(cmd.PersistentFlags())

	// Inject logs.InitLogs after command line parsing into one of the
	// PersistentPre* functions.
	switch {
	case cmd.PersistentPreRun != nil:
		pre := cmd.PersistentPreRun
		cmd.PersistentPreRun = func(cmd *cobra.Command, args []string) {
			logs.InitLogs()
			logsInitialized = true
			pre(cmd, args)
		}
	case cmd.PersistentPreRunE != nil:
		pre := cmd.PersistentPreRunE
		cmd.PersistentPreRunE = func(cmd *cobra.Command, args []string) error {
			logs.InitLogs()
			logsInitialized = true
			return pre(cmd, args)
		}
	default:
		cmd.PersistentPreRun = func(cmd *cobra.Command, args []string) {
			logs.InitLogs()
			logsInitialized = true
		}
	}

	err = cmd.Execute()
	return
}
</code></pre>
<p>可以看到最终是调用 <code>command.Execute() </code> 执行，这个是执行本身构建的命令，而真正被执行的则是上面的 <code>app.NewSchedulerCommand()</code> ,那么来看看这个是什么</p>
<p><a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/cmd/kube-scheduler/app/server.go#L72-L114" target="_blank"
   rel="noopener nofollow noreferrer" >app.NewSchedulerCommand()</a> 构建了一个cobra.Commond对象， <a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/cmd/kube-scheduler/app/server.go#L117-L142" target="_blank"
   rel="noopener nofollow noreferrer" >runCommand()</a> 被封装在内，这个是作为启动scheduler的函数</p>
<pre><code class="language-go">func NewSchedulerCommand(registryOptions ...Option) *cobra.Command {
	opts := options.NewOptions()

	cmd := &amp;cobra.Command{
		Use: &quot;kube-scheduler&quot;,
		Long: `The Kubernetes scheduler is a control plane process which assigns
Pods to Nodes. The scheduler determines which Nodes are valid placements for
each Pod in the scheduling queue according to constraints and available
resources. The scheduler then ranks each valid Node and binds the Pod to a
suitable Node. Multiple different schedulers may be used within a cluster;
kube-scheduler is the reference implementation.
See [scheduling](https://kubernetes.io/docs/concepts/scheduling-eviction/)
for more information about scheduling and the kube-scheduler component.`,
		RunE: func(cmd *cobra.Command, args []string) error {
			return runCommand(cmd, opts, registryOptions...)
		},
		Args: func(cmd *cobra.Command, args []string) error {
			for _, arg := range args {
				if len(arg) &gt; 0 {
					return fmt.Errorf(&quot;%q does not take any arguments, got %q&quot;, cmd.CommandPath(), args)
				}
			}
			return nil
		},
	}

	nfs := opts.Flags
	verflag.AddFlags(nfs.FlagSet(&quot;global&quot;))
	globalflag.AddGlobalFlags(nfs.FlagSet(&quot;global&quot;), cmd.Name(), logs.SkipLoggingConfigurationFlags())
	fs := cmd.Flags()
	for _, f := range nfs.FlagSets {
		fs.AddFlagSet(f)
	}

	cols, _, _ := term.TerminalSize(cmd.OutOrStdout())
	cliflag.SetUsageAndHelpFunc(cmd, *nfs, cols)

	if err := cmd.MarkFlagFilename(&quot;config&quot;, &quot;yaml&quot;, &quot;yml&quot;, &quot;json&quot;); err != nil {
		klog.ErrorS(err, &quot;Failed to mark flag filename&quot;)
	}

	return cmd
}
</code></pre>
<p>下面来看下 <a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/cmd/kube-scheduler/app/server.go#L117-L142" target="_blank"
   rel="noopener nofollow noreferrer" >runCommand()</a> 在启动 <em>scheduler</em> 时提供了什么功能。</p>
<p>在新版中已经没有 <code>algorithmprovider</code> 的概念，所以在 <code>runCommand</code> 中做的也就是仅仅启动这个 <code>scheduler</code> ，而 scheduler 作为kubernetes组件，也是会watch等操作，自然少不了informer。其次作为和 <code>controller-manager</code> 相同的工作特性，<code>kube-scheduler</code> 也是 基于Leader选举的。</p>
<pre><code class="language-go">func Run(ctx context.Context, cc *schedulerserverconfig.CompletedConfig, sched *scheduler.Scheduler) error {
	// To help debugging, immediately log version
	klog.InfoS(&quot;Starting Kubernetes Scheduler&quot;, &quot;version&quot;, version.Get())

	klog.InfoS(&quot;Golang settings&quot;, &quot;GOGC&quot;, os.Getenv(&quot;GOGC&quot;), &quot;GOMAXPROCS&quot;, os.Getenv(&quot;GOMAXPROCS&quot;), &quot;GOTRACEBACK&quot;, os.Getenv(&quot;GOTRACEBACK&quot;))

	// Configz registration.
	if cz, err := configz.New(&quot;componentconfig&quot;); err == nil {
		cz.Set(cc.ComponentConfig)
	} else {
		return fmt.Errorf(&quot;unable to register configz: %s&quot;, err)
	}

	// Start events processing pipeline.
	cc.EventBroadcaster.StartRecordingToSink(ctx.Done())
	defer cc.EventBroadcaster.Shutdown()

	// Setup healthz checks.
	var checks []healthz.HealthChecker
	if cc.ComponentConfig.LeaderElection.LeaderElect {
		checks = append(checks, cc.LeaderElection.WatchDog)
	}

	waitingForLeader := make(chan struct{})
	isLeader := func() bool {
		select {
		case _, ok := &lt;-waitingForLeader:
			// if channel is closed, we are leading
			return !ok
		default:
			// channel is open, we are waiting for a leader
			return false
		}
	}

	// Start up the healthz server.
	if cc.SecureServing != nil {
		handler := buildHandlerChain(newHealthzAndMetricsHandler(&amp;cc.ComponentConfig, cc.InformerFactory, isLeader, checks...), cc.Authentication.Authenticator, cc.Authorization.Authorizer)
		// TODO: handle stoppedCh and listenerStoppedCh returned by c.SecureServing.Serve
		if _, _, err := cc.SecureServing.Serve(handler, 0, ctx.Done()); err != nil {
			// fail early for secure handlers, removing the old error loop from above
			return fmt.Errorf(&quot;failed to start secure server: %v&quot;, err)
		}
	}

	// Start all informers.
	cc.InformerFactory.Start(ctx.Done())
	// DynInformerFactory can be nil in tests.
	if cc.DynInformerFactory != nil {
		cc.DynInformerFactory.Start(ctx.Done())
	}

	// Wait for all caches to sync before scheduling.
	cc.InformerFactory.WaitForCacheSync(ctx.Done())
	// DynInformerFactory can be nil in tests.
	if cc.DynInformerFactory != nil {
		cc.DynInformerFactory.WaitForCacheSync(ctx.Done())
	}

	// If leader election is enabled, runCommand via LeaderElector until done and exit.
	if cc.LeaderElection != nil {
		cc.LeaderElection.Callbacks = leaderelection.LeaderCallbacks{
			OnStartedLeading: func(ctx context.Context) {
				close(waitingForLeader)
				sched.Run(ctx)
			},
			OnStoppedLeading: func() {
				select {
				case &lt;-ctx.Done():
					// We were asked to terminate. Exit 0.
					klog.InfoS(&quot;Requested to terminate, exiting&quot;)
					os.Exit(0)
				default:
					// We lost the lock.
					klog.ErrorS(nil, &quot;Leaderelection lost&quot;)
					klog.FlushAndExit(klog.ExitFlushTimeout, 1)
				}
			},
		}
		leaderElector, err := leaderelection.NewLeaderElector(*cc.LeaderElection)
		if err != nil {
			return fmt.Errorf(&quot;couldn't create leader elector: %v&quot;, err)
		}

		leaderElector.Run(ctx)

		return fmt.Errorf(&quot;lost lease&quot;)
	}

	// Leader election is disabled, so runCommand inline until done.
	close(waitingForLeader)
	sched.Run(ctx)
	return fmt.Errorf(&quot;finished without leader elect&quot;)
}
</code></pre>
<p>上面看到了 <code>runCommend</code> 是作为启动 <em>scheduler</em> 的工作，那么通过参数构建一个 <em>scheduler</em> 则是在 <a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/cmd/kube-scheduler/app/server.go#L298-L355" target="_blank"
   rel="noopener nofollow noreferrer" >Setup</a> 中完成的。</p>
<pre><code class="language-go">// Setup creates a completed config and a scheduler based on the command args and options
func Setup(ctx context.Context, opts *options.Options, outOfTreeRegistryOptions ...Option) (*schedulerserverconfig.CompletedConfig, *scheduler.Scheduler, error) {
	if cfg, err := latest.Default(); err != nil {
		return nil, nil, err
	} else {
		opts.ComponentConfig = cfg
	}
	// 验证参数
	if errs := opts.Validate(); len(errs) &gt; 0 {
		return nil, nil, utilerrors.NewAggregate(errs)
	}
	// 构建一个config对象
	c, err := opts.Config()
	if err != nil {
		return nil, nil, err
	}

	// 返回一个config对象，包含了scheduler所需的配置，如informer，leader selection
	cc := c.Complete()

	outOfTreeRegistry := make(runtime.Registry)
	for _, option := range outOfTreeRegistryOptions {
		if err := option(outOfTreeRegistry); err != nil {
			return nil, nil, err
		}
	}

	recorderFactory := getRecorderFactory(&amp;cc)
	completedProfiles := make([]kubeschedulerconfig.KubeSchedulerProfile, 0)
	// 创建出来的scheduler
	sched, err := scheduler.New(cc.Client,
		cc.InformerFactory,
		cc.DynInformerFactory,
		recorderFactory,
		ctx.Done(),
		scheduler.WithComponentConfigVersion(cc.ComponentConfig.TypeMeta.APIVersion),
		scheduler.WithKubeConfig(cc.KubeConfig),
		scheduler.WithProfiles(cc.ComponentConfig.Profiles...),
		scheduler.WithPercentageOfNodesToScore(cc.ComponentConfig.PercentageOfNodesToScore),
		scheduler.WithFrameworkOutOfTreeRegistry(outOfTreeRegistry),
		scheduler.WithPodMaxBackoffSeconds(cc.ComponentConfig.PodMaxBackoffSeconds),
		scheduler.WithPodInitialBackoffSeconds(cc.ComponentConfig.PodInitialBackoffSeconds),
		scheduler.WithPodMaxInUnschedulablePodsDuration(cc.PodMaxInUnschedulablePodsDuration),
		scheduler.WithExtenders(cc.ComponentConfig.Extenders...),
		scheduler.WithParallelism(cc.ComponentConfig.Parallelism),
		scheduler.WithBuildFrameworkCapturer(func(profile kubeschedulerconfig.KubeSchedulerProfile) {
			// Profiles are processed during Framework instantiation to set default plugins and configurations. Capturing them for logging
			completedProfiles = append(completedProfiles, profile)
		}),
	)
	if err != nil {
		return nil, nil, err
	}
	if err := options.LogOrWriteConfig(opts.WriteConfigTo, &amp;cc.ComponentConfig, completedProfiles); err != nil {
		return nil, nil, err
	}

	return &amp;cc, sched, nil
}
</code></pre>
<p>上面了解到了 <em>scheduler</em> 是如何被构建出来的，下面就看看 构建时参数是如何传递进来的，而对象 option就是对应需要的配置结构，而 <a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/cmd/kube-scheduler/app/options/options.go#L203-L243" target="_blank"
   rel="noopener nofollow noreferrer" >ApplyTo</a> 则是将启动时传入的参数转化为构建 <em>scheduler</em> 所需的配置。</p>
<blockquote>
<p>对于Deprecated flags可以参考官方对于kube-scheduler启动参数的说明 <sup><a href="#5">[5]</a></sup></p>
<p>对于如何编写一个scheduler config请参考 <a href="#6">[6]</a> 与 <a href="#7">[7]</a></p>
</blockquote>
<pre><code class="language-go">func (o *Options) ApplyTo(c *schedulerappconfig.Config) error {
	if len(o.ConfigFile) == 0 {
		// 在没有指定 --config时会找到 Deprecated flags:参数
        // 通过kube-scheduler --help可以看到这些被弃用的参数
		o.ApplyDeprecated()
		o.ApplyLeaderElectionTo(o.ComponentConfig)
		c.ComponentConfig = *o.ComponentConfig
	} else {
        // 这里就是指定了--config
		cfg, err := loadConfigFromFile(o.ConfigFile)
		if err != nil {
			return err
		}
		// 这里会将leader选举的参数附加到配置中
		o.ApplyLeaderElectionTo(cfg)

		if err := validation.ValidateKubeSchedulerConfiguration(cfg); err != nil {
			return err
		}

		c.ComponentConfig = *cfg
	}

	if err := o.SecureServing.ApplyTo(&amp;c.SecureServing, &amp;c.LoopbackClientConfig); err != nil {
		return err
	}
	if o.SecureServing != nil &amp;&amp; (o.SecureServing.BindPort != 0 || o.SecureServing.Listener != nil) {
		if err := o.Authentication.ApplyTo(&amp;c.Authentication, c.SecureServing, nil); err != nil {
			return err
		}
		if err := o.Authorization.ApplyTo(&amp;c.Authorization); err != nil {
			return err
		}
	}
	o.Metrics.Apply()

	// Apply value independently instead of using ApplyDeprecated() because it can't be configured via ComponentConfig.
	if o.Deprecated != nil {
		c.PodMaxInUnschedulablePodsDuration = o.Deprecated.PodMaxInUnschedulablePodsDuration
	}

	return nil
}
</code></pre>
<p><code>Setup</code> 后会new一个 <code>schedueler</code> , <a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/pkg/scheduler/scheduler.go#L234-L333" target="_blank"
   rel="noopener nofollow noreferrer" >New</a> 则是这个动作，在里面可以看出，会初始化一些informer与 Pod的list等操作。</p>
<pre><code class="language-go">func New(client clientset.Interface,
	informerFactory informers.SharedInformerFactory,
	dynInformerFactory dynamicinformer.DynamicSharedInformerFactory,
	recorderFactory profile.RecorderFactory,
	stopCh &lt;-chan struct{},
	opts ...Option) (*Scheduler, error) {

	stopEverything := stopCh
	if stopEverything == nil {
		stopEverything = wait.NeverStop
	}

	options := defaultSchedulerOptions // 默认调度策略，如percentageOfNodesToScore
	for _, opt := range opts {
		opt(&amp;options) // opt 是传入的函数，会返回一个schedulerOptions即相应的一些配置
	}

	if options.applyDefaultProfile { // 这个是个bool类型，默认scheduler会到这里
        // Profile包含了调度器的名称与调度器在两个过程中使用的插件
		var versionedCfg v1beta3.KubeSchedulerConfiguration
		scheme.Scheme.Default(&amp;versionedCfg)
		cfg := schedulerapi.KubeSchedulerConfiguration{} // 初始化一个配置，这个是--config传入的类型。因为默认的调度策略会初始化
        // convert 会将in转为out即versionedCfg转换为cfg
		if err := scheme.Scheme.Convert(&amp;versionedCfg, &amp;cfg, nil); err != nil {
			return nil, err
		}
		options.profiles = cfg.Profiles
	}

	registry := frameworkplugins.NewInTreeRegistry() // 调度框架的注册
	if err := registry.Merge(options.frameworkOutOfTreeRegistry); err != nil {
		return nil, err
	}

	metrics.Register() // 指标类

	extenders, err := buildExtenders(options.extenders, options.profiles)
	if err != nil {
		return nil, fmt.Errorf(&quot;couldn't build extenders: %w&quot;, err)
	}

	podLister := informerFactory.Core().V1().Pods().Lister()
	nodeLister := informerFactory.Core().V1().Nodes().Lister()

	// The nominator will be passed all the way to framework instantiation.
	nominator := internalqueue.NewPodNominator(podLister)
	snapshot := internalcache.NewEmptySnapshot()
	clusterEventMap := make(map[framework.ClusterEvent]sets.String)

	profiles, err := profile.NewMap(options.profiles, registry, recorderFactory, stopCh,
		frameworkruntime.WithComponentConfigVersion(options.componentConfigVersion),
		frameworkruntime.WithClientSet(client),
		frameworkruntime.WithKubeConfig(options.kubeConfig),
		frameworkruntime.WithInformerFactory(informerFactory),
		frameworkruntime.WithSnapshotSharedLister(snapshot),
		frameworkruntime.WithPodNominator(nominator),
		frameworkruntime.WithCaptureProfile(frameworkruntime.CaptureProfile(options.frameworkCapturer)),
		frameworkruntime.WithClusterEventMap(clusterEventMap),
		frameworkruntime.WithParallelism(int(options.parallelism)),
		frameworkruntime.WithExtenders(extenders),
	)
	if err != nil {
		return nil, fmt.Errorf(&quot;initializing profiles: %v&quot;, err)
	}

	if len(profiles) == 0 {
		return nil, errors.New(&quot;at least one profile is required&quot;)
	}

	podQueue := internalqueue.NewSchedulingQueue(
		profiles[options.profiles[0].SchedulerName].QueueSortFunc(),
		informerFactory,
		internalqueue.WithPodInitialBackoffDuration(time.Duration(options.podInitialBackoffSeconds)*time.Second),
		internalqueue.WithPodMaxBackoffDuration(time.Duration(options.podMaxBackoffSeconds)*time.Second),
		internalqueue.WithPodNominator(nominator),
		internalqueue.WithClusterEventMap(clusterEventMap),
		internalqueue.WithPodMaxInUnschedulablePodsDuration(options.podMaxInUnschedulablePodsDuration),
	)

	schedulerCache := internalcache.New(durationToExpireAssumedPod, stopEverything)

	// Setup cache debugger.
	debugger := cachedebugger.New(nodeLister, podLister, schedulerCache, podQueue)
	debugger.ListenForSignal(stopEverything)

	sched := newScheduler(
		schedulerCache,
		extenders,
		internalqueue.MakeNextPodFunc(podQueue),
		MakeDefaultErrorFunc(client, podLister, podQueue, schedulerCache),
		stopEverything,
		podQueue,
		profiles,
		client,
		snapshot,
		options.percentageOfNodesToScore,
	)
	// 这个就是controller中onAdd等那三个必须的事件函数
	addAllEventHandlers(sched, informerFactory, dynInformerFactory, unionedGVKs(clusterEventMap))

	return sched, nil
}
</code></pre>
<p>接下来会启动这个 <em>scheduler</em>， 在上面我们看到 <a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/cmd/kube-scheduler/app/server.go#L72-L114" target="_blank"
   rel="noopener nofollow noreferrer" >NewSchedulerCommand</a> 构建了一个cobra.Commond对象， <a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/cmd/kube-scheduler/app/server.go#L117-L142" target="_blank"
   rel="noopener nofollow noreferrer" >runCommand()</a> 最终会返回个 Run，而这个Run就是启动这个 <em>sche</em> 的。</p>
<p>下面这个 <a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/pkg/scheduler/scheduler.go#L336-L340" target="_blank"
   rel="noopener nofollow noreferrer" >run</a> 是 <em>sche</em> 的运行，他运行并watch资源，直到上下文完成。</p>
<pre><code class="language-go">func (sched *Scheduler) Run(ctx context.Context) {
	sched.SchedulingQueue.Run()

	// We need to start scheduleOne loop in a dedicated goroutine,
	// because scheduleOne function hangs on getting the next item
	// from the SchedulingQueue.
	// If there are no new pods to schedule, it will be hanging there
	// and if done in this goroutine it will be blocking closing
	// SchedulingQueue, in effect causing a deadlock on shutdown.
	go wait.UntilWithContext(ctx, sched.scheduleOne, 0)

	&lt;-ctx.Done()
	sched.SchedulingQueue.Close()
}
</code></pre>
<p>而调用这个 <em>Run</em> 的部分则是作为server的 <em>kube-scheduler</em> 中的 <a href="https://github.com/kubernetes/kubernetes/blob/140c27533044e9e00f800d3ad0517540e3e4ecad/cmd/kube-scheduler/app/server.go#L145-L237" target="_blank"
   rel="noopener nofollow noreferrer" >run</a></p>
<pre><code class="language-go">// Run executes the scheduler based on the given configuration. It only returns on error or when context is done.
func Run(ctx context.Context, cc *schedulerserverconfig.CompletedConfig, sched *scheduler.Scheduler) error {
	// To help debugging, immediately log version
	klog.InfoS(&quot;Starting Kubernetes Scheduler&quot;, &quot;version&quot;, version.Get())

	klog.InfoS(&quot;Golang settings&quot;, &quot;GOGC&quot;, os.Getenv(&quot;GOGC&quot;), &quot;GOMAXPROCS&quot;, os.Getenv(&quot;GOMAXPROCS&quot;), &quot;GOTRACEBACK&quot;, os.Getenv(&quot;GOTRACEBACK&quot;))

	// Configz registration.
	if cz, err := configz.New(&quot;componentconfig&quot;); err == nil {
		cz.Set(cc.ComponentConfig)
	} else {
		return fmt.Errorf(&quot;unable to register configz: %s&quot;, err)
	}

	// Start events processing pipeline.
	cc.EventBroadcaster.StartRecordingToSink(ctx.Done())
	defer cc.EventBroadcaster.Shutdown()

	// Setup healthz checks.
	var checks []healthz.HealthChecker
	if cc.ComponentConfig.LeaderElection.LeaderElect {
		checks = append(checks, cc.LeaderElection.WatchDog)
	}

	waitingForLeader := make(chan struct{})
	isLeader := func() bool {
		select {
		case _, ok := &lt;-waitingForLeader:
			// if channel is closed, we are leading
			return !ok
		default:
			// channel is open, we are waiting for a leader
			return false
		}
	}

	// Start up the healthz server.
	if cc.SecureServing != nil {
		handler := buildHandlerChain(newHealthzAndMetricsHandler(&amp;cc.ComponentConfig, cc.InformerFactory, isLeader, checks...), cc.Authentication.Authenticator, cc.Authorization.Authorizer)
		// TODO: handle stoppedCh and listenerStoppedCh returned by c.SecureServing.Serve
		if _, _, err := cc.SecureServing.Serve(handler, 0, ctx.Done()); err != nil {
			// fail early for secure handlers, removing the old error loop from above
			return fmt.Errorf(&quot;failed to start secure server: %v&quot;, err)
		}
	}

	// Start all informers.
	cc.InformerFactory.Start(ctx.Done())
	// DynInformerFactory can be nil in tests.
	if cc.DynInformerFactory != nil {
		cc.DynInformerFactory.Start(ctx.Done())
	}

	// Wait for all caches to sync before scheduling.
	cc.InformerFactory.WaitForCacheSync(ctx.Done())
	// DynInformerFactory can be nil in tests.
	if cc.DynInformerFactory != nil {
		cc.DynInformerFactory.WaitForCacheSync(ctx.Done())
	}

	// If leader election is enabled, runCommand via LeaderElector until done and exit.
	if cc.LeaderElection != nil {
		cc.LeaderElection.Callbacks = leaderelection.LeaderCallbacks{
			OnStartedLeading: func(ctx context.Context) {
				close(waitingForLeader)
				sched.Run(ctx)
			},
			OnStoppedLeading: func() {
				select {
				case &lt;-ctx.Done():
					// We were asked to terminate. Exit 0.
					klog.InfoS(&quot;Requested to terminate, exiting&quot;)
					os.Exit(0)
				default:
					// We lost the lock.
					klog.ErrorS(nil, &quot;Leaderelection lost&quot;)
					klog.FlushAndExit(klog.ExitFlushTimeout, 1)
				}
			},
		}
		leaderElector, err := leaderelection.NewLeaderElector(*cc.LeaderElection)
		if err != nil {
			return fmt.Errorf(&quot;couldn't create leader elector: %v&quot;, err)
		}

		leaderElector.Run(ctx)

		return fmt.Errorf(&quot;lost lease&quot;)
	}

	// Leader election is disabled, so runCommand inline until done.
	close(waitingForLeader)
	sched.Run(ctx)
	return fmt.Errorf(&quot;finished without leader elect&quot;)
}
</code></pre>
<p>而上面的 <em>server.Run</em> 会被 <code>runCommand</code> 也就是在 <code>NewSchedulerCommand</code> 时被返回，在 <code>kube-scheduler</code> 的入口文件中被执行。</p>
<pre><code class="language-go">cc, sched, err := Setup(ctx, opts, registryOptions...)
if err != nil {
    return err
}

return Run(ctx, cc, sched)
</code></pre>
<p>至此，整个 <code>kube-scheduler</code> 启动流就分析完了，这个的流程可以用下图表示</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220718174104043.png" alt="image-20220718174104043" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center class="podsc">图2：scheduler server运行流程</center>
<blockquote>
<p>Reference</p>
<p><sup id="1">[1]</sup> <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/" target="_blank"
   rel="noopener nofollow noreferrer" >kube scheduler</a></p>
<p><sup id="2">[2]</sup> <a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-scheduling/scheduler_algorithm.md#filtering-the-nodes" target="_blank"
   rel="noopener nofollow noreferrer" >Scheduler Algorithm in Kubernetes</a></p>
<p><sup id="3">[3]</sup> <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/" target="_blank"
   rel="noopener nofollow noreferrer" >scheduling framework</a></p>
<p><sup id="4">[4]</sup> <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/#permit" target="_blank"
   rel="noopener nofollow noreferrer" >permit</a></p>
<p><sup id="5">[5]</sup> <a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-scheduler/" target="_blank"
   rel="noopener nofollow noreferrer" >kube-scheduler parmater</a></p>
<p><sup id="6">[6]</sup> <a href="https://kubernetes.io/docs/reference/config-api/kube-scheduler-config.v1beta3/" target="_blank"
   rel="noopener nofollow noreferrer" >kube-scheduler config.v1beta3/</a></p>
<p><sup id="7">[7]</sup> <a href="https://kubernetes.io/docs/reference/scheduling/config/" target="_blank"
   rel="noopener nofollow noreferrer" >kube-scheduler config</a></p>
</blockquote>


    
    


<div class="copyrightBlock" >
    <div class="articleSuffix-bg"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 147.78 155.96"> <path d="M10.5,99.81a1.9,1.9,0,0,0-.53-.09,1.66,1.66,0,0,0-1.64,1.65A1.64,1.64,0,0,0,10,103a1.57,1.57,0,0,0,.87-.25l26.76,26.82.45-1.08L11.52,101.91A1.65,1.65,0,0,0,10.5,99.81Zm-.13,2a.57.57,0,0,1-.8,0,.58.58,0,0,1-.17-.41.58.58,0,0,1,.57-.57h0a.57.57,0,0,1,.56.58A.55.55,0,0,1,10.37,101.77Z" style="fill:#c5c9e0"></path><path d="M56.15,117.58H39.06l0-.09a1.65,1.65,0,0,0-1.36-1H37.5a1.65,1.65,0,1,0,1.56,2.19H55.7L92.92,156h41.44v-1.08h-41Zm-18.25.94a.56.56,0,0,1-.79,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.56-.57h0a.58.58,0,0,1,.57.58A.54.54,0,0,1,37.9,118.52Z" style="fill:#c5c9e0"></path><path d="M23.52,50.32a1.65,1.65,0,0,0,1.55-1.11H55.28l48-48.13h31.06V0H102.85l-48,48.13H25.07a1.64,1.64,0,0,0-2.09-1,1.64,1.64,0,0,0,.54,3.2Zm0-2.21a.57.57,0,0,1,0,1.13.57.57,0,1,1,0-1.13Z" style="fill:#c5c9e0"></path><polygon points="102.86 0 102.86 0 102.86 0 102.86 0" style="fill:#c5c9e0"></polygon><path d="M107.72,12.14h26.64V11.07H107.27L57.4,61H3.09a1.66,1.66,0,0,0-1.45-.86H1.52A1.65,1.65,0,1,0,2.81,63a1.59,1.59,0,0,0,.45-.87H57.85ZM2.05,62.23a.57.57,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.56-.57h.09a.57.57,0,0,1,.32,1Z" style="fill:#c5c9e0"></path><path d="M134.36,43.22V42.14h-22.3l-9.62,9.63a1.64,1.64,0,0,0-2.19.77,1.61,1.61,0,0,0-.17.71,1.65,1.65,0,1,0,3.29,0,1.61,1.61,0,0,0-.16-.72l9.3-9.32Zm-32.64,10.6a.57.57,0,0,1,0-1.13.57.57,0,0,1,0,1.13Z" style="fill:#c5c9e0"></path><path d="M147,52.3l-9,9H111.48a1.64,1.64,0,0,0-1.61-1.33h-.14a1.65,1.65,0,1,0,1.6,2.41h27.19l9.26-9.29L147,52.3Zm-37.15,9.85a.56.56,0,0,1-.56-.57h0a.56.56,0,0,1,.56-.56h0a.57.57,0,1,1,0,1.13Z" style="fill:#c5c9e0"></path><path d="M66.79,75.35l11,11.06h56.53V85.33H78.27l-11-11.06H49.49L37.12,86.67a1.64,1.64,0,0,0-2.09,1,1.61,1.61,0,0,0-.09.54,1.65,1.65,0,0,0,3.29,0,1.68,1.68,0,0,0-.26-.89l12-12ZM36.58,88.79a.57.57,0,1,1,.57-.56A.57.57,0,0,1,36.58,88.79Z" style="fill:#c5c9e0"></path><path d="M110.61,95.55,92.8,113.4a1.62,1.62,0,1,0,.77.76l17.49-17.53h23.31V95.55ZM92.49,115.28a.56.56,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,.57-.57h0a.58.58,0,0,1,.56.58A.55.55,0,0,1,92.49,115.28Z" style="fill:#c5c9e0"></path><path d="M97.89,122.3H76.62L64.2,109.85a1.65,1.65,0,0,0-.77-2.2,1.77,1.77,0,0,0-.72-.17h-.14a1.65,1.65,0,0,0,.15,3.29,1.58,1.58,0,0,0,.71-.17l12.74,12.77H98.34l17.48-17.52h18.54v-1.08h-19ZM63.12,109.53a.56.56,0,0,1-.8,0,.58.58,0,0,1-.17-.41.57.57,0,0,1,1.14,0A.54.54,0,0,1,63.12,109.53Z" style="fill:#c5c9e0"></path> </svg> </div>
    <p>本文发布于<a href="https://www.oomkill.com/about" target="_blank">Cylon的收藏册</a>，转载请著名原文链接~</p>
    <p>链接：<a href="https://www.oomkill.com/2022/07/ch16-scheduler/" target="_blank">https://www.oomkill.com/2022/07/ch16-scheduler/</a></p>
    <p style="margin-bottom: 0px;">版权：本作品采用<a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">「署名-非商业性使用-相同方式共享 4.0 国际」</a> 许可协议进行许可。</p>
    </div>
</div>
  </div>

  <footer class="post-footer">
    
<nav class="paginav">
  <a class="prev" href="https://www.oomkill.com/2022/07/ch20-schedule-workflow/">
    <span class="title"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left" style="user-select: text;"><line x1="19" y1="12" x2="5" y2="12" style="user-select: text;"></line><polyline points="12 19 5 12 12 5" style="user-select: text;"></polyline>
      </polyline></svg>&nbsp; </span>
    
    <span>kube-scheduler的调度上下文</span>
  </a>
  <a class="next" href="https://www.oomkill.com/2022/07/ch33-admission-webhook/" >
    <span class="title"> </span>
    
    <span>深入理解Kubernetes 4A - Admission Control源码解析&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right" style="user-select: text;"><line x1="5" y1="12" x2="19" y2="12" style="user-select: text;"></line><polyline points="12 5 19 12 12 19" style="user-select: text;"></polyline></svg></span>
  </a>
</nav>

  </footer>

  
  <div class="pagination__title">
    <span class="pagination__title-h"></span>
  </div>
  
  
  
  
    <div class="comments-separator"></div>
    

<h3 class="relatedContentTitle" >相关阅读</h3>
<ul class="relatedContent">
	
	<li><a href="/2022/07/ch33-admission-webhook/"><span>深入理解Kubernetes 4A - Admission Control源码解析</span></a></li>
	
	<li><a href="/2022/06/ch27-leader-election/"><span>源码分析Kubernetes HA机制 - leader election</span></a></li>
	
	<li><a href="/2022/06/ch15-controller-runtime/"><span>源码分析Kubernetes controller组件 - controller-runtime</span></a></li>
	
	<li><a href="/2022/06/ch04-apiserver-aggregation/"><span>扩展Kubernetes API的另一种方式 - APIServer aggregation</span></a></li>
	
	<li><a href="/2022/06/ch14-code-generator/"><span>kubernetes代码生成器 - code-generator</span></a></li>
	
</ul>

  

  
    
      <div class="comments-separator"></div>
<div class="comments">
    <script>
    function loadComment() {
        let theme = localStorage.getItem('pref-theme') === 'dark' ? 'dark' : 'light';
        let s = document.createElement('script');
        s.src = 'https://giscus.app/client.js';
        s.setAttribute('data-repo', 'cylonchau\/cylonchau.github.io');
        s.setAttribute('data-repo-id', 'R_kgDOIRlNSQ');
        s.setAttribute('data-category', 'Announcements');
        s.setAttribute('data-category-id', 'DIC_kwDOIRlNSc4CXy1U');
        s.setAttribute('data-mapping', 'title');
        s.setAttribute('data-reactions-enabled', '1');
        s.setAttribute('data-emit-metadata', '1');
        s.setAttribute('data-input-position', 'top');
        s.setAttribute('data-lang', 'zh-TW');
        s.setAttribute('data-theme', theme);
        s.setAttribute('crossorigin', 'anonymous');
        s.setAttribute('async', '');
        document.querySelector('div.comments').innerHTML = '';
        document.querySelector('div.comments').appendChild(s);
    }
    loadComment();
    </script>
</div>
</article>
    </main>
    
<footer class="footer">
  <p>
  Copyright
  <span>&copy; 2024 <a href="https://www.oomkill.com">Cylon&#39;s Collection</a></span></p>
  <span style="display: inline-block; margin-left: 1em;">
    Powered by
    <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> on github-page & Theme
    <a href="https://github.com/reorx/hugo-PaperModX/" rel="noopener" target="_blank">PaperModX</a>
  </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
  (function() {
     
    const disableThemeToggle = '' == '1';
    if (disableThemeToggle) {
      return;
    }

    let button = document.getElementById("theme-toggle")
    
    button.removeEventListener('click', toggleThemeListener)
    
    button.addEventListener('click', toggleThemeListener)
  })();
</script>

<script>
  (function () {
    let menu = document.getElementById('menu')
    if (menu) {
      menu.scrollLeft = localStorage.getItem("menu-scroll-position");
      menu.onscroll = function () {
        localStorage.setItem("menu-scroll-position", menu.scrollLeft);
      }
    }

    const disableSmoothScroll = '' == '1';
    const enableInstantClick = '1' == '1';
    
    if (window.matchMedia('(prefers-reduced-motion: reduce)').matches || disableSmoothScroll || enableInstantClick) {
      return;
    }
    
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener("click", function (e) {
        e.preventDefault();
        var id = this.getAttribute("href").substr(1);
        document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
          behavior: "smooth"
        });
        if (id === "top") {
          history.replaceState(null, null, " ");
        } else {
          history.pushState(null, null, `#${id}`);
        }
      });
    });
  })();
</script>

<script>
  document.addEventListener('scroll', function (e) {
      const readProgress = document.getElementById("read_progress");
      const scrollHeight = document.documentElement.scrollHeight;
      const clientHeight = document.documentElement.clientHeight;
      const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
      readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
  })
</script>

<script>
  var menu = document.getElementById('menu')
  if (menu) {
      menu.scrollLeft = localStorage.getItem("menu-scroll-position");
      menu.onscroll = function () {
          localStorage.setItem("menu-scroll-position", menu.scrollLeft);
      }
  }

  document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener("click", function (e) {
          e.preventDefault();
          var id = this.getAttribute("href").substr(1);
          if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
              document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                  behavior: "smooth"
              });
          } else {
              document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
          }
          if (id === "top") {
              history.replaceState(null, null, " ");
          } else {
              history.pushState(null, null, `#${id}`);
          }
      });
  });
</script>
<script>
  var mybutton = document.getElementById("top-link");
  window.onscroll = function () {
      if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
          mybutton.style.visibility = "visible";
          mybutton.style.opacity = "1";
      } else {
          mybutton.style.visibility = "hidden";
          mybutton.style.opacity = "0";
      }
  };
</script>
<script>
  if (window.scrollListeners) {
    
    for (const listener of scrollListeners) {
      window.removeEventListener('scroll', listener)
    }
  }
  window.scrollListeners = []
</script>



<script src="/js/medium-zoom.min.js" data-no-instant
></script>
<script>
  document.querySelectorAll('pre > code').forEach((codeblock) => {
    const container = codeblock.parentNode.parentNode;

    const copybutton = document.createElement('button');
    copybutton.classList.add('copy-code');
    copybutton.innerText = 'copy';

    function copyingDone() {
      copybutton.innerText = 'copied';
      setTimeout(() => {
        copybutton.innerText = 'copy';
      }, 2000);
    }

    copybutton.addEventListener('click', (cb) => {
      if ('clipboard' in navigator) {
        navigator.clipboard.writeText(codeblock.textContent);
        copyingDone();
        return;
      }

      const range = document.createRange();
      range.selectNodeContents(codeblock);
      const selection = window.getSelection();
      selection.removeAllRanges();
      selection.addRange(range);
      try {
        document.execCommand('copy');
        copyingDone();
      } catch (e) { };
      selection.removeRange(range);
    });

    if (container.classList.contains("highlight")) {
      container.appendChild(copybutton);
    } else if (container.parentNode.firstChild == container) {
      
    } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
      
      codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
    } else {
      
      codeblock.parentNode.appendChild(copybutton);
    }
  });
</script>




<script>
  
  
  (function() {
    const enableTocScroll = '1' == '1'
    if (!enableTocScroll) {
      return
    }
    if (!document.querySelector('.toc')) {
      console.log('no toc found, ignore toc scroll')
      return
    }
    

    
    const scrollListeners = window.scrollListeners
    const headings = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id]');
    const activeClass = 'active';

    
    let activeHeading = headings[0];
    getLinkByHeading(activeHeading).classList.add(activeClass);

    const onScroll = () => {
      const passedHeadings = [];
      for (const h of headings) {
        
        if (getOffsetTop(h) < 5) {
          passedHeadings.push(h)
        } else {
          break;
        }
      }
      if (passedHeadings.length > 0) {
        newActiveHeading = passedHeadings[passedHeadings.length - 1];
      } else {
        newActiveHeading = headings[0];
      }
      if (activeHeading != newActiveHeading) {
        getLinkByHeading(activeHeading).classList.remove(activeClass);
        activeHeading = newActiveHeading;
        getLinkByHeading(activeHeading).classList.add(activeClass);
      }
    }

    let timer = null;
    const scrollListener = () => {
      if (timer !== null) {
        clearTimeout(timer)
      }
      timer = setTimeout(onScroll, 50)
    }
    window.addEventListener('scroll', scrollListener, false);
    scrollListeners.push(scrollListener)

    function getLinkByHeading(heading) {
      const id = encodeURI(heading.getAttribute('id')).toLowerCase();
      return document.querySelector(`.toc ul li a[href="#${id}"]`);
    }

    function getOffsetTop(heading) {
      if (!heading.getClientRects().length) {
        return 0;
      }
      let rect = heading.getBoundingClientRect();
      return rect.top
    }
  })();
  </script>

<script src="/js/instantclick.min.js" data-no-instant
></script>
<script data-no-instant>
  
  
  
  
  
  
  InstantClick.init();
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.6.0/mermaid.min.js" crossorigin="anonymous"></script>
<script>
    mermaid.init(undefined, '.language-mermaid');
</script>
</body>

</html>
