<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>operation system on Cylon&#39;s Collection</title>
    <link>https://www.oomkill.com/categories/operation-system/</link>
    <description>Recent content in operation system on Cylon&#39;s Collection</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 03 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://www.oomkill.com/categories/operation-system/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ch12 进程间通讯</title>
      <link>https://www.oomkill.com/2022/05/ch12-ipc/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/05/ch12-ipc/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="overview">Overview</h2>
<p>进程间是相互保持独立的，内存管理中，就是保护进程的地址空间不被其他进程访问。而<strong>进程间通信</strong> ( <em><strong>Inter-process Communication IPC</strong></em>) 用于在一个或多个进程间交换数据</p>
<p>进程间合作是那些可以影响或受其他过程影响的过程。例如网站包含 JS、H5、Flash，当有一个相应缓慢时，会发生整个网站的布局或其他功能的展示。</p>
<p>通常情况下进程间合作被允许的原因有：</p>
<ul>
<li>
<p>信息共享：多个进程需要访问同一个文件。（如管道）</p>
</li>
<li>
<p>计算加速：将复杂功能拆分为多个子任务（多处理器时效果更佳），可以更快地解决问题</p>
</li>
<li>
<p>模块化：将整体系统架构分为不同功能模块，模块间相互协作</p>
</li>
<li>
<p>便利：单用户可以同时多任务处理，如 编辑、编译、打印等</p>
</li>
</ul>
<h3 id="communications-model">Communications model</h3>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/3_12_CommunicationsModels.jpg" alt="img" style="zoom:100%;" /></center>
<center>(a) 消息队列（间接通信） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(b) 共享内存（直接通信）</center>
<h3 id="message-passing">Message Passing</h3>
<p>IPC背后关键的一点是消息的传递，即一个进程发消息，一个进程接收消息</p>
<p>而为了使进程间通信，就必须在进程间建立连接，连接可以是单/双向。连接可以使用直接通信和间接通信来实现</p>
<h3 id="direct-communication">Direct Communication</h3>
<p>直接通信，必须明确声明发送者或接收者的名称，通常定义为：</p>
<ul>
<li><code>Send(P, message)</code>：发送信息到进程 P</li>
<li><code>Receive(Q, message)</code>：接收来自进程 Q 的信息</li>
</ul>
<p>在直接通信中，一般连接的属性有以下特征：</p>
<ul>
<li>一个链路与一对进程相关联</li>
<li>自动建立链接</li>
<li>链接是通用的双向链接</li>
</ul>
<h3 id="indirect-communication">Indirect Communication</h3>
<p>间接通信，为异步通信，通常情况下互通信都需要有<strong>消息队列</strong>；发送者将信息放置消息队列中，接受者从消息队列中取出消息</p>
<ul>
<li><code>Send(P, message)</code>：像消息队列发送消息</li>
<li><code>Receive(Q, message)</code>：接受消息队列中的消息</li>
<li>每个进程都有唯一ID</li>
<li>共享一个消息队列</li>
</ul>
<p>在间接通信中，一般连接的属性有以下特征：</p>
<ul>
<li>一对进程共享消息队列时，才会在进程之间建立链接</li>
<li>链接可以被许多进程关联</li>
<li>链接可以是单向也可以是双向</li>
<li>每个进程可以有多个链接</li>
</ul>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220419222401782.png" alt="img" style="zoom:120%;" /></center>
<center>&nbsp;&nbsp;直接通信&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;间接通信</center>
<h3 id="synchronization">Synchronization</h3>
<p>从另一方面来讲，消息传递可以是阻塞 <code>Blocking</code> 或非阻塞 <code>Non-Blocking</code> 的；同步 <code>synchronous</code> 会<strong>阻塞</strong>一个进程，直到发送完成。异步 <code>asynchronous</code> 则是是<strong>非阻塞的</strong>，发送操作完成后会立即返回不等待返回结果</p>
<h3 id="buffer">Buffer</h3>
<p>消息通过队列传递，队列的容量则具有下列三种配置之一：</p>
<ul>
<li><strong>0容量</strong>：消息不能存储在队列中，因此发送者必须阻塞，直到接收者接受消息</li>
<li><strong>有限容量</strong>：队列中有一定的预先约定大小的容量。如果队列已满，发送者必须阻塞，直到队列中有可用空间（反之为空，接受者阻塞），否则可能是阻塞的或非阻塞的</li>
<li><strong>无限容量</strong>：具有无限容量的队列，发送者永远不会被迫阻塞</li>
</ul>
<p>至此整节围绕对消息传递功能的三个方面做了介绍：</p>
<ul>
<li>直接或间接通信</li>
<li>同步或异步通信</li>
<li>显式缓冲</li>
</ul>
<h2 id="signal">Signal</h2>
<p>信号是一种有限IPC形式，通常用于Unix、类Unix、POSIX的操作系统。信号是异步的，发送信号后，操作系统会中断进程正常的执行流程来传递信号，如果进程注册过相关信号处理逻辑，则执行对应代码，否则按照POSIX标准执行相关操作。</p>
<p>信号类似于中断，与中断的区别是，中断是由CPU调解，内核处理，信号是由内核调解，用户程序处理</p>
<p><strong>接收到信号时会发生什么?</strong></p>
<ul>
<li><code>catch</code>:  指定信号处理函数被调用</li>
<li><code>ignore</code>: 依靠操作系统的默认操作(abort，memory dump，suspend or resume process)</li>
<li><code>mask</code>:   屏蔽信号因此不会传送(可能是暂时的，当处理同样类型的信号)</li>
</ul>
<p><strong>信号的缺点</strong></p>
<ul>
<li>不能传输要交换的任何数据</li>
</ul>
<p><strong>信号的实现</strong>：</p>
<ul>
<li>应用程序注册信号处理函数，作为系统调用发给操作系统</li>
<li>产生了信号，操作系统返回为信号处理函数入口</li>
<li>通过修改 Stack ，将后续的执行改为信号处理函数的入口</li>
</ul>
<h2 id="pipe">Pipe</h2>
<p>管道是用来数据交换的，是进程之间最简单的通讯方式。通过将一个命令的输出，作为另一个命令的输入来实现的</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/3_22_PipeFileDescriptors.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h2 id="message-queue">Message Queue</h2>
<p>消息队列是按FIFO 无界 队列，克服了管道的一些缺点：</p>
<ul>
<li>无需父进程建立通道</li>
<li>Pipe是数据流，MQ是一个结构化数据</li>
<li>MQ和Pipe一样是 Bounded Buffer</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/ipc-using-message-queues.png" alt="使用消息队列的 IPC" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h2 id="share-memory">Share Memory</h2>
<p>共享内存是一种直接通信方式，对于进程来说，每个进程是私有地址空间；在每个地址空间内，明确地设置了共享内存段。</p>
<ul>
<li>
<p>优点：共享内存速度快更快，不需要系统调用并且以正常的内存速度进行访问。</p>
</li>
<li>
<p>缺点</p>
<ul>
<li>
<p>设置更复杂</p>
<ul>
<li>需要保障进程间同步机制</li>
</ul>
</li>
<li>
<p>无法在在多台计算机上正常工作</p>
</li>
</ul>
</li>
</ul>
<p><strong>如何实现内存共享</strong></p>
<p>如图所示，可以将共享内存映射到两个不同的进程内存段之间</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/xshared-memory.png.pagespeed.ic.lPvwNQSSC_.webp" alt="share memory" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h2 id="other-ipc">Other IPC</h2>
<p>Socket被定义为通信中的端点，是指一对进程通过网络使用一对套接字进行通信，套接字由连接的端口号和 IP 地址组成，通常为C/S架构。</p>
<p><code>UNIX Domain Socket</code> 是基于Socket网络通信架构的基础上发展出的一种IPC机制，相比于Socket，UNIX Domain Socket更高效。</p>
<p><code>IP Socket</code> 是可以用在同一台主机的进程间通讯（通过loopback地址127.0.0.1），但 <code>UNIX Domain Socket</code> ，不是使用底层网络协议（不需要打包拆包、计算校验和、维护序号和应答等），所有通信都完全发生在操作系统内核中。通过使用文件系统，是两个进程可以同时打开一个UDS进行通信</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/1ekw1o4xE_7ew9kYh6tVkCA.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><strong>一些其他的IPC</strong></p>
<ul>
<li>RPC <code>Remote Procedure Calls</code></li>
<li>基于Socket的 FTP HTTP等</li>
</ul>
<blockquote>
<p>Reference</p>
<p><a href="https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/3_Processes.html" target="_blank"
   rel="noopener nofollow noreferrer" >Processes</a></p>
<p><a href="https://www.cs.unc.edu/~dewan/242/s07/notes/ipc/node4.html" target="_blank"
   rel="noopener nofollow noreferrer" >IPC</a></p>
<p><a href="https://akaedu.github.io/book/ch37s04.html" target="_blank"
   rel="noopener nofollow noreferrer" >UNIX Domain Socket</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch13 file system</title>
      <link>https://www.oomkill.com/2022/05/ch13-file-system/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/05/ch13-file-system/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="overview">Overview</h2>
<h3 id="文件系统和文件">文件系统和文件</h3>
<p>文件系统: 一种用于持久性存储的系统抽象，决定了辅存中的内容如何组织与存储的抽象概念</p>
<p>文件：文件系统中的一个单元的相关数据在操作系统中的抽象，展现给用户的抽象概念</p>
<p><strong>文件系统的功能</strong>：</p>
<ul>
<li>分配文件磁盘空间
<ul>
<li>管理文件块(哪一块属于哪一个文件)</li>
<li>管理空闲空间(哪一块是空闲的)</li>
<li>分配算法(策略)</li>
</ul>
</li>
<li>管理文件集合
<ul>
<li>定位文件及其内容</li>
<li>命名：通过名字找到文件的接口</li>
<li>最常见：分层文件系统</li>
<li>文件系统类型(组织文件的不同方式)</li>
</ul>
</li>
<li>提供的便利及特征
<ul>
<li>保护：分层来保护数据安全</li>
<li>可靠性，持久性：保持文件的持久即使发生崩溃,媒体错误,攻击等</li>
</ul>
</li>
</ul>
<p><strong>为什么需要文件系统</strong>：</p>
<p>如果将文件放入一个房间中，整个房间都是堆积的文件</p>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/pexels-photo-6571015-1.jpg" alt="pexels-照片-6571015-1" style="zoom:40%;" /></center>
<p>有了文件系统的存在将会改变一切</p>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/pexels-photo-6571015-2.jpg" alt="pexels-照片-6571015-2" style="zoom:40%;" /></center>
<p>空间管理、元数据、数据加密、文件访问控制和数据完整性等等都是文件系统的职责。</p>
<h3 id="文件属性">文件属性</h3>
<p>文件具有名称和数据，还存储文件创建日期和时间、当前大小、上次修改日期等元信息。所有这些信息都称为文件系统的属性。常见的文件属性有</p>
<ul>
<li><strong>名称</strong>：它是以人类可理解的形式。</li>
<li><strong>标识符</strong>：每个文件都由文件系统中的唯一标记号标识，称为标识符。</li>
<li><strong>位置</strong>：设备上的文件位置。</li>
<li><strong>类型</strong>：支持各种类型文件的系统需要此属性。</li>
<li><strong>大小</strong>：当前文件大小的属性。</li>
<li><strong>保护</strong>：分配和控制读、写和执行文件的访问权限。</li>
<li><strong>时间、日期和安全</strong>：用于对文件的保护、安全，也用于监控</li>
</ul>
<h3 id="文件描述符">文件描述符</h3>
<p>文件头 <code>File Header</code>；类似于Unix的 <code>inode</code>，在存储元数据中保存了每个文件的信息，保存文件的属性，跟踪哪一块存储块属于逻辑上文件结构的哪个偏移</p>
<p><strong>文件描述符</strong> （<code>file-descriptor</code>）；是唯一标识操作系统中打开文件的数字（整形），用于用户和内核空间之间的接口，以识别 文件/Socket 资源。因此，当使用 <code>open()</code> 或 <code>socket()</code>（与内核接口的系统调用）时，会得到一个文件描述符，一个整数。因此，如果直接与内核交互，使用系统调用 <code>read()</code>, <code>write()</code> 等 <code>close()</code>。使用的是一个文件描述符句柄。</p>
<p>在 C 语言中 <code>stdin</code>，<code>stdout</code>、 和 <code>stderr</code> ，在 UNIX 中分别映射到文件描述符 <code>0</code>  <code>1</code> <code>2</code></p>
<pre><code>f = open(name, flag);
...
... = read(f, ...);
...
close(f);
</code></pre>
<p>内核跟踪每个进程打开的文件：</p>
<ul>
<li>操作系统为每个进程维护一个打开文件表</li>
<li>一个打开文件描述符是这个表中的索引</li>
<li>描述符由唯一的非负整数表示，例如 0、12 或 567。系统上每个打开的文件至少存在一个文件描述符</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/file-descriptor.jpg" alt="png" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>如果对文件需要更好的管理，就需要元数据来管理打开文件:</p>
<ul>
<li>
<p>文件指针：指向最近的一次读写位置，每个打开了这个文件的进程都这个指针</p>
</li>
<li>
<p>文件打开计数：记录文件打开的次数； 当最后一个进程关闭了文件时，允许将其从打开文件表中移除</p>
</li>
<li>
<p>文件磁盘位置：缓存数据访问信息</p>
</li>
<li>
<p>访问权限：每个程序访问模式信息</p>
</li>
</ul>
<p><strong>从用户角度来看</strong>：文件是持久的数据结构</p>
<ul>
<li>系统访问接口:
<ul>
<li>字节的集合(UNIX)</li>
<li>系统不会关心你想存储在磁盘上的任何的数据结构</li>
</ul>
</li>
<li>操作系统内部视角：
<ul>
<li>块的集合（块是逻辑转换单元，而扇区是物理转换单元）</li>
<li>块大小&lt;&gt; 扇区大小：在UNIX中，块的大小是 4KB</li>
</ul>
</li>
</ul>
<h3 id="空间管理">空间管理</h3>
<p>在系统层面上来看，存储设备在被划分为称为<strong>扇区</strong>的固定大小的块；扇区是存储设备上的<strong>最小存储单元</strong> ，介于 512 bytes 和 4096bytes 之间；所有的操作都是操作磁盘块，读写1bytes也是对整个磁盘块的读写。</p>
<p>文件系统使用的是<strong>块</strong>，块是物理扇区的抽象</p>
<p><strong>用户怎么访问文件：在系统层面需要知道用户的访问模式</strong></p>
<ul>
<li>顺序访问：按字节依次读取
<ul>
<li>几乎所有的访问都是这种方式</li>
</ul>
</li>
<li>随机访问：从中间读写
<ul>
<li>不常用,但是仍然重要，如：虚拟内存支持文件，内存页存储在文件中；</li>
<li>更加快速，不希望获取文件中间的内容的时候也必须先获取块内所有字节</li>
</ul>
</li>
<li>内容访问：通过特征（索引）
<ul>
<li>更多是数据库形式的存在；通过index，找到包含关系的文件</li>
</ul>
</li>
</ul>
<h3 id="文件访问控制">文件访问控制</h3>
<p>多用户操作系统中的文件共享是很必要的，不是每个人都能够删除或修改他们没有权限的文件。</p>
<p>有关用户权限和文件所有权的数据在不同的操作系统上有不同的格式：</p>
<ul>
<li>类 Unix被存储为访问控制列表 ；<code>Access-Control List</code> <strong>（ACL）</strong></li>
<li>Windows 上被存储为访问控制条目；<code>Access-Control Entries </code> <strong>(ACE)</strong></li>
</ul>
<p>谁能够获得哪些文件的哪些访问权限</p>
<ul>
<li>访问模式: 读,写,执行,删除,列举等</li>
</ul>
<p>文件访问控制列表(ACL)：</p>
<ul>
<li>&lt;文件实体, 权限&gt;</li>
</ul>
<p>UNIX模式：</p>
<ul>
<li>&lt;用户|组|物主,读|写|可执行&gt;</li>
<li>用户ID识别用户；表明每个用户所允许的权限及保护模式</li>
<li>组ID允许用户组成组，并指定了组访问权限</li>
</ul>
<p><strong>多用户下，如何同时访问共享文件</strong>：</p>
<ul>
<li>
<p>和进程同步算法相似</p>
</li>
<li>
<p>因磁盘IO和网络延迟而设计简单</p>
</li>
<li>
<p>文件共享的一致性语义 <code>Consistency Semantics</code></p>
<ul>
<li>
<p>UNIX文件系统语义 <code>Unix Semantics</code> ：</p>
<ul>
<li>
<p>对打开文件的写入内容立即对其他打开同一文件的其他用户可见</p>
</li>
<li>
<p>共享文件指针允许多用户同时读取和写入文件</p>
</li>
</ul>
</li>
<li>
<p>会话语义 <code>Session Semantics</code>：</p>
<ul>
<li>用户对文件的写入对其他用户不可见。</li>
<li>文件关闭后，更改仅对新会话可见。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>锁:</p>
<ul>
<li>一些操作系统和文件系统提供该功能</li>
</ul>
</li>
</ul>
<h3 id="目录">目录</h3>
<p>目录是磁盘上的一个位置，是一种特殊的文件；用于对文件分层。文件夹和目录是可互换的术语。</p>
<p>目录的特点：</p>
<ul>
<li>
<p>目录是一类特殊的文件：每个目录都包含了一张表 <code>&lt;name, pointer to file header&gt;</code></p>
</li>
<li>
<p>目录和文件的树形结构：早期的文件系统是扁平的(只有一层目录)</p>
</li>
<li>
<p>层次名称空间：</p>
<ul>
<li><left><img src="../../images/ch13 file system/image-20220422230459824.png" alt="image-20220422230459824" style="zoom:55%;" /></left></li>
</ul>
</li>
</ul>
<p>名字解析：逻辑名字转换成物理资源（如文件）的过程:</p>
<ul>
<li>在文件系统中：到实际文件的文件名(路径)</li>
<li>遍历文件目录直到找到目标文件</li>
<li>举例：解析 <code>/bin/ls</code>
<ul>
<li>读取root的文件头(在磁盘固定位置)</li>
<li>读取root的数据块: 搜索bin项</li>
<li>读取bin的文件头</li>
<li>读取bin的数据块: 搜索ls项</li>
<li>读取ls的文件头</li>
</ul>
</li>
</ul>
<p>当前工作目录：当前目录的内容存储在内存中可以快速的指向一个目录</p>
<ul>
<li>每个进程都会指向一个文件目录用于解析文件名</li>
<li>允许用户指定相对路径来代替绝对路径</li>
</ul>
<h4 id="单级目录">单级目录</h4>
<p>单级目录 <code>Single-Level Directory</code>；单级目录理解起来比较简单，单级目录中所有文件都包含在同一目录中，必须具有唯一的名称</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/11_09_SingleLevel.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="两级目录">两级目录</h4>
<p>两级目录 <code>Two-Level Directory</code>；两级目录通常为不同用户的自己的目录 User File Director UDF，文件名只需在指定目录下唯一即可。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/11_10_TwoLevelStructure.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="树形目录">树形目录</h4>
<p>树形目录 <code>Tree-Structured Directories</code>；通常是指深度大于<strong>2</strong>的目录，在此结构中，每个文件都有一个唯一的路径</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/11_11_TreeStructure.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="文件别名">文件别名</h4>
<h5 id="无环图目录">无环图目录</h5>
<p>无环图目录 <code>Acyclic-Graph Directories</code>；也被称作为<strong>别名</strong> <code>Alias</code>，是指在目录结构中一个文件有多个绝对位置（绝对路径）。UNIX中提供了两种类型的<strong>链接</strong>来实现该类型：</p>
<ul>
<li><strong>硬链接</strong> <code>hard link</code>：硬链接会创建新的文件，指向同一个inode；在删除一个文件时，会删除一个指向底层 inode的链接。当所有指向该 inode 的链接都被删除，inode才会被删除（同一文件系统中的普通文件）
<ul>
<li>每个文件都有引用计数器，以跟踪当前有多少文件引用该文件。每当删除其中一个引用（有别名的文件）时，计数器就会减少，当它达到零时，可以回收磁盘空间。</li>
</ul>
</li>
<li><strong>符号链接</strong> <code>symbolic link</code>；也称软连接，是一个特殊文件，包含被链接文件的信息，可以是目录或文件。
<ul>
<li>符号链接在删除或被移动时
<ul>
<li>找到所有链接并同时修改</li>
<li>符号链接悬空，<code>Dangling Pointer</code>；不在有效</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Windows中仅支持符号链接，称为快捷方式</p>
</blockquote>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/11_12_AcyclicGraph.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h5 id="通用图目录">通用图目录</h5>
<p>通用图目录 <code>General Graph Directory</code> ；是一种允许循环的目录；上述无环目录中是会进入无限循环</p>
<p>通用图目录比其他类型目录更佳灵活，最大问题是计算大小时的难度。通用图目录实现常见的是通过线性列表或哈希表：</p>
<ul>
<li>线性列表：将所有文件保存在一个目录中，类似一个单链表。每个文件都包含一个数据块指向指针和目录中的下一个文件。
<ul>
<li><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-129.png" alt="操作系统中的目录结构" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></li>
</ul>
</li>
<li>哈希表：目录中对于每个文件，都会生成一个键值对，将其存入哈希表中。借助文件名的哈希函数，我们可以确定存储在目录中的各个文件 key 和其指针 <code>key points</code>
<ul>
<li><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-130.png" alt="操作系统中的目录结构" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></li>
</ul>
</li>
</ul>
<p>图：通用图目录结构</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/11_13_GeneralGraph.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="文件系统挂载">文件系统挂载</h3>
<p>在类Unix系统中，VFS 会为每个分区或可移动存储设备分配一个<strong>设备 ID</strong> 如 <code>dev/disk1s1</code>；然后，创建一个<strong>虚拟目录树</strong> ，并将每个设备的内容作为单独的目录放在该目录树下。</p>
<p>将目录分配给存储设备的行为称为<strong>挂载</strong> <code>mount</code>，被分配的目录称为<strong>挂载点</strong></p>
<ul>
<li>一个文件系统需要先挂载才能被访问</li>
<li>一个未挂载的文件系统被挂载在挂载点上</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/11_14_MountVolumes.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="文件系统种类">文件系统种类</h3>
<ul>
<li>
<p>磁盘文件系统：文件存储在数据存储设备上,如磁盘; 例如: FAT，NTFS，ext2 3， ISO9660等</p>
</li>
<li>
<p>数据库文件系统：文件根据其特征是可被寻址的; 例如: WinFS</p>
</li>
<li>
<p>日志文件系统: 记录文件系统的修改,事件; 例如: journaling file system</p>
</li>
<li>
<p>网络，分布式文件系统：例如：NFS，SMB，AFS，GFS</p>
</li>
<li>
<p>虚拟文件系统</p>
</li>
</ul>
<h2 id="虚拟文件系统">虚拟文件系统</h2>
<p>虚拟文件系统 <code>Virtual File Systems</code> <strong>VFS</strong>；是对多种类型文件系统提供统一的通用API，使得在上层软件中，可以用单一的方式实现不同底层的文件系统。</p>
<p>虚拟文件系统的功能：</p>
<ul>
<li>提供相同的文件和文件系统接口</li>
<li>管理所有文件和文件系统关联的数据结构</li>
<li>高效查询例程，遍历文件系统</li>
<li>与特定文件系统模块的交互</li>
</ul>
<p>VFS除了统一的API外，还提供了唯一标识符 <code>vnode</code>；对于类UNIX操作系统中，inode是惟一的，并不会跨网络</p>
<p>Linux中虚拟文件系统的对象类型：</p>
<ul>
<li><strong>inode</strong>：代表单个文件
<ul>
<li>存储文件的元信息（许可，拥有者，大小，数据库位置等）</li>
<li>一个文件对应一个inode，每个inode都由一个inode编号唯一标识</li>
<li>一个inode通常对应于存储在磁盘上的一个文件控制块</li>
</ul>
</li>
<li><strong>file</strong>：代表一个打开的文件
<ul>
<li>存储进程和打开文件之间交互的信息。这个信息只存在于内核空间，不保存在磁盘上。</li>
</ul>
</li>
<li><strong>superblock</strong>：卷控制块代表一个文件系统
<ul>
<li>每个文件系统一个</li>
<li>文件系统详细信息</li>
<li>块，块大小，空余块，计数，指针等</li>
</ul>
</li>
<li><strong>dentry</strong>：代表目录项 <code>dirctory entry</code>
<ul>
<li>用于将一个inode（文件）与一个目录关联</li>
<li>将目录项数据结构及树形布局编码成树形数据结构</li>
<li>指向文件控制块，父节点，项目列表等</li>
</ul>
</li>
</ul>
<h2 id="数据块缓存">数据块缓存</h2>
<h2 id="打开文件的数据结构">打开文件的数据结构</h2>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/12_03_FileSystemStructures.jpg" alt="img" style="zoom:90%;" /></center>
<center>内存中文件系统结构。(a) 文件打开 &nbsp;&nbsp;&nbsp;(b) 文件读取</center>
<p>由图可知，当一个文件在程序中被访问时（创建、打开），<code>open()</code> 系统调用从磁盘读入FCB信息，并将其存储在系统打开文件表中。一个条目被添加到每个进程的打开文件表中，这个索引引用的是系统范围的打开文件表，并且进程表的索引由 <code>open()</code> 这个系统调用返回。这个索引称为<strong>文件描述符</strong>， Windows中为<strong>文件句柄</strong>。</p>
<p>如果有多个进程打开同一个文件，此时系统表中的计数器会递增。对应打开文件表条目会引用到系统表中</p>
<p>文件被关闭时，每个进程的打开文件表的条目被释放，系统表中的计数器递减。如果计数器到零，则系统表也被释放。</p>
<p><strong>打开文件描述</strong>：</p>
<ul>
<li>
<p>每个被打开的文件一个</p>
</li>
<li>
<p>文件状态信息</p>
</li>
<li>
<p>FCB：目录项，当前文件指针，文件操作设置等</p>
</li>
</ul>
<p><strong>打开文件表</strong>：</p>
<ul>
<li>
<p>一个进程一个</p>
</li>
<li>
<p>一个系统级的</p>
</li>
<li>
<p>每个卷控制块也会保存一个列表</p>
</li>
<li>
<p>所以如果有文件被打开将不能被卸载</p>
</li>
<li>
<p>一些操作系统和文件系统提供该功能</p>
</li>
</ul>
<p><strong>调节对文件的访问</strong></p>
<ul>
<li>强制 - 根据锁保持情况和需求拒绝访问</li>
<li>劝告 - 进程可以查找锁的状态来决定怎么做</li>
</ul>
<h2 id="文件分配">文件分配</h2>
<p>在文件分配中，存在一些问题</p>
<p>大多数文件很小</p>
<ul>
<li>需要对小文件支持</li>
<li>块的空间不能设置太小</li>
</ul>
<p>一些文件却很大</p>
<ul>
<li>必须支持大文件</li>
<li>大文件需要高效访问</li>
</ul>
<p>磁盘的分配主要有三种方式：连续 <code>contiguous</code>、链式 <code>linked</code> 、索引 <code>indexed</code> ；分配指标必须遵循 高效的存储利用，与访问速度的表现</p>
<h3 id="连续分配">连续分配</h3>
<p>连续分配  （<code>Contiguous Allocation</code>）是指文件的所有块连续地保存在一起</p>
<p>连续分配的特点：</p>
<ul>
<li>
<p>只需要一个起始块，与长度</p>
</li>
<li>
<p>性能非常快，读取同一文件的连续块不需要移动磁头；或仅需要移动一小块到达相邻柱面</p>
</li>
</ul>
<p>连续分配存在的问题：固定递归存储时不会出现问题，当文件增长或创建时文件的确切大小未知，会出现问题：</p>
<ul>
<li>
<p>碎片：</p>
<ul>
<li>
<p>过高估计文件最终的大小会增加外部碎片从而浪费浪费磁盘空间</p>
</li>
<li>
<p>文件增长超出其最初分配的空间，过低预估则可能需要移动文件位置或中止进程</p>
</li>
</ul>
</li>
<li>
<p>文件增长问题：</p>
<ul>
<li>如果一个文件初始分配大小很大，并长期没有写入，在文件填满时，很多空间将变得不可用</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/12_05_ContiguousAllocation.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="链式分配">链式分配</h3>
<p>链式分配（ <code>Linked Allocation</code> ）是指文件按照数据链表方式存储，并以每个链接消耗的存储空间为代价</p>
<p>链式分配的特点：</p>
<ul>
<li>无外部碎片，无需预先知道文件大小，并支持文件的动态增长</li>
</ul>
<p>链式分配的不足：</p>
<ul>
<li>无法实现高效的随机访问；链式访问仅可以串行访问文件，必须从每个位置的列表头开始</li>
<li>可靠性：指针丢失或损坏</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/12_06_LinkedAllocation.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="索引分配">索引分配</h3>
<p>索引分配（<code>Indexed Allocation</code>）是指将每个文件的索引组合在一个公共块上，每个索引项指向了一个数据块</p>
<p>索引分配的特点：基本包含链式分配和连续分配的所有优点</p>
<p>索引分配的不足：会浪费一部分磁盘空间</p>
<ul>
<li>无论文件大小，存储索引都有一定开销（文件大小&lt;索引大小）</li>
<li>单个索引块不能保存大文件的所有指针</li>
</ul>
<p>对于单个索引块不能保存大文件的所有指针这个问题，一般情况下有下述解决方案</p>
<ul>
<li>链式索引块模式 <code>Linked Scheme</code>：索引块为一个磁盘块，第一个索引块包含一些头信息、前 N 个块地址；还包含指向其他链接索引块的指针</li>
<li>多级索引 <code>Multi-Level Index</code>：类似于多级页表，第一个索引块包含一组指向二级索引块的指针，而二级索引块又包含指向实际数据块的指针</li>
<li>联合模式 <code>Combined Scheme</code>：</li>
</ul>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/12_08_IndexedAllocation.jpg" alt="img" style="zoom:80%;" /></center>
<center>图：索引分配</center>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/chp11_11.png" alt="Figure 11.11" style="zoom:80%;" /></center>
<center>图：多级索引</center>
<blockquote>
<p>Reference</p>
<p><a href="https://www.cs.uct.ac.za/mit_notes/database/htmls/chp11.html#multilevel-indexes" target="_blank"
   rel="noopener nofollow noreferrer" >multilevel-indexes</a></p>
</blockquote>
<h2 id="空闲空间管理">空闲空间管理</h2>
<p>空闲空间管理只是磁盘管理中，需要追踪和分配对空闲空间部分的管理，对于空闲空间的管理的表现是位图 <code>bitmap</code>；即通过位向量来标记数据块的使用情况</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220425184448442.png" alt="image-20220425184448442" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><strong>其他管理空闲空间的方式</strong>：</p>
<ul>
<li>链表：链表也可以作为管理空闲块的一种方式</li>
<li>分组：将空闲块存储在第一个空闲块中，前 <code>n-1</code> 个空闲块是空闲的，最后一个包含下一个分组</li>
<li>计数：存储一个磁盘块的地址和之后n个空闲块的数量</li>
</ul>
<blockquote>
<p>Reference</p>
<p><a href="https://testbook.com/objective-questions/mcq-on-free-space-management--5eea6a1439140f30f369f304" target="_blank"
   rel="noopener nofollow noreferrer" >一些空闲空间管理的测试题</a></p>
</blockquote>
<h2 id="多磁盘管理-raid">多磁盘管理 RAID</h2>
<p>冗余磁盘阵列 **RAID **（<code>redundant array of independent disks</code>）；是一种小磁盘分区组成大分区的一种解决方案，一种磁盘管理技术</p>
<h3 id="raid的工作原理">RAID的工作原理</h3>
<p>RAID 的工作原理是将数据分别放置在多个磁盘上，并允许I/O操作以平衡的方式，从而提高磁盘性能</p>
<h3 id="raid-controller">RAID Controller</h3>
<p>RAID 控制器是用于管理存储阵列中的硬盘驱动器的设备，是操作系统和物理磁盘中间的一个抽象层，将磁盘表示为逻辑单元。</p>
<p>RAID控制器分为软RAID和硬RAID</p>
<ul>
<li>硬RAID <code>Hardware RAID</code>：物理控制器管理整个磁盘阵列；如主板或RAID卡</li>
<li>软RAID <code>Software RAID</code>：使用硬件资源来管理磁盘阵列；如CPU、内存；软RAID可能无法实现性能提升，反而影响性能</li>
</ul>
<h3 id="raid级别">RAID级别</h3>
<h4 id="raid0">RAID0</h4>
<p>RAID0（无容错的条带化磁盘阵列），是将数据体划分为块并将数据块分布在独立磁盘冗余阵列中的多个存储设备中，但不提供容错。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/8b11.png" alt="RAID 0" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="raid1">RAID1</h4>
<p>RAID1又称为磁盘镜像 <code>mirroring</code>，将数据复制到两个或更多磁盘，由至少两个数据存储驱动器组成，读性能提升，写性能与单磁盘相同。RAID1提供了全面的数据保护</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/8b111.png" alt="RAID 1" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="raid5">RAID5</h4>
<p>RAID0（基于奇偶校验块的条带化磁盘阵列）；它使用类似于 RAID0 的分布式数据存储，但通过包含写入不同阵列磁盘的冗余信息（奇偶校验码）来提高数据存储的可靠性。RAID 5 至少需要三个磁盘，但出于性能原因，通常建议使用至少五个磁盘。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/8b115.png" alt="RAID 5" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="raid-10">RAID 10</h4>
<p>RAID 0+1是结合 RAID 1 和 RAID 0的一种模式，通常称为 RAID 10；RAID10需要至少四个磁盘；通过跨镜像的条带化保存数据，只要每个镜像对中的一个磁盘正常，那么数据就正常</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/raid10-165089735841849.png" alt="raid10" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h2 id="磁盘调度">磁盘调度</h2>
<p>磁盘调度是指在操作系统层面重新组织IO请求的顺序，来有效的减少磁盘访问开销。</p>
<p>在传统磁盘中由多个盘面组成，每个盘面被臂组件上的磁盘头来通过旋转读取，通过所希望的扇区开始</p>
<img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/10_01_DiskMechanism.jpg" alt="img" style="zoom:80%;" />
<p>在操作中，磁盘会告诉旋转例如 7200RPM（<code>revolutions per minute</code>）（实际读写速度120 MB/s ）。数据从磁盘传输到计算机的速率由几个步骤组成：</p>
<ul>
<li>寻道时间 <code>seek time</code>：是将磁头从一个柱面移动到另一个柱面所需的时间，以及磁头在移动后稳定下来所需的时间。是过程中最慢的步骤，也是整体传输速率的主要瓶颈。</li>
<li>旋转延迟 <code>rotational latency</code>：扇区从开始处到目的处所需时间</li>
<li>传输速率 <code>transfer rate</code>：数据从磁盘移动到计算机所需的时间</li>
</ul>
<p>$access\ time=SK+RL+TR$</p>
<ul>
<li>$T_a$ access time 访问时间</li>
<li>$T_s$ seek time 寻址时间</li>
<li>$T_r$ rotational latency 旋转延迟</li>
<li>$T$ transfer time 传输速率</li>
<li>$b$  transfer b bytes 传输位</li>
<li>$N $ bytes per track 每轨存多少字节</li>
<li>$r$ Rotational speed</li>
<li>$\frac{1}{r}$ 旋转一周的时间</li>
<li>$\frac{1}{2r}$ 平均旋转延迟，旋转一周时间再取一半</li>
<li>$\frac{b}{rN}$ 数据访问时间</li>
</ul>
<p>那么 传输速率 $T = \frac{b}{rN}$</p>
<p>平均访问时间为 $T_a = T_s + \frac{1}{2r} + \frac{b}{rN}$</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220425225845651.png" alt="image-20220425225845651" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>如：$T_s = 2ms$，$r=10000rpm$，512B扇区大小，每轨320个扇区， 1.3 MB的文件大小</p>
<ul>
<li>
<p>转一圈的时间：RPM=10000时，每6毫秒转一圈：$\frac{1}{r} = \frac{60}{10000}=0.006s = 6ms$</p>
</li>
<li>
<p>一个文件有多少扇区：$\frac{1.3MB}{512} = \frac{1300000}{512}=2540$</p>
</li>
<li>
<p>一共多少轨道：$2540\div320=8$</p>
</li>
</ul>
<p><strong>通过磁道 <code>tracks</code> 访问需要耗时多少？</strong></p>
<ul>
<li>
<p>一个磁道要传输的数据大小：$b=512\times320$</p>
</li>
<li>
<p>每轨有多少字节：$N=512\times320$</p>
</li>
<li>
<p>$\frac{1}{r}=6$，$\frac{1}{2r} = 3$</p>
</li>
<li>
<p>$\frac{b}{rN}=6$ ；因$b=N$ 故$\frac{b}{rN}=6$</p>
</li>
<li>
<p>因 $T_s=2$，$Average T_r=3$，$\frac{b}{rN}=6$ ；那么 $T_a = T_s + \frac{1}{2r} + \frac{b}{rN}=2+3+6=11$</p>
</li>
<li>
<p>那么按轨寻址访问的总时间为：$8*11=88ms$</p>
</li>
</ul>
<p><strong>通过扇区 <code>sectors</code> 访问需要耗时多少？</strong></p>
<ul>
<li>每轨多少字节 $N=512\times320$</li>
<li>因磁轨转一圈多少时间 $\frac{1}{r} = 6$，$\frac{1}{2r} = 3$；每磁道耗时 $\frac{1}{r} = \frac{6}{320} = 0.01875ms$</li>
<li>因 $\frac{1}{r} = \frac{6}{320}$ ；$b=512$；$N=512\times320$；那么 $\frac{b}{rN}=0.01875$</li>
<li>那么一个扇区的时间为：
<ul>
<li>因 $T_s=2$，$Average T_r=3$，$\frac{b}{rN}=0.01875$
<ul>
<li>b=512，N=512，$\frac{1}{r} = 0.01875$，那么，$\frac{b}{rN}=0.01875$</li>
</ul>
</li>
<li>那么 $T_a = T_s + aT_r + \frac{n}{rN} = 2+3+0.01875 = 5.01875$</li>
<li>那么总共时间为 $2540*5.01875=12748ms$</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>那么就可以得出结论</strong>：</p>
<ul>
<li>寻道方式是性能上区别的原因
<ul>
<li>如果来回寻道，会导致性能急剧下降</li>
</ul>
</li>
<li>对单个磁盘，会有一个IO请求数目</li>
<li>如果请求是随机的，那么会表现很差</li>
</ul>
</blockquote>
<h3 id="磁盘调度算法">磁盘调度算法</h3>
<ul>
<li>
<p>磁盘传输速度主要受<strong>寻道时间</strong>和<strong>旋转延迟的限制</strong>。当要处理多个请求时，在等待其他请求被处理时也会有一些固有的延迟。</p>
</li>
<li>
<p><strong>带宽</strong>是通过传输的数据量除以从发出第一个请求到完成最后一次传输的总时间量来衡量的</p>
</li>
<li>
<p>通过以良好的顺序处理请求，可以提高带宽和访问时间。</p>
</li>
<li>
<p>磁盘请求包括磁盘地址、内存地址、要传输的扇区数以及请求是读还是写。</p>
</li>
</ul>
<h4 id="fcfs">FCFS</h4>
<p>先来先服务 <code>First-Come First-Serve</code>：</p>
<ul>
<li>按顺序处理请求</li>
<li>公平对待所有进程</li>
<li>在有很多进程的情况下，接近随机调度的性能</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/10_04_FCFS.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>可以看到柱面 cylinder从122 到 14 在回到124摆动很巨大：</p>
<h4 id="sstf">SSTF</h4>
<p>最短寻道优先 <strong>Shortest Seek Time First</strong></p>
<ul>
<li>选择从磁臂当前位置需要移动最少的IO请求</li>
<li>总是选择最短寻道时间</li>
<li>可能会导致饥饿</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/10_05_SSTF.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>由图可以看出相同的情况下<strong>SSTF</strong>将柱面移动数减少到 236 个柱面，低于**FCFS **所需的 640 个柱面。</p>
<h4 id="scan">SCAN</h4>
<p><strong>SCAN</strong>算法，又称<strong>电梯</strong>算法，磁臂在一个方向上移动，满足所有为完成的请求，直到磁臂到达该方向上最后的磁道，类似于在高层建筑中处理请求的电梯。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/10_06_SCAN.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="c-scan">C-SCAN</h4>
<p><code>Circular-SCAN</code>，通过循环队列方式来改进 SCAN ：一旦磁臂到达磁盘的末端，它会返回到另一端而不处理任何请求，然后从磁盘的开头重新开始：</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/10_07_C_SCAN.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="look">LOOK</h4>
<p>LOOK是通过待处理请求的队列来改进SCAN，而不是磁盘序列，并且不会将磁头移向磁盘末端的距离超过必要的位置。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/10_08_C_LOOK.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="n-step-look-or-n-step-scan">N-Step LOOK or N-Step-SCAN</h4>
<p>N-Step-SCAN是将请求队列分为成长度为<em>N</em>的子队列，使用SCAN算法进行处理；当在一个队列的处理过程中，如果有一些新的请求到达，那么它们必须被放置在另一个队列中。</p>
<p>设有从 0 到 199 编号为 200 磁道；请求顺序为， 122、90、160、24、102、89、143、18、67；$N=2$</p>
<p>子队列有：</p>
<ul>
<li>
<p>1 = {122, 90}</p>
</li>
<li>
<p>2 = {160, 24}</p>
</li>
<li>
<p>3 = {102, 89}</p>
</li>
<li>
<p>4 = {143, 18}</p>
</li>
<li>
<p>5 = {67}</p>
</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220717124809354.png" alt="image-20220717124809354" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><code>N-step-SCAN</code> 磁盘调度算法的吞吐量高，平均响应时间低。</p>
<blockquote>
<p>Reference</p>
<p><a href="https://www.electronicsmind.com/2022/01/n-step-scan-disk-scheduling-algorithm.html" target="_blank"
   rel="noopener nofollow noreferrer" >n-step-scan disk scheduling algorithm</a></p>
</blockquote>
<h4 id="fscan">FSCAN</h4>
<p>FSCAN <code>Fixed period SCAN</code>，是 <code>N-step-SCAN</code> 的简化版本，FSCAN将磁盘请求队列分成两个子队列，一个是由当前所有请求磁盘I/O的进程所形成的队列，由磁盘调度按SCAN算法进行处理，在扫描期间，将新出现的请求磁盘I/O的进程放入另一个等待处理的请求队列。这样，所有的新请求都被推迟到下一次扫描时处理。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/finalFSCAN.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch11 死锁</title>
      <link>https://www.oomkill.com/2022/05/ch11-deadlock/</link>
      <pubDate>Mon, 02 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/05/ch11-deadlock/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="死锁问题">死锁问题</h2>
<p>死锁 <code>deadlock</code>；是一组阻塞的进程，每个进程都持有一个资源并等待获取另一个进程持有的资源。</p>
<p>死锁的示例：交通桥</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/122319_0715_Introductio1.png" alt="死锁示例" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>如图所示，桥是资源，进程是车辆，两个不同方向的车辆同时占用桥，此时发生谁也过不去的情况（死锁的发生）；</p>
<ul>
<li>当死锁发生时，如果一辆车倒车（抢占资源和回滚）就可以解决死锁问题</li>
<li>死锁发生时，可能需要后退多台车辆</li>
<li>饥饿，而饥饿并不一定是死锁</li>
</ul>
<h2 id="系统模型">系统模型</h2>
<p>在正常情况下，进程必须在使用之前请求资源，并在完成后释放它，顺序如下：</p>
<ul>
<li>
<p>请求：如果不能立即授予请求，则进程等待，直到它需要的资源变得可用。例如，系统调用 <code>open()</code>、<code>malloc()</code>、<code>new()</code>  、<code>request()</code>  等。</p>
</li>
<li>
<p>使用：进程使用资源，例如文件中读取数据；使用硬件。</p>
</li>
<li>
<p>释放：进程完成后放弃资源，以便其可用于其他进程。如，<code>close()</code>、<code>free()</code>、<code>delete()</code> 、 <code>release()</code>。</p>
</li>
</ul>
<p>当在集合中的每个进程都在等待当前分配给集合中另一个进程的资源时，这一组进程就会发生死锁</p>
<h3 id="资源分配">资源分配</h3>
<p>通过实例来理解死锁，</p>
<ul>
<li>
<p>一组资源：</p>
<ul>
<li>${ R_1,\ R_2,\ R_3,\ &hellip;.,\ R_N }$；为方形，图形内的点代表资源数量</li>
</ul>
</li>
<li>
<p>一组进程：</p>
<ul>
<li>${ P_1,\ P_2,\ P_3,\ &hellip;.,\ P_N }$</li>
</ul>
</li>
<li>
<p>请求边缘 <code>Request Edge</code>：进程需要一些资源，被称为请求边缘；如 $P_i\ →\ R_j$</p>
</li>
<li>
<p>分配边缘 <code>Assign Edge</code>：当资源已经被分配给进程，被称为分配边缘；如 $R_j\ →\ P_i$</p>
</li>
<li>
<p>当请求被授予时，可以通过反转方向的线将<strong>请求边缘</strong>转换为<strong>分配边缘</strong></p>
</li>
</ul>
<table>
<thead>
<tr>
<th>类型</th>
<th>示意图</th>
</tr>
</thead>
<tbody>
<tr>
<td>Process</td>
<td><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220417173948923.png" alt="image-20220417173948923" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></td>
</tr>
<tr>
<td>Resource</td>
<td><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220417174015953.png" alt="image-20220417174015953" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></td>
</tr>
<tr>
<td>$P_i$ 请求的 $R_j$ 实例</td>
<td><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220417174158072.png" alt="image-20220417174158072" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></td>
</tr>
<tr>
<td>$P_i$ 持有一个 $R_j$ 的实例<br>也可以说 $R_j$ 被 $P_i$ 所持有</td>
<td><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220417174238047.png" alt="image-20220417174238047" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></td>
</tr>
</tbody>
</table>
<h3 id="资源分配图">资源分配图</h3>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/7_01_ResourceAllocation.jpg" alt="img" style="zoom:100%;" /></center>
<center>资源分配图</center>
<p>如图所示，资源类型为：</p>
<ul>
<li>P = ${P_1,\ P_2,\ P_3}$</li>
<li>R = ${R_1,\ R_2,\ R_3,\ R_4}$</li>
<li>RE = ${P_1\ →\ R_1,\ P_2\ →\ R_3}$</li>
<li>AE = ${R_1\ →\ P_2,\ R_2\ →\ P_2,\ R_2\ →\ P_1,\ R_3\ →\ P_3}$
<ul>
<li>${P_1}$ 持有 ${R_2}$ 等待 ${R_1}$</li>
<li>${P_2}$ 持有 ${R_1}$ 和 ${R_2}$ 等待 ${R_3}$</li>
<li>${P_3}$ 持有 ${R_3}$</li>
</ul>
</li>
</ul>
<h3 id="死锁示意图">死锁示意图</h3>
<p>资源分配图不包含循环，则不会死锁；如果有向图为环形，则为死锁，例如</p>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220417175945207.png" alt="image-20220417175945207" style="zoom:80%;" /></center>
<center>环形有向图</center>
<p>死锁示意图资源类型为：</p>
<ul>
<li>P = ${P_1,\ P_2,\ P_3}$</li>
<li>R = ${R_1,\ R_2,\ R_3,\ R_4}$</li>
<li>RE = ${P_1\ →\ R_1,\ P_2\ →\ R_3,\ P_3\ →\ R_2 }$</li>
<li>AE = ${R_1\ →\ P_2,\ R_2\ →\ P_2,\ R_2\ →\ P_1,\ R_3\ →\ P_3}$
<ul>
<li>${P_1}$ 持有 ${R_2}$ 等待 ${R_1}$</li>
<li>${P_2}$ 持有 ${R_1}$ 和 ${R_2}$ 等待 ${R_3}$</li>
<li>${P_3}$ 持有 ${R_3}$ 等待 $R_2$</li>
</ul>
</li>
</ul>
<p>这个图出现两个环形，这种情况下会发生死锁</p>
<ul>
<li>$P_1\ →\ R_1\ →\ P_2\ →\ R_3\ →\ P_3\ →\ R_2\ →\ P_1$</li>
<li>$P_2\ →\ R_3\ →\ P_3\ →\ R_2\ →\ P_2$</li>
</ul>
<h3 id="有环但无死锁">有环但无死锁</h3>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/7_03_CycleNoDeadlock.jpg" alt="img" style="zoom:1-0%;" /></center>
<center>有环但无死锁</center>
<p>有环但无死锁意图资源类型为：</p>
<ul>
<li>P = ${P_1,\ P_2,\ P_3,\ P_4}$</li>
<li>R = ${R_1,\ R_2}$</li>
<li>RE = ${P_1\ →\ R_1,\ P_3\ →\ R_2 }$</li>
<li>AE = ${R_1\ →\ P_2,\ R_1\ →\ P_3,\ R_2\ →\ P_4,\ R_2\ →\ P_1}$
<ul>
<li>${P_1}$ 持有 ${R_2}$ 等待 ${R_1}$</li>
<li>${P_2}$ 持有 ${R_1}$</li>
<li>${P_3}$ 持有 ${R_1}$ 等待 $R_2$</li>
<li>${P_4}$ 持有 ${R_2}$</li>
</ul>
</li>
</ul>
<p>此图中，$P_4$ 执行完会释放 $R_2$，$R_2$会被分配给 $P_3$，这样就跳出了循环</p>
<h3 id="结论">结论</h3>
<ul>
<li>如果图中没有循环，则无死锁</li>
<li>如果图中，一个资源仅包含一个实例，必然会发生死锁</li>
<li>如果图中，一个资源包含多个实例，则可能会发生死锁</li>
</ul>
<h2 id="死锁特性">死锁特性</h2>
<h3 id="必要条件">必要条件</h3>
<ul>
<li>实现死锁需要四个条件：
<ul>
<li><strong>Mutual Exclusion</strong>：至少一个资源必须以不可共享的方式持有；如果任何其他进程请求此资源，则该进程必须等待资源被释放。</li>
<li><strong>Hold and Wait</strong>：一个进程必须同时持有至少一个资源并等待至少一个当前被其他进程持有的资源。</li>
<li><strong>No preemption</strong>：一旦进程持有资源，则该资源不能从该进程中被抢占，直到该进程自愿释放。</li>
<li><strong>Circular Wait</strong> ：一组等待的进程 ${P_0,\ P_1,\ P_2,\ &hellip;,\ P_N}$ 必须存在每个 $P[ i ] $ 都在等待 $P[ ( i + 1 ) % ( N + 1 )]$</li>
</ul>
</li>
</ul>
<h2 id="死锁处理方法">死锁处理方法</h2>
<ul>
<li>确保系统永远不会进入死锁</li>
<li>允许系统进入死锁状态，然后恢复</li>
<li>忽略这个问题，假装系统中从来没有发生死锁，用于大多数操作系统,包括UNIX</li>
</ul>
<h3 id="死锁预防">死锁预防</h3>
<p>限制资源的申请方式</p>
<ul>
<li>
<p>互斥</p>
<ul>
<li>对于只读文件资源来说不会引起死锁</li>
<li>对于只允许单独访问的资源，需要互斥，如打印机</li>
</ul>
</li>
<li>
<p>等待：必须确保进程在访问资源时，没有持有其他资源</p>
<ul>
<li>要求对所有进程同时请求所有资源。这种情况下当一个资源被占用，导致等待很长时间，这可能会浪费系统资源。</li>
<li>只有当进程能够获得旧的资源以及它请求新的资源，进程才可以执行</li>
<li>这种情况资源利用率低，饥饿</li>
</ul>
</li>
<li>
<p>非抢占式：以下情况下可以防止死锁</p>
<ul>
<li>如果进程占有某些资源，并请求其他不能被立即分配的资源，则释放当前正占有的资源（可能资源浪费）</li>
<li>当请求资源不可用时，并本身属于阻塞；这时资源会被抢占，添加到进程等待资源列表中</li>
</ul>
</li>
<li>
<p>循环等待</p>
<ul>
<li>对所有资源进行编号排序，并要求进程仅以严格的递增（递减）顺序请求资源（常见于嵌入式操作系统）</li>
<li>如：为了请求资源 $R_j$，进程必须首先释放所有的 $R_i$，使得 $i &gt;= j$</li>
<li>挑战性：如何确定不同资源的排序</li>
</ul>
</li>
</ul>
<h2 id="避免死锁">避免死锁</h2>
<p>死锁避免，与死锁预防的区别是，死锁预防是确保可以预防死锁必要条件的其中一个；死锁避免是确保进程不会导致死锁。</p>
<p>要想防止死锁，就需要更多有关进程的信息，这样的话会导致系统资源利用率低（保守方法），根据不同的调度算法，会得到进程所需的资源的数量，还可以知道以什么顺序进行调度。</p>
<p>调取器会根据资源分配状态检测将来是否出现死锁</p>
<h3 id="安全状态">安全状态</h3>
<p>如果系统可以分配所有进程的所有资源，而不进入死锁状态，则被称为安全状态。更严格来讲，存在安全的进程序列，则状态是<strong>安全</strong>的，（${P_0,\ P_1,\ P_2,\ &hellip;,\ P_N }$）</p>
<ul>
<li>
<p>如果 $P_i$ 资源的需求不是立即可用，那么 $P_i$ 可以等到所有 $P_j$ 完成</p>
</li>
<li>
<p>当 $i&gt;j$ 时，$P_i$ 要求的资源能够由 $当前可用的资源+所有的\ P_j\ 持有的资源$ 来满足；如果 $P_i$ 完成了并释放了所有资源，那么 $P_j$ 也能够完成</p>
</li>
</ul>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/7_06_StateSpaces.jpg" alt="img" style="zoom:100%;" /></center>
<p>如图所示：如果不存在安全序列，则系统处于不安全状态，这<strong>可能</strong>会导致死锁。（所有安全状态都是无死锁的，但并非所有不安全状态都会导致死锁。）</p>
<p>例如：考虑一个具有 12 个磁带驱动器的系统，分配如下。这是一个安全的状态吗？安全顺序是什么？</p>
<table>
<thead>
<tr>
<th>Process</th>
<th>Maximum Needs</th>
<th>Current Allocation</th>
</tr>
</thead>
<tbody>
<tr>
<td>$P_0$</td>
<td>10</td>
<td>5</td>
</tr>
<tr>
<td>$P_1$</td>
<td>4</td>
<td>2</td>
</tr>
<tr>
<td>$P_2$</td>
<td>9</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>是安全的</p>
<ul>
<li>当 $t=0$ 时，$P_0$ 持有5个资源； $P_1$ 持有 2；$P_2$ 持有 2，此时是安全的；</li>
</ul>
<p>安全顺序为：</p>
<ul>
<li>$P_1$ 可以分配所有的资源；$P_1\ need = Total - Allocation = 12-9=3$，$P_1$ 需要4 ，已分配2，剩余3，可以分配给 $P_1$；当 $P_1$ 执行完成并释放，此时 $available=2+2+1 = 5$</li>
<li>$P_0$，可用5，已分配5，需要5；此时 $P_2$ 也可以执行；释放 $available=5+5=10$</li>
<li>$P_2$，可用10，已分配2，需要9；此时 $P_2$ 也可以执行；释放 $available=2+9+1=12$</li>
</ul>
<p>如果进程 P2 请求并被多分配一个磁带资源，会发生什么情况？</p>
<ul>
<li>会从安全状态变为不安全状态，$P_2$ 当前分配为3 ，此时 $P_1$ 还是可以执行，执行释放完之后，可用为4，不满足 $P_0$ 所需5 ，$P_2$ 所需的6，死锁</li>
</ul>
<h3 id="资源分配图-1">资源分配图</h3>
<p>当资源类别仅具有其资源单实例，可以通过资源分配图中循环来检测死锁。这种情况下，使用声明边缘 （<code>claim  edge</code>  根据上下文翻译的，不知道对不对），指向了在未来所需要请求的资源，用虚线表示，来避免不安全状态</p>
<ul>
<li>声明边缘 <code>claim edge</code>：未来需要请求的资源</li>
<li>请求边缘 <code>request edge</code>：请求的资源</li>
<li>进程在请求资源会从 <code>claim edge</code> 转为 <code>request edge</code></li>
<li>进程释放资源会从 <code>assignment edge</code> 转为  <code>claim edge</code></li>
</ul>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/7_07_DeadlockAvoidance.jpg" alt="img" style="zoom:100%;" /></center>
<p>此方法的工作原理是，拒绝会在资源分配图中产生循环的请求，从而使声明边缘生效</p>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/7_08_UnsafeState.jpg" alt="img" style="zoom:100%;" /></center>
<center>图：当生成的资源分配中会形成一个循环，此资源申请无法授予</center>
<blockquote>
<p>Reference</p>
<p><a href="https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/7_Deadlocks.html" target="_blank"
   rel="noopener nofollow noreferrer" >Deadlocks</a></p>
<p><a href="https://angom.myweb.cs.uwindsor.ca/teaching/cs330/ch7.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >ch7 deadlock</a></p>
</blockquote>
<h2 id="银行家算法">银行家算法</h2>
<p>银行家算法 <strong>The Banker&rsquo;s algorithm</strong>，是一种资源分配和避免死锁的算法，是通过模拟所有资源的一种”预测“最大可能需求来为进程分配资源是否 安全；这个成为 <code>safe state check</code></p>
<h3 id="为何被命名为银行家算法">为何被命名为银行家算法？</h3>
<p>银行家算法与银行使用相同的手法来检查资金是否可以批给贷款客户，假设一家银行有 <code>N</code> 个账户持有人，他们存入银行的总金额为 <code>M</code>。在分配任何贷款金额之前，银行会检查在从银行的总金额中减去贷款金额后，剩余的钱是否大于 <code>M</code>，大于 <code>M</code> 则分配这笔贷款是安全的，否则不是。</p>
<p>而银行家算法是，在一个进程启动时，必须事先声明它可能请求的最大资源分配数，最高可达系统上可用的数量；在发出请求后，调度器确定分配给该进程资源是否会使系统处于不安全状态。如果是，则该进程等待，直到分配后系统处于安全状态。</p>
<h3 id="银行家算法的数据结构">银行家算法的数据结构</h3>
<ul>
<li>
<p><code>n</code> ：进程数</p>
</li>
<li>
<p><code>m</code>：资源数</p>
</li>
<li>
<p>$Available[ m ]$：当前每种类型有多少资源可用。</p>
</li>
<li>
<p>$Max[n][m]$：每个资源的每个进程的最大需求。</p>
</li>
<li>
<p>$Allocation[n][m]$：分配给每个进程的每个资源类别的数量。</p>
</li>
<li>
<p>$Need[n][m]$：每个进程每个类型所需的剩余资源。</p>
</li>
<li>
<p>$Need[ i ][ j ] = Max[ i ][ j ] - Allocation[ i ][ j ]$</p>
</li>
</ul>
<blockquote>
<p>银行家算法需要实现知道每个进程所需的最大资源个数</p>
</blockquote>
<h3 id="银行家算法应用">银行家算法应用</h3>
<p>首先需要一个算法来确定特定状态是否安全；算法会根据以下步骤确定系统的当前状态是否安全：</p>
<ul>
<li>⑴  <code>Work</code> 和 <code>Finish</code> 分别是长度为 <code>m</code> 和 <code>n</code> 的向量。
<ul>
<li><code>Work</code> 是 <code>available</code> 的副本，将在分析期间进行修改。</li>
<li><code>finish</code> 是一个布尔值的向量，表示进程是否完成</li>
<li>初始化时，所有 $Work=Available$ ；$Finish = false$</li>
</ul>
</li>
<li>⑵  运行时，找到满足 $Finish[i] == false$；$Need[i]&lt;Work[i]$；此时可以分配，如果不存在转4</li>
<li>⑶  完成时，设置 $Work = Work + Allocation[i]$，代表释放资源回到 2</li>
<li>⑷ 如果所有的 $finish[ i ] == true$，则状态是安全的，因为已经完成并有安全序列</li>
</ul>
<p>有了具体的规范，就需要看银行家算法本身如何执行，算法确定新请求是否安全，当发出请求时，对其做满足推定（假装被授予），查看结果是否安全，安全则批准，不安全则拒绝，如：</p>
<ul>
<li>$Request[ n ][ m ]$，代表当前请求需要的资源数，如果 $Request[ i ] &gt; Need[ i ]$ 则拒绝</li>
<li>如果 $Request[ i ] &gt; Available[i]$，那么则需要等待可用。</li>
<li>方法是满足推论，会检查结构是否安全，如果是，授予；如果否，则进程等待，直到请求可以被安全授予</li>
</ul>
<p>整个过程的计算方式是：</p>
<ul>
<li>$Available = Available - Request$</li>
<li>$Allocation = Allocation + Request$</li>
<li>$Need = Need - Request$</li>
</ul>
<table>
<thead>
<tr>
<th>Processes</th>
<th>Allocation<br>A B C</th>
<th>Max<br>A B C</th>
<th>Available<br>A B C</th>
</tr>
</thead>
<tbody>
<tr>
<td>$P_0$</td>
<td>1 1 2</td>
<td>4 3 3</td>
<td>2 1 0</td>
</tr>
<tr>
<td>$P_1$</td>
<td>2 1 2</td>
<td>3 2 2</td>
<td></td>
</tr>
<tr>
<td>$P_2$</td>
<td>4 0 1</td>
<td>9 0 2</td>
<td></td>
</tr>
<tr>
<td>$P_3$</td>
<td>0 2 0</td>
<td>7 5 3</td>
<td></td>
</tr>
<tr>
<td>$P_4$</td>
<td>1 1 2</td>
<td>1 1 2</td>
<td></td>
</tr>
</tbody>
</table>
<p>计算每个进程Need，列出矩阵图</p>
<p>$Need = Max – Allocation$</p>
<table>
<thead>
<tr>
<th>Processes</th>
<th>Allocation<br>A B C</th>
<th>Max<br>A B C</th>
<th>Available<br>A B C</th>
<th>Need<br>A B C</th>
</tr>
</thead>
<tbody>
<tr>
<td>$P_0$</td>
<td>1 1 2</td>
<td>4 3 3</td>
<td>2 1 0</td>
<td>3 2 1</td>
</tr>
<tr>
<td>$P_1$</td>
<td>2 1 2</td>
<td>3 2 2</td>
<td></td>
<td>1 1 0</td>
</tr>
<tr>
<td>$P_2$</td>
<td>4 0 1</td>
<td>9 0 2</td>
<td></td>
<td>5 0 1</td>
</tr>
<tr>
<td>$P_3$</td>
<td>0 2 0</td>
<td>7 5 3</td>
<td></td>
<td>7 3 3</td>
</tr>
<tr>
<td>$P_4$</td>
<td>1 1 2</td>
<td>1 1 2</td>
<td></td>
<td>0 0 0</td>
</tr>
</tbody>
</table>
<p><strong>这个是否安全？</strong></p>
<ul>
<li>
<p>$P_0$ 需要 $(3\ 2\ 1)$，Available为 $(2\ 1\ 0)$；则 $Need &lt;=Available = False$</p>
</li>
<li>
<p>$P_1$ 需要 $(1\ 1\ 0)$，Available为 $(2\ 1\ 0)$；则 ==$Need &lt;= Available = True$==</p>
<ul>
<li>$P_1$ 可以授予，执行结束后，$Available = Available +Allocation$</li>
<li>$(2, 1, 0) + (2, 1, 2)$ = $(4, 2, 2)$</li>
</ul>
</li>
<li>
<p>$P_2$ 需要 $(5\ 0\ 1)$，Available为 $(4\ 2\ 2)$；则 $Need &lt;=Available = False$.</p>
</li>
<li>
<p>$P_3$ 需要 $(7\ 3\ 3)$，Available为 $(4\ 2\ 2)$；则 $Need &lt;=Available = False$</p>
</li>
<li>
<p>$P_4$ 需要 $(0\ 0\ 0)$，Available为 $(4\ 2\ 2)$；则 ==$Need &lt;= Available = True$==</p>
<ul>
<li>$P_1$ 可以授予，执行结束后，$Available = Available +Allocation$</li>
<li>$(4, 2, 2) + (1, 1, 2)$ = $ (5, 3, 4)$</li>
</ul>
</li>
<li>
<p>$P_2$ 需要 $(5\ 0\ 1)$，Available为 $(5\ 3\ 4)$；则 ==$Need &lt;= Available = True$==.</p>
<ul>
<li>$Available = Available +Allocation$</li>
<li>$ (5, 3, 4) + (4, 0, 1)$ = $ (9, 3, 5) $</li>
</ul>
</li>
<li>
<p>$P_3$ 需要 $(7\ 3\ 3)$，Available为 $(9\ 3\ 5)$；则 ==$Need &lt;=Available = True$==</p>
<ul>
<li>$Available = Available +Allocation$</li>
<li>$(9, 3, 5) + (0, 2, 0) = (9, 5, 5)$</li>
</ul>
</li>
<li>
<p>$P_0$ 需要 $(3\ 2\ 1)$，Available为 $(9\ 5\ 5)$；则 ==$Need &lt;=Available = True$==</p>
</li>
</ul>
<p>故序列是安全的，安全序列为 $P_1, P_4, P_2, P_3, P_0$</p>
<p><a href="https://angom.myweb.cs.uwindsor.ca/teaching/cs330/ch7.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >https://angom.myweb.cs.uwindsor.ca/teaching/cs330/ch7.pdf</a></p>
<h2 id="死锁检测">死锁检测</h2>
<p>死锁检测是指如果在不能避免死锁的情况下，检测死锁何时发生，并以某些方式恢复。</p>
<p>对死锁检测会对性能造成影响，除此以外，还必须有策略（算法）来从死锁中恢复，当进程必须被终止或抢占时，那进程工作会丢失</p>
<h3 id="每个资源类型单一实例">每个资源类型单一实例</h3>
<center><img src="../../images/ch11 deadlock/7_09_TwoGraphs.jpg" alt="img" style="zoom:80%;" /></center>
<center>(a) 资源分配图&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(b) 进程等待图</center>
<p>如图所示：等待图是资料类型的图的变种</p>
<ul>
<li>等待图中从 $P_i\ →\ P_j$ 的线表示进程 $P_i$ 正在等待进程 $P_j$ 持有的资源。</li>
<li>等待图中的循环表示死锁</li>
<li>算法必须可以做到维护一个等待图，并定期检测死锁循环</li>
</ul>
<h3 id="死锁检测算法">死锁检测算法</h3>
<p>死锁检测算法与银行家算法基本相同，但有两个差别：</p>
<ul>
<li>银行家算法步骤一中，初始将所有 $Finish[i] = false$。而改算法仅 $Allocation[ i ]  \ne 0$，才将 $Finish[ i ] = false$。如果进程分配资源为0，则 $Finish[i] = true$。
<ul>
<li>假设如果所有其他进程都可以完成，那么这个进程也可以完成。此外，算法会寻找哪些进程涉及死锁情况，没有分配任何资源的进程不能参与死锁。</li>
</ul>
</li>
<li>步骤2, 3 与银行家算法一致</li>
<li>银行家算法中，如果 $Finish[ i ] == true$ 则不存在死锁。该算法中，如果存在 $Finish[ i ] == false$ ，则检测到死锁。</li>
</ul>
<p><strong>如：有5个进程 $P_0$ ~ $P_4$；三种资源 $A=7$，$B=2$，$C=6$</strong></p>
<table>
<thead>
<tr>
<th>Processes</th>
<th>Allocation<br>A B C</th>
<th>Request<br>A B C</th>
<th>Available<br>A B C</th>
</tr>
</thead>
<tbody>
<tr>
<td>$P_0$</td>
<td>0 1 0</td>
<td>0 0 0</td>
<td>0 0 0</td>
</tr>
<tr>
<td>$P_1$</td>
<td>2 0 0</td>
<td>2 0 2</td>
<td></td>
</tr>
<tr>
<td>$P_2$</td>
<td>3 0 3</td>
<td>0 0 0</td>
<td></td>
</tr>
<tr>
<td>$P_3$</td>
<td>2 1 1</td>
<td>1 0 0</td>
<td></td>
</tr>
<tr>
<td>$P_4$</td>
<td>0 0 2</td>
<td>0 0 2</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>这个是否安全？</strong></p>
<ul>
<li>
<p>$P_0$ request  $(0\ 0\ 0)$，执行释放后</p>
<ul>
<li>
<p>$Available = Available +Allocation$</p>
</li>
<li>
<p>$(0, 0, 0) + (0, 1, 0)$ = $(0, 1, 0)$</p>
</li>
</ul>
</li>
<li>
<p>$P_2$  同 $P_0$</p>
<ul>
<li>$(0, 1, 0) + (0, 1, 0)$ = $(3, 1, 3)$</li>
</ul>
</li>
<li>
<p>$P_1$ request  $(2\ 0\ 0)$，执行释放后</p>
<ul>
<li>$(3, 1, 3) + (2, 0, 0)$ = $(5, 1, 3)$</li>
</ul>
</li>
<li>
<p>$P_3$ request  $(2\ 1\ 1)$，执行释放后</p>
<ul>
<li>$(5, 1, 3) + (2, 1, 1)$ = $(7, 2, 4)$</li>
</ul>
</li>
<li>
<p>$P_4$ request  $(0\ 0\ 2)$，执行释放后</p>
<ul>
<li>$(7, 2, 4) + (0, 0, 2)$ = $(7, 2, 6)$</li>
</ul>
</li>
</ul>
<p>估是安全的</p>
<h3 id="检测算法使用">检测算法使用</h3>
<p>何时，使用什么样的频率来检测依赖于:</p>
<ul>
<li>死锁多久可能会发生？</li>
<li>多少进程需要被回滚？ one for each disjoint cycle</li>
</ul>
<p>这取决于预期死锁发生的频率，已经发生死锁后的后果，（如果发生死锁没有立即恢复，会越来越多的进程导致死锁后得不到资源阻塞）；通常情况下，常用方法：</p>
<ul>
<li>授予的资源分配后进行死锁检测，这样做可以立即检测到死锁；缺点是由于频繁检查死锁而导致性能下降。</li>
<li>仅在可能发生死锁的边缘（进程对资源的请求的边）时才进行死锁检测，这样检查频率就会很低，缺点是无法检测到原来死锁所涉及的进程，会导致死锁复杂化，恢复过程复杂</li>
<li>保留资源分配的历史日志定期检查死锁（如计时器、CPU资源利用率低）；通过追踪日志确定何时发生死锁以及哪些进程导致了最初的死锁</li>
</ul>
<h2 id="死锁恢复">死锁恢复</h2>
<p>通常从死锁中恢复有三种方法：</p>
<ul>
<li>人工干预；终止所有的死锁进程</li>
<li>终止一个或多个死锁进程，直到死锁消除</li>
<li>抢占资源</li>
</ul>
<h3 id="进程终止">进程终止</h3>
<p>基本可以恢复死锁的方法：</p>
<ul>
<li>终止所有涉及死锁的进程</li>
<li>一个一个的终止进程，直到死锁被消除
<ul>
<li>这种情况下，很多因素都决定接下来要终止进程的顺序：</li>
<li>优先级</li>
<li>进程运行了多久，还需多久才可完成</li>
<li>进程持有多少资源和什么类型的资源。</li>
<li>进程完成还需多少资源</li>
<li>需要终止多少个进程</li>
<li>进程是交互式的还是批处理</li>
<li>进程是否对任何资源进行了不可逆的更改</li>
</ul>
</li>
</ul>
<h3 id="资源抢占">资源抢占</h3>
<ul>
<li><strong>选择受害者</strong>：选择一个进程进行资源抢占，最小成本</li>
<li><strong>回滚</strong>：返回到一些安全状态,重启进程到安全状态</li>
<li><strong>饥饿</strong>：同一进程可能一直被选作受害者，包括回滚的数量
<ul>
<li>使用优先级系统，并在每次进程资源被抢占时增加进程的优先级。最终，获得足够高的优先级，使其不再被抢占。</li>
</ul>
</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch10 信号量和监视器</title>
      <link>https://www.oomkill.com/2022/05/ch10-semaphore-and-monitors/</link>
      <pubDate>Sun, 01 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/05/ch10-semaphore-and-monitors/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="backgound">Backgound</h2>
<p>信号量 <code>semaphores</code>，是操作系统中非常重要的技术，通过使用一个简单的整数值来管理并发进程，信号量只是一个在线程之间共享的整数变量。该变量用于解决临界区问题并实现进程同步。 信号量具有两个原子操作：</p>
<ul>
<li><code>P()</code>：sem减一，如果sem&lt;0，等待；否则继续</li>
<li><code>V()</code>：sem加一，如果sem≤0，唤醒一个等待的P；</li>
</ul>
<h2 id="semaphore">Semaphore</h2>
<h3 id="信号量的使用">信号量的使用</h3>
<p>型号量的特点：</p>
<ul>
<li>
<p><strong>两个类型信号量</strong></p>
<ul>
<li>
<p><strong>二进制信号量</strong> <code>Binary Semaphore</code>：也称为互斥锁。它只能有两个值0和1。它的值被初始化为1。它用于实现多进程临界区问题的解决。</p>
</li>
<li>
<p><strong>计数信号量</strong> <code>Counting Semaphore</code>：值可以跨越一个不受限制的域（可以取任何非负数）。它用于控制对具有多个实例的资源的访问。</p>
</li>
</ul>
</li>
<li>
<p>信号量是被保护的变量</p>
<ul>
<li>
<p>初始化完成后，唯一改变一个信号量的值的办法是通过<code>P()</code> 和 <code>V()</code></p>
</li>
<li>
<p>操作必须是原子</p>
</li>
<li>
<p><code>P()</code> 能够阻塞，<code>V()</code> 不会阻塞</p>
</li>
</ul>
</li>
<li>
<p>信号量可以用在2个方面</p>
<ul>
<li>
<p>互斥</p>
</li>
<li>
<p>条件同步(调度约束  ——  一个线程等待另一个线程的事情发生)</p>
</li>
</ul>
</li>
</ul>
<h3 id="信号量实现的互斥">信号量实现的互斥</h3>
<pre><code class="language-c">mutex = new Semaphore(1);

mutex-&gt;P(); // 临界区前p
... 
    critical section
...    
mutex-&gt;V(); // 临界区后v
</code></pre>
<h4 id="信号量实现调度约束">信号量实现调度约束</h4>
<pre><code class="language-c">condition = new Semaphore(0);

// Thread A
...
condition-&gt;P(); // 等待线程B某一些指令完成之后再继续运行,在此阻塞
...

// Thread B
...
condition-&gt;V(); // 线程b执行某程度后，使用信号量增加唤醒线程A
</code></pre>
<h4 id="信号量实现有界缓冲">信号量实现有界缓冲</h4>
<p>在更复杂的同步场景下，用二进制信号量无法有效的解决问题，此时就需要计数信号量来完成这些功能；例如一个线程等待另一个线程处理事情</p>
<ul>
<li>
<p>比如生产东西或消费东西(生产者消费者模式)，互斥(锁机制)是不够的</p>
</li>
<li>
<p>有界缓冲区的生产者-消费者问题</p>
<ul>
<li>一个或者多个生产者产生数据将数据放在一个缓冲区里</li>
<li>单个消费者每次从缓冲区取出数据</li>
<li>在任何一个时间只有一个生产者或消费者可以访问该缓冲区</li>
</ul>
</li>
</ul>
<p>在这里需要注意一些问题：</p>
<ul>
<li>
<p>正确性要求</p>
<ul>
<li>
<p>在任何一个时间只能有一个线程操作缓冲区(互斥)；可多个</p>
</li>
<li>
<p>当缓冲区为空时，消费者必须等待生产者(调度，同步约束)</p>
</li>
<li>
<p>当缓存区满，生产者必须等待消费者(调度，同步约束)</p>
</li>
</ul>
</li>
<li>
<p>每个约束用一个单独的信号量</p>
<ul>
<li>一个二进制信号量，互斥</li>
<li>两个计数信号量
<ul>
<li>一般信号量 fullBuffers</li>
<li>一般信号了 emptyBuffers</li>
</ul>
</li>
</ul>
</li>
</ul>
<pre><code class="language-c">class BoundedBuffer{
		mutex = new Semaphore(1);
		fullBuffers = new Semaphore(0);   //说明缓冲区初始为空
 		emptyBuffers = new Semaphore(n);  //同时可以有n个生产者来生产
};

// 生产者
BoundedBuffer::Deposit(c){
		emptyBuffers-&gt;P(); // emptyBuff 操作 -1，当EB被阻塞时，
		mutex-&gt;P();  // 操作buffer时，是互斥操作，需要使用pv
		Add c to the buffer; // 临界区
		mutex-&gt;V();	// 操作buffer时，是互斥操作，需要使用pv
		fullBuffers-&gt;V(); // FB初始值为0，通过通知机制可以通知消费者可以开始取数据
}

// 消费者
BoundedBuffer::Withdraw(c){
    	// 消费者先执行，此时BF为0 会阻塞，等待先写后读
    	// 生产者先执行，初始FB为0，+1 此时会读取数据
		fullBuffers-&gt;P();
		mutex-&gt;P(); 	// 操作buffer时，是互斥操作，需要使用pv
		Remove c from buffer; // 临界区
		mutex-&gt;V();		// 操作buffer时，是互斥操作，需要使用pv
		emptyBuffers-&gt;V();
    	// 消费后会+1，使得EB不满，起到通知生产者继续写数据
}
</code></pre>
<h2 id="管程">管程</h2>
<p>管程是一种解决进程间同步问题的程序结构，英文是 <code>Monitors</code>；管程通过编程语言级别的支持，实现进程间的互斥。管程包含了一些列共享变量，以及针对变量的共享函数的组合，在设计上管程定义了：</p>
<ul>
<li>锁
<ul>
<li>用锁来确保在任何情况下监视器中只有一个进程。</li>
<li>对共享数据提供互斥</li>
</ul>
</li>
<li>0或者多个条件变量，用于管理对共享数据的并发访问
<ul>
<li>通过使进程进入睡眠状态的同时释放它们的锁，使线程在临界区内进入睡眠状态。</li>
</ul>
</li>
</ul>
<p>如下图所示：monitor是一种数据结构，用于将所有控制信息、时间信息和共享数据封装为一个整体。这个整体是对信号量的抽象，可以在其中定义互斥的控制语句。</p>
<ul>
<li>
<p>进入管程需要有队列（entry queue），是互斥的，首先要获得lock</p>
</li>
<li>
<p>进入临界区后，执行函数对共享变量进行操作，这是在条件变量中</p>
</li>
<li>
<p>lock</p>
<ul>
<li><code>Lock::Acquire()</code> 等待直到锁可用,然后抢占锁</li>
<li><code>Lock::Release()</code> 释放锁,唤醒等待者如果有</li>
</ul>
</li>
<li>
<p>Condition Variable</p>
<ul>
<li>允许等待状态进入临界区
<ul>
<li>允许处于等待(睡眠)的线程进入临界区</li>
<li>某个时刻原子释放锁进入睡眠</li>
</ul>
</li>
<li><code>Wait()</code> operation
<ul>
<li>暂停对任何条件变量执行等待操作的进程。挂起的进程被放置在该条件变量的块队列中。</li>
</ul>
</li>
<li><code>Signal()</code> operation(or broadcast() operation)
<ul>
<li>唤醒等待的进程，需要进程存在</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/1f9Az-JtUUhn_BrAQYag6VA.jpeg" alt="monitor" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<pre><code class="language-c">class Condition{
		int numWaiting = 0;
		WaitQueue q;
};


Condition::Wait(lock){
		numWaiting++;
		Add this thread t to q;
		release(lock);
		schedule(); // 选择下一个进程执行，选择就绪进程执行
		require(lock);
}

Condition::Signal(){
		if(numWaiting &gt; 0){
				Remove a thread t from q;
				wakeup(t); // 唤醒进程，将睡眠进程置为就绪状态
				numWaiting--;
		}
}
</code></pre>
<p>使用monitor，抽象出一个管程，并用word满足管程的锁和条件变量，word将计时器和控制信息聚合了，只有初始化时的结构才能获得锁：</p>
<ul>
<li>**Wait() **：如果定义了成员变量，则等待函数获取互斥锁</li>
<li>**Signal() **：释放获取的锁，以便其他线程可以获取它。</li>
</ul>
<pre><code class="language-go">package main

import (
	&quot;fmt&quot;
	&quot;math/rand&quot;
	&quot;strconv&quot;
	&quot;sync&quot;
	&quot;time&quot;
)

// 一个管程
type Monitor interface {
	Wait()
	Signal()
	GetData() []string // 返回整个数组，
	PutData(string)    //原子操作
}

// 管程的实现
type Words struct {
	mutex         *sync.Mutex
	wordsArray    []string
	isInitialized bool
}

func (m *Words) Wait(p int) {

	if m.isInitialized {
		fmt.Printf(&quot;process %d got a lock\n&quot;, p)
		m.mutex.Lock()
	}
	fmt.Printf(&quot;process %d not get a lock\n&quot;, p)
}
func (m *Words) Signal(p int) {
	if m.isInitialized {
		fmt.Printf(&quot;process %d release a lock\n&quot;, p)
		m.mutex.Unlock()
	}
}
func (m *Words) GetData() []string { return m.wordsArray }

func (m *Words) PutData(word string, pn int) {
	m.Wait(pn)
	fmt.Printf(&quot;start process %d \n&quot;, pn)
	// critical section
	m.wordsArray = append(m.wordsArray, word)
	time.Sleep(time.Millisecond * time.Duration(rand.Intn(800)))
	// critical section done
	fmt.Printf(&quot;process %d done.\n&quot;, pn)
	m.Signal(pn)
}

func (m *Words) Init() {
	m.mutex = &amp;sync.Mutex{}
	m.wordsArray = []string{}
	m.isInitialized = true
}

func main() {
	m := &amp;Words{}
	m.Init()
	wg := &amp;sync.WaitGroup{}
	wg.Add(10)
	for n := 0; n &lt; 10; n++ {
		go func(i int) {
			defer wg.Done()
			m.PutData(&quot;Angad&quot;+strconv.Itoa(rand.Intn(100000)), i)
		}(n)
	}
	wg.Wait()
	fmt.Println(m.GetData())
}
</code></pre>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220414184847152.png" alt="image-20220414184847152" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<blockquote>
<p>Reference</p>
<p><a href="https://pages.mtu.edu/~shene/NSF-3/e-Book/MONITOR/monitor-types.html" target="_blank"
   rel="noopener nofollow noreferrer" >monitor types</a></p>
<p><a href="https://medium.com/@angadsharma1016/process-synchronization-monitors-in-go-d31f4c42fce7" target="_blank"
   rel="noopener nofollow noreferrer" >monitor implement</a></p>
<p><a href="https://www.cs.utexas.edu/users/lorenzo/corsi/cs372h/07S/notes/Lecture12.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >https://www.cs.utexas.edu/users/lorenzo/corsi/cs372h/07S/notes/Lecture12.pdf</a></p>
<p><a href="https://medium.com/algorithm-solving/os-synchronization-2-semaphore-and-classical-problems-of-synchronization-fdbbcb027b79" target="_blank"
   rel="noopener nofollow noreferrer" >https://medium.com/algorithm-solving/os-synchronization-2-semaphore-and-classical-problems-of-synchronization-fdbbcb027b79</a></p>
</blockquote>
<h2 id="question-of-synchronize">question of synchronize</h2>
<h3 id="readers-writers问题">Readers-Writers问题</h3>
<p><code>Readers-Writers Problem</code> 是允许多个进程读临界区，多个写者修改临界区；该问题的约束:</p>
<ul>
<li>允许同一时间有多个读者，但在任何时候只有一个写者</li>
<li>没有写者时，读者才能访问数据</li>
<li>没有读者和写者时，写者才能访问数据</li>
<li>在任何时候只能有一个线程可以操作共享变量</li>
</ul>
<p>读进程</p>
<pre><code>wait(mutex); // 修改计数器，因为保证计数器互斥，需要加锁
	rc++;
	if (rc == 1)
		wait(wrt);  // 保证不会有写进入
signal(mutex);

// critical section

// critical section END
wait(mutex); // release rc 
	rc--;
	if (rc == 0) // 计数器为0则代表已经无读进程，
	signal (wrt); // 释放读写锁
signal(mutex);
</code></pre>
<p>上面代码 <code>mutex</code> 和 <code>wrt</code> 是信号量，<code>rc</code> 是读进程计数器，初始化时为0</p>
<p>写进程</p>
<pre><code>wait(wrt);
// critical section
signal(wrt);
</code></pre>
<p><strong>基于管程的实现</strong></p>
<pre><code>AR = 0; // # 活跃的读者进程
AW = 0; // # 活跃的写者进程
WR = 0; // # 等待的读者进程
WW = 0; // # 等待的写者进程

Condition okToRead;
Condition okToWrite;
Lock lock;

//writer
Public Database::Write(){
		//Wait until no readers/writers;
		StartWrite();
		write database;
		//check out - wake up waiting readers/writers;
		DoneWrite();
}

Private Database::StartWrite(){
		lock.Acquire();
		// 写优先，存在任意读 写进程都将被阻塞直到满足条件
		while((AW + AR) &gt; 0){
				WW++;
				okToWrite.wait(&amp;lock);
				WW--;		
		}
		AW++;
		lock.Release();
}

Private Database::DoneWrite(){
		lock.Acquire();
		AW--;
		if(WW &gt; 0){
				okToWrite.signal();  // signal是唤醒一个
		}
		else if(WR &gt; 0){
				okToRead.broadcast(); // broadcase是唤醒所有
		}
		lock.Release();
}

//reader
Public Database::Read(){
		//Wait until no writers;
		StartRead();
		read database;
		//check out - wake up waiting writers;
		DoneRead();
}

Private Database::StartRead(){
		lock.Acquire();
		while(AW + WW &gt; 0){    //关注等待的writer,体现出写者优先
				WR++;
				okToRead.wait(&amp;lock);
				WR--;
		}
		AR++;
		lock.Release();
}

private Database::DoneRead(){
		lock.Acquire();
		AR--;
		if(AR == 0 &amp;&amp; WW &gt; 0){  //只有读者全部没有了,才需要唤醒
				okToWrite.signal();
		}
		lock.Release();
}
</code></pre>
<p><strong>其他实现方式</strong></p>
<p>通常情况下为了保证读写问题，一般会通过互斥或信号量来实现。然而，go中提供了<strong>读写锁</strong> <code>sync.RWMutex</code> 是为了解决这个问题的一种数据结构。</p>
<pre><code class="language-go">package main

import (
	&quot;fmt&quot;
	&quot;math/rand&quot;
	&quot;sync&quot;
	&quot;time&quot;
)

var mutex = new(sync.RWMutex)
var cs = []string{}

func writer(data string) {
	mutex.Lock()
	defer mutex.Unlock()
	cs = append(cs, fmt.Sprintf(&quot;updated with %s&quot;, data))

	// Write to data.
}

func reader(data string) {

	fmt.Printf(&quot;%s start execute.\n&quot;, data)
	mutex.RLock()
	defer mutex.RUnlock()
	fmt.Println(cs)
	time.Sleep(time.Millisecond * time.Duration(rand.Intn(800)))
	// Read from data.
}

func main() {
	wg := &amp;sync.WaitGroup{}
	wg.Add(12)
	for i := 0; i &lt; 2; i++ {
		go func(i int) {
			go writer(fmt.Sprintf(&quot;writer thread %d&quot;, i))
			wg.Done()
			time.Sleep(time.Millisecond * time.Duration(rand.Intn(800)))
		}(i)
	}
	for i := 0; i &lt; 10; i++ {
		go func(i int) {
			reader(fmt.Sprintf(&quot;reader thread %d&quot;, i))
			wg.Done()
		}(i)
	}

	wg.Wait()
}
</code></pre>
<h3 id="哲学家就餐问题">哲学家就餐问题</h3>
<p>哲学家就餐问题 <code>dining philosophers problem</code>；有五位哲学家，餐厅中间是一张圆桌，但只有五根筷子，每次吃饭需要两根筷子；当哲学家饿了就会拿起离自己最近的两根筷子；如果可以同时拿起离自己最近的两根筷子吃饭，吃完饭后，放下筷子思考。</p>
<center><img src="../../images/ch10 Semaphore and Pipe/DIAGRAM-philosopher.jpg" alt="img" style="zoom:100%;" /></center>
<h4 id="如何设计">如何设计</h4>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/DIAGRAM-philosopher-cycle.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>如图所示首先，哲学家们处于的状态 思考&mdash;&mdash;拿筷子&mdash;&mdash;吃饭&mdash;&mdash;放下筷子&mdash;&mdash;思考的状态中变化。</p>
<p>吃就是对临界区的访问，而如何拿筷子才是重点问题，而筷子则是 整个问题中的 <strong>Race Condition</strong>；可以将每根筷子互斥锁保护的共享对象，而在吃饭前，对其左右筷子进行加锁，两把锁都加成功，视为可以吃饭（访问临界区），吃完饭解锁筷子，进行思考</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/DIAGRAM-philosopher-flow.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>共享数据有：</p>
<ul>
<li>Bowl of rice(data set)</li>
<li>Semaphone chopsticks [5] initialized to 1</li>
</ul>
<p>步骤：</p>
<ul>
<li><code>think()</code>:</li>
<li><code>pickUpChopsticks()</code>：</li>
<li><code>eating()</code></li>
<li><code>PutDownChopsticks()</code></li>
</ul>
<pre><code class="language-cpp">#define N 5 // 哲学家数量

void philosopher(int i) { // 哲学家编号
    while(TRUE) {
        think();					// 思考
        PickUpChopsticks(i);       // 拿起左边的筷子
        PickUpChopsticks((i+1)%N); // 拿起右边的筷子，筷子保证不大于哲学家数量
        eat();		// 吃饭
        PutDownChopsti(i);		// 放下左边的筷子
        PutDownChopsti((i+1)%N); // 放下右边的筷子
    }
}
</code></pre>
<p>这样在哪左边筷子完成时，再拿右边筷子时发现都被占用拿不到，而又不满足吃饭条件，导致死锁。为了防止死锁问题需要进一步的判断</p>
<pre><code class="language-cpp">#define N 5 // 哲学家数量

void philosopher(int i) { // 哲学家编号
    while(TRUE) {
        think();					// 思考
        PickUpChopsticks(i);       // 拿起左边的筷子
        if (chopsticks((i+1)%N)){
            PickUpChopsticks((i+1)%N); // 拿起右边的筷子，筷子保证不大于哲学家数量
            break;
        } else { 
            // 不存在则放下左边筷子，并阻塞
            PutDownChopsti(i);		// 放下左边的筷子
            wait()
        }
        
        eat();		// 吃饭
        PutDownChopsti(i);		// 放下左边的筷子
        PutDownChopsti((i+1)%N); // 放下右边的筷子
    }
}
</code></pre>
<p>互斥访问，可以解决但是同时只能一个哲学家就餐；这里将就餐看为临界区，而不是筷子，会造成筷子资源的浪费</p>
<pre><code class="language-cpp">#define N 5 // 哲学家数量

void philosopher(int i) { // 哲学家编号
    while(TRUE) {
        p(mutex)
            think();					// 思考
            PickUpChopsticks(i);       // 拿起左边的筷子
            PickUpChopsticks((i+1)%N); // 拿起右边的筷子，筷子保证不大于哲学家数量
            eat();		// 吃饭
            PutDownChopsticks(i);		// 放下左边的筷子
            PutDownChopsticks((i+1)%N); // 放下右边的筷子
        v(mutex)
    }
}
</code></pre>
<p>为了防止死锁的发生，可以设置两个条件：</p>
<ul>
<li>必须同时拿起左右两根筷子；</li>
<li>只有在两个邻居都没有进餐的情况下才允许进餐。</li>
<li>这种就诞生了一个原则：要么不拿，要么拿两个：
<ul>
<li>step1：thinking</li>
<li>step2：Hungry</li>
<li>step3：左右邻居正在就餐则等待，否则下一步</li>
<li>step4：拿起两个筷子</li>
<li>step5：eating</li>
<li>step6：方向左边筷子</li>
<li>step7：方下右边筷子</li>
<li>step8：to step1</li>
</ul>
</li>
</ul>
<pre><code class="language-cpp">#define N 5  // 哲学家数量
#define LEFT (i + N - 1) % N // 左邻居
#define RIGHT (i + 1) % N    // 右邻居
#define THINKING 0
#define HUNGRY   1
#define EATING   2
typedef int semaphore;
int state[N];                // 跟踪每个哲学家的状态
semaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥
semaphore s[N];              // 同步信号量，每个哲学家一个信号量

void philosopher(int i) {
    while(TRUE) {
        think(i);   // step1
        take_two(i); // step2~4
        eat(i);	// step5
        put_two(i); // step6~7
    }
}

void take_two(int i) {
    P(&amp;mutex);
    state[i] = HUNGRY; // 饿了
    checkChopsticks(i);  // 拿筷子
    V(&amp;mutex);
    // 离开临界区
    P(&amp;state[i]); // 
}

void put_two(i) {
    P(&amp;mutex);
    state[i] = THINKING;
    // 尝试通知左右邻居，自己吃完了，你们可以开始吃了
    checkChopsticks(LEFT); 
    checkChopsticks(RIGHT);
    V(&amp;mutex);
}

void eat(int i) {
    down(&amp;mutex);
    state[i] = EATING;
    up(&amp;mutex);
}

// 检查两个邻居是否都没有用餐，如果是的话，就 up(&amp;s[i])，使得 down(&amp;s[i]) 能够得到通知并继续执行
void checkChopsticks(i) {   
    // 第一个，当前哲学家饿了
    // 左边和右边都没有在吃饭
    if(state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] !=EATING) {
        state[i] = EATING;
        V(&amp;s[i]);
    }
}
</code></pre>
<p>具体的实现：</p>
<pre><code class="language-go">package main

import (
	&quot;log&quot;
	&quot;math/rand&quot;
	&quot;sync&quot;
	&quot;time&quot;
)

const (
	THINKING = iota
	HUNGRY
	EATING
)

type chopstick struct {
	sync.Mutex
}

type Philosopher struct {
	Id    int
	Left  *chopstick
	Right *chopstick
	State int
}

func init() {
	log.SetFlags(log.Ldate | log.Lmicroseconds | log.Lshortfile)
}

// 哲学家
var ph = []string{&quot;Mark&quot;, &quot;Russell&quot;, &quot;Rocky&quot;, &quot;Haris&quot;, &quot;Root&quot;}

// 同时可以吃饭的哲学家数量
var host = make(chan int, int(len(ph)/2))
var wg sync.WaitGroup

func (p *Philosopher) think() {
	log.Printf(&quot;Philosopher %s start thinging.\n&quot;, ph[p.Id])
	time.Sleep(time.Millisecond * time.Duration(rand.Intn(1000)))
}

func (p *Philosopher) hungry() {
	log.Printf(&quot;Philosopher %s has hungry.\n&quot;, ph[p.Id])
	time.Sleep(time.Millisecond * time.Duration(rand.Intn(500)))
}

func (p *Philosopher) pickUpChopsticks() {
	// 两个筷子被锁，则阻塞
	p.Left.Lock()
	p.Right.Lock()
	log.Printf(&quot;Philosopher %s pick up two chopsticks.\n&quot;, ph[p.Id])
}

func (p *Philosopher) eating() {
	// 有两个哲学家在吃，阻塞
	host &lt;- p.Id
	p.State = EATING
	p.pickUpChopsticks()
	log.Printf(&quot;Philosopher %s begin eating.\n&quot;, ph[p.Id])
	time.Sleep(time.Millisecond * time.Duration(rand.Intn(10000)))
	p.putDonwChopsticks()
	&lt;-host
}

func (p *Philosopher) putDonwChopsticks() {
	p.Left.Unlock()
	p.Right.Unlock()
	log.Printf(&quot;Philosopher %s put down two chopsticks.\n&quot;, ph[p.Id])
}

func (p *Philosopher) seat() {
	for n := 0; n &lt; 3; n++ {
		p.think()
		p.hungry()
		p.eating()
	}
	wg.Done()
}

func main() {
	// 创建五根筷子
	ChopSticks := make([]*chopstick, 5)
	for i := 0; i &lt; 5; i++ {
		ChopSticks[i] = new(chopstick)
	}

	// 创建五个哲学家
	philosophers := make([]*Philosopher, len(ph))

	for n := 0; n &lt; len(ph); n++ {
		philosophers[n] = &amp;Philosopher{
			Id:    n,
			Left:  ChopSticks[n],
			Right: ChopSticks[(n+1)%len(ph)],
			State: THINKING,
		}
	}
	// 哲学家就坐
	for i := 0; i &lt; 5; i++ {
		wg.Add(1)
		go philosophers[i].seat()
	}

	wg.Wait()
}
</code></pre>
<p>可以从执行结果看到，同时满足左右筷子都可以拿起的哲学家才可以进程吃</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220416192756283.png" alt="image-20220416192756283" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<blockquote>
<p>Reference</p>
<p><a href="https://medium.com/algorithm-solving/os-synchronization-2-semaphore-and-classical-problems-of-synchronization-fdbbcb027b79" target="_blank"
   rel="noopener nofollow noreferrer" >read-write problom</a></p>
<p><a href="https://pages.mtu.edu/~shene/NSF-3/e-Book/index.html" target="_blank"
   rel="noopener nofollow noreferrer" > Dining Philosophers Problem</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch8 CPU调度算法</title>
      <link>https://www.oomkill.com/2022/04/ch8-cpu-scheduling-algorithms/</link>
      <pubDate>Sat, 30 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/04/ch8-cpu-scheduling-algorithms/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="overview">Overview</h2>
<p><strong>CPU调度</strong> (<code>cpu scheduling </code>)，是决定在一个时间窗口内，哪个进程可以拥有CPU而另外一个个进程会被暂停的过程。CPU调度的作用是为了确保每当CPU空闲时，操作系统至少选择就绪队列中一个可用的进程执行。这个选择过程将由CPU调度器来执行。</p>
<p>调度程序：挑选就绪进程的内核函数</p>
<ul>
<li>调度策略：依据什么挑选进程？</li>
<li>调度时机：什么时间进行调度？
<ul>
<li>进程从运行状态切换到等待状态</li>
<li>进程退出</li>
<li>非抢占式：当前进程主从放弃CPU时，</li>
<li>抢占式：当前进程被抢占
<ul>
<li>时间片用完</li>
<li>进程从等待切换到就绪（当前就绪进程优先级高于当前运行进程）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="调度准则">调度准则</h2>
<h3 id="cpu的调度策略">CPU的调度策略</h3>
<h4 id="抢占式调度">抢占式调度</h4>
<p>抢占式调度（<code>Preemptive</code>）在分配进程时有对应的优先级。而在另一个较低优先级进程之前运行具有较高优先级的进程很重要，即使较低优先级的进程仍在运行。较低优先级的进程扔会等待一段时间，让较高优先级的进程完成执行后恢复。</p>
<p>抢占式调度主要发生在运行状态切换到就绪或等待状态</p>
<h4 id="非抢占式调度">非抢占式调度</h4>
<p>非抢占式调度 （<code>Non-Preemptive</code>），在这种类型的调度中，一旦将资源（CPU 周期）分配给一个进程，该进程就会持有CPU使用权，直到它被终止或达到等待状态。</p>
<p>抢占式调度主要发生在运行状态终止的情况下</p>
<h4 id="如何确定调度是抢占式还是非抢占式">如何确定调度是抢占式还是非抢占式？</h4>
<p>一般来讲，确定调度的方式是通过以下四点来确定的：</p>
<ul>
<li>当进程从运行状态切换到等待状态；如I/O请求或调用 wait() 系统调用</li>
<li>当进程从运行状态切换到就绪状态；如响应中断。</li>
<li>当进程从等待状态切换到就绪状态；如在 I/O 完成或从 wait() 返回时。</li>
<li>进程完成执行并终止；</li>
</ul>
<p>如果调度发生在1 4情况下，则为非抢占式，否则为抢占式</p>
<h3 id="程序执行模型">程序执行模型</h3>
<p>需要关注的是进程在计算机系统中运行时存在什么状态？</p>
<p>几乎所有进程都在一个连续的循环的两种模型之间交替：即<strong>CPU突发</strong>和<strong>I/O突发</strong>中交替</p>
<ul>
<li>每个调度决定都是关于在下一个CPU突发时将哪个工作交给CPU</li>
<li>在时间分片机制下，线程可能在结束当前CPU突发前被迫放弃CPU</li>
</ul>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/6_01_CPU_BurstCycle.jpg" alt="img" style="zoom:80%;" /></center>
<center>CPU突发和 I/O突发的交替序列逻辑</center>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/6_02_CPU_Histogram.jpg" alt="img" style="zoom:80%;" /></center>
<center>CPU 突发型的持续时间</center>
<h3 id="调度指标">调度指标</h3>
<p>在了解评价指标前，需要对CPU调度中的一些术语需要了解</p>
<ul>
<li><strong>CPU突发</strong> （<code>Burst Time</code> BT）：进程开始执行的时间，从到达到开始执行花费的时间</li>
<li><strong>到达时间</strong> （<code>Arrival Time</code> AT）：进程到达就绪队列的时间</li>
<li><strong>完成时间</strong>（<code>End Time</code> ET 或 <code>Completion Time</code> CT）：进程执行完成的时间</li>
<li><strong>等待时间</strong> （<code>Waiting Time</code> WT）：进程在就绪队列中等待轮到 CPU 占用的时间；$WT = TT - BT$</li>
<li><strong>周转时间</strong> （<code>Turnaround Time</code> TT）：完成时间和到达时间的差  $TT=CT-AT$</li>
<li><strong>相应时间</strong>（<code>Response Time</code> RT）：开始响应请求所需的时间。第一次请求到相应的时间。</li>
<li><strong>吞吐量</strong> (<code>Throughput</code>)：单位时间内完成的进程数。$Throughput = (Number\ of\ processes\  completed) \div (Time\ unit)$</li>
</ul>
<p>一般情况下，需要的服务”越快“越好，而快的定义：</p>
<ul>
<li>传输文件的高带宽（相应时间）</li>
<li>玩游戏的低延迟（吞吐量）</li>
<li>上述两个因素是互相独立的</li>
</ul>
<p>需要对低延迟和高带宽做一个平衡</p>
<h3 id="比较算法的准则">比较算法的准则</h3>
<ul>
<li>相应时间目标：通过低延迟的调度改善用户的交互体验
<ul>
<li>减少相应的时间：及时处理用户的输出并且尽快将输出提供给用户</li>
<li>减少平均相应时间的波动：在交互式系统中，可预测性比高差异低平均更重要</li>
<li>相应时间是操作系统的计算延迟</li>
</ul>
</li>
<li>吞吐量目标：操作系统应该保证吞吐量不受用户交互的影响
<ul>
<li>增加吞吐量，增加系统吞吐量大概可以从两个角度来提出
<ul>
<li>减少开销（上下文切换）</li>
<li>系统资源的高效利用（CPU，I/O）</li>
</ul>
</li>
<li>减少等待时间</li>
<li>吞吐量是操作系统的计算带宽</li>
</ul>
</li>
</ul>
<h3 id="公平的目标">公平的目标</h3>
<p>在整个操作系统进程管理中的调度挑战在于如何使整个系统尽可能地“高效”与“公平”（<code>efficient</code>&quot; and <code>fair</code>），这受制于不断变化且通常是在动态的条件下，而“高效”和“公平”在某种程度上是主观的，经常会受到不断变化的抢先策略而被影响。</p>
<p>而公平的定义是可以让每个进程等待相同的时间，如：</p>
<ul>
<li>保证每个进程占用相同CPU的时间</li>
<li>如果一个用户比其他用户运行更多的进程的情况下该如何处理？</li>
</ul>
<p>而保证公平带来的则通常会增加平均的相应时间</p>
<h2 id="调度算法">调度算法</h2>
<h3 id="基本调度算法">基本调度算法</h3>
<h4 id="先到先服务">先到先服务</h4>
<p>先来先服务 (<code>First Come First Serve</code> FCFS)，是最简单的调度算法，FCFS是根据进程的到达时间进行调度；即表示，先请求 CPU 的进程先分配CPU。它是通过使用<code>FIFO</code>  队列来实现的。当一个进程进入就绪队列时，该进程的 PCB 会被放置到队列的尾部。当CPU空闲时，会将队列头部。然后从队列中删除正在运行的进程。FCFS 是一种非抢占式调度算法。</p>
<p>实例：假设有三个进程按以下顺序到达：P<sub>1</sub> , P<sub>2</sub>, P<sub>3</sub>；CPU突发时间为 24 3 3</p>
<table>
<thead>
<tr>
<th>Process</th>
<th>Burst Time</th>
</tr>
</thead>
<tbody>
<tr>
<td>P1</td>
<td>24</td>
</tr>
<tr>
<td>P2</td>
<td>3</td>
</tr>
<tr>
<td>P3</td>
<td>3</td>
</tr>
</tbody>
</table>
<p>那么对应的甘特图是：</p>
<img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img//image-20220406190723836.png" alt="image-20220406190723836" style="zoom:80%;" />
那么衡量指标的信息如：
<ul>
<li>等待时间WT为：P1=0；P2=24；P3=27</li>
<li>平均相应AT时间为:  $(0 + 24 + 27)\div3 = 17$</li>
</ul>
<p>这里存在一个问题，如果第一个进程执行时间过长，会导致后面所有的进程等待时间过长，这样会拖长整个队列的平均相应时间。这种现象被称为<strong>护航效应</strong> （<code>Convoy Effect</code>）。</p>
<p>护航效应，在调度算法中当CPU密集型（<code>CPU-bound</code>）进程在 I/O密集型（<code> I/O-bound</code>）进程之前到达系统时，即使 I/O密集型进程需要较少的CPU时间，此时CPU密集型进程也会根据FCFS的策略而获得CPU时间。</p>
<center><img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/convoy-effect-0-1640667641.jpg" alt="img" style="zoom:80%;" /></center>
<center>护航效应类比图</center>
<p>为了更有效的避免护航效应，可以使用抢占式的调度算法，如RR；抢占式调度算法可以使每个进程都有相同的机会使用CPU。而这些较小的进程占用很短的CPU时间，而不必等待很长的CPU时间，从而加快执行速度并减少闲置资源。</p>
<p>例如假设执行顺序按照：P<sub>2</sub> , P<sub>3</sub>, P<sub>1</sub>，那么整个的执行队列如下图</p>
<img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img//image-20220406192925398.png" alt="image-20220406192925398" style="zoom:80%;" />
<p>此时平局等待时间WT为： P<sub>1</sub> = 6;P<sub>2</sub> = 0; P<sub>3</sub> = 3</p>
<p>平均等待时间为：$(6 + 0 + 3)\div3 = 3$</p>
<p>缺点:</p>
<ul>
<li>平均等待时间波动较大</li>
<li>花费时间少的任务可能排在花费时间长的任务后面</li>
<li>可能导致IO和CPU之间的重叠处理(CPU密集型进程会导致IO设备闲置时，IO密集型进程也在等待)</li>
</ul>
<h4 id="最短作业优先">最短作业优先</h4>
<p>最短作业优先 （<code>Shortest Job First</code> SJF），是一种非抢占式的调度算法，SJF会首先调度具有最短CPU Brust的进程。如果两个进程具有相同的BT，则使用FCFS来打破平局。其特点为：</p>
<ul>
<li>对每个进程关联其下一个CPU Brust的大小，使用这些长度来排序以最短会被优先调度</li>
<li>SJF最大的优势是，给定一组进程的最短平均等待时间 AT</li>
<li>SJF难度在于如何知道下一个 CPU请求的长度</li>
</ul>
<p>如：假设有三个进程按以下顺序到达：P<sub>1</sub> , P<sub>2</sub>, P<sub>3</sub>，P<sub>4</sub>；CPU突发时间为 6 8 7 3，将其排好序后如图</p>
<table>
<thead>
<tr>
<th>Process</th>
<th>Burst Time</th>
</tr>
</thead>
<tbody>
<tr>
<td>P1</td>
<td>6</td>
</tr>
<tr>
<td>P2</td>
<td>8</td>
</tr>
<tr>
<td>P3</td>
<td>7</td>
</tr>
<tr>
<td>P4</td>
<td>3</td>
</tr>
</tbody>
</table>
<pre><code class="language-mermaid">gantt
    dateFormat  YYYY-MM-DD
    axisFormat  %S
    title       SJF scheduling chart
   
    P4            :p1, 2014-01-01, 3s
    P1            :p2, after p1, 6s
    P3            :p3, after p2, 7s
    P2            :p4, after p3, 8s
</code></pre>
<p>此时平均相应时间为 $(P_{1}+P_2+P_3+P_4)\div4$ = $(3 + 16 + 9 + 0) \div 4 = 7$ 。</p>
<p>此时如果将某一个进程的顺序作为调整，如：P<sub>4</sub> 调整到 P<sub>3</sub>之后，会减少对应的平均相应时间吗？对应的gantt如下：</p>
<pre><code class="language-mermaid">gantt
    dateFormat  YYYY-MM-DD
    axisFormat  %S
    title       SJF scheduling chart
   
    P1            :p1, 2014-01-01, 6s
    P3            :p2, after p1, 7s
    P4            :p3, after p2, 3s
    P2            :p4, after p3, 8s
</code></pre>
<p>此时平均相应时间为 ：（P<sub>i</sub> 为进程的运行时间，R<sub>i</sub> 为进程的TT）</p>
<ul>
<li>$((P_1-R_4)+(P_3-R_4)+2(P_1+P_3-2\times P_4)+P_2)\div4$</li>
<li>$((6-3)+(7-3)+2(6+7 - 2\times3)+8) \div 4 = 7.25$</li>
</ul>
<p><strong>SJF存在的问题</strong>：</p>
<ul>
<li>
<p>饥饿 ；饥饿（<code>starvation</code>）又被称为无限阻塞（<code>indefinite blocking</code>）,</p>
<ul>
<li>连续的短任务流会使场任务饥饿</li>
<li>短任务可用时的任何长任务的CPU时间都会增加增加整个队列的平均等待时间</li>
</ul>
</li>
<li>
<p>需要预知进程的执行时间</p>
<ul>
<li>怎么预估下一个CPU突发的持续时间
<ul>
<li>简单的解决：询问用户</li>
</ul>
</li>
<li>如果用户欺骗就杀死进程</li>
<li>如果不知道怎么办?</li>
</ul>
</li>
</ul>
<p><strong>如何确定下一个进程的CPU Brust</strong></p>
<p>只能通过预估的方式确定进程的执行长度，可以通过使用历史的CPU Brust的长度，使用其平均指数来预估，这里就有几个参数：</p>
<ul>
<li>$t_n$：第N点的CPU Brust的实际值</li>
<li>$\tau_{n}$：第N点的CPU Brust的预估值，。</li>
<li>$\alpha$：是一个因子，控制整个历史相对的权重，$0 \leq \alpha \leq 1$，通常情况下 $\alpha$ 设置为 ${1 \over 2}$
<ul>
<li>$\alpha = 0$，则 $\tau^{n+1} = \tau^n$，初始预估值永远没有变化</li>
<li>$\alpha = 1$，则 $\tau^{n+1} = \tau^n$，初始预估值始终根据第几个进程的实际值的变化而变化</li>
<li>当$\alpha = {1 \over 2}$，则历史和最近的权重相同</li>
</ul>
</li>
<li><strong>Τ0</strong>：是一个常数或整个系统的平均值。</li>
</ul>
<p>得到一个公式：</p>
<ul>
<li>
<p>$\tau_{n} = \alpha t_n+(1-\alpha)\tau_{n}$</p>
</li>
<li>
<p>$\tau_{n+1} = \alpha t_n+(1-\alpha)\tau_{n-1} + (1-\alpha)^2\tau_{n-2}&hellip;.(1-\alpha)^j\tau_{n+1}$</p>
</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img//image-20220406235249748.png" alt="image-20220406235249748" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<blockquote>
<p><strong>实例题：$\tau_1=10$，$\alpha=5$，之前执行的队列为8,7,4,16，接下来预估值是多少？</strong></p>
<p>A. 9		B. 8		C. 7.5		D. None</p>
<p>解析：因为是SJF算法，及历史执行的序列为 [4, 7, 8, 16]，并且已知 $\tau_1=10$ $t_1=4$ $\alpha=0.5$</p>
<p>$\tau_2 =  \alpha \times t_{n-1} +(1-\alpha)\tau_{n-1}$ = $0.5\times4+0.5\times 10=7$ 	 因为$t_1=4$，$\tau_1=10$</p>
<p>$\tau_3 =  \alpha \times t_{n-1} +(1-\alpha)\tau_{n-1}$ = $0.5\times7+0.5\times 7=7$		因为$t_2=7$，$\tau_2=7$</p>
<p>$\tau_4 =  \alpha \times t_{n-1} +(1-\alpha)\tau_{n-1}$ = $0.5\times 8+0.5\times 7=7.5$	因为$t_3=8$，$\tau_3=7$</p>
</blockquote>
<blockquote>
<p>Reference</p>
<p><a href="http://www.cs.cornell.edu/courses/cs4410/2017sp/schedule/slides/08.scheduling.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >handout scheduling</a></p>
<p><a href="https://testbook.com/objective-questions/mcq-on-shortest-job-first--5eea6a1539140f30f369f363" target="_blank"
   rel="noopener nofollow noreferrer" >SJF Quiz</a></p>
</blockquote>
<h4 id="最高响应比优先">最高响应比优先</h4>
<p><strong>HRRN</strong>（Highest Response Ratio Next）调度算法是操作系统中的一种非抢占式调度算法。HRRN是对<strong>SJF</strong>的改进版，从而减少饥饿问题。</p>
<p>HRRN的特点：</p>
<ul>
<li>非抢占式</li>
<li>对进程增加了关注点：进程等待了多长时间</li>
<li>防止饥饿问题（无限期延后）</li>
</ul>
<p>$RR  = (W+S)\div S$</p>
<p><strong>RR</strong>：响应比，<strong>Response Ratio</strong></p>
<p><strong>W</strong>：表示等待时间。</p>
<p><strong>S</strong>：表示服务的时间，即Burst Time或执行时间。</p>
<p>HRRN是综合考虑了执行时间和等待时间，如：假设有三个进程按以下顺序到达：P<sub>1</sub> , P<sub>2</sub>, P<sub>3</sub>，P<sub>4</sub>；CPU突发时间为 6 8 7 3，将其排好序后如图</p>
<table>
<thead>
<tr>
<th>Process</th>
<th>Burst Time</th>
<th>Arrival Time</th>
</tr>
</thead>
<tbody>
<tr>
<td>P1</td>
<td>3</td>
<td>1</td>
</tr>
<tr>
<td>P2</td>
<td>6</td>
<td>3</td>
</tr>
<tr>
<td>P3</td>
<td>8</td>
<td>5</td>
</tr>
<tr>
<td>P4</td>
<td>4</td>
<td>7</td>
</tr>
<tr>
<td>P5</td>
<td>5</td>
<td>8</td>
</tr>
</tbody>
</table>
<ul>
<li>time=0 时，就绪队列为空，0 到 1 为是 CPU 空闲时间。</li>
<li>在 time=1 时，就绪队列仅有P1。因此，进程 P1 一直执行直到完成。</li>
<li>在进程P1之后，在 time=4 时只有进程 P2 到达，故进程 P2 被执行。</li>
<li>在 time=10 时，进程 P3、P4 和 P5 已全达到就绪队列中。故P2之后，需要计算响应率。</li>
<li>P<sub>3</sub> $RR=(10-5+8)/8 = 1.625$</li>
<li>P<sub>4</sub> $RR=(10-7+4)/4 = 1.75$</li>
<li>P<sub>5</sub> $RR=(10-8+5)/5 = 1.4$</li>
</ul>
<p>此时P<sub>4</sub>响应率最高，故P<sub>4</sub>先执行，执行后需要计算P<sub>3</sub>和P<sub>5</sub>的顺序：</p>
<ul>
<li>P<sub>3</sub> $RR=(14-5+8)/8 = 2.125$</li>
<li>P<sub>5</sub> $RR=(14-8+5)/5 = 2.2$</li>
</ul>
<p>此时整个队列中的执行周转时间和等待时间如下表：</p>
<ul>
<li>$TT=ET-AT$</li>
<li>$WT=TT-BT$</li>
</ul>
<table>
<thead>
<tr>
<th>Process</th>
<th>AT</th>
<th>BT</th>
<th>ET</th>
<th>TT</th>
<th>WT</th>
</tr>
</thead>
<tbody>
<tr>
<td>P1</td>
<td>1</td>
<td>3</td>
<td>4</td>
<td>3</td>
<td>0</td>
</tr>
<tr>
<td>P2</td>
<td>3</td>
<td>6</td>
<td>10</td>
<td>7</td>
<td>1</td>
</tr>
<tr>
<td>P3</td>
<td>5</td>
<td>8</td>
<td>27</td>
<td>22</td>
<td>14</td>
</tr>
<tr>
<td>P4</td>
<td>7</td>
<td>4</td>
<td>14</td>
<td>7</td>
<td>3</td>
</tr>
<tr>
<td>P5</td>
<td>8</td>
<td>5</td>
<td>19</td>
<td>11</td>
<td>6</td>
</tr>
</tbody>
</table>
<p>这个队列的执行甘特图就如下：</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img//image-20220408185457559.png" alt="image-20220408185457559" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>平均等待时间：$AWT=(0+1+14+3+6)\div5 = 24\div5=4.8$</p>
<h5 id="hrrn的特点">HRRN的特点</h5>
<p><strong>优点</strong>：</p>
<ul>
<li>HRRN教SJF有更好的性能。</li>
<li>HRRN可以减少较长进程的等待时间，同时也鼓励较短的作业。</li>
<li>增加了吞吐量，避免了饥饿现象</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>HRRN处于理想状态，因为无法提前预知每个进程的BT。</li>
<li>HRRN会增加CPU的开销。</li>
</ul>
<h4 id="轮训">轮训</h4>
<p>轮训调度算法<code>Round-Robin</code> RR，是最简单的调度算法，即每个进程获得相同的CPU时间量子（<code>quantum</code>）并轮流执行</p>
<p>如：假设有三个进程按以下顺序到达：P<sub>1</sub> , P<sub>2</sub>, P<sub>3</sub>，P<sub>4</sub>；CPU突发时间为 53  8 68 24，时间片为20</p>
<table>
<thead>
<tr>
<th>Process</th>
<th>BT</th>
</tr>
</thead>
<tbody>
<tr>
<td>P1</td>
<td>53</td>
</tr>
<tr>
<td>P2</td>
<td>8</td>
</tr>
<tr>
<td>P3</td>
<td>68</td>
</tr>
<tr>
<td>P4</td>
<td>24</td>
</tr>
</tbody>
</table>
<p>这四个进程轮流占用CPU，那么执行的甘特图如下：</p>
<pre><code class="language-mermaid">gantt
    dateFormat  YYYY-MM-DD
    axisFormat  %j
    title       RR Gantt chart
    P1 [0,20]            :active,p1, 2020-01-01, 20d
    P2 [20,8]            :active,p2, after p1, 8d
    P3 [28,48]           :active,p3, after p2, 20d
    P4 [48,68]           :active,p4, after p3, 20d
    P1 [68,88]			 :active,p5, after p4, 20d
    P3 [88,108]		  	 :active,p6, after p5, 20d
    P4 [108,112]	     :active,p7, after p6, 4d
    P1 [112,125]		 :active,p8, after p7, 13d
    P3 [125,145]		 :active,p9, after p8, 20d
    P3 [145,153]		 :active,p10, after p9, 8d
    idel [153,]	  		 :done, p11, after p10, 10d
</code></pre>
<p>等待时间 WT：</p>
<ul>
<li>$P_1 = (68-20)+(112-88)=72$</li>
<li>$P_2=20-0=20$</li>
<li>$P_3=(28-0)+(88-48)+(125-108)=85$</li>
<li>$P_4=(48-0)+(108-68)=88$</li>
</ul>
<p>平均等待时间 AWT：</p>
<ul>
<li>$AWT=(72+20+85+88)\div4=66.25$</li>
</ul>
<h5 id="性能">性能</h5>
<ul>
<li>q 较大时，类似于FIFO</li>
<li>q较小时，上下文切换此时很多，所以q需要设置的较大些</li>
<li>通常情况下，平均周转率要优于SJF，也不会出现饥饿状态</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img//image-20220409171756385.png" alt="image-20220409171756385" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h5 id="rr的特点">RR的特点</h5>
<p><strong>优点</strong>：</p>
<ul>
<li>避免了饥饿或护航现象</li>
<li>所有进程获得量子都是公平的</li>
<li>没有优先级</li>
<li>不依赖Brust time</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>花费更多的时间在上下文切换上</li>
<li>性能取决于量子的大小</li>
<li>不能设置优先级</li>
<li>如何设置一个平均大小的量子非常困难</li>
</ul>
<h4 id="多级反馈队列">多级反馈队列</h4>
<p>多级反馈队列（<code>Multilevel Feedback Queue</code>）是指，当进程进入系统时被永久分配给相应队列。进程不会在队列之间移动。</p>
<ul>
<li>
<p>就绪队列被划分为不同的队列：</p>
<ul>
<li>
<p>前台（交互式 <code>interactive</code>）</p>
</li>
<li>
<p>后台（批处理 <code>batch</code>）</p>
</li>
</ul>
</li>
<li>
<p>每个队列是对应的调度算法：</p>
<ul>
<li>前台 – RR</li>
<li>后台 - FCFS</li>
</ul>
</li>
<li>
<p>调度必须在队列之间进行：</p>
<ul>
<li>固定的调度优先级：如：先前台，再后台</li>
<li>会存在饥饿现象</li>
</ul>
</li>
<li>
<p>时间分片：</p>
<ul>
<li>每个队列获得一定的时间分片，并在进程间调度</li>
<li>如 RR - 80%前台，FCFS - 20%后台</li>
</ul>
</li>
</ul>
<p>多级反馈队列通过历史来预测未来，克服了SJF的预测问题；如果进程过去是I/O密集型的，那么未来也可能发生I/O密集型。通过利用这种行为，调度器可以选择使用最少CPU的进程进行调度。</p>
<ul>
<li>拥有不同优先级的队列，如RR
<ul>
<li>一次结束后，将在下一个高优先级的队列进行作业</li>
<li>循环的时间片随着优先级的降低而增长</li>
</ul>
</li>
</ul>
<p><strong>优先级的调整</strong>：</p>
<ul>
<li>进程开始在最高优先级队列中执行</li>
<li>当时间片结束，降低优先级</li>
<li>当时间片没结束（发生CPU上下文切换是I/O事件）则提高优先级，直到最高优先级队列</li>
<li>CPU密集型的优先级下降，I/O密集型的优先级上升</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img//1606975413-71449.png" alt="多级反馈队列调度" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="公平共享调度">公平共享调度</h4>
<p>公平共享调度 <code>Fair-share scheduling</code>，是将处理器的时间平均分配给用户，在用户级别公平分享CPU；如有5个用户同时执行一个进程，调度器会将同等份额的 CPU 周期，分配给每个用户，即每个用户20%</p>
<ul>
<li>一些用户组比其他用户组更重要</li>
<li>保证不重要的组无法垄断资源</li>
<li>未使用的资源按照每个组所分配的资源的比例来分配</li>
<li>没有达到资源使用率目标的组获得更高的优先级</li>
</ul>
<h3 id="实时调度">实时调度</h3>
<p>实时操作系统 <strong>RTS</strong>，正确性依赖于其时间和功能两方面的一个操作系统；RTS调度算法主要目标是关注满足任务期限，而不是对任务吞吐量、延迟和响应时间等指标。</p>
<p>举个例子：喂养不同种类的动物，如马和奶牛。</p>
<ul>
<li>马，每20分钟喂养一次，一次需要10分钟</li>
<li>奶牛，每50分钟喂养一次，每次25分钟</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img//image-20220409193117791.png" alt="image-20220409193117791" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<ul>
<li>如果使用rr，第一次喂马10分钟，第二次喂牛25分钟，第三次喂马，此时喂养时间不够，马死了</li>
<li>使用固定时间片喂养的话，喂马10分钟，喂牛10分钟，牛喂养时间不足，牛死了</li>
<li>EDF：截止日期最早优先
<ul>
<li>喂马10分钟</li>
<li>喂牛10分钟</li>
<li>到达第三次，需要又需要喂马，10分钟</li>
<li>第四次，喂牛15分钟，此时时间为45，满足牛和马的喂养时间，使用EDF，可以保障到牛和马都不会死</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img//image-20220409194038911.png" alt="image-20220409194038911" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<ul>
<li>性能指标：
<ul>
<li>时间约束的及时性 <strong>deadline</strong></li>
<li>速度和平均性能相对不重要</li>
</ul>
</li>
<li>主要特征：时间约束的可预测性</li>
</ul>
<h4 id="rts分类">RTS分类:</h4>
<ul>
<li>硬实时系统 <strong>Hard RTS</strong>：需要在保证时间内完成重要的任务；必须完成，错过最后期限deadline，将对整个系统产生灾难性的故障。</li>
<li>软实时系统 <strong>Soft RTS</strong>: 要求重要的进程的优先级更高，尽量完成，并非必须</li>
</ul>
<h4 id="rts相关时间参数">RTS相关时间参数</h4>
<ul>
<li>$a_j$ ：<strong>Arrival Time</strong>，工作准备好执行的时间。</li>
<li>$C_j$：<strong>Computation (execution) time</strong>，任务在处理器不中断的情况下执行所需要的时间</li>
<li>$d_j$：<strong>Absolute deadline</strong>，绝对截止时间，工作应该完成的时间</li>
<li>$D_j$：<strong>Relative deadline</strong>，到达时间和绝对截止时间之间的长度</li>
<li>$S_j$：<strong>Start Time</strong>，进程开始执行的时间</li>
<li>$f_j$：<strong>Finishing Time</strong>，进程完成执行的时间</li>
<li>$R_j$：<strong>Response time</strong>，作业到达后执行时间的长度，$R_j=f_j-a_j$</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220409194849293.png" alt="image-20220409194849293" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="实时系统要求">实时系统要求</h4>
<ul>
<li>决定任务执行的顺序</li>
<li>静态优先级调度</li>
<li>动态优先级调度</li>
</ul>
<h3 id="edf">EDF</h3>
<p><strong>Earliest Deadline First (EDF)</strong>，截止日期最早优先，EDF使用进程的优先级进行调度。它根据绝对终止期限为进程分配优先级。截止日期最近的任务获得最高优先级。</p>
<p>有五个进程，如表：</p>
<table>
<thead>
<tr>
<th>Process</th>
<th>$a_j$</th>
<th>$C_j$</th>
<th>$d_j$</th>
</tr>
</thead>
<tbody>
<tr>
<td>J1</td>
<td>0</td>
<td>5</td>
<td>6</td>
</tr>
<tr>
<td>J2</td>
<td>2</td>
<td>2</td>
<td>8</td>
</tr>
<tr>
<td>J3</td>
<td>8</td>
<td>6</td>
<td>20</td>
</tr>
<tr>
<td>J4</td>
<td>10</td>
<td>3</td>
<td>14</td>
</tr>
<tr>
<td>J5</td>
<td>15</td>
<td>4</td>
<td>22</td>
</tr>
</tbody>
</table>
<p>那么其执行甘特图如下</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220409202939904.png" alt="image-20220409202939904" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><strong>EDF特点</strong>：</p>
<ul>
<li>最佳的动态优先级调度算法</li>
<li>deadline越早优先级越高</li>
<li>先执行deadline最早的任务</li>
</ul>
<h4 id="rm">RM</h4>
<p>速率单调 <code>Rate-Monotonic</code> 算法是指，周期较小的任务具有较高的优先级。（$C_i, T_i, D_i$）</p>
<p>$T_i$ ：周期任务</p>
<ul>
<li>t1 = (1, 6, 6),</li>
<li>t2 =  (2, 8, 8),</li>
<li>t3 = (4, 12, 12)</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220409202922051.png" alt="image-20220409202922051" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><strong>RM特点</strong>：</p>
<ul>
<li>提前进行优先级排序</li>
<li>适合静态优先调度</li>
<li>周期越短，优先级越高</li>
<li>先执行周期最短的任务</li>
</ul>
<blockquote>
<p>Reference</p>
<p><a href="https://cps.cse.uconn.edu/wp-content/uploads/sites/2687/2019/10/ch6.2.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >Real-Time Scheduling</a></p>
</blockquote>
<h2 id="多处理器调度">多处理器调度</h2>
<p>多处理器调度，即存在<strong>多个 CPU</strong>可用，然而，与单处理器调度相比，多处理器调度更<strong>复杂。</strong></p>
<h3 id="多处理器调度方法">多处理器调度方法</h3>
<ul>
<li>非对称多处理，<strong>Asymmetric multiprocessing</strong> AMP
<ul>
<li>一个系统只允许一个CPU执行代码，如一个处理器处理用户代码，其他处理器处理I/O</li>
</ul>
</li>
<li>对称多处理，<strong>Symmetrical Multi-Processing</strong> SMP，
<ul>
<li>每个处理器是自调度的，即单独的就绪队列或者公共就绪队列，通过调度器分配要执行的程序</li>
</ul>
</li>
</ul>
<h3 id="亲和度">亲和度</h3>
<p>亲和度 <strong>Affinity</strong> 是指，进程在一个处理器上运行时，当发生转移时，需要释放对应的缓存，在新处理器上在加载，此时增加了系统的相应速度，通常情况下，SMP会视图避免进程从一个处理器迁移至另一个处理器上。</p>
<ul>
<li>软亲和度，<strong>Soft Affinity</strong>，是调度器尽可能长时间地将进程保持在同一个 CPU 上。这只是一种尝试；如果不可行，则将进程迁移到另一个处理器</li>
<li>硬亲和度，<strong>hard affinity</strong>，硬亲和度是利用系统调用 (<code>system call</code>)，强行将进程绑定到指定的CPU上</li>
</ul>
<h3 id="负载均衡">负载均衡</h3>
<p>负载均衡是为了使多个CPU尽可能均衡的处理任务，即出现在SMP的现象，负载均衡可以保持所有处理器之间的工作负载平衡，以充分利用多个处理器的；否则就出现一个或多个处理器将处于空闲状态，而其他处理器具有高工作负载状态。</p>
<p><strong>负载均衡的通用方法</strong>：</p>
<ul>
<li>推送迁移：是指操作系统定期检查每个处理器上的负载。如果存在不平衡，一些进程将从一个处理器移动到另一个处理器。</li>
<li>拉取迁移：调度器发现一个处理器的运行队列中没有更多进程时。会从繁忙的处理器中拉出等待的任务</li>
</ul>
<blockquote>
<p>Reference</p>
<p><a href="http://boron.physics.metu.edu.tr/ozdogan/OperatingSystems/ceng328/node130.html" target="_blank"
   rel="noopener nofollow noreferrer" >Load Balancing</a></p>
<p><a href="https://www.how-hard-can-it.be/cpu-affinity-introduction/" target="_blank"
   rel="noopener nofollow noreferrer" >cpu affinity</a></p>
<p><a href="https://www.geeksforgeeks.org/multiple-processor-scheduling-in-operating-system/" target="_blank"
   rel="noopener nofollow noreferrer" >multiple-processor-scheduling</a></p>
<p><a href="https://quick-adviser.com/what-are-the-types-of-process-affinity/#What_is_the_difference_between_soft_affinity_and_hard_affinity" target="_blank"
   rel="noopener nofollow noreferrer" >what are the types of process affinity</a></p>
</blockquote>
<h2 id="优先级反转">优先级反转</h2>
<p>由于低优先级任务的干扰而导致的任务执行延迟称为优先级反转 <strong>priority inversion</strong>，优先级反转是1997年火星拓荒者着陆的一个问题。</p>
<p>如图所示：高优先级任务与低优先级任务共享资源时。当低优先级任务锁定资源时，高优先级任务必须等待，即使高优先级任务有资格运行。</p>
<img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/1606.jpg" alt="点击展开" style="zoom:130%;" />
<p>如图所示，LP任务使用对共享资源加锁，t2时间HP发生抢占，此时因为LP没有对锁释放，HP处于阻塞状态，而MP发生抢占直到t5结束，此时CPU回到LP任务，直到t6结束，释放锁，此时HP才开始执行，即使HP处于高优先级也不会被执行。</p>
<img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/1607.jpg" alt="点击展开" style="zoom:130%;" />
<p>解决的方法：</p>
<ul>
<li>优先级继承 <strong>Priority Inheritance</strong>
<ul>
<li>低优先级任务持有高优先级请求的资源，则低优先级任务将提高到与高优先级任务相同的优先级
<ul>
<li>
<img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/1608.jpg" alt="点击展开" style="zoom:120%;" />
</li>
<li><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/1609.jpg" alt="点击展开" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></li>
<li>如图所示：具有不同优先级的三个任务共享一个资源。LP首先在时间 t1 获取资源。在t2，MP抢占 LP到 t3，当MP它需要资源时。MP被阻止。此时，LP 提升优先级同MP并恢复执行。HP在 t4抢占 LP 任务。当 HP 访问共享资源时，在 t5 被阻止。此时LP 从 HP 继承其优先级并恢复执行。一旦 LP 完成，它的优先级立即降低到最初分配的级别。</li>
</ul>
</li>
</ul>
</li>
<li>优先级天花板 <strong>Priority ceiling</strong>
<ul>
<li>优先级天花板中，每个任务的优先级都是已知的。每个任务所需的资源在执行之前也是已知的。任何时候正在运行的任务的当前优先级上限是当时正在使用的所有资源的最高优先级上限。</li>
<li><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/1610.jpg" alt="点击展开" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></li>
</ul>
</li>
</ul>
<blockquote>
<p>Reference</p>
<p><a href="http://www.embeddedlinux.org.cn/rtconforembsys/5107final/LiB0101.html" target="_blank"
   rel="noopener nofollow noreferrer" > Priority Inversion</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch9 同步</title>
      <link>https://www.oomkill.com/2022/04/ch9-synchronization/</link>
      <pubDate>Sat, 30 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/04/ch9-synchronization/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="background">Background</h2>
<p>多进程作为现代操作系统的重要特性，交互则会引起同时对共享资源的访问，当这些资源访问不正确会出现冲突或产生不适当的输出（冲突、死锁、饥饿）；而在同步的基础上，进程被分为以下两种类型：</p>
<ul>
<li>独立进程 <strong>Independent Process</strong>
<ul>
<li>不和其他进程共享资源或状态</li>
<li>确定性，输入状态确定结果</li>
<li>可重现，能够重现起始条件，I/O</li>
<li>调度的顺序不重要</li>
</ul>
</li>
<li>协作进程 <strong>Cooperative Process</strong>；
<ul>
<li>多进程共享资源或状态</li>
<li>不确定性 <code>probabilistic</code></li>
<li>不可重现</li>
</ul>
</li>
</ul>
<p>不确定性和不可重现意味着bug可能是间歇性发生的</p>
<h3 id="cooperation">Cooperation</h3>
<p>进程的互相影响，即进程间的合作（相互或破坏）；最简单的例子就是两个进程使用同一个文件，一个进程读，一个进程写。读进程的结果会被写进程所影响。</p>
<p>进程需要合作的原因：</p>
<ul>
<li>资源共享：多个进程访问相同的数据
<ul>
<li>一台电脑，多个用户</li>
<li>一个银行存款余额,多台ATM机</li>
<li>嵌入式系统（机器人手臂和收的协调）</li>
</ul>
</li>
<li>计算加速：
<ul>
<li>I/O 和 CPU计算可重叠</li>
<li>多处理器 - 将任务分解为子任务并分布在不同的进程中，它通常可以更快地运行（也需要多个可共享的 CPU）</li>
</ul>
</li>
<li>模块化：复杂的任务组织成单独的子任务，让不同的进程运行
<ul>
<li>大程序分成小程序</li>
<li>是系统易于扩展</li>
</ul>
</li>
</ul>
<p>程序可以调用函数fork()来创建一个新的进程</p>
<ul>
<li>操作系统需要分配一个新的并且唯一的进程ID</li>
<li>因此在内核中,这个系统调用会运行 <code>new_pid = next_pid++</code>;</li>
<li>翻译成机器指令:
<ul>
<li><code>Load next_pid Reg1</code></li>
<li><code>STORE Reg1 new_pid</code></li>
<li><code>INC Reg1</code></li>
<li><code>STORE Reg1 next_pid</code></li>
</ul>
</li>
</ul>
<p>假设两个进程并发执行</p>
<ul>
<li>如果next_pid等于100, 那么其中一个进程得到的ID应该是100, 另一个进程的ID应该是101, next_pid应该增加到102</li>
<li>可能在INC前进行了上下文切换, 最终导致两个进程的pid都是100,而next_pid也是101</li>
</ul>
<p>无论多个线程的指令序列怎样交替执行,程序都必须正常工作</p>
<ul>
<li>多线程程序具有不确定性和不可重现的特点</li>
<li>不经过专门设计,调试难度很高</li>
</ul>
<p>不确定性要求并行程序的正确性</p>
<ul>
<li>先思考清楚问题，把程序的行为设计清楚</li>
<li>切忌给予着手编写代码，碰到问题再调试</li>
</ul>
<h2 id="race-condition">Race Condition</h2>
<p><strong>竞态条件</strong>是由操作系统软件中的同步错误。出现在进程试图同时执行两个或多个操作时，这是一种不希望出现的情况。</p>
<p>怎么样避免竞态?</p>
<p>Atomic Operator(原子操作)</p>
<p>原子操作是指一次不存在任何终端或者失败的执行</p>
<ul>
<li>该执行成功结束</li>
<li>或者根本没有执行</li>
<li>并且不应发生任何部分执行的状态</li>
</ul>
<p>假设设计一个程序，A和B两个进程互相竞争，一个进程使counter+1，另外一个进程使counter-1</p>
<pre><code class="language-c">while (true) {
    /* produce an item in next produced */
    while (counter == BUFFER_SIZE) ;
    /* do nothing */
    buffer[in] = next_produced;
    in = (in + 1) % BUFFER_SIZE;
    counter++;
} 
</code></pre>
<pre><code class="language-c">while (true) {
    while (counter == 0)
    ; /* do nothing */
    next_consumed = buffer[out];
    out = (out + 1) % BUFFER_SIZE;
    counter--;
    /* consume the item in next consumed */
} 
</code></pre>
<p>P1和P2指令的执行顺序不同，产生的结果也不同。可能存在P1执行完或P2先执行完，也可能永远执行不完</p>
<ul>
<li>临界区：程序中试图访问共享资源并可能导致竞态条件的区域称为临界区 <code>Critical Section</code></li>
<li>互斥 <strong>Mutual Exclusion</strong>：如果一个进程在临界区并访问共享资源，则不允许临界区有其他进程处于临界区并访问共享资源。</li>
<li>死锁 <strong>Deadlock</strong>：两个或两个以上进程，互相等待完成特定任务，而最终没法将自身任务进行下去</li>
<li>有界等待 <strong>Bounded Waiting</strong>：在一个进程发出进入其临界区的请求后，在该进程的请求被批准之前，有多少个进程可以进入临界区是有限制的。因此，达到限制后，必须有授予权限的进程才能进入其临界区。此条件的目的是确保每个进程都有机会进入其临界区，从而没有进程永远饥饿。</li>
<li>饥饿 <strong>Starvation</strong>：一个可执行的进程，长期被调度器忽略，以至于虽然处于可执行状态却不被执行。</li>
<li>无忙等待</li>
</ul>
<h3 id="忙等待">忙等待</h3>
<p><code>busy-waiting</code>：忙等待是指，进程在继续执行之前等待并不断的检查要满足的条件，例如说循环、锁；一般情况下忙等待分为两种</p>
<ul>
<li>消耗处理器的同时不断检查要满足的条件</li>
<li>不消耗处理器，当满足条件时，会被唤醒</li>
</ul>
<p>在一些操作系统中，忙等待很低效，循环会浪费CPU资源。但通常情况下，解决忙等待的方法就是延迟；例如</p>
<pre><code>while z is still in use do
	sleep(900)
end
</code></pre>
<p>另外一种方式就是信号量的阻塞进程，即处于忙碌等待状态的进程被阻塞并放置在不消耗资源的等待队列中。一旦满足条件，该过程将重新启动并放置在就绪队列中。</p>
<blockquote>
<p>Reference
<a href="https://cps.cse.uconn.edu/wp-content/uploads/sites/2687/2019/10/ch5.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >synchronization</a></p>
<p><a href="https://www.gatevidyalay.com/process-synchronization-race-condition-in-os/" target="_blank"
   rel="noopener nofollow noreferrer" >race condition</a></p>
<p><a href="https://www.baeldung.com/cs/os-busy-waiting" target="_blank"
   rel="noopener nofollow noreferrer" >busy waiting</a></p>
</blockquote>
<h2 id="禁用硬件中断">禁用硬件中断</h2>
<p>如何保障临界区操作是原子的，只要不发生上下文切换，那么操作就是原子的，即禁用硬件中断 <code>disable interupt instruction</code> DI instruction</p>
<ol>
<li>进入临界区禁用中断</li>
<li>操作临界区代码</li>
<li>离开临界区启用中断</li>
</ol>
<pre><code>class Lock { int value = FREE; }

Lock::Acquire() {
    Disable interrupts; # 禁用中断
    while (value != FREE) { # 等待锁
        Enable interrupts;  
        Disable interrupts;
    }
    value = BUSY; 
    Enable interrupts; 
}

Lock::Release() {
    Disable interrupts;
    value = FREE; # 解锁
    Enable interrupts; # 启用中断
}
</code></pre>
<p><strong>缺点</strong>：</p>
<ul>
<li>
<p>一旦中断被禁用，线程就无法被停止</p>
<ul>
<li>整个系统都会为你停下来</li>
<li>可能导致其他线程处于饥饿状态</li>
</ul>
</li>
<li>
<p>要是临界区可以任意长怎么办？</p>
<ul>
<li>无法限制响应中断所需的时间(可能存在硬件影响)</li>
</ul>
</li>
<li>
<p>要小心使用，适合于较小的操作</p>
</li>
</ul>
<h2 id="软件解决方案">软件解决方案</h2>
<p>屏蔽硬件中断简单有效，但受制于临界区执行时间，影响整个系统的效率。</p>
<h3 id="peterson">Peterson</h3>
<p>一个满足两个进程进程P<sub>i</sub> 和 P<sub>j</sub> 之间互斥的经典的基于软件的解决方法(1981年)，Peterson算法；Peterson 算法是基于双进程的互斥访问，需要两个锁：</p>
<ul>
<li>一个使用  flag，是一个布尔数组</li>
<li>另外一个使用 turn 的int锁</li>
</ul>
<p>而这两个锁都有可能出现死锁的情况：如</p>
<pre><code>int turn = 0
turn = j
do {
	while( turn != i);
	
    Critical Section
    turn = j;
    remainder section	
} while(1)
</code></pre>
<p>另外一个进程</p>
<pre><code>int turn = 0
turn = i
do {
	while( turn != j);
	
    Critical Section
    turn = i;
    remainder section	
} while(1)
</code></pre>
<p>满足了互斥，没满足progress（想进入临界区的进程），最终只有一个进程可以进入，无法进行流转。</p>
<p>Peterson 算法基于两个锁的临界区问题的解决方案：</p>
<ul>
<li>一个使用  flag，是一个布尔数组；<code>boolean flag[i]</code> 初始化为false，即没有进程有兴趣进入临界区</li>
<li>另外一个使用 turn 的int锁；进入临界区的进程</li>
</ul>
<pre><code class="language-c">int trun;
boolean flag[];
do{
    flag[i] = true; // 此时i想进入临界区
    turn  = j  // 但是当前是i
    while(flag[j] &amp;&amp; turn  ==j);
    	critical section
    flag[i] = false;
    	remander section
} while(true);
</code></pre>
<p>Peterson 算法可以解决上述单锁的问题：</p>
<ul>
<li>互斥是有保证：任何时候仅有一个进程可以访问临界区</li>
<li>进程有保证：不会阻止临界区外其他进程进入临界区</li>
</ul>
<p>Peterson 算法的缺点：</p>
<ul>
<li>忙等待</li>
<li>仅限于两个进程</li>
</ul>
<h3 id="dekker">Dekker</h3>
<p>Dekker是另外一种临界区解决方法，Dekker从第五版才完整满足了所有的条件；dekker算法类似于Peterson 算法；下面是算法的实现：</p>
<pre><code class="language-go">package main

import (
	&quot;fmt&quot;
	&quot;math/rand&quot;
	&quot;time&quot;
)

var thread1wantstoenter = false // 进程是否在执行
var thread2wantstoenter = false // 进程是否在执行
var favouredthread int // 进入临界区的进程
var cs = 0

func main() {

	go thread1()
	go thread2()

	time.Sleep(time.Second * 20)

}
func thread1() {
	fmt.Printf(&quot;thread %d Start execute\n&quot;, 1)
	for {
		fmt.Printf(&quot;get a lock, %d \n&quot;, cs)
		thread1wantstoenter = true
		for thread2wantstoenter == true {
			fmt.Printf(&quot;1 get a lock, thread %d also executing.\n&quot;, 2)
			if favouredthread == 2 {
				fmt.Printf(&quot;current cs thread is %d also executing.\n&quot;, favouredthread)
				thread1wantstoenter = false
				for favouredthread == 2 {
					// 忙等待，一直等到当前临界区进程不为对方
				}
				thread1wantstoenter = true
			}
		}
		fmt.Printf(&quot;not get lock, begin update cs1.\n&quot;)
		cs = 1
		time.Sleep(time.Millisecond * time.Duration(rand.Intn(1000)))
		favouredthread = 2
		thread1wantstoenter = false

		fmt.Printf(&quot;thread %d has completed\n&quot;, favouredthread)
		fmt.Printf(&quot;cs value with update %d \n&quot;, cs)
	}
}

func thread2() {
	fmt.Printf(&quot;thread %d Start execute\n&quot;, 2)
	for {
		fmt.Printf(&quot;get a lock, %d \n&quot;, cs)
		thread2wantstoenter = true
		for thread1wantstoenter == true {
			fmt.Printf(&quot;2 get a lock, thread %d also executing.\n&quot;, 1)
			if favouredthread == 1 {
				fmt.Printf(&quot;current cs thread is %d also executing.\n&quot;, favouredthread)
				thread2wantstoenter = false

				for favouredthread == 1 {
					// 忙等待，一直等到当前临界区进程不为对方
				}
				thread2wantstoenter = true
			}
		}
		fmt.Printf(&quot;not get lock, begin update cs2.\n&quot;)
		cs = 2

		favouredthread = 1
		time.Sleep(time.Millisecond * time.Duration(rand.Intn(1000)))
		// 退出，标记着线程2已完成，
		thread2wantstoenter = false
		fmt.Printf(&quot;thread %d has completed\n&quot;, favouredthread)
		fmt.Printf(&quot;cs value with update %d \n&quot;, cs)
	}
}
</code></pre>
<p>整个for部分是一个锁，如果其他进程没有占用临界区，则可以进入临界区；这样第一个 for保证了<strong>互斥</strong>，在两个进程都没有被标记时，至少有一个进程可以进入，这样保证了<strong>progess</strong>。</p>
<p>再假设，<strong>thread1</strong>永远卡在<code>thread2wantstoenter == true</code>；最终thread2会退出<code>favouredthread = 1</code>；这样的话不存在死锁，最终会脱离循环，脱离后会将自己设置为true <code>thread1wantstoenter = true</code>；这样的话，只要对方（<strong>thread2</strong>）为false了，即结束临界区访问；那么下一次循环将退出锁部分，并且可已访问临界区</p>
<p>如果不对 <code>favouredthread == counterpart</code> 进行判断，那么就会出现饥饿现象。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220412232216377.png" alt="image-20220412232216377" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<blockquote>
<p>Reference</p>
<p><a href="https://www.tutorialspoint.com/dekker-s-algorithm-in-operating-system" target="_blank"
   rel="noopener nofollow noreferrer" >dekker algorithm</a></p>
<p><a href="https://en.wikipedia.org/wiki/Dekker%27s_algorithm" target="_blank"
   rel="noopener nofollow noreferrer" >wikipedia</a></p>
</blockquote>
<h3 id="bakery">bakery</h3>
<p>bakery算法是针对N个进程互斥提出的解决方法之一；</p>
<ul>
<li>每当有进程进入临界区时，会被分配一个数</li>
<li>拥有最小数的进程会被选入临界区；</li>
<li>如果进程P<sub>i</sub> 和 P<sub>j</sub> 被分配相同的数，并且 $i&lt;j$，那么进程P<sub>i</sub> 首先进入临界区，进程编号 i j不会重复
<ul>
<li>定义操作符号 &lt;
<ul>
<li>判断 $(a,b) &lt; (c,d)$；当 $a&lt;c$即 $(a,b)&lt;(c,d)$; 如果 $a=c$，那么则判断b和d</li>
<li>定义操作函数 <code>max()</code></li>
<li>$max(a_0,\ &hellip;,\ a_{n-1})$，是整个序列 $(a_0,\ &hellip;,\ a_{n-1})$ 中的一个数 <code>k</code>，使 $k &gt; a_i$；</li>
<li><code>for i=0,... n-1</code></li>
</ul>
</li>
<li>定义共享数据
<ul>
<li><code>boolean choosing[n]</code></li>
<li><code>int number[n]</code></li>
<li>初始值分别为false和0</li>
</ul>
</li>
</ul>
</li>
<li>数的分配以递增顺序产生 1 2 3 4 5&hellip;.</li>
</ul>
<p>需要满足的条件，当一个线程想要进入临界区时，它必须确保它具有最小的数字，但是还需：</p>
<ul>
<li>线程状态不为真，即已经完成选号，在进程数组中，并且状态为false</li>
<li>如果线程编号相同，那么最小id的可以进入，即 id和index比谁小 id是当前的id，index是列表中其他的线程</li>
</ul>
<pre><code class="language-go">package main

import (
	&quot;fmt&quot;
	&quot;math&quot;
	&quot;math/rand&quot;
	&quot;time&quot;
)

var choosing []bool
var number []int
var cs int

func thread(id int) {
	var maximum int
	time.Sleep(time.Millisecond * time.Duration(rand.Intn(500)))

	// 19-25 线程i开始选择号码，为maximum+1
	choosing[id] = true
	maximum = 0
	for i := range number {
		maximum = int(math.Max(float64(maximum), float64(i)))
	}
	number[id] = maximum + 1
	choosing[id] = false

	for i := range number {
		if i != id {
			// 此时进程j进入临界区但没有选号完成则i进行忙等待等待选号完成
			for choosing[id] {
				// 忙等待
				fmt.Printf(&quot;thread %d busy-waiting 1. \n&quot;, id)
			}
			// 当一个线程想要进入临界区时，必须确保它具有最小的数字（优先级最高）
			// 当前线程 必须为最小，即number[id] &gt; number[i]需要忙等待
			// 如果线程获得相同编号 ，id低的可以抢先 即 (number[id] == number[i] &amp;&amp; id &gt; i) 需要阻塞
			for number[i] != 0 &amp;&amp; (number[id] &gt; number[i] || (number[id] == number[i] &amp;&amp; id &gt; i)) {
				// 忙等待
				fmt.Printf(&quot;thread %d busy-waiting 2.\n&quot;, id)
			}
		}
	}
    // 即所有的id全部等于0就是没有其他进程抢占。就可以进入临界区
	// 临界区
	fmt.Printf(&quot;critical section used by thread %d \n&quot;, id)
	cs = id
	fmt.Printf(&quot;critical section has been modified to %d \n&quot;, cs)
	// 退出临界区
	time.Sleep(time.Millisecond * time.Duration(rand.Intn(100)))
	number[id] = 0

}

func main() {
	number = make([]int, 6)
	choosing = make([]bool, 6)
	for n := 1; n &lt;= 5; n++ {
		number[n] = n
		choosing[n] = false
		go thread(n)
	}

	time.Sleep(time.Second * 5)
}
</code></pre>
<p>python的实现</p>
<pre><code class="language-python">import threading
import random
import time

class BakeryAlgorithm():
    #  declaration and initial values of global variables

    # ticket for threads in line, n - number of threads
    tickets = [0,1,2,3,4]

    # True when thread entering in line
    entering = [False]*5
    def lock(self,*args):
        self.entering[args[0]] = True
        maximum = 0
        for ticket in self.tickets:
            maximum = max(maximum, ticket)
        self.tickets[args[0]] = maximum+1
        self.entering[args[0]] = False
        for i in range(len(self.tickets)):
            if i != args[0]:
                # Wait until thread j receives its number:
                while self.entering[i]:
                    print(&quot;waiting %d&quot; % (args[0]))

                # Wait until all threads with smaller numbers or with the samenumber, but with higher priority, finish their work:
                while self.tickets[i] != 0 and (self.tickets[args[0]] &gt; self.tickets[i] or (self.tickets[args[0]]==self.tickets[i] and args[0])&gt;i):
                    print(&quot;waiting %d 2&quot; % (args[0]))

        # The critical section goes here...
        print(f&quot;critical section used by process{args[0]}&quot;)

        #exit section
        self.tickets[args[0]] = 0
    
    def main(self):
        # Running all the 5 processes using thread module and  passing process index as args since Thread supports args and kwargs argument only
        t1 = threading.Thread(target = self.lock, args = (0,)) 
        t2 = threading.Thread(target = self.lock, args = (1,)) 
        t3 = threading.Thread(target = self.lock, args = (2,)) 
        t4 = threading.Thread(target = self.lock, args = (3,)) 
        t5 = threading.Thread(target = self.lock, args = (4,)) 
        t1.start()
        t2.start()
        t3.start()
        t4.start()
        t5.start()

if __name__ == &quot;__main__&quot;:
    b = BakeryAlgorithm()
    b.main()
</code></pre>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220413171749388.png" alt="image-20220413171749388" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<ul>
<li>互斥：有没有可能2个以上进程同时进临界区
<ul>
<li>最小的id才可进入临界区</li>
<li>如果多个id拿到同样最小号，那么他们的进程id也不一样，进程id最小的可以进入临界区</li>
<li>上述保证了互斥</li>
</ul>
</li>
<li>有界等待：等待的进程不超过$n-1$；可以保证每个进程都能进入临界区</li>
<li>progress：想进入临界区的进程，不想进入的number=0也会被驱逐</li>
</ul>
<blockquote>
<p>Reference</p>
<p><a href="https://cppsecrets.com/users/120612197115104981111171149751485164103109971051084699111109/Python-Implementation-of-Bakery-Algorithm.php" target="_blank"
   rel="noopener nofollow noreferrer" >Python Implementation of Bakery Algorithm</a></p>
<p><a href="https://www.geeksforgeeks.org/bakery-algorithm-in-process-synchronization/" target="_blank"
   rel="noopener nofollow noreferrer" >bakery algorithm</a></p>
</blockquote>
<h2 id="更高级抽象">更高级抽象</h2>
<p>硬件提供了一些原语</p>
<ul>
<li>像中断禁用, 原子操作指令等</li>
<li>大多数现代体系结构都这样</li>
</ul>
<p>操作系统提供更高级的编程抽象来简化并行编程</p>
<ul>
<li>例如，锁，信号量</li>
<li>从硬件原语中构建</li>
</ul>
<p>锁是一个抽象的数据结构</p>
<ul>
<li>一个二进制状态(锁定,解锁),两种方法</li>
<li><code>Lock::Acquire()</code> 锁被释放前一直等待,然后得到锁</li>
<li><code>Lock::Release()</code> 锁释放,唤醒任何等待的进程</li>
</ul>
<p>使用锁来编写临界区</p>
<ul>
<li>
<p>前面的例子变得简单起来:</p>
<pre><code>lock_next_pid-&gt;Acquire();
new_pid = next_pid++;
lock_next_pid-&gt;Release();
</code></pre>
</li>
</ul>
<p>大多数现代体系结构都提供特殊的原子操作指令</p>
<ul>
<li>通过特殊的内存访问电路</li>
<li>针对单处理器和多处理器</li>
</ul>
<p>Test-and-Set 测试和置位</p>
<ul>
<li>从内存中读取值</li>
<li>测试该值是否为1(然后返回真或假)</li>
<li>内存值设置为1</li>
</ul>
<p>交换</p>
<ul>
<li>交换内存中的两个值</li>
</ul>
<pre><code>bool TestandSet(bool *target){
		bool rv = *target;
		*target = true;
		return rv;
}

void Exchange(bool *a, bool *b){
		bool tmp = *a;
		*a = *b;
		*b = tmp;
}
</code></pre>
<ul>
<li>
<p>总结</p>
<p>锁是更高等级的编程抽象</p>
<ul>
<li>互斥可以使用锁来实现</li>
<li>通常需要一定等级的硬件支持</li>
</ul>
<p>常用的三种实现方法</p>
<ul>
<li>禁用中断(仅限于单处理器)</li>
<li>软件方法(复杂)</li>
<li>原子操作指令(单处理器或多处理器均可)</li>
</ul>
<p>可选的实现内容:</p>
<ul>
<li>有忙等待</li>
<li>无忙等待</li>
</ul>
</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch7 进程管理</title>
      <link>https://www.oomkill.com/2022/04/ch7-process-management/</link>
      <pubDate>Fri, 29 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/04/ch7-process-management/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="overview">Overview</h2>
<ul>
<li>进程的描述</li>
<li>进程的状态 State</li>
<li>线程 Thread</li>
<li>进程间通信 Inter-Process Communication</li>
<li>进程互斥与同步</li>
<li>死锁 DeadLock</li>
</ul>
<h2 id="进程的描述">进程的描述</h2>
<p>在操作系统中，通常来说进程 <code>Process</code> 是当前正在执行的东西。因此，一个具有一定独立功能的程序在一个数据集合上的一次动态执行过程，可以称之为进程。</p>
<ul>
<li>
<p>程序是静态的文件</p>
</li>
<li>
<p>进程是程序动态执行的过程</p>
</li>
</ul>
<h3 id="进程的组成">进程的组成</h3>
<p>进程包括 :</p>
<ul>
<li>程序的代码</li>
<li>程序处理的数据</li>
<li>程序计数器 (PC) 中的值, 指示下一条将运行的指令</li>
<li>一组通用的寄存器的当前值, 堆 <code>Heap</code> , 栈 <code>Stack</code></li>
<li>一组系统资源(如打开的文件、内存、网络)</li>
</ul>
<p>而进程的主要构成如下，</p>
<ol>
<li>Stack Section</li>
<li>Heap Section</li>
<li>Data Section</li>
<li>Text Section</li>
</ol>
<img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220323215907450.png" alt="image-20220323215907450" style="zoom: 67%;" />
<h4 id="stack">Stack</h4>
<p>Stack部分包含：</p>
<ul>
<li>局部变量</li>
<li>函数和返回地址</li>
<li>main函数</li>
</ul>
<p>如上图所示，<code>Stack</code>和 <code>heap</code> 以相反的方向增长，如果两者都以相同的方向增长，那么其两者可能会重叠，因此如果它们以相反的方向增长则很好。</p>
<p>示例：如，调用下列函数时，将存储在Stack部分，一旦函数返回，该函数堆栈部分的值将被删除。</p>
<p>Stack上有一个堆栈帧，其中包含main函数以及局部变量<code>a, b sum</code> 。使用 <code>printf()</code>，创建的帧以及局部变量只能在内存中访问，帧的持续时间在从函数 <code>return 0</code>  后释放。</p>
<pre><code class="language-c">int main(void) {
    int a, b, sum;
    a = 2;
    b = 3;
    sum = a + b;
    printf(&quot;%d\n&quot;, sum);
    return 0
}
</code></pre>
<p>Stack是一种后进先出 (LIFO) 数据结构，最后一个被推到Stack上的内容就是从顶部弹出的第一个内容。不允许从Stack的中间插入或移除。因此Stack必须至少支持两种操作：<code>push </code> 和  <code>pop</code> ；其他操作也是可以，但不是必需的。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/stack2.gif" alt="stack2" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>在Linux中，<code>ulimit -a</code> 是可以获取和设置用户限制的函数</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220323223534060.png" alt="image-20220323223534060" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="heap">Heap</h4>
<p>当程序在运行时需要内存时，此部分用于提供动态内存。它是从Heap提供的。</p>
<p>如在C语言中，<code>malloc()</code>和<code>calloc()</code>用于此目的，例如：</p>
<ul>
<li><code>malloc(4)</code> 将<strong>返回Heap区域中 4 BYTE 块的起始地址</strong>。</li>
<li><code>alloca()</code>：从Stack申请内存，因此无需释放.</li>
</ul>
<blockquote>
<p>需要注意的是，在 C 语言中，动态内存需要处理，即在不需要时释放，否则一段时间后堆会变满。</p>
<p>因此，在 C 程序中使用了<code>free()</code>函数来执行此操作。</p>
</blockquote>
<p>相比于Stack，Heap更为灵活，在Heap中，程序可以在的任何位置分配或释放内存。这种情况下就意味着Heap中间可能有一个“hole”，即未分配的内存被分配的内存包围着</p>
<p>由图可以看出 ，当程序释放或释放两个相邻的内存块时，Heap区域会将其合并成一个大块。这样做可以让heap更好地满足未来对大块内存的需求。交叉阴影（彩色块大小的两倍）块说明了对大块内存的请求。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/heap-animation.gif" alt="heap-Demonstration" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="data">data</h4>
<p>data部分包含全局变量和静态局部变量。例如：</p>
<pre><code class="language-c">#include&lt;stdio.h&gt;
int glbal _var ; // 全局变量将存储到data区
int main()
{
	static int var ;  // 静态变量存储到data区
	// code statement
	return 0;
}
</code></pre>
<p>在保存全局变量和静态变量的内存通常在程序启动时分配。</p>
<h4 id="text">text</h4>
<p>text部分包含可执行指令、常量和宏，它是只读位置并且是可共享的，因此也可以被其他进程使用。</p>
<p>通常情况下，Text区域是可共享的，因此对于频繁执行的程序，只需要在内存中保存一个副本。此外，文本段通常是只读的，以防止程序意外修改其指令。</p>
<blockquote>
<p>Reference</p>
<p><a href="https://www.includehelp.com/operating-systems/memory-layout-of-a-process.aspx" target="_blank"
   rel="noopener nofollow noreferrer" > layout of a process</a></p>
<p><a href="https://icarus.cs.weber.edu/~dab/cs1410/textbook/4.Pointers/memory.html" target="_blank"
   rel="noopener nofollow noreferrer" >memory</a></p>
<p><a href="https://nickolasteixeira.medium.com/stack-vs-heap-whats-the-difference-and-why-should-i-care-5abc78da1a88" target="_blank"
   rel="noopener nofollow noreferrer" >stack vs heap</a></p>
</blockquote>
<h3 id="程序和进程的关系">程序和进程的关系</h3>
<p>进程和程序之间的联系</p>
<ul>
<li>程序是产生进程的基础</li>
<li>程序的每次运行构成不同的进程</li>
<li>进程是程序功能的体现</li>
<li>通过多次执行，一个程序可以对应多个进程，通过调用关系，一个进程可包括多个程序。</li>
</ul>
<p>进程和程序的区别 :</p>
<ul>
<li>进程是动态的，程序是静态的：程序是有序代码的集合。进程是程序的执行，进程有核心态/用户态.</li>
<li>进程是暂时的，程序是永久的：进程是一个状态变化的过程，程序可以长久保存。</li>
<li>进程和程序的组成不同：进程的组成包括程序，数据和进程控制块(进程状态信息)</li>
</ul>
<h3 id="进程的特点">进程的特点</h3>
<ul>
<li><strong>动态性</strong> : 可动态地创建，结果进程;</li>
<li><strong>并发性</strong>：进程可以被独立调度并占用处理机运行；(并发:一段, 并行:一时刻)</li>
<li><strong>独立性</strong>：不同进程的工作不相互影响；(页表是保障措施之一)</li>
<li><strong>制约性</strong> ：因访问共享数据, 资源或进程间同步而产生制约。</li>
</ul>
<h3 id="进程控制结构">进程控制结构</h3>
<h4 id="进程控制块">进程控制块</h4>
<p>在操作系统中会同时运行多个进程。每个进程都有一些数据和执行指令。这些指令可以是代码执行或在进程执行期间将用于交互的设备列表（如打印机）。因此，需要一种可以存储进程的每个进程运行时的信息的数据结构，这个数据结构称为<strong>进程控制块 (  Process Control block PCB)</strong>。</p>
<p>PCB是进程存在的唯一标准</p>
<ul>
<li><strong>进程的创建</strong>： 为该进程生成一个PCB</li>
<li><strong>进程的终止</strong>： 回收它的PCB</li>
<li><strong>进程的组织管理</strong>： 通过对PCB的组织管理来实现</li>
</ul>
<h3 id="pcb的组成">PCB的组成</h3>
<p>**PCB有以下三大类信息 **:</p>
<ul>
<li>
<p>进程标志信息</p>
<ul>
<li>进程标志信息：如本进程的标志, 本进程的产生者标志(父进程标志). 用户标志</li>
<li>进程号 (PID)：每个进程的唯一标识号</li>
</ul>
</li>
<li>
<p>处理器状态信息保存区：保存进程的运行现场信息 :</p>
<ul>
<li>进程结构 <code>Process structuring</code>：进程的子id，或以某种功能方式与当前进程相关的其他进程的id，可以表示为队列 <code>queue</code> 、环 <code>ring</code> 或其他类型的数据结构</li>
<li>程序计数器 ( <code>Program Counter</code> PC)：指向该进程要执行的下一条指令地址</li>
<li>CPU 寄存器 ：存储进程以执行运行状态</li>
<li>CPU调度信息：调度CPU的时间</li>
</ul>
</li>
<li>
<p>进程控制信息</p>
<ul>
<li>进程调度状态 <code>Process Sheduling  State</code> ，指定了进程的状态，如 “ready”、“waiting ”等和一些其他信息，例如优先级、自进程获得 CPU 控制权或自进程获得 CPU 控制权以来经过的时间向量。此外，在暂停进程的情况下，必须为进程正在等待的事件记录事件标识数据。</li>
<li>进程状态 <code>Process State</code>：<code>new</code>,  <code>ready</code>,  <code>running</code>,  <code>waiting</code>,  <code>dead</code></li>
<li>内存管理信息：页表、内存限制、段表</li>
<li>I/O 状态信息：分配给进程的 I/O 设备列表。</li>
<li>进程权限 <code>Privileges</code>：是否允许访问系统资源</li>
<li>进程间通信 <code>IPC</code>：独立进程之间的通信相关的标志、信号和消息</li>
</ul>
</li>
</ul>
<h2 id="进程的状态">进程的状态</h2>
<h3 id="进程生命期管理">进程生命期管理</h3>
<h4 id="进程的生命周期">进程的生命周期</h4>
<p>当一个进程执行时，它会经历不同的状态。这些阶段在不同的操作系统中可能会有所不同，并且这些状态的名称也没有标准化。但一般来将，一个进程一次可以有以下五种状态之一。而进程在执行过程中改变其状态被称为进程的声明周期 <code>process life cycle</code></p>
<table>
<thead>
<tr>
<th>State</th>
<th style="text-align:left">Descriptio</th>
</tr>
</thead>
<tbody>
<tr>
<td>New&amp;Start</td>
<td style="text-align:left">进程被首次启动/创建时的初始状态</td>
</tr>
<tr>
<td>Ready</td>
<td style="text-align:left">表示进程正在等待操作系统分配CPU资源，以便其可以运行。</td>
</tr>
<tr>
<td>Running</td>
<td style="text-align:left">一旦操作系统将CPU资源分配给进程，进程状态就会设置为Running，并且执行其指令。</td>
</tr>
<tr>
<td>Waiting</td>
<td style="text-align:left">进程需要等待资源的完成，如：等待用户输入或等待文件变为可用，则进程进入等待状态。</td>
</tr>
<tr>
<td>Terminated  Exit</td>
<td style="text-align:left">当进程完成其执行，或者它被操作系统终止，其状态就会变为Exit状态，等待从主存中删除</td>
</tr>
</tbody>
</table>
<h4 id="进程的创建">进程的创建</h4>
<p>引起进程创建的3个主要事件：</p>
<ul>
<li>系统初始化</li>
<li>用户请求创建一个新进程</li>
<li>正在运行的进程执行了创建进程的系统调用</li>
</ul>
<h4 id="进程运行">进程运行</h4>
<p>创建完进程时，不一定会被执行，还需要操作系统内核选择一个可以执行的进程，这种进程称之为就绪进程 <code>Ready</code>，让它占用CPU并执行  (为何选择？如何选择？)</p>
<h4 id="进程等待阻塞">进程等待(阻塞)</h4>
<p>在执行过程中，可能会发生等待，无法完成的事件会发生进程等待(阻塞)，通常下面情况下会触发</p>
<ul>
<li>
<p>请求并等待系统服务, 无法马上完成（如进程从辅存将数据读入主存，这个时间对于CPU会很慢，此时会发生等待）</p>
</li>
<li>
<p>启动某种操作, 无法马上完成（如多进程协同，其他进程没有完成也会等待）</p>
</li>
<li>
<p>需要的数据没有到达</p>
</li>
</ul>
<p>进程等待事件发起只能进程自己阻塞自己，因为只有进程自身才能知道何时需要等待某种事件的发生。</p>
<h4 id="进程唤醒">进程唤醒</h4>
<p>进程唤醒是将进程的等待状态转换为就绪态，意味着该进程可以被CPU去调度执行。唤醒进程的原因 :</p>
<ul>
<li>被阻塞进程需要的资源可被满足</li>
<li>被阻塞进程等待的事件到达</li>
<li>将该进程的PCB插入到就绪队列</li>
</ul>
<p>进程只能被别的进程或操作系统唤醒</p>
<h4 id="进程结束">进程结束</h4>
<p>在以下四种情况下, 进程结束 :</p>
<ul>
<li>正常退出（自愿）</li>
<li>错误退出（自愿）</li>
<li>致命错误（强制性）</li>
<li>被其他进程杀死（强制性）</li>
</ul>
<h3 id="进程的变化模型">进程的变化模型</h3>
<h4 id="两态模型">两态模型</h4>
<p>两态模型 <code> Two state</code> 是指，进程主要有两个状态：</p>
<ul>
<li><code>Not-running</code>：非运行状态是指，进程正在等待执行</li>
<li><code>Running</code>：运行状态是指当前正在运行的状态</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/2state.png" alt="两态过程模型图" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>如图可以看出，当操作系统创建进程时，会为该进程初始化PCB；当进程被事件打断，操作系统会将该进程从<code>Running</code>状态转换到到<code>Not-running</code>状态。</p>
<h4 id="三态模型">三态模型</h4>
<p>三态模型是两态模型的改善，在两态模型中，存在一个主要的缺点。当调度器将一个新进程从非运行态转换为运行态时，该进程可能仍在等待某个事件或 I/O请求。因此，调度器必须遍历队列并从中找到准备好执行但还未运行进程。这样的话效率很低。而且两态模型总体来说不能算满足进程的生命周期。</p>
<p>为了克服这个问题，三态模型将 <code>Not-running</code> 状态分为两种情况：</p>
<ul>
<li>就绪 <code>Ready</code>：一个进程获得了除CPU之外的一切所需资源，等待CPU分配时间片</li>
<li>等待 <code>Waiting</code>（阻塞 <code>Blocked</code>）：进程在等待某一事件而暂停运行；如等待某资源，等待输入/输出完成。</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/3statemodel.png" alt="三态过程模型图" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><strong>操作系统会为Ready</strong>和<strong>Waiting</strong>维护一个单独的队列。一旦进程的等待的事件完成，进程就会从阻塞态进入就绪态。</p>
<h4 id="五态模型">五态模型</h4>
<p>五态模型，是在三态模型的基础上，加入了进程的两个新状态**：New** 和 <strong>Terminated</strong>。</p>
<p><strong>为什么会有五态</strong></p>
<p>在之前三态模型中，进程有状态代表的，在主存储器中加载所有进程。很显然这是不可能实现的。所以当创建一个新进程时，程序并不会立即加载到主存中。操作系统仅在主存中存储有关进程的一些信息。当内存有足够可用空间时，长期调度器 <code>long term scheduler</code> 会将程序移动到主存。这样的过程就是<strong>New</strong>。</p>
<h5 id="五态模型下的状态">五态模型下的状态</h5>
<ul>
<li><strong>Running</strong>：当前正在执行的进程；也可以理解为当前占用CPU时间的进程。</li>
<li><strong>Waiting/Blocked</strong>： 等待某些事件的进程，如 I/O，等待其他进程，同步信号等。</li>
<li><strong>Ready</strong>：等待执行的进程；也可以理解为等待分配CPU时间的进程。</li>
<li><strong>New</strong>：刚创建的新进程。PCB已经初始化完成，但程序尚未加载到主内存中。程序保持在New状态，直到长期调度器 <code>long term scheduler</code> 将进程转换到Ready状态（已在主内存中）。</li>
<li><strong>Terminated/Exit</strong>：完成的进程或中止的进程。</li>
</ul>
<p>五态模型下的状态变化过程</p>
<ul>
<li>
<p><strong>NULL -&gt; New</strong>：新进程的创建过程</p>
</li>
<li>
<p><strong>New -&gt; Ready</strong>：当有足够的可用资源时，长期调度程序从辅存中选择一个New状态的进程并将其加载到主存中。该进程现在处于Ready状态，等待分配CPU时间。</p>
</li>
<li>
<p><strong>Ready -&gt; Running</strong> ：短期调度器<code>Short Term Scheduler</code> 或调度器将一个进程从Ready调度到Running，标记着该进程正在被执行。</p>
</li>
<li>
<p><strong>Running -&gt; Exit</strong>：当进程完成执行或中止，操作系统将进程从Running移动到Exit。</p>
</li>
<li>
<p><strong>Running -&gt; Ready</strong>： 当一个进程运行了一定时间而没有任何中断时，可能会发生这种变化；如，轮训调度算法。另一个常见的情况是，如果处于就绪状态的进程的优先级高于当前正在运行的进程的优先级，操作系统会抢占正在运行的进程并将其改变为就绪状态。</p>
</li>
<li>
<p><strong>Running -&gt; Waiting</strong>：进程必须等待某个事件，则将其置于Waitting状态。如：进程可能会请求一些可能不可用的资源或内存事，该进程可能正在等待 I/O 操作，或者该进程正在等待其他进程完成，然后才能继续执行。</p>
</li>
<li>
<p><strong>Waiting -&gt; Ready</strong>：进程完成了等待的事件，将从Waitting状态进入Ready。</p>
</li>
</ul>
<h3 id="进程挂起模型">进程挂起模型</h3>
<p>进程挂起 <code>process suspension</code>，是为了合理且充分地利用系统资源。进程在挂起状态时, 意味着进程没有占用内存空间，处在挂起 <code>Suspended</code> 状态的进程把进程放到磁盘上。当一个挂起进程准备好时运行时，它会进入 Ready-Suspend 队列中。因此，挂起状态也分为两个状态，即 阻塞挂起 <code>Blocked Suspend</code> 和 就绪挂起<code>Ready Suspend</code>。</p>
<h4 id="六态模型">六态模型</h4>
<p>六态模型通常情况下是具有挂起状态的五态模型。在六态模型存在一个缺陷，众所周知处理器比 I/O 设备要快很多。因此，会出现CPU执行速度过快导致所有进程都处于阻塞态而没有进程处于就绪态的情况。此时CPU 处于空闲状态，直到至少有一个进程完成 I/O 操作。这种情况下会导致 CPU 利用率低。</p>
<p>为了防止这种情况发生，即如果主存中的所有进程都处于阻塞态，操作系统会挂起( <code>Suspended</code> ) 处于阻塞态的进程并将其移动到辅存中。这种过程称为交换。所有处于挂起状态的进程都保存在一个队列中，内存被释放。此时，CPU 可以将一些其他进程带入主存。起到更好的利用CPU资源</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/5state1suspend.png" alt="具有挂起状态的五态进程模型图" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><strong>六态模型的状态转换</strong></p>
<p>在六态模型中，除了五态模型的转换外，还具有下述的几个状态间装换：</p>
<ul>
<li><strong>Waiting -&gt; Suspend</strong>：如果主存中的所有进程都处于等待状态，操作系统将进程从Waitting转换为到<code>Suspended</code></li>
<li><strong>Suspend -&gt; Ready</strong>：当有足够的内存可用时，操作系统将处于Suspended状态的进程移回主内中执行。</li>
<li><strong>Suspend -&gt; Waiting</strong>：操作系统从辅存换入到主存的进程仍在等待某个事件的完成。</li>
</ul>
<h4 id="七态模型">七态模型</h4>
<p>七态模型是将六态模型的阻塞状态又严格的分为 <strong>阻塞挂起（Blocked Suspend)</strong> 和 <strong>就绪挂起 (Ready Suspend )</strong></p>
<ul>
<li>
<p><strong>阻塞挂起（Blocked Suspend)</strong> ：进程在辅存中，尚未Ready。</p>
</li>
<li>
<p><strong>就绪挂起 (Ready Suspend )</strong>：:进程在辅存中, 但只要进入内存，即可运行。</p>
</li>
</ul>
<p><strong>七态模型的状态转换</strong></p>
<ul>
<li>
<p><strong>在内存中会出现的转换情况</strong></p>
<ul>
<li><strong>Blocked -&gt; Blocked-Suspend</strong>：如果主存中的所有进程都处于Waiting状态，则处理器将至少一个等待进程换回辅存以释放内存使得CPU资源被有效的利用。</li>
<li><strong>Ready -&gt;Ready-Suspend</strong>：当具有高优先级发生阻塞等待，操作系统会认为该进程很快会被就绪，此时，操作系统会选择挂起低优先级就绪进程，从Ready移动到Ready-Suspend，以释放主内存用于更高优先级的进程</li>
<li><strong>Running -&gt;Ready-Suspend</strong>：对抢先式分时系统，当有高优先级阻塞挂起进程因事件出现而进入就绪挂起时, 系统可能会把运行进程转换为就绪挂起状态。</li>
<li><strong>New -&gt; Ready-Suspend</strong>：如果主存使用空间不足，操作系统可能会将新进程移动为<code>Ready-Suspended</code> 状态。</li>
</ul>
</li>
<li>
<p><strong>在外存会出现的转换情况</strong></p>
<ul>
<li><strong>Blocked-Suspend -&gt; Ready-Suspend</strong>： 当有阻塞挂起因相关事件得到满足时，操作系统会把<code>Blocked-Suspend </code>进程转换为<code>Ready-Suspend</code>。</li>
</ul>
</li>
<li>
<p><strong>与挂起相关的状态转换</strong>（将进程从外存转入内存）</p>
<ul>
<li><strong>Ready-Suspend -&gt; Ready</strong>：当处于Ready-Suspend的高优先级进程高于Ready的进程，则操作系统会将其与主存中的较低优先级Ready进程交换。</li>
<li><strong>Blocked-Suspend -&gt; Blocked</strong>：当主存空间足够时, 系统会把一个高优先级Blocked-Suspend进程(系统认为会很快出现所等待的事件)进程转换为Blocked状态</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/2state2suspended2.png" alt="具有两个挂起状态的五状态进程模型图" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<blockquote>
<p>Reference</p>
<p><a href="https://slaystudy.com/process-state-models-in-operating-system/" target="_blank"
   rel="noopener nofollow noreferrer" >process state models</a></p>
<p><a href="https://www.guru99.com/process-scheduling.html#long-term-scheduler" target="_blank"
   rel="noopener nofollow noreferrer" >process-scheduling</a></p>
<p><a href="https://www.tutorialspoint.com/what-is-process-suspension-and-process-switching" target="_blank"
   rel="noopener nofollow noreferrer" >process suspension</a></p>
</blockquote>
<h2 id="进程队列">进程队列</h2>
<p>进程队列 (<code>Process Queues</code>) 是操作系统为管理进程的各种状态维护不同类型的队列，PCB会被存放在相同状态的队列中。如果进程状态发送改变，那么PCB也会进行转换到新的状态队列中。</p>
<ul>
<li>工作队列 <code>Job queue</code>：保存操作系统中所有的进程，存储在辅存中</li>
<li>就绪队列 <code>Ready queue</code>： 保存在主存中，短期调度器负责分配CPU时间</li>
<li>等待队列 <code>Waiting Queue</code>  或  <code>Device queues</code>：当进程发生阻塞事件，即需要I/O，此时进程会从 Ready转换为 Waitting 状态，进程的上下文 <code>Context</code>（PCB），都将存储在在等待队列中。</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/Process-Queue-2.png" alt="Process Queue" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<blockquote>
<p>Reference</p>
<p><a href="https://srinix.org/lecture_notes/Materials_2020_21/CSE/5TH%20SEM/OS%28MOD-2%29.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >Process scheduling</a></p>
</blockquote>
<h2 id="线程">线程</h2>
<p>线程 <code>Thread</code> 是进程中的一条执行流程，线程是CPU独立运行的基本单位，由程序计数器（PC），Stack，和一组寄存器组成。Code、File和Data段等可以在不同的线程共享。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/4_01_ThreadDiagram.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>由上图可以看出，线程的组成比进程要少一些，进程的主要构成是：</p>
<ol>
<li>Stack Section</li>
<li>Heap Section</li>
<li>Data Section</li>
<li>Text Section</li>
</ol>
<p>而线程主要构成部分是：</p>
<ul>
<li>独立的Stack</li>
<li>Heap 与进程共享</li>
<li>Data 与进程共享</li>
<li>Text 与进程共享</li>
</ul>
<h3 id="线程的控制结构">线程的控制结构</h3>
<p>线程控制块 TCB，是操作系统中的数据结构，每个线程都会维护一个TCB，TCB则是操作系统中线程的表现方式。</p>
<h3 id="线程的特点">线程的特点</h3>
<h4 id="线程的优点">线程的优点</h4>
<ul>
<li>线程减少了上下文切换时间，这有助于管理任务的时间；</li>
<li>各个线程之间可以并发地执行；</li>
<li>各个线程之间可以共享地址空间和文件等资源；</li>
</ul>
<h4 id="线程的缺点">线程的缺点</h4>
<ul>
<li>整个进程过分依赖线程，如单个线程中断，则整个进程中断并阻塞。</li>
<li>安全可靠性无保障：因为共享data（全局变量在线程间共享），这会产生安全问题。</li>
</ul>
<p><strong>多线程优点大概分为以下四类</strong>：</p>
<ul>
<li><strong>响应能力</strong>：</li>
</ul>
<p>交互式应用程序的多线程可以允许程序继续运行，即使它的一部分被阻塞或正在执行冗长的操作，从而提高对用户的响应能力。例如，多线程网络浏览器仍然可以允许用户交互</p>
<p>在另一个线程中加载图像时在一个线程中。</p>
<ul>
<li>
<p><strong>资源共享</strong>：线程共享其所属进程的内存和资源。</p>
</li>
<li>
<p><strong>经济</strong>：因为线程共享所属进程的资源，线程的创建和上下文切换线程更</p>
</li>
<li>
<p><strong>更高效的利用多处理器</strong>：每个线程可以在不同的处理器上并行运行，而一个单线程进程只能在一个 CPU 上运行，多线程增加了并发性。</p>
</li>
</ul>
<h4 id="线程与进程的比较">线程与进程的比较</h4>
<ul>
<li>进程是最小的资源分配单位，线程是最小的CPU调度单位</li>
<li>进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；</li>
<li>线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；</li>
<li>线程能减少并发执行的时间和空间开销；
<ul>
<li>创建时间</li>
<li>终止时间</li>
<li>切换（如页表切换、CPU上下文切换）
<ul>
<li>不同的进程CPU分别执行，不同的线程视为同一个任务</li>
</ul>
</li>
<li>资源的使用（IPC和资源共享）</li>
</ul>
</li>
</ul>
<h3 id="线程的实现">线程的实现</h3>
<p>现代系统中实现了两种类型的线程 用户线程 (<code>User-Level Threads</code>)和内核线程(<code>Kernel-Level Threads</code>)。</p>
<ul>
<li>内核线程是操作系统内核支持的线程，由操作系统直接管理。所有现代操作系统都支持内核级线程。
<ul>
<li>内核知道并管理所有线程。</li>
<li>每个进程一个进程控制块 (PCB)。</li>
<li>系统中每个线程一个线程控制块 (TCB)。</li>
<li>提供系统调用：可以从用户空间创建和管理线程。</li>
</ul>
</li>
<li>用户线程是存与用户空间，并且在没有内核支持的情况下进行管理；内核不知道用户线程。从内核的角度来看，进程是一个不透明的黑匣子。
<ul>
<li>线程完全由运行时系统 <code> run-time system</code> （用户级线程库）管理。</li>
<li>理想情况下，线程操作应该与函数调用一样快。</li>
<li>内核不知道用户线程的存在，管理用户线程与管理单进程一样。</li>
</ul>
</li>
</ul>
<h3 id="用户线程模型">用户线程模型</h3>
<p>通常，可以使用一下四种模型之一来实现用户线程。</p>
<ul>
<li>多对一</li>
<li>一对一</li>
<li>多对多</li>
<li>两级</li>
</ul>
<p>以上所有模型都是将用户级线程映射到内核级线程。而<strong>内核线程</strong>又类似于非线程（单线程）系统中的进程。内核线程是内核调度在CPU上执行单元。</p>
<h4 id="多对一">多对一</h4>
<p>在多对一模型是将所有用户线程都映射到同一个内核线程上执行。该进程一次只能运行一个用户线程。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/many-to-one.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>从图可以看出，一对一模型的特点如下：</p>
<ul>
<li>多个用户线程都映射到单个内核线程上。</li>
<li>线程对内核不透明，线程的管理是由用户空间的线程库处理，效率很高。</li>
<li>如果发生阻塞的系统调用，那么整个进程都会阻塞，即使其他用户线程能够继续执行。</li>
<li>因为单个内核线程只能在单个 CPU 上运行，所以多对一模型不允许将单个进程拆分到多个CPU上。</li>
</ul>
<h4 id="一对一">一对一</h4>
<p>在一对一模型中，内核必须提供一个系统调用来创建一个新的内核线程。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/many-to-many.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>一对一模型的特点：</p>
<ul>
<li>在一对一模型中，一个单独的内核线程用户来处理一个用户线程。</li>
<li>一对一模型有效的克服了一对多模型中涉及阻塞式系统调用和跨CPU拆分进程的问题。</li>
<li>管理一对一模型的开销更大，大的开销将减慢系统的调用速度。</li>
<li>该模型中，的大多数实现都对可创建的线程数量进行了限制。</li>
</ul>
<h4 id="多对多">多对多</h4>
<p>在多对多模型中，进程将分配了 m 个内核级线程来执行 n 个用户级线程。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/many-to-many.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>多对多模型的特点：</p>
<ul>
<li>可将任意数量的用户程多路复用到数量相等或更少的内核线程上。</li>
<li>用户对创建的线程数没有限制。</li>
<li>阻塞内核级系统调用不会阻塞整个进程。</li>
<li>进程可以跨多个处理器拆分。</li>
</ul>
<h4 id="两级">两级</h4>
<p>两级模型（<code>Two-Level</code>）是严格意义上的多对多模型，可以为单个用户线程专门一对一绑定内核线程的能力的模型</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/two-level.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="用户线程缺点">用户线程缺点</h3>
<ul>
<li>
<p>用户级线程与操作系统的集成度不高；如用空闲线程调度进程，阻塞其线程发起 I/O 的进程，即使该进程有其他线程可以运行，以及有锁的线程取消调度进程。</p>
</li>
<li>
<p>用户级线程需要非阻塞系统调用，否则，当一个线程阻塞，即使进程中还有可运行的线程，整个进程也会在内核中阻塞。例如，如果一个线程导致页面错误，则进程阻塞。</p>
</li>
<li>
<p>用户线程和操作系统内核之间缺乏协调性；无论进程有 1 个线程还是 1000 个线程，都仅能获得一个CPU时间片。由每个线程主动将控制权交给其他线程。</p>
</li>
<li>
<p>由于进程时资源分配的最小单位，多线程情况下，每个线程得到的时间片较少，执行会较慢。</p>
</li>
</ul>
<h4 id="内核级线程优缺点">内核级线程优缺点</h4>
<p><strong>优点</strong>：</p>
<ul>
<li>线程对操作系统内核透明，调度程序可以决定给拥有大量线程的进程比拥有少量线程的进程更多的时间。</li>
<li>内核级线程适用于经常阻塞的应用程序。</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>内核级线程缓慢且效率低下；如，操作内核级线程比用户级线程慢。</li>
<li>由于内核管理和调度线程与进程。每个线程又需要一个完整的TCB来维护有关线程的信息。因此，存在大量开销并增加了内核复杂性。</li>
</ul>
<blockquote>
<p>Reference</p>
<p><a href="https://www-users.cselabs.umn.edu/classes/Fall-2019/csci5103/proj_writeup/PROJ1.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >User-level Thread Library</a></p>
<p><a href="http://www.it.uu.se/education/course/homepage/os/vt18/module-4/implementing-threads/" target="_blank"
   rel="noopener nofollow noreferrer" >implementing threads</a></p>
<p><a href="https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/4_Threads.html" target="_blank"
   rel="noopener nofollow noreferrer" >Threads</a></p>
</blockquote>
<h2 id="进程控制">进程控制</h2>
<h3 id="上下文切换">上下文切换</h3>
<h4 id="introduction">Introduction</h4>
<p>上下文（<code>Context</code>）是指，进程的CPU占用被移除时，需要存储进程的相关信息，以便稍后获得处理器时，可以从相同的状态继续运行。这个状态数据被称之为上下文。可以理解为为上下文对进程的就如同书签对一本书。</p>
<p>上下文切换（<code>Context Switch</code>）是将CPU占用的时间片从一个进程或切换到另一个的过程。在这种现象中，处于运行状态的进程的执行会被挂起，而另一个处于就绪态的进程则会占用CPU时间。</p>
<p><strong>在操作系统中，什么情况下会发生上下文切换？</strong></p>
<ul>
<li>当进程终止时</li>
<li>当CPU计时器超时，应该切换到其他进程时</li>
<li>当前进程挂起</li>
<li>当前进程需要一些时间等待I/O事件</li>
<li>当来自计时器之外的中断产生，如优先级高的进程抢占</li>
</ul>
<p><strong>上下文切换时需要存储什么上下文?</strong></p>
<p>当进程从一种状态转换到另一种状态时，操作系统必须更新进程PCB信息。PCB是一种数据结构，在操作系统中用于将所有与数据相关的信息存储到进程和上下文中。PCB包含进程，即寄存器、时间片、优先级等。</p>
<p>进程的上下文包含：</p>
<ul>
<li>地址空间、Stack空间、虚拟地址空间</li>
<li>寄存器集，如进程计数器（PC）、Stack指针（SP）、指令寄存器（IR）、程序状态寄存器（PSW）</li>
</ul>
<p>所有信息都会保存在PCB中</p>
<p><strong>什么时候会触发上下文切换</strong></p>
<p>上下文切换只要发生在三种情况下：</p>
<ul>
<li><strong>多任务</strong>：一个进程从CPU 中换出，下一个可运行进程换入。在抢占式系统只不过，进程可能会被调度器换出。</li>
<li><strong>中断处理</strong>：当中断发生时，硬件切换部分上下文。这会自动发生。</li>
<li><strong>用户空间到内核空间</strong>：操作系统在用户空间和内核空间之间进行转换时，会发生上下文切换。</li>
</ul>
<h4 id="上下文切换的过程">上下文切换的过程</h4>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/what-is-context-switching-in-operating-system-context-switching-flow.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>又图可以看出P1占用CPU，P2处于就绪状态。如果发生中断或进程发生 I/O 事件，则 P1将会被换出；在更改 P1 的状态前，会将P1 的上下文保存在寄存器中，并将PC保存到 PCB1。之后，将加载PCB2上下文信息，此时PC从就绪状态转变为运行状态。</p>
<p>类似地，P2发生中断，恢复P1恢复执行。P1 从 PCB1 重新加载到运行状态以在上次停止时间重新执行任务。如信息丢失，并且CPU再次执行该进程时，会从其初始状态开始执行。</p>
<blockquote>
<p>Reference</p>
<p><a href="https://iq.opengenus.org/context-switching-in-os/" target="_blank"
   rel="noopener nofollow noreferrer" >context-switching in os</a></p>
</blockquote>
<h3 id="进程创建">进程创建</h3>
<p>进程创建是操作系统给用户使用的一个系统调用，用来完成新进程的创建工作。在Unix中进程的创建采用 <code>fork()/exec()</code> 系统调用来完成新进程的创建</p>
<ul>
<li><code>fork()</code> 的功能是创建一个与调用它的进程的几乎完全相同的副本
<ul>
<li>使用父进程的资源（例如，打开的文件）初始化新进程</li>
<li>PC、SP与父级相同</li>
<li>使用父进程的地址空间的内容作为副本初始化一个新地址空间</li>
<li><code>fork()</code> 的系统调用会返回两次
<ul>
<li>父进程会返回子进程的PID</li>
<li>子进程返回0，失败返回-1</li>
</ul>
</li>
</ul>
</li>
<li><code>exec()</code> 的功能是用新的进程替换当前进程，exec会将程序加载到当前的地址空间内并从头开始执行。
<ul>
<li>进程的Text、Data、Stack段会被替换成新的</li>
<li>exec()系统调用是使用了新程序替换了当前进程，因此PID没有发生改变</li>
<li>exec()的调用时由调用的进程发起的，被执行的是一个新程序，并不是一个进程，没有创建新进程</li>
<li>exec()系统调用不会返回给调用程序在执行，除非exec() 执行出错。</li>
</ul>
</li>
</ul>
<p>一个fork()示例：</p>
<pre><code class="language-c">int main(void) {
  printf(“Parent (PID = %d)\n”, getpid());
  fork();
  printf(“My PID is %d\n”, getpid() );
  return 0;
}
</code></pre>
<p>一个exec()示例</p>
<pre><code class="language-c">int main(void) {
  printf(“before execl\n”);
  execl(“/bin/ls”, “/bin/ls”, NULL);
  printf(“after execl\n”);
  return 0;
}
</code></pre>
<p><strong>fork()是如何工作的</strong></p>
<ul>
<li>在内核空间内，进程被排列成一个双向链表，称为<strong>任务列表</strong>。
<ul>
<li>父进程1234调用fork()</li>
<li>PCB会在内核空间内被复制，同时用户空间的代码也会被复制</li>
<li>子进程返回0，父进程返回子进程的PID</li>
</ul>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220404233414592.png" alt="image-20220404233414592" style="zoom: 80%;" />
<img src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220404233344415.png" alt="image-20220404233344415" style="zoom:80%;" />
<blockquote>
<p>Reference</p>
<p><a href="https://levelup.gitconnected.com/operating-system-process-management-26c73901166" target="_blank"
   rel="noopener nofollow noreferrer" >process management</a></p>
</blockquote>
<h3 id="进程加载">进程加载</h3>
<p>进程加载是指，用户程序通过exec()系统调用进行加载。</p>
<p>exec()系列函数用新的用户程序替换当前的进程的地址空间</p>
<ul>
<li>通过exec()更改子进程正在执行的程序代码来转换子进程，切换后的程序从main()开始执行</li>
<li>允许程序加载时指定启动参数；<code>execvp(argv[1], &amp;argv[1])</code></li>
<li>当调用成功时
<ul>
<li>两个为相同的进程，仅仅做了替换，不会生成新的进程</li>
<li>运行的是不同的程序</li>
</ul>
</li>
</ul>
<p><strong>exec()是如何工作的</strong></p>
<ul>
<li>清除局部变量和动态分配的内存</li>
<li>全局的程序（代码）和常量会被替换为新的程序（代码）和常量</li>
<li>全局变量重置为基于新代码的</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220404233011879.png" alt="image-20220404233011879" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="进程等待与退出">进程等待与退出</h3>
<h4 id="进程的等待">进程的等待</h4>
<p>等待和退出实际上是父子进程间的交互，完成子进程的资源回收</p>
<ul>
<li><code>wait()</code>系统调用用于父进程等待子进程的结束
<ul>
<li>子进程被创建并被执行后，父进程会被挂起，父进程通过wait()系统调用等待子进程返回值并再次获得控制权
<ul>
<li>子进程调用exit()唤醒父进程，将exit()返回值作为父进程中wait()的返回值</li>
<li>有僵尸子进程等待时，wait()立即返回其中一个值</li>
<li>无子进程存活，wait()立即返回</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="进程的有序退出">进程的有序退出</h4>
<p>进程在执行结束时调用<code>exit()</code>，完成进程资源回收。<code>exit()</code> 是一个系统调用，有如下功能：</p>
<ul>
<li>接受退出状态作为参数传给父进程。</li>
<li>资源回收
<ul>
<li>关闭所有文件和套接字</li>
<li>释放内存</li>
<li>释放创建出进程相关的数据结构
<ul>
<li>检查子进程是否存活，保留结果值直到父进程需要，进入zombie状态</li>
<li>否则释放所有数据结构，进程结束</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="其他进程控制系统调用">其他进程控制系统调用</h3>
<p>上述是对进程模型流的一些进程控制的系统调用，但操作系统还必须包含对进程的特殊控制：</p>
<ul>
<li>优先级操作
<ul>
<li><code>nice()</code>，指定进程的初始优先级进</li>
<li>在UNIX中，进程优先级会随着进程对CPU的消耗而减少</li>
</ul>
</li>
<li>调试的支持：<code>ptrace()</code>，允许一个进程来控制另一个进程，如设置断点、查看寄存器。</li>
<li>定时：<code>Sleep()</code>可以将进程置于定时器等待队列中，等待数秒</li>
</ul>
<blockquote>
<p>Reference</p>
<p><a href="https://www.cs.utexas.edu/~lorenzo/corsi/cs372/03F/notes/9-9.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >Process Management</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch6 页面置换算法</title>
      <link>https://www.oomkill.com/2022/04/ch6-page-replacement-algorithms/</link>
      <pubDate>Thu, 28 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/04/ch6-page-replacement-algorithms/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="overviews">Overviews</h2>
<ul>
<li>功能与目标</li>
<li>实验设置与评价方法</li>
<li>局部页面算法
<ul>
<li>最优页面置换算法</li>
<li>先进先出算法</li>
<li>最近最久未使用算法</li>
<li>时钟页面置换算法</li>
<li>最不常用置换算法</li>
<li>Belady现象</li>
<li>LRU FIFO Clock对比</li>
</ul>
</li>
<li>全局页面置换算法
<ul>
<li>工作集模型</li>
<li>工作集页面置换算法</li>
<li>缺页率置换算法</li>
</ul>
</li>
</ul>
<h2 id="功能与目标">功能与目标</h2>
<p>功能 : 当缺页中断发生，需要调入新的页面而内存已满时，选择内存当中哪个物理页面被置换。</p>
<p>目标 : 尽可能地减少页面的换进换出次数(即缺页中断的次数)。 具体来说，把未来不再使用的或短期内较少使用的页面换出，通常只能在局部性原理指导下依据过去的统计数据来进行预测。</p>
<p>页面锁定 <code>frame locking</code>：用于描述必须常驻内存的操作系统的关键部分或时间关键（<code>time critical</code>）的应用进程。实现的方式是：在页表中添加锁定标记位(<code>lock bit</code>)。</p>
<h2 id="实验设置与评价方法">实验设置与评价方法</h2>
<p>实例：记录一个进程对页访问的一个轨迹</p>
<ul>
<li>举例 : 模拟一个实验环境，记录对应的地址访问序列，虚拟地址跟踪(页号, 偏移)&hellip;
<ul>
<li><code>(3,0)</code>  <code>(1,9)</code>  <code>(4,1)</code>  <code>(2,1)</code>  <code>(5,3)</code>  <code>(2,0)</code> &hellip;</li>
</ul>
</li>
<li>而offset可以忽略（页不存在才会产生 <code>page fault</code>），生成的页面轨迹
<ul>
<li>3, 1, 4, 2, 5, 2, 1, &hellip;（替换为，3,1,4,2,5,2,1）</li>
</ul>
</li>
</ul>
<p>模拟一个页面置换的行为并且记录产生页缺失数的数量</p>
<ul>
<li>更少的缺失，更好的性能</li>
</ul>
<h2 id="局部页面置换算法">局部页面置换算法</h2>
<h3 id="最优页面置换算法">最优页面置换算法</h3>
<p>基本思路：当一个缺页中断发生时，对于保存在内存当中的每一个逻辑页面，计算在它的下一次访问之前，还需等待多长时间，从中选择等待时间最长的那个，作为被置换的页面。</p>
<p>这是一种理想情况, 在实际系统中是无法实现的, 因为操作系统无法知道每一个页面要等待多长时间以后才会再次被访问.</p>
<p>最优页面置换算法（<code>Optimal Page Replacement</code>）可用作其他算法的性能评价的依据，(在一个模拟器上运行某个程序, 并记录每一次的页面访问情况，在第二遍运行时即可使用最优算法)</p>
<p>在该算法中，会<strong>替换在未来最长持续时间内不会使用的页面</strong>。如下图所示有 a b c d e五个页，但是只有四个页帧。此时会产生物理页不够，会产生 <code>Page Fault</code>。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220321222007583.png" alt="image-20220321222007583" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>前四次因为a b c d 已经存在物理页帧中，故前四次不会产生缺页中断，第5次请求e不在物理页帧，此时会产生<code>page fault</code>，发生页面置换。可以看出目前最久不会被访问的页面为d，故将d替换出。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220321222225824.png" alt="image-20220321222225824" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="先进先出置换算法">先进先出置换算法</h3>
<p>先进先出页面置换算法 <code>First In First Out (FIFO)</code>，这是最简单的页面替换算法。在这个算法中，操作系统在一个队列中跟踪内存中的所有页面，最旧的页面在队列的前面。当一个页面需要被替换时，<strong>队列前面的页面被移除</strong>，进行置换。</p>
<p>性能较差, 调出的页面有可能是经常要访问的页面。并且有belady现象，FIFO算法很少单独使用.</p>
<p>FIFO算法实现起来非常简单。通过对主存储器中的队列来跟踪所有页面。一旦页面进入，我们就会将其放入队列并继续。这样，最旧的页面将始位于于队列中的第一位。</p>
<p>图是FIFO的伪代码</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/quicklatex.com-dbcb178160c7c5f3cc5dff1ce288a146_l3.svg" alt="由 QuickLaTeX.com 渲染" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<blockquote>
<p>Reference</p>
<p><a href="https://www.baeldung.com/cs/fifo-page-replacement" target="_blank"
   rel="noopener nofollow noreferrer" >fifo-page-replacement</a></p>
<p><a href="https://slideplayer.com/slide/17170897/" target="_blank"
   rel="noopener nofollow noreferrer" >page replacement algorithms</a></p>
</blockquote>
<p>实例，0时刻物理页中存放了 a b c d虚拟页，</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220321225453455.png" alt="image-20220321225453455" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>当时刻为5时，此时e不在物理页帧中，触发 page fault进行页面置换，假设 0 时刻时 入栈顺序为 a-b-c-d，此算法将会把a置换出，把e置换入。后续的换入换出也是按照进入队列顺序进行替换</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220321225600170-16478745692234.png" alt="image-20220321225600170" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="最近最久未使用页面置换算法">最近最久未使用页面置换算法</h3>
<p>最近最久未使用，<code>Least Recently Used</code>。基本思路是LRU会在一段时间内跟踪页面的使用情况，<strong>当发生缺页时，将最长时间未使用的页面替换为新请求的页面</strong>。</p>
<p>LRU是与OPT近似的一个算法，该算法基于程序的局部性原理，即在最近时间内, 被频繁地访问页面,  再将来的一小段时间内，还可能会再一次被频繁地访问。</p>
<ul>
<li>LRU 根据历史推测未来</li>
<li>OPT 根据未来推测未来</li>
</ul>
<p>实例，0时刻物理页中存放了 a b c d虚拟页，</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220321230813035.png" alt="image-20220321230813035" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>当访问5时刻时，此时该替换的应该为最久没有被访问的页面，此时c上次访问时间为1，c为最久没有被访问的页面。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220321230831419.png" alt="image-20220321230831419" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="时钟页面置换算法">时钟页面置换算法</h3>
<p>时钟页面置换算法 <code>The Clock Algorithm</code>，是类似于LRU的一种算法，对FIFO的一种改进</p>
<p>基本思路 :</p>
<ul>
<li>需要用到页表项的访问位，当一个页面被装入内存时，把该位初始化为0。 然后如果这个页面被访问，则把该位置设为1;</li>
<li>把各个页面组织成环形链表(类似钟表面)，把指针指向最老的页面(最先进来的)；</li>
<li>当发生一个缺页中断时，考察指针所指向的最老页面，若它的访问位为0，立即淘汰；若访问位为0，然后指针往下移动一格。如此下去，直到找到被淘汰的页面，然后把指针移动到下一格。</li>
</ul>
<p>实例：维护一个驻留在内存中的链表，指针指向上一次访问的位置</p>
<ul>
<li>使用时钟（或use/reference bit）位来记录页面的访问频率</li>
<li>每当引用页面（被访问）时，都会设置<code>reference bit</code> 为 1</li>
</ul>
<p>时钟指针扫过页面，寻找 <code>reference bit</code> = 0 的页面，替换时钟扫过一圈未被引用的页面</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220321234327704.png" alt="image-20220321234327704" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>实例：0时刻物理页中存放了 a b c d虚拟页，在 1 2 3 4时刻请求时，此时会命中，并且在访问时，将<code>reference bit</code> 设置为1，由下图可见</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220321235251072.png" alt="image-20220321235251072" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>当时刻为5时，触发置换条件，此时时钟所有<code>reference bit</code> 都为 1，此时会转到第二圈，由于第一圈全将<code>reference bit</code> 设置为0，故，替换的页为 <code>a</code>，同时指针指向下个位置</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220321235223407.png" alt="image-20220321235223407" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="二次机会算法">二次机会算法</h3>
<p>二次机会置换算法 <code>Second Chance</code>，是对时钟算法的一个改进，具体表现为如下几个方面：</p>
<ul>
<li>为每个帧添加一个 <code>drity bit</code>。</li>
<li>当每次引用时，将 该  <code>drity bit</code> 设置为<code>1</code> ； 这样就为该页面提供了二次机会。</li>
<li>当需要找到被置换出的页面时，请在时钟（维护的帧列表）中循环查找
<ul>
<li>如  <code>drity bit</code>=1，则将其重置（设置为零）并继续。</li>
<li>如 <code>drity bit</code>=0，则置换出该物理帧中的页面。</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220322161003485.png" alt="image-20220322161003485" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>增加了 <code>drity bit</code> 如 drity bit=0，此时仅为读操作，在置换时无需做写入操作。这样也被称作，增强时钟算法 <code>Enhance Clock</code>。</p>
<p>实例：0时刻物理页中存放了 a b c d虚拟页，在 1 2 3 4时刻请求时，此时会命中，并且在访问时，将<code>reference bit</code> 设置为1，并且，区分了读写操作，基于这种方式可以清楚的了解那页可以被置换出。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220322162430894.png" alt="image-20220322162430894" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>因为做了写操作，当时刻为4时，a b 的<code>dirty bit</code> 都为1。在经过两轮后，将00位的页替换出，同时指针指向下一位，则替换出C，并将指针指向下一位</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220322162834999.png" alt="image-20220322162834999" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<blockquote>
<p>Reference</p>
<p><a href="http://www.mathcs.emory.edu/~cheung/Courses/355/Syllabus/9-virtual-mem/SC-replace.html" target="_blank"
   rel="noopener nofollow noreferrer" >Second Chance Page Replacement Policy</a></p>
</blockquote>
<h3 id="最不常用置换算法">最不常用置换算法</h3>
<p>最不常用置换算法 <code>Least Frequently Used</code>，并不是说算法本身不常用，而是说在该算法中，系统会跟踪内存页的引用次数。当发生 <code>Page Fault</code>时，会置换出使用频率最低的页。</p>
<p>设计思路， LFU是在每个页表项都有增加一个计数器，对于每次内存引用，MMU 都会递增该计数器。当发生缺页中断时，操作系统选择计数器最小的页作为置换。</p>
<p>实例，有如下页面，此时物理页帧仅有三个，执行图如下：</p>
<blockquote>
<p>0 1 2 3 0 1 2 3 0 1 2 3 4 5 6 7</p>
</blockquote>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/LFU.png" alt="LFU" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>Page Fault = $12 \div 16 = 75%$</p>
<h3 id="belady现象">Belady现象</h3>
<p>Belady现象也可以称作Belady异常 <code>beladys anomaly</code>，是在操作系统中，随着增加物理页帧数量会导致``Page fault`数量增加的现象。</p>
<p>如 : FIFO算法的置换特征与进程访问内存的动态特征是矛盾的，与置换算法的目标是不一致的（即替换较少使用的页面），因此，被他置换出去的页面不一定是进程不会访问的。</p>
<p>如：</p>
<p><code>f</code> 标记位为 缺页中断。</p>
<table>
<thead>
<tr>
<th>Page Requests</th>
<th>3</th>
<th>2</th>
<th>1</th>
<th>0</th>
<th>3</th>
<th>2</th>
<th>4</th>
<th>3</th>
<th>2</th>
<th>1</th>
<th>0</th>
<th>4</th>
</tr>
</thead>
<tbody>
<tr>
<td>Newest Page</td>
<td>3f</td>
<td>2f</td>
<td>1f</td>
<td>0f</td>
<td>3f</td>
<td>2f</td>
<td>4f</td>
<td>4</td>
<td>4</td>
<td>1f</td>
<td>0f</td>
<td>0</td>
</tr>
<tr>
<td></td>
<td></td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>0</td>
<td>3</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>4</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>Oldest Page</td>
<td></td>
<td></td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>0</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>2</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>
<p>示例1：当存在3个物理页面时 Page Fault = 9。</p>
<table>
<thead>
<tr>
<th>Page Requests</th>
<th>3</th>
<th>2</th>
<th>1</th>
<th>0</th>
<th>3</th>
<th>2</th>
<th>4</th>
<th>3</th>
<th>2</th>
<th>1</th>
<th>0</th>
<th>4</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Newest Page</strong></td>
<td>3f</td>
<td>2f</td>
<td>1f</td>
<td>0f</td>
<td>0</td>
<td>0</td>
<td>4f</td>
<td>3f</td>
<td>2f</td>
<td>1f</td>
<td>0f</td>
<td>4f</td>
</tr>
<tr>
<td></td>
<td></td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>4</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>3</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>1</td>
<td>0</td>
<td>4</td>
<td>3</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td><strong>Oldest Page</strong></td>
<td></td>
<td></td>
<td></td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>0</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>示例2：当存在4个物理页面时 Page Fault = 10。</p>
<p>如何避免：使用stack 算法</p>
<h3 id="什么是stack算法">什么是stack算法</h3>
<blockquote>
<p>堆栈算法是指，大小为N的集合始终是大小为N+1集合的子集。</p>
<p>例如：一个大小为N页的集合保存在内存中的页面始终是大小为 N + 1 的帧保存的页面的子集。</p>
</blockquote>
<p>如  具有3 帧的内存中的 <code>{0,1,2}</code> 不是具有 4 帧内存中 <code>{0,1,4,5}</code> 的子集  ，这种情况下基于堆栈的算法的。</p>
<p>从上面belady现象可以看出，从 4  3  2  1  0  4  开始是违反基于堆栈的算法的属性</p>
<table>
<thead>
<tr>
<th>Page Requests</th>
<th>4</th>
<th>3</th>
<th>2</th>
<th>1</th>
<th>0</th>
<th>4</th>
</tr>
</thead>
<tbody>
<tr>
<td>Newest Page</td>
<td>4f</td>
<td>3f</td>
<td>2f</td>
<td>1f</td>
<td>0f</td>
<td>4f</td>
</tr>
<tr>
<td></td>
<td>0</td>
<td>4</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td></td>
<td>1</td>
<td>0</td>
<td>4</td>
<td>3</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>Oldest Page</td>
<td>2</td>
<td>1</td>
<td>0</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Page Requests</th>
<th>4</th>
<th>3</th>
<th>2</th>
<th>1</th>
<th>0</th>
<th>4</th>
</tr>
</thead>
<tbody>
<tr>
<td>Newest Page</td>
<td>4f</td>
<td>4</td>
<td>4</td>
<td>1f</td>
<td>0f</td>
<td>0</td>
</tr>
<tr>
<td></td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>4</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>Oldest Page</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>2</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Reference</p>
<p><a href="https://cs.stackexchange.com/questions/59355/how-do-stack-based-cache-algorithms-avoid-beladys-anomaly" target="_blank"
   rel="noopener nofollow noreferrer" >why stack-based cache algorithms avoidbeladys-anomaly</a></p>
<p><a href="https://www.geeksforgeeks.org/beladys-anomaly-in-page-replacement-algorithms/" target="_blank"
   rel="noopener nofollow noreferrer" >page replacement algorithms</a></p>
</blockquote>
<h4 id="为什么stack-based算法不会发生belady现象">为什么stack-based算法不会发生belady现象</h4>
<p>基于堆栈的算法不会产生Belady 现象，这是因为这些类型的算法会为页面（用于替换）分配一个优先级，该优先级与页帧的数量没有管理。如 <code>Optimal</code>、<code>LRU</code> 和 <code>LFU</code>。此外，此类算法还具有良好的模拟特性，即通过一次引用可以计算出任意数量的页帧的命中率缺页率。</p>
<table>
<thead>
<tr>
<th>Page Requests</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>1</th>
<th>2</th>
<th>5</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
</tr>
</thead>
<tbody>
<tr>
<td>Newest Page</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>1</td>
<td>2</td>
<td>5</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
</tr>
<tr>
<td></td>
<td></td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>1</td>
<td>2</td>
<td>5</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>Oldest Page</td>
<td></td>
<td></td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>1</td>
<td>2</td>
<td>5</td>
<td>1</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>Page Fault</td>
<td>F</td>
<td>F</td>
<td>F</td>
<td>F</td>
<td>F</td>
<td>F</td>
<td>F</td>
<td></td>
<td></td>
<td>F</td>
<td>F</td>
<td>F</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Page Requests</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>1</th>
<th>2</th>
<th>5</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
</tr>
</thead>
<tbody>
<tr>
<td>Newest Page</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>1</td>
<td>2</td>
<td>5</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
</tr>
<tr>
<td></td>
<td></td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>1</td>
<td>2</td>
<td>5</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>1</td>
<td>2</td>
<td>5</td>
<td>1</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>Oldest Page</td>
<td></td>
<td></td>
<td></td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>5</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>Page Fault</td>
<td>F</td>
<td>F</td>
<td>F</td>
<td>F</td>
<td></td>
<td></td>
<td>F</td>
<td></td>
<td></td>
<td>F</td>
<td>F</td>
<td>F</td>
</tr>
</tbody>
</table>
<p>由上述两表可以看出，在LRU算法中，每次引用一个页面时，它都会移动到堆栈的顶部，因此堆栈的顶部的n个页面是最近使用的n个页面*。*即使帧数增加到 <code>n+1</code>，堆栈顶部也会有 <code>n+1</code> 个最近使用的页面。 构成基于堆栈的算法。</p>
<h3 id="lru--fifo-和-clock-的比较">LRU / FIFO 和 Clock 的比较</h3>
<p>LRU和FIFO都是先进先出的思路，只不过LRU是针对页面最近访问时间来进行排序，所以需要在每一次页面访问的时候动态地调整各个页面之间的先后顺序(有一个页面的最近访问时间变了)。而FIFO是针对页面进入内存的时间来进行排序，这个时间是固定不变的, 所以各个页面之间的先后顺序是固定的。如果一个页面在进入内存后没有被访问，那么它的最近访问时间就是它进入内存的时间。 换句话说，如果内存当中的所有页面都未曾访问过，那么LRU算法就退化为了FIFO算法。</p>
<p>例如 : 给进程分配3个物理页面, 逻辑页面的访问顺序是 : 1,2,3,4,5,6,1,2,3 &hellip;</p>
<h2 id="全局页面置换算法">全局页面置换算法</h2>
<p>局部页面置换算法是基于单一程序来说明的，但对于操作系统来讲，执行的程序有很多，如果每个程序使用固定的页面置换算法会产生一定的问题，所以全局页面置换算法就是解决这种问题的。</p>
<p>存在问题，随着物理页帧的增加，通常情况下会大大减少缺页的次数，而为每个程序分配固定的物理页帧则会大大限制了程序执行的性能；程序是一个动态变化的过程，对内存的需求是可变的。</p>
<h3 id="工作集模型">工作集模型</h3>
<ul>
<li>如果局部性原理不成立，那么各种页面置换算法就没有说明分别，也没有什么意义。例如：假设进程对逻辑页面的访问顺序是<code>1,2,3,4,5,6,6,7,8,9...</code>，即单调递增，那么在物理页有限的前提下,  不管采用何种置换算法，每次的页面访问都必然导致缺页中断。</li>
<li>如果局部性原理是成立的，那么如何来证明它的存在，如何来对它进行定量地分析? 这就是工作集模型.</li>
</ul>
<p><strong>什么是工作集</strong>：进程当前正在使用的页面集称之为工作集 <code>Working Set</code>，可以用一个二元函数来表示：$W(t, \tau )$；在区间$[t-\tau+1..t] $ 内的页数。</p>
<ul>
<li>t是当前执行的时刻</li>
<li>$\tau$ 是工作集窗口 <code>Working-set window</code>，一个定长页面访问的时间窗口</li>
<li>$W(t, \tau )$ 是工作集的大小，即逻辑页的数量.</li>
</ul>
<blockquote>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220322192606257.png" alt="image-20220322192606257" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>如果 Example ($\tau = 10$ ):</p>
<p>t1 → WS =<code> {1,2,5,6,7}</code></p>
<p>t2 → WS = <code>{3,4}</code></p>
</blockquote>
<p>由此可知，</p>
<ul>
<li>工作集是工作集窗口中的页面集
<ul>
<li>工作集是窗口是一个移动的窗口，表现形式为对每个内存的引用。</li>
<li>当一个新的引用出现在窗口中，对应的页将被标记位该工作集中的成员</li>
<li>最旧一端的引用将从工作窗口中弹出，相应的页就不会再被标记位工作集中的成员了。</li>
</ul>
</li>
</ul>
<p>例如：如图所示：一个请求序列，假设 $\tau = 10$ ，则应该如何计算工作集？</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220322193820089.png" alt="image-20220322193820089" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>工作集大小的变化 : 进程开始执行后，随着访问新页面逐步建立较稳定的工作集。当内存访问的局部性区域的位置大致稳定时，工作集大小也大致稳定；局部性区域的位置改变时，工作集快速扩张和收缩过渡到下一个稳定值。</p>
<table>
<thead>
<tr>
<th>ti</th>
<th>WS</th>
</tr>
</thead>
<tbody>
<tr>
<td>t1</td>
<td>{1,2,5,6,7}</td>
</tr>
<tr>
<td>t2</td>
<td>{1,5,6,7}</td>
</tr>
<tr>
<td>t3</td>
<td>{1,2,5,6,7}</td>
</tr>
<tr>
<td>t4</td>
<td>{1,2,3,5,6,7}</td>
</tr>
<tr>
<td>t5</td>
<td>{1,2,3,4,5,6,7}</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Reference</p>
<p><a href="https://www.cs.cornell.edu/courses/cs4410/2016su/slides/lecture13.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >Computing the working set</a></p>
</blockquote>
<h3 id="常驻集">常驻集</h3>
<p>常驻集是指在当前时刻, 进程实际驻留在内存当中的页面集合.</p>
<ul>
<li>工作集是进程在运行过程中固有的性质，而常驻集取决于系统分配给进程的物理页面数目，以及所采用的页面置换算法;</li>
<li>如果一个进程的整个工作集都在内存当中，即常驻集 包含 工作集, 那么进程将很顺利地运行，而不会造成太多的缺页中断(直到工作集发生剧烈变动, 从而过渡到另一个状态);</li>
<li>当进程常驻集的大小达到某个数目之后，再给它分配更多的物理页面，缺页率也不会明显下降。</li>
</ul>
<h3 id="工作集页面置换算法">工作集页面置换算法</h3>
<p>如图所示，跟踪最后一个 $\tau$ 参考（不包括断层参考）</p>
<ul>
<li>最后一次$\tau$ 内存访问期间引用的页面是工作集</li>
<li>$\tau$ 被称为窗口大小</li>
<li>例如，工作集大小为$\tau=4$</li>
</ul>
<p>0时刻，被引用的页面为 a d e 此时 工作集窗口为 <code>{-2, -1, 0}</code></p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220322215333300.png" alt="image-20220322215333300" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>时刻1，工作集窗口为 <code>{-2, -1, 0, 1} </code>  工作集为<code>{a c d e}</code></p>
<p>时刻2，此时工作集窗口 {-1, 0, 1,2 } 而 工作集为 {a c d} 因为 e已经不在工作集窗口内了。</p>
<p>时刻4，产生缺页中断，此时将a换出，因为a已经不在工作集窗口内了</p>
<p>时刻6，产生缺页，将e换入工作集 此时工作集为 {b c e d}</p>
<p>时刻7，因d不在工作集窗口内，则将d换出，此时工作集为 {b c d}</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220322215753155.png" alt="image-20220322215753155" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="缺页率页面置换算法">缺页率页面置换算法</h3>
<p>计算工作集的另一种方法：</p>
<ul>
<li>尝试最小化页面错误
<ul>
<li>当缺页率较高时，增加工作集</li>
<li>当缺页率较低时，减少工作集</li>
</ul>
</li>
</ul>
<p>缺页率页面置换算法 <code>Page-Fault-Frequency Page Replacment</code>，即可变分配策略：<strong>常驻集大小可变</strong>。 例如 : 每个进程在刚开始运行的时候, 先根据程序大小给它分配一定数目的物理页面, 然后在进程运行过程中, 再动态地调整常驻集的大小.</p>
<ul>
<li>可采用全局页面置换的方式，当发生一个缺页中断时，被置换的页面可以是在其他进程当中，各个并发进程竞争地使用物理页面。</li>
<li>优缺点：性能较好，但增加了系统开销。</li>
<li>具体实现：可以使用缺页率算法来动态调整常驻集的大小.</li>
</ul>
<p>缺页率： $缺页次数 \div 内存访问次数$；</p>
<p>影响因素 :</p>
<ul>
<li>页面置换算法</li>
<li>分配给进程的物理页面数目</li>
<li>页面本身的大小</li>
<li>程序的编写方法</li>
</ul>
<p>缺页集算法实现：保持跟踪缺页发生的概率，当出现缺页异常时，计算并记录从上一次缺页异常起到现在的时间。上次最后一次缺页异常的时间 <strong>t<sub>last</sub></strong></p>
<p>如果两次缺页异常间隔时间 “很大”，则减少工作集</p>
<ul>
<li>如果 $t_{current} - t_{last} &gt; \tau $，则从内存中移除 [$t_{current}$ , $t_{last}$]时间内没有被引用的页。</li>
</ul>
<p>如果两次缺页异常间隔时间 “很小”，则增加工作集</p>
<ul>
<li>如果 $t_{current} - t_{last} &lt; \tau $，则将缺失的页增加到工作集中。</li>
</ul>
<p><strong>示例</strong>：假设窗口大小为2  $\tau = 2$</p>
<p>如果当 $t_{current} - t_{last} &gt; 2$，则移除 [$t_{current}$ , $t_{last}$]时间内没有被引用的页。</p>
<p>如果当  $t_{current} - t_{last} &lt; 2$，则将缺失的页增加到工作集中</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220322224045359.png" alt="image-20220322224045359" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>时刻1：产生缺页异常</p>
<p>时刻4：产生缺页异常，此时 $t_{current} - t_{last} = 4-3 &gt; 2$，此时工作集窗口为{1,2,3,4}，工作集为 {a,c,d,e}则在工作集窗口内没有被访问到的 a,e 则被从工作集中清除。</p>
<p>时刻6：产生缺页异常，此时 $t_{current} - t_{last} = 6-4 \leq 2$，此时工作集窗口为{6,5,4}，工作集为 {b,c,d}；此时增加工作集，将e增加到工作集中</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220322224322218.png" alt="image-20220322224322218" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<blockquote>
<p>Reference</p>
<p><a href="http://www.cs.cornell.edu/courses/cs4410/2013su/slides/lecture14.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >Page Fault Frequency</a></p>
</blockquote>
<h3 id="抖动问题">抖动问题</h3>
<p>抖动问题是对工作集与常驻集问题的深入</p>
<ul>
<li>工作集：程序在执行过程中对内存访问的固有属性</li>
<li>常驻集：当前程序要访问那些页面放到内存中来</li>
</ul>
<p>如果分配给一个进程的物理页面太少，不能包含整个的工作集, 即常驻集 属于工作集，那么进程将会造成很多的缺页中断，需要频繁的在内存与外存之间替换页面，从而使进程的运行速度变得很慢，我们把这种状态称为 &ldquo;抖动&rdquo; <code>Thrashing</code> 。</p>
<p>产生抖动的原因：随着驻留内存的进程数目增加, 分配给每个进程的物理页面数不断就减小, 缺页率不断上升. 所以OS要选择一个适当的进程数目和进程需要的帧数, 以便在并发水平和缺页率之间达到一个平衡.</p>
<p>更好的负载控制标准：调整MPL，以便：</p>
<p>平均缺页间隔时间（ <code>means time between page faults</code> MTBF）= 缺页服务时间（ <code>page fault service time</code> PFST）</p>
<p>$\sum WS_i = Size of memory$</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220322231054093.png" alt="image-20220322231054093" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch5 虚拟内存</title>
      <link>https://www.oomkill.com/2022/04/ch5-virtual-memory/</link>
      <pubDate>Wed, 27 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/04/ch5-virtual-memory/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="objective">Objective</h2>
<ul>
<li>覆盖技术</li>
<li>交换技术</li>
<li>虚拟内存
<ul>
<li>目标</li>
<li>程序局部性原理</li>
<li>基本概念</li>
<li>基本特征</li>
<li>虚拟页式内存管理</li>
</ul>
</li>
</ul>
<h2 id="覆盖技术-overlay">覆盖技术 overlay</h2>
<p>在固定分区中的主要遇到的问题是进程的大小受到分区的最大大小的限制，这将意味着一个进程将不能跨越另一个进程。为了解决这个问题，早期使用了称为覆盖(<code>overlay</code>) 的解决方案，覆盖技术是为了在较小的可用内存中运行较大的程序。常用于多道程序系统，与<strong>分区存储管理</strong>配合使用。这样并非所有模块都需要同时存在于内存中，实现了运行大于物理内存大小的程序的技术。</p>
<h3 id="覆盖技术的原理">覆盖技术的原理：</h3>
<ul>
<li>将程序按照执行逻辑拆分为多个功能上相对独立的部分（<code>overlays</code>）, 那些不会同时执行的模块共享同一块内存区域, 按时间先后来运行（分时）。
<ul>
<li>必要部分，常驻内存的代码和数据，负责管理，在某个时间片将相应的程序和数据导入或导出内存。</li>
<li>可选部分，在其他程序模块中实现, 平时存放在外存中, 在需要用到时才装入内存;</li>
<li>不存在调用关系的模块不必同时装入到内存, 从而可以相互覆盖, 即这些模块共用一个分区.</li>
</ul>
</li>
</ul>
<h3 id="覆盖技术实例">覆盖技术实例</h3>
<blockquote>
<p>覆盖技术说明：</p>
<p>有一个程序，分位A B C D E F G 六个模块，每一个模块占用了一定空间，程序的覆盖树如图所示。</p>
<p>问：当满足加载（和运行）该程序所需物理内存中的大小是多少？</p>
</blockquote>
<p>使用覆盖技术，实际上不需要将整个程序放在主内存中。只需要在对应时间片时所需要的部分即可，其逻辑调用关系树可以分为：<code>Root-A-D</code>或者 <code>Root-A-E</code> ;  <code>Root-B-F </code> 或  <code>Root-C-G </code> 部分。</p>
<p>Root是常驻内存，因为其需要调用A B C D E F G 六个模块，占用2KB</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/os_overlaymemory-164128439798517.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>如图：加载与运行改程序所需的物理内存大小是多少？</p>
<p>​	(a) 12 KB</p>
<p>​	(b) 14 KB</p>
<p>​	(c) 10 KB</p>
<p>​	(d) 8 KB</p>
<p>答：由公式可得，最大运行层所需的物理内存为14KB，即拥有 14KB 大小的分区就可以运行上图任意一个分区</p>
<pre><code>Root+A+D = 2KB + 4KB + 6KB = 12KB
Root+A+E = 2KB + 4KB + 8KB = 14KB
Root+B+F = 2KB + 6KB + 2KB = 10KB
Root+C+G = 2KB + 8KB + 4KB = 14KB
</code></pre>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/Concepts-of-overlays-164128440033218.png" alt="Concepts of overlays" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>如图所示，<code>Overlay Driver</code> ,也就是root区，是一个由用户负责如何覆盖的代码段，并不是操作系统提供的功能。这就意味着Overlay模式下需要用户自行去管理内存，这就是所谓的<code>Overlay Driver</code>，通俗来讲，<code>Overlay Driver</code> 是帮助整个程序如何换入换出各个部分的代码。</p>
<h3 id="覆盖技术的优缺点">覆盖技术的优缺点</h3>
<p>**优势 **</p>
<ul>
<li>减少内存需求</li>
<li>减少时间要求</li>
</ul>
<p>**坏处 **</p>
<ul>
<li>覆盖的关系必须由开发者去指定</li>
<li>开发者需要知道整个程序所需的内存</li>
<li>覆盖的模块必须完全没有交集</li>
</ul>
<h2 id="交换技术">交换技术</h2>
<p>交换技术(<code>swapping</code>)，是操作系统实现的一种内存交换机制，与覆盖技术最大的不同是，覆盖技术是由开发者在程序内实现的内存交换机制，而swapping则是操作系统实现的内存交换机制。</p>
<p>实现原理：可将暂时不能运行的程序送到外存，从而获得空闲内存空间。操作系统把一个进程的整个地址空间的内容保存到外存中(换出 swap out)，而将外存中的某个进程的地址空间读入到内存中(换入 swap in)。换入换出内容的大小为整个程序的地址空间。</p>
<p>![交换](../../../images/ch5 Virtual Memory/Swapping.jpg)</p>
<h3 id="交换技术存在的问题">交换技术存在的问题</h3>
<ul>
<li>交换时机的确定：何时需要发生交换? 只当内存空间不够或有不够的危险时换出;</li>
<li>交换区的大小：必须足够大以存放所有用户进程的所有内存映像的拷贝，必须能够对这些内存映像进行直接存取</li>
<li>程序换入时的重定位：换出后再换入的内存位置一定要在原来的位置上嘛?(可能出现寻址问题) 最好采用动态地址映射的方法</li>
</ul>
<h3 id="交换技术与覆盖技术的比较">交换技术与覆盖技术的比较</h3>
<p>覆盖技术是一种编程方法（换入换出单位为程序内的一个模块），用来解决程序大于计算机主内存的限制，在嵌入式系统中通常会考虑该技术。</p>
<p>交换技术是操作系统中内存交换的机制，换入换出单位是在内存中一个程序为单位，无需开发者给出各个模块之间的逻辑覆盖结构。</p>
<p>在内存不够用的情形下, 可以采用覆盖技术和交换技术, 但是 :</p>
<ul>
<li>覆盖技术：需要程序要自己把整个程序划分为若干个小的功能模块, 并确定各个模块之间的覆盖关系, 增加了程序员的负担.</li>
<li>交换技术 : 以进程作为交换的单位，需要把进程的整个地址空间都换入换出, 增加了处理器的开销.</li>
</ul>
<h2 id="虚拟内存技术">虚拟内存技术</h2>
<h3 id="objective-1">Objective</h3>
<ul>
<li>
<p>像覆盖技术那样，不用把程序的所有内容都放在内存中，因而能够运行比当前的空闲内存空间还要大的程序。但做的更好，由操作系统自动来完成，无需程序员的干涉。</p>
<p>像交换技术那样，能够实现进程在内存与外存之间的交换，因而获得更多的空闲内存空间。但做的更好，只对进程的部分内容在内存和外存之间进行交换。</p>
</li>
</ul>
<p>![虚拟内存](../../../images/ch5 Virtual Memory/virtual_memory.jpg)</p>
<h3 id="程序局部性原理">程序局部性原理</h3>
<p>程序的局部性 (<code>principle of locality</code>)，是虚拟内存中重要组成的概念，表明了，程序在操作系统中运行期间在任意的时间内只需要访问整个内存中的一小部分。有个这个概念就可以对操作系统的内存进行优化，从而获得更好的整体性能。局部性又可分为：</p>
<ul>
<li><strong>时间局部性</strong>：时间局部性(<code>Temporal locality</code>)是指，访问过的内存地址很快又会被再次访问，例如：在循环中，循环变量每次迭代期间都会被访问到。</li>
<li><strong>空间局部性</strong>：空间局部性(<code>Spatial locality</code>)是指，在特定时间访问过的内存位置，则很可能很快就会引用其附近位置的内存地址，例如：在数组中，常规情况下，访问完数组的第一个元素会直接访问数组的下一个元素。</li>
<li><strong>顺序局部性</strong>：所谓顺序局部性(<code>Sequential locality</code>)，是指内存位置按升序或降序顺序方法被访问。</li>
<li><strong>分支局部性</strong>：分支局部性(<code> Branch locality</code>)，在计算机中，大多数指令是顺序执行的，这种情况通常发生在分支情况下，当在简单结构或分支中，所需要访问的内存地址仅限于在一个小范围内。</li>
<li><strong>等距局部性</strong>：等距局部性(<code>Equidistant locality</code>)位于空间和分支之间，是指如果某个位置被访问，那和它相邻等距离的连续地址极有可能会被访问到。</li>
</ul>
<blockquote>
<p>Reference</p>
<p><a href="https://stackoverflow.com/questions/9784407/locality-of-reference-english-explanation-for-equidistant-locality" target="_blank"
   rel="noopener nofollow noreferrer" >explame of locality</a></p>
<p><a href="https://www.quora.com/What-is-the-locality-of-reference-or-the-principle-of-locality" target="_blank"
   rel="noopener nofollow noreferrer" >locality of reference</a></p>
</blockquote>
<p><strong>实例</strong>：为什么下列代码有问题?</p>
<p>页面大小为4k，但会产生4M大小。分配给每个进程的物理页面是1</p>
<p>在一个进程中, 定义了如下的二维数组 <code>int A[1024][1024]</code>. 该数组按行存放在内存, 每一行放在一个页面中。考虑一下程序的编写方法对缺页率的影响?</p>
<pre><code># Option #1
for (j = 0; j &lt; 20; j++)
	for (i = 0; i &lt; 200; i++)
		x[i][j] = x[i][j] + 1;

## Option #2
for (i = 0; i &lt; 200; i++)
	for (j = 0; j &lt; 20; j++)
		x[i][j] = x[i][j] + 1;
</code></pre>
<p>option1，按照行访问</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>a(0,0)</td>
<td>a(1,0)</td>
<td>a(2,0)</td>
<td>&hellip;.</td>
<td>a(1023,0)</td>
</tr>
<tr>
<td>a(0,1)</td>
<td>a(1,1)</td>
<td>a(2,1)</td>
<td>&hellip;.</td>
<td>a(1023,1)</td>
</tr>
</tbody>
</table>
<p>option #2 按照列访问</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>a(0,0)</td>
<td>a(0,1)</td>
<td>a(0,2)</td>
<td>&hellip;.</td>
<td>a(0,1023)</td>
</tr>
<tr>
<td>a(1,0)</td>
<td>a(1,1)</td>
<td>a(1,2)</td>
<td>&hellip;.</td>
<td>a(1,1023)</td>
</tr>
</tbody>
</table>
<p>option #1 每个数据值占用1页，总共$1024X 1024$页，会发生$1024X 1024$ 次<code>page fault</code></p>
<p>option #2 总共会发生1024次 <code>page fault</code></p>
<p>基本特征</p>
<ul>
<li>大的用户空间：通过把物理内存和外存相结合, 提供给用户的虚拟内存空间通常大于实际的物理内存，即实现了这两者的分离。如32位的虚拟地址理论上可以访问4GB，而可能计算机上仅有256M的物理内存，但硬盘容量大于4GB。</li>
<li>部分交换：与交换技术相比较，虚拟存储的调入和调出是对部分虚拟地址空间进行的;</li>
<li>不连续性： 物理内存分配的不连续性，虚拟地址空间使用的不连续性。</li>
</ul>
<h2 id="虚拟页式内存管理">虚拟页式内存管理</h2>
<h3 id="请求调页-demand-paging">请求调页 Demand Paging</h3>
<p>当用户程序要调入内存运行时，不是将该程序的所有页面都装入内存，而是只装入部分的页面，就可启动程序运行。</p>
<p>在运行的过程中，如果发现要运行的程序或要访问的数据不再内存，则向系统发出缺页的中断请求，系统在处理这个中断时，将外存中相应的页面调入内存，使得该程序能够继续运行。</p>
<p>为了能够实现请求调页和页面置换，需要在页表项中增加一些位(<code>bit</code>)，来辅助完成该功能。</p>
<p>![image-20220320174819945](../../../images/ch5 Virtual Memory/image-20220320174819945.png)</p>
<p>访问位或引用位（<code>Reference bit</code>）：如果该页被访问过(包括读写操作)，则设置此位，用于页面置换算法。</p>
<p>修改位（<code>Modified bit (or “dirty bit”)</code>）：表示此页在内存中是否被修改（写）过；当系统回收该物理页面时，根据此位来决定是否把它的内容写回辅存</p>
<p>保护位 <code>Protection bits (RWX)</code>：能否访问该页,, 如只读, 可读写, 可执行等</p>
<p>驻留位或存在位 <code>present/absent bit</code> or <code>resident bit </code>：表示该页是在内存中还是在外存；逻辑页号与物理页帧相对应。</p>
<blockquote>
<p>Reference</p>
<p><a href="https://www.cs.umd.edu/~hollings/cs412/s02/lectures/lect13/lect13.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >Page State</a></p>
<p><a href="https://sites.cs.ucsb.edu/~chris/teaching/cs170/doc/cs170-08.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >Mapping Pages to Page Frames</a></p>
</blockquote>
<p>如图所示：</p>
<ul>
<li>
<p>Virtual memory: 64KB</p>
</li>
<li>
<p>Physical memory: 32KB</p>
</li>
<li>
<p>Page size: 4KB</p>
</li>
<li>
<p>Virtual memory pages: 16</p>
</li>
<li>
<p>Physical memory pages: 8</p>
</li>
</ul>
<p>![image-20220320175528794](../../../images/ch5 Virtual Memory/image-20220320175528794.png)</p>
<p>当虚拟内存页第一项为2，那么代表物理页帧为2的项，公式则为 $vmItme \times page size= 2\times4069=8192$</p>
<h3 id="页式内存管理的处理流程">页式内存管理的处理流程</h3>
<h4 id="什么是缺页中断">什么是缺页中断</h4>
<p>在操作系统中，进程和内核都会通过页表项(<code>PTE</code>)，来访问一个物理页面的，访问一个目前并未被加载在物理内存中的一个页面时，由MMU引发异常，触发缺页中断 <code>Page Fault</code>。通常情况下，缺页中断不能被准确说为是一种异常错误，而是操作系统内存管理的一种机制，通过这一机制可以实现增加程序可用的内存空间。</p>
<h4 id="内存管理中的处理流程">内存管理中的处理流程</h4>
<p>![image-20220320180502614](../../../images/ch5 Virtual Memory/image-20220320180502614.png)</p>
<p>由图可知：</p>
<ul>
<li>第一部，CPU Load内存地址，如果有对页面的引用，首先对该页面的引用将追溯到操作系统（第二步），否则产生 <code>Page Fault</code> 到第四步
<ul>
<li>操作系统查看页表，请求无效则终止，如不在内存中就进行加载到内存中</li>
</ul>
</li>
<li>第二步，找到空闲帧</li>
<li>第三步，使用页面置换算法，从辅存中调度到物理页帧中，换出前修改标记位</li>
<li>第四步，重置页表项标记位为1</li>
<li>第五步，重启导致 <code>Page Fault</code> 的指令</li>
</ul>
<blockquote>
<p>Reference</p>
<p><a href="https://www.bbau.ac.in/dept/dit/TM/Virtual%20Memory%20and%20Demand%20Paging.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >Page Fault</a></p>
</blockquote>
<h3 id="后备存储">后备存储</h3>
<p>后备存储（有时称为辅助存储）是所有其他存储数据的设备的统称：如硬盘</p>
<ul>
<li>一个虚拟地址空间的页面可以被映射到一个文件(在二级存储中)的某个位置</li>
<li>代码段 : 映射到可执行二进制文件</li>
<li>动态加载的共享库程序段 : 映射到动态调用的库文件</li>
<li>其他段 : 可能被映射到交换文件(swap file)</li>
</ul>
<h3 id="虚拟内存性能计算">虚拟内存性能计算</h3>
<p><code>effective memory access time</code> ETA 是指有效的内存访问时间，计算EAT的公式如下：</p>
<p>P：页表命中率</p>
<p>1-P：缺页率</p>
<p>$EAT= P \times hit \quad memory \quad time + (1-P) \times miss \quad memory \quad time. $​</p>
<p>例如：在 TLB 找到页的百分比称为命中率。 80% 的命中率意味着在 80% 的时间在 TLB 中找到所需的页码。 如果搜索 TLB 需要 20 纳秒，访问内存需要 100 纳秒，那么当页码在 TLB 中时，映射内存的访问需要 120 纳秒。</p>
<p>如果在 TLB 中找不到页号（20 纳秒），那么必须首先访问内存中的页表和帧号（100 纳秒），然后访问内存中所需的字节（100 纳秒），总共 220 纳秒。 为了找到有效的内存访问时间，则需要权衡有效的内存访问的概率：</p>
<p>$EAT = 0.80 \times 120 + 0.20 \times 220 = 140 \quad nano seconds$​</p>
<p>例2：已知内存访问时间是10millisecond，缓存访问时间为10microseconds。设，TLB命中率15%，则有效内存访问时间是多少</p>
<p>$EAT = 0.15\times(10+0.001)+(1-0.15)\times(10\times2 + 0.001)$​</p>
<p>例3：</p>
<p>已知TLB命中率为 70%，TLB 访问时间为 30ns，访问主存时间为 90ns，则有效内存访问时间是多少</p>
<p>$0.7 \times (30+90) + (1-0.7) \times (30+90\times2)$​</p>
<p>$0.7\times 120 + 0.3\times210 = 84+63=170$​</p>
<blockquote>
<p>Reference</p>
<p><a href="https://www.cukashmir.ac.in/cukashmir/User_Files/imagefile/DIT/StudyMaterial/OperatingSystemBTech/BTechCSE_3_Rizwana_BTCS304_unit3_B.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >ETA</a></p>
<p><a href="https://stackoverflow.com/questions/18550370/calculate-the-effective-access-time" target="_blank"
   rel="noopener nofollow noreferrer" >calculate the effective access time</a></p>
</blockquote>
<p><a href="https://courses.engr.illinois.edu/cs423/sp2018/slides/15-memory.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >https://courses.engr.illinois.edu/cs423/sp2018/slides/15-memory.pdf</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch4 操作内存管理 - 非连续内存分配</title>
      <link>https://www.oomkill.com/2022/04/ch4-non-contiguous-memory-allocation/</link>
      <pubDate>Tue, 26 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/04/ch4-non-contiguous-memory-allocation/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="overview">overview</h2>
<blockquote>
<p>Q1: 为什么需要非连续内存分配</p>
</blockquote>
<p>连续内存管理 （<code>contiguous memory allocation</code>）, 即 : 操作系统加载到内存以及程序加载到内存中时, 分配一块连续的内存块. 但这种方式会出现碎片问题，而非连续内存分配（<code>Non-contiguous memory allocation</code> ）可以有效的减少碎片（<code>Fragmentation</code>）的出现。</p>
<blockquote>
<p>Q2: 主要的非连续内存分配的管理方法</p>
</blockquote>
<ul>
<li>分段（<code>Segmentation</code>）</li>
<li>分页（<code>Paging</code>）</li>
<li>页表 （<code>Page Table</code>）</li>
</ul>
<h2 id="1非连续内存分配的必要性">1.非连续内存分配的必要性</h2>
<p><strong>连续内存管理的缺陷</strong>：</p>
<ul>
<li>内存利用率较低（<code>memory wastage</code>），在程序运行时分配的内存是增长的，但在进程使用为达到分配大小时，分配的块并未使用，并且也不能给其他进程使用，造成了内存的浪费。</li>
<li>分配给一个程序的物理内存必须是连续的。</li>
<li>碎片化问题</li>
<li>不灵活（<code>inflexibility</code>），当进程或文件使用的内存超出预期时（即：超出分配的内存块大小），将停止并抛出异常，例如：<code>No disk space</code>。</li>
</ul>
<p><strong>非连续内存分配的优点</strong>:</p>
<ul>
<li>一个程序的物理地址空间是非连续的</li>
<li>更好的内存利用和管理，（减少了内存浪费）</li>
<li>允许共享代码与数据(共享库等&hellip;)</li>
<li>支持动态加载和动态链接</li>
</ul>
<p><strong>非连续内存分配的缺点</strong>：</p>
<ol>
<li>建立虚拟地址和物理地址的转换难度大
<ul>
<li>软件方案</li>
<li>硬件方案(采用硬件方案) : 分段 / 分页</li>
</ul>
</li>
</ol>
<h2 id="分段segmentation">分段（segmentation）</h2>
<p>首先 segmentation mechanism需要考虑的问题：</p>
<ul>
<li>程序的分段地址空间</li>
<li>分段寻址方案</li>
</ul>
<h3 id="什么是segmentation">什么是segmentation</h3>
<p>段（<code>segmentation</code>）是一个逻辑单元 (<code>logical unit</code>)，例如：</p>
<ul>
<li>主程序 <code>main program</code></li>
<li>程序（主要是指功能的代码，如一段函数） <code>procedure</code></li>
<li>函数 <code>function</code></li>
<li>方法 <code>method</code></li>
<li>对象 <code>object</code></li>
<li>局部变量和全局变量 <code>local variables</code>, <code>global variables</code></li>
<li>公共块 <code>common block</code></li>
<li>堆 <code>stack</code></li>
<li>符号表 <code>symbol table</code></li>
<li>数组 <code>arrays</code></li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20211219232723274-16412841827931.png" alt="image-20211219232723274" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20211219232741181-16412841956352.png" alt="image-20211219232741181" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>[segmentation的逻辑视图]</center>
<p>可以看到左边是逻辑地址，右边是不连续的物理地址，中间有一个映射机制将两边建立了一个关联关系（<code>ST</code> Segment Table）。通过映射机制将不同的块（如stack，function..）分别映射到内存中的段中。</p>
<h3 id="分段寻址方案">分段寻址方案</h3>
<p>一维逻辑地址与分段的物理地址对应的方法，分段寻址 （<code>Segmentation Addressing modes</code>），逻辑地址由两部分组成，<strong>segment number (==s==) 和 offset (==d==)</strong>。</p>
<ul>
<li><strong>s</strong> 表示段所需的总位数</li>
<li><strong>d</strong> 指定了段大小所需的位数</li>
</ul>
<h4 id="基于硬件的分段管理机制--segmention-hardware">基于硬件的分段管理机制  Segmention hardware</h4>
<p>程序表示为了一个二维地址，但在实际物理内存中是一个一维地址。因此需要将二位地址 （ <code>two-dimensional</code>）映射为一个一维物理地址 (<code>one-dimensional</code>)，这个机制就是段表 （<code>Segment Table</code>）,ST映射了逻辑地址的段号和物理地址的段号。并且段的长度与起始信息也是存放在ST中的。</p>
<p>段表（ST）中的每个条目都有一个<code>base</code>和一个段 <code>limit</code>。==<strong>base</strong>== 包含段所在在内存中的起始物理地址，而==<strong>limit</strong>==指定段的长度。</p>
<p>如图所示，逻辑地址由两部分组成：<code>s</code>和<code>d</code>。<code>s</code> 作为 <code>ST</code> 的 <code>index</code> 。d必须在0和 <code>limit</code> 之间。当超出limit范围是，CPU会产生异常。当 <code>d</code> 合法时，将其添加到 <code>base</code> 以生成地址物理地址。</p>
<p>起始物理地址 = d + base</p>
<p>结束物理地址 = base + limit</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20211219232755022-16412842068243.png" alt="image-20211219232755022" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h2 id="分页paging">分页(Paging)</h2>
<h3 id="overview-1">overview</h3>
<p>本章主要分为两部分：</p>
<ul>
<li>分页地址空间</li>
<li>页寻址方式</li>
</ul>
<p>分页 (<code>Paging</code>) 与 分段 (<code>Segmentation</code>) 都是非连续性内存管理的机制，分段允许进程的物理地址空间不连续；而分页则是比分段较有优势的另一种内存管理方案。</p>
<p><strong>分页的特点</strong>:</p>
<ul>
<li>将每个块划分为固定的页。
<ul>
<li>划分物理内存为固定大小( <code>fixed-sized</code> ) 的块 (<code>block</code>) 称作帧 ( <code>frame</code> ）
<ul>
<li>大小是2的幂, e.g. 512 / 4096 / 8192</li>
</ul>
</li>
<li>逻辑地址相同大小的的块 (<code>blocks</code>) 称作 (<code>Pages</code>)
<ul>
<li>大小是2的幂, e.g. 512 / 4096 / 8192</li>
</ul>
</li>
</ul>
</li>
<li>每个段需要一个页表。</li>
<li>CPU的内存管理单元需要同时支持 分页和分段。</li>
</ul>
<h3 id="帧-frame">帧 Frame</h3>
<p>物理地址 （<code>Physical Address</code>）空间在划分为若干固定大小的块，称为帧。帧由两部分组成，<strong>Frame number(f)</strong> 和 <strong>Frame offset(==d==)</strong></p>
<ul>
<li><strong>Frame number(f)</strong>:  表示物理地址空间的帧所需的位数。</li>
<li><strong>Frame offset(d)</strong>: 表示页中物理地址空间的页大小或页或页偏移量的字数所需的位数。</li>
</ul>
<p>如图所示，物理地址是一个二元组  $(f,d)$，页帧占 $F$ 位，共有 $2^F$ 帧；偏移量 o 占了 $S$ 位（一个帧的大小），共$2^S$ 字节 ，则物理地址 =  $2^S\times f+d$ 。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20211219232803970-16412842156934.png" alt="image-20211219232803970" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<blockquote>
<p><strong>地址计算：16bit的物理地址空间，页帧大小为9bit（512byte）</strong></p>
<ul>
<li>给出物理地址$(f,d) = (3,6)$，求物理地址的位置 。
<ul>
<li>$S=9$，$F=7$， $f=3$ ，$d=6$</li>
<li>套用公式得出，$2^9\times3+6 = 1542$</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20211219232813003-16412842188565.png" alt="image-20211219232813003" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
</blockquote>
<h3 id="页-page">页 Page</h3>
<p>逻辑地址相同大小的的块 (<code>blocks</code>) 称作 (<code>Pages</code>)，</p>
<ul>
<li>页的偏移的大小=帧内偏移的大小</li>
<li>页号 &lt;&gt; 帧号大小</li>
</ul>
<p>Page也有两部分组成，页号和页的偏移。<strong>Page number(==p==)</strong> 和 <strong>Page offset(==d==)</strong>；</p>
<ul>
<li><strong>Page number(p)</strong> 逻辑地址空间中页所需的位数</li>
<li><strong>Page offset(d)</strong>：逻辑地址空间中页偏移量的字数所需的位数。</li>
</ul>
<p>如图所示，一个逻辑地址表示为一个二元组 $(p,d)$，页帧占 $P$ 位，共有 $2^P$ 帧；偏移量 o 占了 $S$ 位 (一个页的大小)，共$2^S$ 字节 ，则物理地址 =  $2^S\times p+d$ 。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20211219232823332-16412842301146.png" alt="image-20211219232823332" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="页的寻址机制">页的寻址机制</h4>
<p>在图中可以看出，逻辑地址是一个连续的地址空间，并且由一个个Page组成，首先CPU寻址，地址分位两块（一个二元组）$(p,d)$，p作为一个<code>index</code> 去查一个<code>page table</code> (以页号为索引的值为帧号) ，以index与base（基地址）作为查找项查找对应的f，$f + (f)d$ 就找到了对应的物理地址。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20211219232835340-16412842404887.png" alt="image-20211219232835340" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20211219232844391-16412842422978.png" alt="image-20211219232844391" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<ul>
<li>页映射到帧</li>
<li>页是连续的虚拟内存</li>
<li>帧是非连续的物理内存</li>
<li>不是所有的页都有对应的帧</li>
</ul>
<h2 id="页表">页表</h2>
<h3 id="overview-2">overview</h3>
<p>页表（<code>page table</code>）结构：页表虚拟内存统用来存储逻辑地址 (<code>Virtual Address</code>) 到物理地址 ( <code>Physical Address</code> ) 映射关系的一种数据结构。</p>
<p><strong>页表的特性</strong>：</p>
<ul>
<li>在页表中，每个映射被称为页表项（<code>Page Table Entries (PTEs)</code>）这个页表项负责逻辑地址到物理地址的转换。</li>
<li>该表存储在页表基址寄存器（<code>PTBR</code> ，``Page-table base register`）</li>
<li>随进程运行状态而动态变化。</li>
</ul>
<p><strong>页表项（<code>PTE</code>） 的组成</strong>：</p>
<ul>
<li>
<p>物理页号（<code>Physical Page Number</code> PPN）</p>
</li>
<li>
<p>DPN（<code>disk page number</code>）的磁盘上的页面</p>
</li>
<li>
<p>帧号</p>
</li>
<li>
<p>标记位</p>
<ul>
<li>脏位/修改位（<code>Dirty Bit</code> (D)）：每个PTE都包含的一个修改位，表示页面自加载后是否已写入。是在操作系统中完成，而不是在硬件中完成的操作。
<ul>
<li>1：表示数据是&quot;脏的（<code>dirty</code>）&quot;，即已写入。</li>
<li>0：数据是“干净的(<code>clean</code>)”，与加载时相同。</li>
</ul>
</li>
<li>存在位/驻留位 (<code>resident bit</code> (R))：每个PTE都包含的一个驻留位，表示逻辑地址是否有一个物理地址与其相对应。
<ul>
<li>1：当逻辑页在物理内存中时，该位被设置为1。</li>
<li>0：如果为0，则访问该虚拟页面将导致页面错误。</li>
</ul>
</li>
<li>引用位 (<code>Eviction Bit</code> ，In x86: <code>Reference Bit</code>)，过去一段时间内是否有对其引用（是否访问过页内的某个存储单元）。存在页表的第二位，在每次访问页面时（读/写），<code>Reference Bit</code>设置为1。
<ul>
<li>1：最近被引用过。</li>
<li>0：从未被引用。</li>
</ul>
</li>
<li>Read/Write Bit</li>
<li>NX Bit</li>
</ul>
</li>
</ul>
<h4 id="页表的转换-translation-process">页表的转换 （<code>translation process</code>）</h4>
<p>CPU的内存单元（<code>MMU</code>， <code>memory management unit</code>）根据程序的page的页号的若干位, 计算出索引值index, 在页表中搜索这个index, 得到的是帧号, 帧号和原本的offset组成物理地址.</p>
<blockquote>
<p><strong>Quick Activity</strong></p>
<p>具有16位地址的计算机系统，物理地址大小32KB，每页大小1024bites，的逻辑地址如何进行转换。</p>
<p>16位地址是0~15，0~9是页内偏移 <code>d</code>, 10~15是页号。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20211227232825378-16412842514469.png" alt="image-20211227232825378" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
</blockquote>
<h4 id="页式存储管理机制存在的问题">页式存储管理机制存在的问题</h4>
<ul>
<li>内存访问性能问题(<code>Performance Issues</code>)：内存访问性能，虚拟地址访问需要2次内存访问
<ul>
<li>第一次获取页表项</li>
<li>第二次访问数据</li>
</ul>
</li>
<li>页表大小问题：页表可以非常大。
<ul>
<li>页表可能很大
<ul>
<li>如图实例，32K内存，每页1K，即32个页表项，如果每项占4byte，则为128byte。</li>
</ul>
</li>
<li>对于具有64位地址和1024字节页的机器，页表的大小是多少？
<ul>
<li>页：$2^{64}$，页的大小：$2^{10}$，需要建立页表的大小：$2^{64} \div 2^{10} = 2^{54}$</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>如何解决上述问题(what to do)：</p>
<ul>
<li>Caching  缓存，solution：快表，利用缓存机制减少对页表的访问。</li>
<li>Indirection 间接访问，solution：多级页表，通过间接引用的方式来减少页表的长度。</li>
</ul>
<h3 id="快表-translation-look-aside-buffers-tlbs">快表 translation look-aside buffers (TLBs)</h3>
<p>对于上述的性能问题，有效的解决方法是对页表项（<code>PTE</code>）的高速缓存，成为快表（<code>translation look-aside buffer (TLB)</code>）。快表就是将近期访问过的页表项在CPU内部使用硬件缓存，即将近期访问过的项缓存到CPU中；TLB由内存管理单元（MMU）管理</p>
<center>[未使用页表的情况]</center>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20211220224356302-164128426198510.png" alt="image-20211220224356302" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>[TLB mechanics]</center>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20211220223035884-164128427175911.png" alt="image-20211220223035884" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>如图所示，如果TLB命中，则直接可以获取到物理地址，如果TLS未命中，则同时将内容缓存到CPU中的TLB。</p>
<h3 id="多级页表">多级页表</h3>
<p>多级页表是通过间接引用的方式将页号分成多级。多级页表是树状结构，用于保存页表。</p>
<p>例子，考虑两个级别的页表再次在具有$2^{12}=4$ KB Page 的32-bit架上，</p>
<blockquote>
<p>Q1：第二级页面表格有多少位？</p>
<ul>
<li>$4KB\div4B = 1024=2^{10}$</li>
</ul>
<p>Q2：顶级页表有多少位？</p>
<ul>
<li>$32-12-10=10$</li>
</ul>
</blockquote>
<p>10bits 表示0级索引，10bits表示1级索引，12bits表示页面内的偏移量。每一个子页表的开头作为上一个页表的页号物理页号填写到上一级页表当中。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20211220225010394-164128428376712.png" alt="image-20211220225010394" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20211220233116354-164128428562713.png" alt="image-20211220233116354" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="多级页表计算题">多级页表计算题</h4>
<p>一个32位操作系统中进程的虚拟地址空间可达到4GB，假设用户地址空间为2GB，页面大小为4KB，</p>
<p>Q1：则一个进程最多可以有（）页。</p>
<ul>
<li>$2G = 2\times 2^{10} \times 2^{10} \times 2^{10} = 2^{31} $​</li>
<li>$4KB = 2^2 \times 2^{10} = 2^{12}$​​</li>
<li>即 $2^{31}\div2^{12} = 2^{19}$​​</li>
</ul>
<p>Q2：若用4个字节表示一页的物理页号，则页表本身就占用（）？</p>
<ul>
<li>$4B\times 2^{19} = 2^2  \times 2^{19} = 2^{21} = 2M	$</li>
</ul>
<p>Q3：即需要（）个页面存放。</p>
<ul>
<li>$2M\div4KB = 2^{21}\div2^{12} = 2^{9} = 512$</li>
</ul>
<h3 id="反置页表">反置页表</h3>
<p>使用页寄存器(<code>Page Registers</code>)，又名反置页表(<code>Inverted page table (IPT)</code>)，是为了减少所占用存储空间的一种做法。使用反置页表的原因是在大地址空间(<code>64-bits</code>)的系统上，多级页表会变得繁琐，例如，逻辑地址空间增长速度快于物理空间地址。（以页帧号为索引，页表号为内容 ）</p>
<p>此时产生一个问题：如何查找？（frame number是索引，pagenumber是内容）。基于关联存储器（<code>associative memory</code>）的方案：</p>
<p>关联存储器也可以并行的查找，与寄存器可以同时比较，如果找到匹配值，则输出与键对应的值。</p>
<ul>
<li>如果帧数较少，页寄存器可以被放置在关联内存中</li>
<li>在关联内存中查找逻辑页号</li>
</ul>
<p>关联存储器的代价：</p>
<p>如果帧数较少，页寄存器可以被放置在关联内存中；在关联内存中查找逻辑页号：</p>
<ul>
<li>成功，则拿到帧号</li>
<li>失败，也错误异常（<code>page fault</code>）</li>
</ul>
<p>限制因素：很难在单个时钟周期完成；耗电。</p>
<p>IPT的具体思路为，不让页表与逻辑地址空间的大小对应，而是让页表与物理地址空间大小相对应，每个帧都与一个寄存器相关联，通常该寄存器包含：</p>
<ul>
<li>引用位(<code>Residence bit</code>）：标记该帧(<code>Frame</code>) 是否被进程占用。</li>
<li>占用页号(<code>Occupier</code>)：页帧对应的页号</li>
<li>保护位(<code>Protection bits</code>)：约定页的访问方式(R/W)</li>
</ul>
<blockquote>
<p><strong>Quick Activity</strong></p>
<p>系统有</p>
<ul>
<li>物理内存大小：16MB( $4096 \times 4096 = 4K \times 4K = 16MB $ )</li>
<li>页大小为：4KB( $4096bytes = 4KB $​​​​)</li>
<li>页帧数为4K(4096)。</li>
<li>假定每一个页寄存器(<code>page resigter</code>)占8bytes， $4096 \times 8 = 32Kbytes$。</li>
</ul>
<p>那么页寄存器占用的开销为： $32Kb\div 16Mb \approx 0.2%$​​。此时和虚拟地址没有关联了。创建​的进程的物理地址就与页寄存器对应。</p>
</blockquote>
<p><strong>页寄存器方案的优缺点</strong>：</p>
<ul>
<li>优点：
<ul>
<li>页表大小相对于物理内存而言很小</li>
<li>页表大小与逻辑（虚拟）地址无关</li>
</ul>
</li>
<li>缺点：
<ul>
<li>页表信息对调后，需要帧号可以找到页号</li>
<li>在页寄存器中搜索逻辑地址中的页号</li>
</ul>
</li>
</ul>
<h4 id="基于hash计算的反向页表-hash-table">基于hash计算的反向页表 hash table</h4>
<p>hash table，一个数学计算的方法。通过hash计算输入为page number，输出为 frame number。由图所示</p>
<ul>
<li>Virtual Page Number (VPN): <code>p</code>, <code>q</code></li>
<li>Page Frame Number (PFN):  <code>r</code></li>
<li>Offset: <code>d</code></li>
<li>Hash Function: <code>h(x)</code></li>
<li>Hashed Page Table with schema <code>(key, VPN, PFN, Pointer to next entry with key)</code> 每一个页表项</li>
</ul>
<p>hash table方式的工作流</p>
<ul>
<li>
<p>操作系统从CPU拿到 虚拟内存 <code>p</code>，并执行 <code>h（p）</code> 以获取 same_key。</p>
</li>
<li>
<p>操作系统查找哈希页表中的第一个条目，其中 key = same_key，并根据第一个页表的 虚拟内存页号 <code> p</code>。(根据第一个项中的指针来查找第二个项。它知道第二个项具有相同的键 = same_key，因为多级页表工作流是如此。操作系统根据第二项的页表号字段检查p。</p>
</li>
<li>
<p>操作系统从第二个条目中获取帧号 <code>r</code>。<code>r</code> 对应于虚拟页号 <code>p</code> 的正确物理帧号；操作系统使用 页帧<code>r</code>  + 偏移量 <code>d</code> 在物理内存中查找它想要的物理地址。</p>
</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220104161937728.png" alt="image-20220104161937728" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>由图可以看出，为了提高效率，可以对hash函数增加一个参数 <code>pid</code> ，可以作为输入，来设计一个hash函数，算出对应的frame number。这种可以很好的解决映射的开销。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20211228221115112-164128430524414.png" alt="image-20211228221115112" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="段页式存储管理">段页式存储管理</h3>
<p>段页式存储管理机制 ( <code>Segmented Paging</code> )，是从页式与段式两种技术中获得最佳特性，纯分段不是很流行，并且在许多操作系统中都没有使用。但是，分段可以与分页相结合。段式存储在内存保护方面有优势，页式存储在内存利用和转移到后备存储方面有优势。</p>
<p>段页式存储管理机制是在段式存储的基础上给每一个段加一级页表。即，主存被划分为可变大小的段，这些段又被进一步划分为固定大小的页，此时就有三个定义词<code>Definitions </code></p>
<ul>
<li>段号 **Segment Number **</li>
<li>页号 **Page Number **</li>
<li>页偏移 **Page Offset **</li>
</ul>
<p>如图所示，通过为每个段创建页表，可以减小页表的大小（要实现这一点，需要硬件支持），CPU提供的地址现在将被划分为段号、页号和偏移量。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/Virtualaddresswithsegmentnoandpageno-164128431474015.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>段页式存储机制工作流如图所示：</p>
<p>CPU生成一个逻辑地址分为两部分：段号和段偏移量。段偏移必须小于段限制。偏移量又分为页码和页偏移。要映射页表中的确切页码，请将页码添加到页表库中。带有页帧号+页偏移组成了实际被映射的物理地址。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/os-segmented-paging2.png" alt="os Segmented Paging" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>通过只想相同的页表基址，时间进程间的段共享</p>
<p><a href="https://www.cs.utexas.edu/users/witchel/372/lectures/15.VirtualMemory.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >https://www.cs.utexas.edu/users/witchel/372/lectures/15.VirtualMemory.pdf</a></p>
<p><a href="https://www.pvpsiddhartha.ac.in/dep_it/lecture%20notes/OS/unit4.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >https://www.pvpsiddhartha.ac.in/dep_it/lecture%20notes/OS/unit4.pdf</a></p>
<p><a href="https://www.studytonight.com/operating-system/difference-between-paging-and-segmentation" target="_blank"
   rel="noopener nofollow noreferrer" >https://www.studytonight.com/operating-system/difference-between-paging-and-segmentation</a></p>
<p><a href="https://www.utc.edu/sites/default/files/2021-04/2800-lecture8-memeory-management.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >https://www.utc.edu/sites/default/files/2021-04/2800-lecture8-memeory-management.pdf</a></p>
<p><a href="https://www.geeksforgeeks.org/paging-in-operating-system/?ref=lbp" target="_blank"
   rel="noopener nofollow noreferrer" >https://www.geeksforgeeks.org/paging-in-operating-system/?ref=lbp</a></p>
<p><a href="https://cw.fel.cvut.cz/old/_media/courses/ae3b33osd/osd-lec6-14.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >https://cw.fel.cvut.cz/old/_media/courses/ae3b33osd/osd-lec6-14.pdf</a>
<a href="https://www.inf.ed.ac.uk/teaching/courses/os/slides/10-paging16.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >https://www.inf.ed.ac.uk/teaching/courses/os/slides/10-paging16.pdf</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch3 操作内存管理 - 连续内存分配</title>
      <link>https://www.oomkill.com/2022/04/ch3-contiguous-memory-allocation/</link>
      <pubDate>Mon, 25 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/04/ch3-contiguous-memory-allocation/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="一-计算机体系结构及内存分层体系">一 计算机体系结构及内存分层体系</h2>
<p>1.计算机硬件体系结构大致分为</p>
<ul>
<li>CPU，完成程序的执行控制</li>
<li>主存 （<code>main memory</code>），放置程序代码和数据</li>
<li>I/O（外）设备，配合程序工作。
<img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220425192206925.png" alt="image-20220425192206925" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></li>
<li>2.内存分层体系（金字塔结构)</li>
</ul>
<p>什么是内存结构：CPU所访问的指令和数据在什么地方。</p>
<p>第一类：位于CPU内部，操作操作系统无法直接进行管理的，寄存器，cache；特点，速度快，容量小</p>
<p>第二类：主存或物理内存，主要用来放置操作系统本身及要运行的代码；其特点是，容量比cache要大很多，单速度交于cache要慢一些。</p>
<p>第三类：磁盘，永久保存的数据及代码，当对于主存要慢，容量比主存大很多。</p>
<p>操作系统的作用可以将数据访问的速度（cache与内存）与存储的大小（硬盘）很好的融合在一起</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220425192237300.png" alt="image-20220425192237300" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" />
3.OS管理内存时需要完成的目标</p>
<p>① 抽象：逻辑地址空间（将物理内存，外设等抽象成逻辑地址空间，只需要访问对应地址空间)</p>
<p>② 保护（独立）：操作系统完成隔离机制实现，独立地址空间（每段程序执行时，不受其他程序的影响）</p>
<p>③ 共享：进程间安全，可靠，有效，进行数据传递，访问相同的内存。</p>
<p>④ 虚拟化：更多的地址空间（利用磁盘的空间)
<img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220425192251895.png" alt="image-20220425192251895" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>4.需要完成在操作系统中管理内存的不同方法</p>
<ul>
<li>
<p>操作系统层面</p>
</li>
<li>
<p>程序重定位</p>
</li>
<li>
<p>分段</p>
</li>
<li>
<p>分页</p>
</li>
<li>
<p>虚拟内存</p>
</li>
<li>
<p>按需分页虚拟内存</p>
</li>
<li>
<p>硬件层面</p>
<ul>
<li>必须知道内存架构</li>
<li>MMU(内存管理单元)：处理CPU的内存访问请求</li>
</ul>
</li>
</ul>
<h2 id="二-地址空间地址生成">二 地址空间&amp;地址生成</h2>
<ul>
<li>
<p>地址空间的定义</p>
</li>
<li>
<p>地址生成器</p>
</li>
<li>
<p>地址安全检查</p>
<h3 id="1内存地址的定义">1.内存地址的定义</h3>
</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220425192335531.png" alt="image-20220425192335531" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>① 物理内存地址：硬件支持的地址空间，如主存（内存）和硬盘，由硬件完成管理和控制
② 逻辑内存地址：一个程序运行时所需要的内存范围。</p>
<hr>
<p>两者间的关系：逻辑地址空间最终是一个存在的物理地址空间，两者间的映射关系是由操作系统来管理的</p>
<hr>
<h3 id="2逻辑地址生成过程把代码转化为计算机能理解语言">2.逻辑地址生成过程（把代码转化为计算机能理解语言）</h3>
<p>一段代码运行→编译→汇编语言→机器语言→产生链接文件→将硬盘中程序载入到内存当中运行（完成逻辑地址的分配）</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220425192353658.png" alt="image-20220425192353658" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>如C中变量的名字，函数的位置，为逻辑地址。</p>
<h3 id="3物理地址生成逻辑地址对应的物理地址的过程">3.物理地址生成（逻辑地址对应的物理地址的过程）</h3>
<ul>
<li>
<p>CPU方面 MMU表示映射关系</p>
<ul>
<li>① CPU ALU <code>Arithmetic logic unit</code> 发出请求，为逻辑地址</li>
<li>② CPU MMU <code>Memory management unit</code> 查找逻辑地址映射表，不存在会去内存中找</li>
<li>③ 控制器提出内存请求（需要的内容，内容即指令）</li>
</ul>
</li>
<li>
<p>内存方面</p>
<ul>
<li>④ 内存通过bus发送物理内存地址的内容给CPU</li>
</ul>
</li>
<li>
<p>OS方面
建立逻辑地址和物理地址之间的映射关系（需在前四部前将映射管理建立好）</p>
</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220425194557713.png" alt="image-20220425194557713" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="4-内存安全监测检查运行的内存是否在对应内存空间范围内">4. 内存安全监测：检查运行的内存是否在对应内存空间范围内</h3>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220425194611872.png" alt="image-20220425194611872" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>操作系统确保程序的有效访问的地址空间，==起始地址==与==长度==（基址寄存器和界限寄存器），也是操作系统所建立和维护的对应的表。</p>
<h2 id="三连续式内存分配内存碎片与分区的动态分配">三、连续式内存分配：内存碎片与分区的动态分配</h2>
<ul>
<li>内存碎片问题</li>
<li>分区动态分配
<ul>
<li>第一适配</li>
<li>最佳适配</li>
<li>最差适配</li>
</ul>
</li>
<li>压缩式碎片整理</li>
<li>交换式碎片整理</li>
</ul>
<h2 id="1内存碎片问题">1.内存碎片问题</h2>
<p><em>什么是碎片？</em> 为程序分配空间后有一些无法被利用的空闲空间，这就是内存碎片。</p>
<p><em>碎片的种类：</em></p>
<ul>
<li>外部碎片：在分配单元间未使用的内存（没分配给程序的那块）</li>
<li>内部碎片：在分配单元中未使用的内存（分配给程序之后，程序无法使用）</li>
</ul>
<p><img loading="lazy" src="../Library/Application%20Support/typora-user-images/image-20211216172522934.png" alt="image-20211216172522934" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="2分区的动态分配">2.分区的动态分配</h3>
<p>操作系统为了管理空闲与非空闲空间，有对应的内存分配算法：</p>
<ul>
<li>首次适配 <code>First-Fit</code></li>
<li>最优适配 <code>Worst Fit</code></li>
<li>最佳适配 <code>Best Fit</code></li>
</ul>
<table>
<thead>
<tr>
<th>sort</th>
<th>First-Fit</th>
<th>Worst Fit</th>
<th>Best Fit</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>overview</strong></td>
<td>空闲分区链首开始查找，直至找到一个能满足其大小要求的空闲分区为止。然后再按    照作业的大小，从该分区中划出一块内存分配给请求者，余下的空闲分区仍留在空闲分区链中。</td>
<td>最坏适应算法与最佳适应算法的排序正好相反，它的队列指针总是指向最大的空闲区，在进行分配时，总是从最大的空闲    区开始查寻；<code>Worst fit</code> 会按大小递减的顺序形成空闲区链，分配时直接从空闲区链的第一个空闲区中分配</td>
<td>寻找整个空间中最适合的的空间块（比分配请求的大小要大，但其差值是最小的）</td>
</tr>
<tr>
<td></td>
<td></td>
<td><img src="../Library/Application%20Support/typora-user-images/image-20211216182201177.png" alt="image-20211216182201177" style="zoom: 50%;" /></td>
<td><img loading="lazy" src="../Library/Application%20Support/typora-user-images/image-20211216174516469.png" alt="image-20211216174516469" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></td>
</tr>
<tr>
<td><strong>benefit</strong></td>
<td>该算法倾向于使用内存中低地址部分的空闲区，在高地址部分的空闲区很少被利用，从而保留了高地址部分的大空闲     区。显然为以后到达的大作业分配大的内存空间创造了条件。</td>
<td>给文件分配分区后剩下的空闲区不至于太小，产生碎片的几率最小，对中小型文件分配分区操作有利</td>
<td>每次分配给文件的都是最合适该文件大小的分区，避免吧大空间块拆散</td>
</tr>
<tr>
<td><strong>defect</strong></td>
<td>不确定性<br/>   容易产生外碎片，（低地址部分不断被划分，留下许多难以利用、很小的空闲区，而每次查找又都从低地址部分开始，会增加查找的开销。)</td>
<td>重新分配慢<br>产生很多外部碎片<br>易于破坏大的空闲块以致大分区无法被分配</td>
<td><strong>缺点</strong>：内存中留下许多难以利用的小的空闲区。</td>
</tr>
<tr>
<td><strong>require</strong></td>
<td>按地址排序<br/>   分配需要找到合适的分区<br/>   重新分配需要检查，看是否自由分区能合并于相邻的空间分区。<br/></td>
<td>按尺寸排列的空闲块列表<br>分配很快（获得最大的分区）<br>重新分配需要合并相邻的空闲分区，然后调整空闲块列表</td>
<td>需要按尺寸排列好空闲块列表<br/>分配需要寻找适合的分区<br/>重新分配（空闲块利用)需要搜索及合并相邻的空闲分区</td>
</tr>
</tbody>
</table>
<h2 id="四连续式内存分配-contiguous-memory-allocation压缩式与交换式碎片化整理">四、连续式内存分配 (contiguous memory allocation)：压缩式与交换式碎片化整理</h2>
<p>无论采用那种算法，都会产生内碎片<code>internal fragmentation</code> 和外碎片 <code>External fragmentation </code> ，所以需要对这些碎片进行处理使得碎片减少甚至消失。</p>
<ul>
<li>紧致算法 <code>compaction</code>：能够调整内存中运行的程序的位置
<ul>
<li>什么时候做（重定位）</li>
<li>开销</li>
<li><img loading="lazy" src="../Library/Application%20Support/typora-user-images/image-20211216191220714.png" alt="image-20211216191220714" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" />      <img loading="lazy" src="../Library/Application%20Support/typora-user-images/image-20211216191258888.png" alt="image-20211216191258888" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></li>
</ul>
</li>
<li>换入换出 <code>swapping</code>：<code>swapping mechanism</code>，是进程可以临时从主存中交换（或移动）到辅存储（磁盘），并使该内存可供其他进程使用。稍后，系统将进程从辅存交换回主存。
<ul>
<li><img loading="lazy" src="../Library/Application%20Support/typora-user-images/image-20211216194523202.png" alt="image-20211216194523202" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></li>
</ul>
</li>
</ul>
<blockquote>
<p>English Version: <a href="https://www.geeksforgeeks.org/memory-management-in-operating-system/" target="_blank"
   rel="noopener nofollow noreferrer" >https://www.geeksforgeeks.org/memory-management-in-operating-system/</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
