<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Linux on Cylon&#39;s Collection</title>
    <link>https://www.oomkill.com/categories/linux/</link>
    <description>Recent content in Linux on Cylon&#39;s Collection</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 29 Mar 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://www.oomkill.com/categories/linux/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Unix归档模式 Unix ar - 深入剖析与构建deb包</title>
      <link>https://www.oomkill.com/2023/03/deb-package/</link>
      <pubDate>Wed, 29 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2023/03/deb-package/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="deb-概述">deb 概述</h2>
<p>deb包（.deb）是 Debian 和基于 Debian衍生操作系统（如Ubuntu）中使用的一种软件包的格式。deb是一种基于 Unix ar <sup><a href="#3">[3]</a></sup> (<em><strong>Unix archiver</strong></em>) 的归档文件。其中包含二进制文件、配置文件和其他软件所需的资源。deb包可用于安装、升级和卸载软件包。通常，Debian操作系统的用户使用apt（Advanced Package  Tool）等软件包管理器工具来管理deb包。通过这些工具，用户可以轻松下载、安装和管理软件包，而无需手动编译、安装和解决软件包之间的依赖关系。</p>
<h3 id="deb-vs-rpm">deb VS rpm</h3>
<ul>
<li>包的归档格式不同：deb是基于 ar 的归档模式，而RPM是基于 cpio 的归档模式</li>
<li>包的结构不同：deb包要求必须包含一个 <code>DEBIAN</code> 目录；而RPM不需要以来额外的目录结构</li>
<li>包的依赖机制不同：
<ol>
<li>Deb使用epoch，而RPM使用build  number：在Deb中，epoch是一个可选的字段，它允许呈现基准日期之前的先前版本。而在RPM中，build  number表示软件包编译的次数。因此，在Deb中，为了解决版本控制问题，epoch是非常重要的，而在RPM中，则更关注build  number。</li>
<li>Deb使用逆向依赖关系，而RPM使用依赖关系：在Deb中，依赖项是从包本身向外扩展，在解决依赖问题时可以通过逆向依赖关系进行。而在RPM中，则更喜欢使用依赖关系直接指向其他包。</li>
<li>Deb允许代理软件包，而RPM则不允许代理软件包：Deb中，软件包可以使用另一种软件包的代理来提供功能。在RPM中，软件包需要直接引用相关的软件包。这意味着在Deb中，对于版本控制，可以用另一种代理软件包来解决问题，而在RPM中必须直接引用包。</li>
<li>Deb允许多重依赖关系，RPM则不允许：Deb允许使用多个依赖项列表，以便包与不同版本的库兼容。在RPM中，需要在每个包中定义依赖项和其版本，不能使用多重依赖。</li>
</ol>
</li>
</ul>
<h2 id="deb包的分析">deb包的分析</h2>
<h3 id="deb包的结构">deb包的结构</h3>
<p>deb 最重要的是 <strong>控制文件</strong> <code>Control</code> ，该文件记录了deb包与其安装的程序的信息。</p>
<p>在deb包内部包含一组模拟 Linux 文件系统的文件夹，例如 <code>/usr</code>, <code>/usr/bin</code>, <code>/opt</code>等等。  放置在其中一个目录中的文件将在安装期间复制到实际文件系统中的相同位置。  因此，例如将二进制文件放入 <code>&lt;.deb&gt;/usr/local/bin/binaryfile</code> 将被安装到  <code>/usr/local/bin/binaryfile</code>.</p>
<p>对于deb 包的命名是遵循着一个特定的格式：</p>
<pre><code>&lt;name&gt;_&lt;version&gt;-&lt;revision&gt;_&lt;architecture&gt;.deb
</code></pre>
<ul>
<li><code>&lt;name&gt;</code> 构建的deb包名称，如nginx</li>
<li><code>&lt;version&gt;</code> 程序的版本号 ，如1.20</li>
<li><code>&lt;revision&gt;</code> 当前 deb 包的版本号</li>
<li><code>&lt;architecture&gt;</code> 表示构建出的包的操作系统架构，如，amd64、i386</li>
</ul>
<p>如果你构建一个nginx-1.20的arm操作系统下的，那么deb包名格式则为 <code>nginx_1.20-1_arm64.deb</code></p>
<h3 id="control文件-supa-id22asup">control文件 <sup><a id="2">[2]</a></sup></h3>
<p>Deb软件包（.deb文件）中的 控制文件 (<em><strong>control</strong></em>) 包含有关软件包的 <font color="#f8070d" size=3>源码元数据</font> 和 <font color="#f8070d" size=3>二进制元数据 </font>，用于描述例如软件包的名称、版本、描述、作者、许可证和依赖关系等信息。在创建和打包Deb软件包时，必须创建和编辑control文件以包含关于软件包的所有必要信息。</p>
<p>控制文件 (<em><strong>control</strong></em>) 由一个或多节组成，各节之间用空行分隔。解析器可以接受仅由空格和制表符组成的行作为节分隔符，但控制文件应该使用空行。一些控制文件只允许一个节；其他人允许多个，在这种情况下，每个节通常指的是不同的包，控制文件中节的顺序很重要。</p>
<p>而 Control 文件存在两种，一种为 <font color="#f8070d" size=3>源代码包控制文件</font> (<em><strong>Source package control files</strong></em>)，这种类型的控制文件主要用于定义源代码在构建时的一些元数据信息，例如需要构建一个nginx.deb，那么源代码控制文件就是用于描述下载下来的源代码相关的数据，这种文件被放置在目录 <code>debian/control</code>；</p>
<p>另一种为<font color="#f8070d" size=3>二进制包控制文件</font> (<em><strong>Binary package control files</strong></em>)，这部分是控制在nginx编译后制作成deb包的控制文件，这种控制文件被放置在  <code>DEBIAN/control</code>。</p>
<p>另外还存在一种 <font color="#f8070d" size=3>源代码控制文件</font> ( <em><strong>Debian source control files</strong></em> ) ，包含完整的源代码和软件包元数据信息。它们通常存储在软件包的源代码存储库中，供开发人员和维护人员使用。包含在源代码控制文件中的信息包括软件包名称、版本、维护人员、许可证、依赖关系、构建和安装指令集等。</p>
<p>例如下面为 <code>control</code> 文件常见的字段类型：</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Package</td>
<td>&lt;软件包的名称&gt;</td>
</tr>
<tr>
<td>Priority</td>
<td>&lt;软件包的优先级&gt;</td>
</tr>
<tr>
<td>Section</td>
<td>&lt;软件包的分类&gt;</td>
</tr>
<tr>
<td>Version</td>
<td>&lt;软件包的版本&gt;</td>
</tr>
<tr>
<td>Depends</td>
<td>&lt;软件包的依赖关系&gt;</td>
</tr>
<tr>
<td>Architecture</td>
<td>&lt;软件包的体系结构&gt;</td>
</tr>
<tr>
<td>Maintainer</td>
<td>&lt;软件包的维护者&gt;</td>
</tr>
<tr>
<td>Description</td>
<td>&lt;软件包的描述&gt;</td>
</tr>
<tr>
<td>Rules-Requires-Root <sup><a id="1">[1]</a></sup></td>
<td>Rules-Requires-Root是Debian软件包中一个可选的控制文件，定义了软件包在安装和运行时是否需要超级用户权限；No/Yes</td>
</tr>
<tr>
<td>Standards-Version:</td>
<td>deb包 控制文件 中的一个元素，用于指定软件包所遵循的标准和规范的版本号。该字段的值应该是一个数字，例如：“3.9.8”,  “2.3.0.0”</td>
</tr>
</tbody>
</table>
<p>其中，上面给出的通常是必须指定的字段，如一个control 文件必须包含 <code>Package</code> 、<code>Priority</code>、<code>Section</code>、<code>Version</code>、<code>Architecture</code>、<code>Maintainer</code> 和<code>Description</code> 。由于等 deb软件包通常都安装在系统上，在 control 文件中指定软件包的依赖关系非常重要。这可通过Depends字段完成。</p>
<p>例如下面是一个 control 文件的示例</p>
<pre><code class="language-conf"># 源代码控制文件
Source: nginx
Maintainer: root &lt;root@debian-template&gt;
Section: comm
Priority: optional
Homepage: https://nginx.org

# 二进制控制文件
Package: nginx
Version: 1.22.1
Architecture: amd64
Standards-Version: 1.0.0
Build-Depends: debhelper-compat (= 13)
Description: Nginx HTTP server Nginx (&quot;engine x&quot;) is a web server created by Igor Sysoev. It is known for its high performance, stability, and low resource consumption.
</code></pre>
<h3 id="rules文件-supa-id55asup">rules文件 <sup><a id="5">[5]</a></sup></h3>
<h4 id="rules文件的规范">rules文件的规范</h4>
<p>rules文件在deb中被成为 主要构建脚本 (<em><strong>Main building script</strong></em>)，这个文件必须是一个可执行的Makefile。它包含了特定于包的源代码（如果需要）和构建一个或多个二进制包的指令。</p>
<p>debian/rules文件 必须以 <code>#!/usr/bin/make  -f</code> 开头，这个声明是为了通过调用其名称而不是显式调用make来调用它。也就是说，调用 <code>make -f debian/rules  args...</code> 或 <code>./debian/rules args...</code> 必须产生相同的行为。</p>
<p>在没有使用其他方法的充分理由的情况下，实现Debian软件包构建过程的推荐方式是使用dh工具。这包括debian/rules构建脚本的内容。dh是Debian中最常见的封装辅助工具。使用它通常可以节省遵守本文档中规则的工作，因为dh将自动实现许多规则而无需明确的指示。</p>
<p>rules 文件内置了一些阶段，这标志着整个源码包构建的过程；如 debian/rules 必须由：clean、binary、binary-arch、binary-indep、build、build-arch 和 build-indep，如果通过 <code>dpkg-buildpackage</code> 构建时，这些阶段则是调用的阶段。</p>
<p>需要注意的一点是，由于交互式 debian/rules 脚本无法自动编译该软件包，也使其他人难以复制相同的二进制软件包，因此所有必需的阶段都必须是非交互式的。它还遵循这些阶段所依赖的任何阶段也必须是非交互式的。</p>
<h4 id="rules文件的构建过程">rules文件的构建过程</h4>
<p>通俗来说，rules文件是一个将源码包转换为二进制包的一个构建模式，首先，binarey二进制包写入解压后的源码包的父目录。其次，所需的目标可以写入 /tmp、/var/tmp 和 TMPDIR 环境变量指定的目录，但不得依赖于其中任何一个的内容。</p>
<p>这个限制旨在防止源代码包构建创建和依赖于其外部状态，从而影响多个独立的重建过程。特别地，所需的目标不能尝试写入 HOME 目录。</p>
<p>rules文件的过程，也是阶段：</p>
<ul>
<li><em><strong>build</strong></em> (required)：该阶段应该执行软件包的所有配置和编译操作，例如 make，这个阶段执行前，会先运行 <code>clean</code> 阶段</li>
<li><em><strong>build-indep</strong></em> 和 <em><strong>build-arch</strong></em> (required)
<ul>
<li>build-arch (required)：该阶段必须执行生成所有与架构（<em><strong>architecture</strong></em>）有关的二进制包，例如 make intall 好的 x86 的二进制文件</li>
<li>build-indep (required)： 该阶段执行生成所有与 架构（<em><strong>architecture</strong></em>）无关的二进制包操作，所需的所有配置和编译操作。build 阶段应该依赖于这些阶段，或者采取与调用这些阶段相同的操作，</li>
<li><code>build-arch</code> 和 <code>build-indep</code> 不能执行任何可能需要 root 权限的操作。</li>
<li>通俗来讲，这两个阶段会被用于操作构建完的事情，对于rpmbuild，这里操作就是%files的操作了。</li>
</ul>
</li>
<li><em><strong>binary</strong></em> (required), <em><strong>binary-arch</strong></em> (required), <em><strong>binary-indep</strong></em> (required)：
<ul>
<li><em><strong>binary</strong></em>：该阶段必须是用户从此源代码包生成二进制包所需的全部内容。它分为两个部分：binary-arch用于生成特定架构的二进制包，binary-indep用于生成其他类型的二进制包</li>
<li><em><strong>binary-*</strong></em> 阶段都应该依赖于 build 阶段或适当的 build-arch 或 build-indep 阶段，以便在没有构建该软件包时构建它。然后使用 dpkg-gencontrol 创建其控制文件以及<code>dpkg-deb</code> 构建成一个二进制包，并将它们放置在顶级目录的父目录中（即你执行构建的目录的上级），以创建相应的二进制包。</li>
<li><em><strong>binary-arch</strong></em> 和 <em><strong>binary-indep</strong></em> 两个阶段必须要存在。如果其中一个阶段无事可做（如果源代码仅生成单个二进制包，无论是否架构相关，始终是如此），它仍必须存在并始终成功。</li>
<li>根据Rules-Requires-Root字段的值的配置，binary阶段可能需要作为root用户调用。</li>
</ul>
</li>
<li><em><strong>clean</strong></em> (required)：该阶段将撤消 <em><strong>build</strong></em> 和 <em><strong>binary</strong></em> 阶段可能产生的所有效果，除了它应该保留在上次运行 <em><strong>binary</strong></em>  阶段时在父目录中创建的任何输出文件。</li>
<li><em><strong>patch</strong></em> (optional)：此阶段执行所需的任何其他操作，以使源代码包准备好进行编辑（解包其他上游归档文件、应用补丁等）</li>
</ul>
<p>这些阶段执行构建的工作目录，与deb包的工作目录不同，他的工作目录为当前目录作为包的根目录来使用，有一点需要注意的是，这里的架构的觉得为 dpkg-architecture 命令决定的，在不同架构机器上构建则为不同的架构的包</p>
<h3 id="工作目录">工作目录</h3>
<p>在构建deb软件包（.deb文件）时，通常需要将软件包的文件和目录安排在特定的文件目录中，这个特定目录就是打包时的工作目录，通过上面的解释，已知，deb包分为两种 <font color="#f8070d" size=3>源代码包</font> 和 <font color="#f8070d" size=3>二进制包</font>，而两中类型的工作目录不相同。</p>
<p>例如，我们需要构建一个源码软件包，假设为要为一个nginx制作 deb包，那么他的工作目录则为 debian，而control 文件 和 rule 文件则是必须的，<font color="#f8070d" size=3>封包的内容目录</font> 则为控制文件中 <code>Package</code> 配置的名字，这里配置的为 nginx，那么这个deb包封包时寻找的内容则为 <code>debian/nginx</code></p>
<p>在例如，我们需要构建一个二进制软件包，那么他的工作目录为<code> DEBIAN</code>，control文件与 changelog 则是必须的，而<font color="#f8070d" size=3>封包的内容目录</font> 当前目录，也就是 <code> DEBIAN</code>，制作时的控制文件这些不会被封入包中</p>
<p><strong>那么完整的制作流程为</strong>：</p>
<ul>
<li>在源代码目录下创建一个名为nginx的子目录 <code>mkdir debian</code></li>
<li>在nginx目录下创建名为 <code>DEBIAN</code> 的子目录，包含 <code>control</code> 文件，在<code>DEBIAN</code>目录中包含<code>control</code>文件是必须的，因为它是软件包元数据的中心存储库。</li>
<li>例如我们编译完的内容，nginx 的配置文件在 /etc/下，那么这个 etc 则在 nginx 子目录下</li>
<li>在工作目录下创建 rules 文件，这里面写明了构建的命令，例如：
<ul>
<li><code>build</code>：这个部分用于执行编译和构建软件的命令。</li>
<li><code>clean</code>：这个部分用于清除编译输出，以便你可以重新构建软件包。</li>
<li><code>install</code>：这个部分指定了如何将软件安装到目标系统中。</li>
<li><code>binary</code>：这个部分用于在 Debian 软件包中打包二进制文件。</li>
</ul>
</li>
<li>其中该结构中还包含一些钩子脚本文件 <code>debian/p*</code> 而这个  <code>p*</code>  文件的命名是固定的。下面是一些常见的 <code>p*</code> 文件名：
<ul>
<li><code>debian/package.install</code>：定义软件包中需要安装的文件和目录。</li>
<li><code>debian/package.manpages</code>：将软件包中的 man 页面添加到 man 手册中。</li>
<li><code>debian/package.docs</code>：将软件包中的文档添加到系统上的 <code>/usr/share/doc</code> 目录。</li>
<li><code>debian/package.preinst</code>：在软件包安装前执行的脚本。</li>
<li><code>debian/package.postinst</code>：在软件包安装后执行的脚本。</li>
<li><code>debian/package.prerm</code>：在软件包卸载前执行的脚本。</li>
<li><code>debian/package.postrm</code>：在软件包卸载后执行的脚本。</li>
</ul>
</li>
</ul>
<h2 id="实战从0构建一个-deb-包">实战：从0构建一个 deb 包</h2>
<h3 id="准备条件">准备条件</h3>
<p>上面介绍的为deb包的一些基础，作为实战的一些理论知识，下面将以nginx为代表将其制作为deb包；通过前面知识了解到，deb包分为 <font color="#f8070d" size=3>源代码包</font> 和 <font color="#f8070d" size=3>二进制包</font>，那么nginx明显为源代码包，我们就需要按照 源代码包 =》二进制包 这种顺序依次定义，而 debian 提供了一系列的命令可以帮助生成这些文件，我们只需要改写具体的逻辑就可以完成包的制作，如 <code>dh_make</code> , <code>dh_install</code> 等命令。</p>
<p>对于 deb 包的标准，debian 官方有一些列的教程，称为 <em><strong>Debian Policy Manual</strong></em> <sup><a id="4">[4]</a></sup>  ，可以通过这个手册，整个deb包中所需的一些理论知识，控制文件，维护脚本，包间的依赖关系，共享库等进行详细的说明</p>
<h3 id="dh工具">dh工具</h3>
<p>dh <sup><a id="6">[6]</a></sup>（Debhelper）工具是Debian中自带的一个构建deb包的工具集。dh工具包含了一系列的脚本，用于从打包的源代码中自动化生成debian目录下的文件。这些脚本是 <code>debian/rules</code> 文件中的一部分，它们负责处理诸如构建、安装、打包、删除等任务。</p>
<p>dh工具包括多个命令及其选项，更多的 dh 工具可以参考官方</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>dh_make</td>
<td>创建一个基本的在deb包打包时的工作框架</td>
</tr>
<tr>
<td>dh_auto_configure</td>
<td>自动运行 <code>configure</code> 脚本以生成 <code>Makefile</code></td>
</tr>
<tr>
<td>dh_install</td>
<td>将文件复制到正确的deb包的构建目录中，一些常见选项：<br><code>-s</code> 或 <code>--sourcedir=</code>: 指定源代码目录；<br><code>-X</code> 或 <code>--exclude</code>: 排除在安装中不必要的文件；<br><code>-n</code> 或 <code>--noscripts</code>: 在安装软件包时不运行脚本；<br><code>-Z</code>: 表示安装的文件不要在规则中注册；</td>
</tr>
<tr>
<td>dh_builddeb</td>
<td>以 <code>.deb</code> 文件格式构建软件包</td>
</tr>
<tr>
<td>dh_clean</td>
<td>清理debian目录和生成的文件，以确保它们不会在构建时对结果造成影响。</td>
</tr>
<tr>
<td>dh_gencontrol</td>
<td>生产和安装control文件</td>
</tr>
<tr>
<td>dh_installsystemd</td>
<td>安装systemd单元文件</td>
</tr>
</tbody>
</table>
<h4 id="dh_make">dh_make</h4>
<p><code>dh_make</code> 命令是一个用于快速创建 deb 包的命令行工具。它可以根据用户提供的基本信息和软件包源代码自动创建 deb 包的基础结构，包括 <code>debian/</code> 目录和相关文件，如 <code>control</code>、<code>rules</code> 以及 <code>changelog</code> 等文件。DH 表示 Debian 包含 debhelper 建议的目录和文件结构。</p>
<p>在默认情况下，<code>dh_make</code> 命令是交互式的，它会提示你输入一些必要的软件包信息，如软件包名称、版本号、作者、软件许可证等。如果你想非交互方式运行 <code>dh_make</code> 命令，并指定软件包信息，则可以使用 <code>-s</code> 选项。</p>
<pre><code class="language-bash">$ dh_make -s --createorig -f ../{some_package-1.2.3}.tar.gz -p {some_package_1.2.3-1}.deb
</code></pre>
<p>在上述命令中，<code>-s</code> 选项表示以非交互方式运行 <code>dh_make</code> 命令，并将软件包的基本信息作为参数指定。<code>--createorig</code> 选项表示我们想要创建一个原始的源代码包，<code>-f</code> 选项指定软件包源代码的文件名和路径，<code>-p</code> 选项指定要创建的 Debian 软件包的名称和版本号。</p>
<p>而上述命令会提示输入一些基本的详细信息，以便在 <code>debian/control</code> 控制文件中为软件包设置元数据。dh_make 会询问输入软件包的名称、版本、描述、组件、维护人员等信息，是否以这些参数作为构建，如果不需要这部确认可以使用 <code>-y</code> 默认同意</p>
<p>下面是通过 <code>dh_make</code> 构建出的在构建deb包的工作目录，这种方式下可以很明了的理解deb包的结构</p>
<pre><code class="language-bash">$ tree debian/
debian/
├── changelog
├── control
├── copyright
├── manpage.1.ex
├── manpage.sgml.ex
├── manpage.xml.ex
├── nginx.cron.d.ex
├── nginx.doc-base.EX
├── nginx-docs.docs
├── postinst.ex
├── postrm.ex
├── preinst.ex
├── prerm.ex
├── README.Debian
├── README.source
├── rules
├── salsa-ci.yml.ex
├── source
│   └── format
└── watch.ex
</code></pre>
<p>到这里，我们就完成了一个源码包的前提条件的构建，只需要稍微修改控制文件即可，进行后续的二进制包的构建。</p>
<p>这里最终的 控制文件 如下所示：</p>
<pre><code class="language-conf"># 源代码控制文件
Source: nginx
Maintainer: root &lt;root@debian-template&gt;
Section: comm
Priority: optional
Homepage: https://nginx.org

# 二进制控制文件
Package: nginx-d
Version: 1.22.1
Architecture: amd64
Standards-Version: 1.0.0
Build-Depends: debhelper-compat (= 13)
Description: Nginx HTTP server Nginx (&quot;engine x&quot;) is a web server created by Igor Sysoev. It is known for its high performance, stability, and low resource consumption.
</code></pre>
<h3 id="准备rules文件">准备rules文件</h3>
<p>通过上面的rules文件部分介绍，了解到 rules 文件就是一个 Makefile，并且包含三个阶段</p>
<ul>
<li>
<p><strong>clean</strong> &ndash; 删除所有build与binary阶段产生的内容</p>
</li>
<li>
<p><strong>build</strong> &ndash; 编译与构建的步骤</p>
</li>
<li>
<p><strong>binary</strong> &ndash; binary阶段将创建deb包的root目录，这个目录被包含在 <code>debian</code> 目录下，而目录名则为 control 文件中配置的 <code>Package</code> 名字，即 <code>debian/&lt;source package name&gt;</code></p>
</li>
</ul>
<p>这些阶段都通过 <code>dpkg-buildpackage</code> 在构建时被执行，一个rules文件的模板如下</p>
<pre><code class="language-makefile">#!/usr/bin/make -f

clean:
	@# Do nothing

build:
	@# Do nothing

binary:
	@# Do nothing
	dh_gencontrol
	dh_builddeb
</code></pre>
<p>那这个 nginx 的 rules 文件则为下述所示：</p>
<pre><code class="language-make">#!/usr/bin/make -f

# 列出您要編譯的檔案和目錄
export DH_VERBOSE=1

PACKAGE=nginx
UPSTREAM_VERSION=1.22.1

# 設置打包的參數
export DEB_BUILD_MAINT_OPTIONS = hardening=+all

export BUILDDIR_WORK = $(CURDIR)/debian/$(PACKAGE)

export BUILDDIR=$(CURDIR)/debian/tmp

# 定義建立目錄，它會在${CURDIR}/debian/$PACKAGE下創建
debian/$PACKAGE::

%:

# build阶段，将完成软件的编译
build: 
	tar zxf nginx-$(UPSTREAM_VERSION).tar.gz
	# 配置 Nginx 以使用必要的模塊和參數
	cd nginx-$(UPSTREAM_VERSION) &amp;&amp; \
	    ./configure \
	    --conf-path=/etc/nginx/nginx.conf \
	    --pid-path=/var/run/nginx \
	    --sbin-path=/usr/sbin/nginx \
	    --http-log-path=/var/log/nginx/error.log \
	    --error-log-path=/var/log/nginx/access.log \
	    --http-client-body-temp-path=/etc/nginx/ \
		--http-proxy-temp-path=/var/run/nginx/ \
		--http-fastcgi-temp-path=/var/run/nginx/ \
		--http-uwsgi-temp-path=/var/run/nginx/ \
		--http-scgi-temp-path=/var/run/nginx/ \
		--pid-path=/var/run/nginx/nginx.pid \
        --with-http_ssl_module \
		--without-http_gzip_module 
	
	cd nginx-$(UPSTREAM_VERSION) &amp;&amp; make
	# 这里存在一个问题，即 prefix 与 DESTDIR 不要同时写，make install 被安装在哪里
	# 如果配置了prefix 那么则被安装在 prefix/DESTDIR 变成了双重目录
	# 这里不配置 prefix 只配置DESTDIR则会被安装在 deb 包在构建时的工作目录，这里制定了$(BUILDDIR)
	# 将被放置在 $(BUILDDIR)
	cd nginx-$(UPSTREAM_VERSION) &amp;&amp; make install DESTDIR=$(BUILDDIR)

	# 清理
	rm -rf nginx-$(UPSTREAM_VERSION)

clean:
	rm -rf nginx-$(UPSTREAM_VERSION)
	rm -rf $(BUILDDIR)
	rm -rf $(BUILDDIR_WORK)

build-indep:
	# 构建前测试目录
	dh_testdir

build-arch:
	dh_testdir

binary-indep:
	dh_testdir
	
	# 测试是否有root权限
	dh_testroot
	
	# 在 binary 阶段中，执行的安装操作，创建 /etc/nginx目录
	# 这些命令执行的是 install -d
	# 为什么使用 dh tool 而不用install，因为dh tool是rules file的一部分，也就是他默认的工作目录是
	# 构建deb包的工作目录，这里必须是相对目录
	# 而对于第一个的 &quot;/&quot; 与 最后一个 &quot;/&quot; 都不要写，会被自动除虫上
	dh_installdirs etc/nginx
	dh_installdirs var/log/nginx
	dh_installdirs var/run/nginx
	dh_install etc/nginx/* etc/nginx
	dh_install usr/sbin/* usr/sbin
	
	# 这里创建了二进制包的目录结构
	install -d $(BUILDDIR_WORK)/DEBIAN
	
	# dh_gencontrol可以根据源码包的配置来生成二进制包的control文件
	# 底层封装的是 dh_gencontrol -O --file --package=nginx 为二进制包生成
	dh_gencontrol -O --file --package=$(PACKAGE)
	
	# dh_installchangelogs 可以根据源码包中的changelog来生成二进制包的changelog
	# changelog 和 control file是二进制包必须的文件
	# dh_gencontrol -O --file --package=nginx
	# 底层执行的为在 deb 包根目录的/usr/share/doc/nginx 中生成changelog
	# dh_installchangelogs
	#    install -d debian/nginx/usr/share/doc/nginx
	#    install -p -m0644 debian/changelog debian/nginx/usr/share/doc/nginx/changelog.Debian
	dh_installchangelogs
	
	# 这里将修复链接路径及压缩，如果你的一些软连接需要修复时可以使用
	dh_compress


binary: binary-indep
	# dh_builddeb命令将会构建一个二进制包
	# dh_builddeb封装的时dpkg-deb命令
	#   dpkg-deb --build debian/nginx ..
	dh_builddeb

.PHONY: clean binary-indep binary-arch binary install build
</code></pre>
<h3 id="执行构建">执行构建</h3>
<p>通过执行 <code>dpkg-buildpackage -b</code> 来构建二进制源码包</p>
<pre><code class="language-log">	install -d debian/nginx/usr/sbin
	cp --reflink=auto -a debian/tmp/usr/sbin/nginx debian/nginx/usr/sbin/
install -d /root/nginx/debian/nginx/DEBIAN
dh_gencontrol -O --file --package=nginx
	dpkg-gencontrol -pnginx -ldebian/changelog -Tdebian/nginx.substvars -Pdebian/nginx
dpkg-gencontrol: warning: unknown information field 'Version' in input data in package's section of control info file
dpkg-gencontrol: warning: unknown information field 'Standards-Version' in input data in package's section of control info file
	chmod 0644 -- debian/nginx/DEBIAN/control
	chown 0:0 -- debian/nginx/DEBIAN/control
dh_installchangelogs
	install -d debian/nginx/usr/share/doc/nginx
	install -p -m0644 debian/changelog debian/nginx/usr/share/doc/nginx/changelog.Debian
dh_compress
	cd debian/nginx
	chmod a-x usr/share/doc/nginx/changelog.Debian
	gzip -9nf usr/share/doc/nginx/changelog.Debian
	cd '/root/nginx'
dh_builddeb
	dpkg-deb --build debian/nginx ..
dpkg-deb: building package 'nginx' in '../nginx_1.22.1-1_amd64.deb'.
 dpkg-genbuildinfo --build=binary
 dpkg-genchanges --build=binary &gt;../nginx_1.22.1-1_amd64.changes
dpkg-genchanges: warning: unknown information field 'Version' in input data in package's section of control info file
dpkg-genchanges: warning: unknown information field 'Standards-Version' in input data in package's section of control info file
dpkg-genchanges: warning: unknown information field 'Build-Depends' in input data in package's section of control info file
dpkg-genchanges: info: binary-only upload (no source code included)
 dpkg-source --after-build .
dpkg-source: warning: unknown information field 'Version' in input data in package's section of control info file
dpkg-source: warning: unknown information field 'Standards-Version' in input data in package's section of control info file
dpkg-source: warning: unknown information field 'Build-Depends' in input data in package's section of control info file
dpkg-buildpackage: info: binary-only upload (no source included)
</code></pre>
<p>构建完成后，生成的deb包在当前执行命令的父目录中，而生成的文件名遵守了 <code>&lt;name&gt;_&lt;version&gt;-&lt;revision&gt;_&lt;architecture&gt;.deb</code> 这种格式</p>
<pre><code class="language-bash">$ dpkg -c ../nginx_1.22.1-1_amd64.deb
./
./etc/
./etc/nginx/
./etc/nginx/fastcgi.conf
./etc/nginx/fastcgi.conf.default
./etc/nginx/fastcgi_params
./etc/nginx/fastcgi_params.default
./etc/nginx/koi-utf
./etc/nginx/koi-win
./etc/nginx/mime.types
./etc/nginx/mime.types.default
./etc/nginx/nginx.conf
./etc/nginx/nginx.conf.default
./etc/nginx/scgi_params
./etc/nginx/scgi_params.default
./etc/nginx/uwsgi_params
./etc/nginx/uwsgi_params.default
./etc/nginx/win-utf
./usr/
./usr/sbin/
./usr/sbin/nginx
./usr/share/
./usr/share/doc/
./usr/share/doc/nginx/
./usr/share/doc/nginx/changelog.Debian.gz
./var/
./var/log/
./var/log/nginx/
./var/run/
./var/run/nginx/
</code></pre>
<h2 id="troubleshooting">Troubleshooting</h2>
<h3 id="no-upstream-tarball-found">no upstream tarball found</h3>
<pre><code>dpkg-source: error: can't build with source format '3.0 (quilt)': no upstream tarball found at ../nginx_1.22.1.orig.tar.{bz2,gz,lzma,xz}
dpkg-buildpackage: error: dpkg-source -b . subprocess returned exit status 2
</code></pre>
<p>解决：需要和你的构建目录 为上级即 <code>debian</code> 的上级</p>
<h3 id="non-native-package-version-does-not-contain-a-revision">non-native package version does not contain a revision</h3>
<pre><code>dpkg-source: error: can't build with source format '3.0 (quilt)': non-native package version does not contain a revision
</code></pre>
<p>解决：在changelog中定义正确的修订号</p>
<p>Debian 软件包版本号由三个部分组成：Major.Minor.Revision，它们通常定义在软件包的 debian/changelog 文件中。</p>
<p>在 debian/changelog 文件中，每个软件包版本都会记录下来，包括软件包的版本号、构建日期和构建者的姓名和电子邮件等信息，形成一个时间线。每个 Debian 软件包版本号应该遵循 X.Y.Z-r (或 X.Y.Z~rN) 的格式，其中 X.Y.Z 是软件包的版本号，r (或 N) 是软件包的修订号。</p>
<p>用于版本号的changelog文件通常位于软件包源代码的 debian/ 目录中。您可以打开 debian/changelog 文件，找到最近的条目，将其中的版本号中的修订号修改为所需的值，并保存文件。在对 Debian 软件包进行重新打包之前，请确保更新了 debian/changelog 文件，以便反映新版本号的修改。</p>
<p>需要注意的是，当您更改 debian/changelog 文件中的版本号时，请确保更新 debian/control 文件中的软件包版本依赖信息，以便与新的软件包版本号匹配。 这是为了确保软件包依赖关系与实际的软件包版本相匹配，避免在安装和使用软件包时出现问题。</p>
<h3 id="is-not-a-valid-version">is not a valid version</h3>
<pre><code>dpkg-genchanges: error:  is not a valid version
</code></pre>
<p>解决：这个问题是因为制定了 -v 重写了 version 配置，而没有指定具体的版本号</p>
<h3 id="yes-is-invalid-use-binary-targets-instead">&ldquo;yes&rdquo; is invalid; use &ldquo;binary-targets&rdquo; instead</h3>
<pre><code class="language-bash">dpkg-buildpackage: error: Rules-Requires-Root field keyword &quot;yes&quot; is invalid; use &quot;binary-targets&quot; instead
</code></pre>
<p>解决：control 文件的 <code>Rules-Requires-Root</code> 没有yes选项 <sup><a id="8">[8]</a></sup></p>
<h3 id="compatibility-levels-before-5-are-no-longer-supported-level-1-requested">Compatibility levels before 5 are no longer supported (level 1 requested)</h3>
<pre><code class="language-bash">dh: error: Compatibility levels before 5 are no longer supported (level 1 requested)
</code></pre>
<p>这个错误提示是由于 Debian Policy 从 3.9.0 开始不再支持 compat level 4 以及更低级别的设置，需要使用符合 Debian Policy 3.9.0 或更高版本的规范定义包。</p>
<p>如果您在 <code>debian/control</code> 文件中设置了 compatibility level 较低的版本（如 3, 4），则会遇到这个错误。您需要将这个 compatibility level 提升至 5 或以上版本，即在 <code>debian/control</code> 文件中加入以下设置：</p>
<h3 id="unwanted-binary-file-debiandebiandeb">unwanted binary file: debian/debian.deb</h3>
<pre><code class="language-bash">dpkg-source: error: unwanted binary file: debian/debian.deb
dpkg-source: error: detected 1 unwanted binary file (add it in debian/source/include-binaries to allow its inclusion).
dpkg-buildpackage: error: dpkg-source -b . subprocess returned exit status 255
</code></pre>
<p>解决：删除上级目录中多余文件即可</p>
<h3 id="cannot-represent-change-to-xauthority-binary-file-contents-changed">cannot represent change to .Xauthority: binary file contents changed</h3>
<pre><code class="language-bash">dpkg-source: error: cannot represent change to .Xauthority: binary file contents changed
dpkg-source: error: add .Xauthority in debian/source/include-binaries if you want to store the modified binary in the debian tarball
dpkg-source: error: unrepresentable changes to source
</code></pre>
<p>解决：这是因为我直接在家目录操作的，家目录存在一些其他文件，如家目录下的隐藏文件</p>
<h2 id="reference">Reference</h2>
<p><sup id="1">[1]</sup> <a href="https://www.debian.org/doc/debian-policy/ch-controlfields.html#rules-requires-root" target="_blank"
   rel="noopener nofollow noreferrer" ><em>rules-requires-root</em></a></p>
<p><sup id="2">[2]</sup> <a href="https://www.debian.org/doc/debian-policy/ch-controlfields.html" target="_blank"
   rel="noopener nofollow noreferrer" ><em>Control files and their fields</em></a></p>
<p><sup id="3">[3]</sup> <a href="https://zh.wikipedia.org/wiki/Ar_%28Unix%29" target="_blank"
   rel="noopener nofollow noreferrer" ><em>ar (Unix)</em></a></p>
<p><sup id="4">[4]</sup> <a href="https://www.debian.org/doc/debian-policy/index.html" target="_blank"
   rel="noopener nofollow noreferrer" ><em>Debian Policy Manual</em></a></p>
<p><sup id="5">[5]</sup> <a href="https://www.debian.org/doc/debian-policy/ch-source.html#main-building-script-debian-rules" target="_blank"
   rel="noopener nofollow noreferrer" ><em>Main building script</em></a></p>
<p><sup id="6">[6]</sup> <a href="https://man7.org/linux/man-pages/man7/debhelper.7.html" target="_blank"
   rel="noopener nofollow noreferrer" ><em>debhelper(7)</em></a></p>
<p><sup id="7">[7]</sup> <a href="https://github.com/FooBarWidget/debian-packaging-for-the-modern-developer/blob/master/tutorial-2/README.md#debianrules" target="_blank"
   rel="noopener nofollow noreferrer" ><em>Tutorial 2: building a binary package using dpkg-buildpackage</em></a></p>
<p><sup id="8">[8]</sup> <a href="https://www.debian.org/doc/debian-policy/ch-controlfields.html#rules-requires-root" target="_blank"
   rel="noopener nofollow noreferrer" ><em>5.6.31. Rules-Requires-Root</em></a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>长期总结 - Linux性能分析命令</title>
      <link>https://www.oomkill.com/2022/12/performance-command/</link>
      <pubDate>Mon, 12 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/12/performance-command/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="perf-supa-href11asup">perf <sup><a href="#1">[1]</a></sup></h2>
<p><em><strong>perf</strong></em> 是基于内核子系统的Linux的性能计数器，也被称为 <em><strong>perf_events</strong></em>，它提供了为所有事件进行性能分析的框架，<em><strong>perf</strong></em> 由两部分组成：</p>
<ul>
<li>内核系统调用，用于提供对这些性能数据的访问</li>
<li>用户空间工具，用于提供收集，显示分析这些性能数据的用户空间程序</li>
</ul>
<p>由于 perf 是内核的一部分，但要想使用 perf 还需要安装另外一部分，通常情况下安装的版本是Linux内核版本，如操作系统内核版本为 5.10 那么安装 linux-tool 后则为 5.10</p>
<pre><code class="language-bash">$ apt-get install linux-perf

$ perf --version
perf version 5.10.149
</code></pre>
<p><strong>各系统下的包名与安装</strong></p>
<ul>
<li>Ubuntu/Debian: <code>linux-perf | linux-tools</code>  ；<code>apt-get install linux-perf</code></li>
<li>CentOS/Fedora:  <code>perf </code> ；<code>yum install -y perf</code></li>
</ul>
<h3 id="list---列出可用事件描述符">list - 列出可用事件描述符</h3>
<p>使用 perf 子命令 <code>list</code>  可以列出所有的 perf 可测量事件</p>
<pre><code class="language-bash">perf list

List of pre-defined events (to be used in -e):

  branch-instructions OR branches                    [Hardware event]
  branch-misses                                      [Hardware event]
  cache-misses                                       [Hardware event]
  cache-references                                   [Hardware event]
  cpu-cycles OR cycles                               [Hardware event]
  instructions                                       [Hardware event]
  stalled-cycles-backend OR idle-cycles-backend      [Hardware event]
  stalled-cycles-frontend OR idle-cycles-frontend    [Hardware event]

  alignment-faults                                   [Software event]
  bpf-output                                         [Software event]
  context-switches OR cs                             [Software event]
  cpu-clock                                          [Software event]
  cpu-migrations OR migrations                       [Software event]
  dummy                                              [Software event]
  emulation-faults                                   [Software event]
  major-faults                                       [Software event]
  minor-faults                                       [Software event]
  page-faults OR faults                              [Software event]
  task-clock                                         [Software event]

  duration_time                                      [Tool event]

  L1-dcache-load-misses                              [Hardware cache event]
  L1-dcache-loads                                    [Hardware cache event]
  L1-dcache-prefetches                               [Hardware cache event]
  L1-icache-load-misses                              [Hardware cache event]
  L1-icache-loads                                    [Hardware cache event]
  branch-load-misses                                 [Hardware cache event]
  branch-loads                                       [Hardware cache event]
  dTLB-load-misses                                   [Hardware cache event]
  dTLB-loads                                         [Hardware cache event]
  iTLB-load-misses                                   [Hardware cache event]
  iTLB-loads                                         [Hardware cache event]
</code></pre>
<p>list 子命令后还可以加过滤器以查看对应类型的事件，示例：</p>
<pre><code class="language-bash"># 列出TCP相关事件
$ perf list tcp

List of pre-defined events (to be used in -e):


  syscalls:sys_enter_getcpu                          [Tracepoint event]
  syscalls:sys_exit_getcpu                           [Tracepoint event]
  tcp:tcp_destroy_sock                               [Tracepoint event]
  tcp:tcp_probe                                      [Tracepoint event]
  tcp:tcp_rcv_space_adjust                           [Tracepoint event]
  tcp:tcp_receive_reset                              [Tracepoint event]
  tcp:tcp_retransmit_skb                             [Tracepoint event]
  tcp:tcp_retransmit_synack                          [Tracepoint event]
  tcp:tcp_send_reset                                 [Tracepoint event]

# 列出bpf相关事件
$ perf list bpf

List of pre-defined events (to be used in -e):

  bpf-output                                         [Software event]


  bpf_test_run:bpf_test_finish                       [Tracepoint event]
  bpf_trace:bpf_trace_printk                         [Tracepoint event]
  syscalls:sys_enter_bpf                             [Tracepoint event]
  syscalls:sys_exit_bpf                              [Tracepoint event]

# 列出硬件相关事件
$ perf list hardware

List of pre-defined events (to be used in -e):

  branch-instructions OR branches                    [Hardware event]
  branch-misses                                      [Hardware event]
  cache-misses                                       [Hardware event]
  cache-references                                   [Hardware event]
  cpu-cycles OR cycles                               [Hardware event]
  instructions                                       [Hardware event]
  stalled-cycles-backend OR idle-cycles-backend      [Hardware event]
  stalled-cycles-frontend OR idle-cycles-frontend    [Hardware event]
</code></pre>
<h3 id="top---查看系统实时信息">top - 查看系统实时信息</h3>
<p>perf 的 top子命令可以查看CPU的实时信息</p>
<pre><code class="language-bash">$ perf top
  23.69%  [kernel]          [k] mpt_put_msg_frame
  14.27%  [kernel]          [k] read_tsc
  13.34%  [kernel]          [k] asm_sysvec_apic_timer_interrupt
  11.72%  [kernel]          [k] vmware_sched_clock
   5.79%  perf_5.10         [.] 0x00000000002901f4
   5.11%  [kernel]          [k] delay_tsc
   4.87%  [kernel]          [k] native_read_msr
   4.57%  perf_5.10         [.] 0x0000000000284c2d
   3.13%  perf_5.10         [.] 0x0000000000284c1a
   3.09%  [kernel]          [k] native_write_msr
   2.07%  [kernel]          [k] s_show
   1.99%  [kernel]          [k] mpt_interrupt
   1.82%  perf_5.10         [.] 0x0000000000284d46
   1.69%  [kernel]          [k] asm_sysvec_call_function_single
   0.86%  [kernel]          [k] __es_tree_search.isra.0
   0.83%  [kernel]          [k] security_task_free
   0.78%  [vdso]            [.] 0x0000000000000698
   0.38%  perf_5.10         [.] 0x0000000000284d57
</code></pre>
<p>上面的信息的展示类似于 <code>top</code> 命令，从左右到信息为：</p>
<ul>
<li>第一列：与CPU使用率百分比占用的相关函数</li>
<li>第二列：那个库或者进程使用的这个函数</li>
<li>第三列：<strong>[k]</strong> 表示内核空间， <strong>[.]</strong> 表示用户空间</li>
<li>第四列：符号或函数的名称</li>
</ul>
<p>默认情况下 <code>perf top</code> 监控的是所有CPU，也可以使用子选项，例如下表（一些常用的命令参数）</p>
<table>
<thead>
<tr>
<th>Option</th>
<th>describe</th>
</tr>
</thead>
<tbody>
<tr>
<td>-a</td>
<td>监控所有CPU包含空闲值</td>
</tr>
<tr>
<td>-c</td>
<td>收集</td>
</tr>
<tr>
<td>-C</td>
<td>收集指定CPU的样本，后接CPU核心编号</td>
</tr>
<tr>
<td>-d</td>
<td>后接数字，将延迟几秒刷新</td>
</tr>
<tr>
<td>-e</td>
<td>指定特殊的事件，事件通过 <code>perf list</code> 查看</td>
</tr>
<tr>
<td>-F</td>
<td>控制采样的频率</td>
</tr>
<tr>
<td>-p</td>
<td>指定PID的进程的事件信息</td>
</tr>
<tr>
<td>-g</td>
<td>启用 显示调用图记录</td>
</tr>
<tr>
<td>-i</td>
<td>不继承模式，子任务将不继承计数器</td>
</tr>
<tr>
<td>-t</td>
<td>指定线程ID的事件信息</td>
</tr>
<tr>
<td>-u</td>
<td>指定user的事件信息</td>
</tr>
</tbody>
</table>
<p>更多选项可以使用 <code>perf top -h</code></p>
<h3 id="stat---cpu相关统计">stat - CPU相关统计</h3>
<p>使用 perf 子命令 <code>stat</code>  可以对指定命令的CPU性能统计</p>
<pre><code class="language-bash">perf stat &lt;commond&gt;
</code></pre>
<p><strong>查看指定命令的CPU计数器统计信息</strong></p>
<pre><code class="language-bash">perf stat &lt;command&gt;
# 如果需要更详细信息可以跟 -d 选项
perf stat -d &lt;command&gt;
</code></pre>
<p>示例</p>
<pre><code class="language-bash">$ perf stat curl baidu.com

 Performance counter stats for 'curl baidu.com':

             31.09 msec task-clock                #    0.012 CPUs utilized          
                27      context-switches          #    0.868 K/sec                  
                 1      cpu-migrations            #    0.032 K/sec                  
               577      page-faults               #    0.019 M/sec                  
        41,691,320      cycles                    #    1.341 GHz                      (17.63%)
                 0      stalled-cycles-frontend                                     
                 0      stalled-cycles-backend    #    0.00% backend cycles idle    
                 0      instructions              #    0.00  insn per cycle           (82.37%)
     &lt;not counted&gt;      branches                                                      (0.00%)
     &lt;not counted&gt;      branch-misses                                                 (0.00%)

       2.646439514 seconds time elapsed

       0.026403000 seconds user
       0.013201000 seconds sys


Some events weren't counted. Try disabling the NMI watchdog:
	echo 0 &gt; /proc/sys/kernel/nmi_watchdog
	perf stat ...
	echo 1 &gt; /proc/sys/kernel/nmi_watchdog
</code></pre>
<p><strong>查看指定PID的CPU计数器统计信息</strong></p>
<p>统计命令将会直到 ctrl - c 结束</p>
<pre><code class="language-bash">perf stat -p &lt;PID&gt; 
</code></pre>
<p>示例：例如统计一个进程的CPU使用情况</p>
<pre><code class="language-bash">perf stat -p 477
^C
 Performance counter stats for process id '477':

            146.96 msec task-clock                #    0.034 CPUs utilized          
                88      context-switches          #    0.599 K/sec                  
                 8      cpu-migrations            #    0.054 K/sec                  
             4,991      page-faults               #    0.034 M/sec                  
       153,052,247      cycles                    #    1.041 GHz                      (36.77%)
                 0      stalled-cycles-frontend                                       (50.31%)
                 0      stalled-cycles-backend    #    0.00% backend cycles idle      (57.94%)
                 0      instructions              #    0.00  insn per cycle           (63.23%)
                 0      branches                  #    0.000 K/sec                    (49.69%)
                 0      branch-misses             #    0.00% of all branches          (42.06%)

       4.336415211 seconds time elapsed
</code></pre>
<p><strong>只统计缓存信息</strong></p>
<pre><code class="language-bash">perf stat -e LLC-loads,LLC-load-misses,LLC-stores,LLC-prefetches
</code></pre>
<ul>
<li>LLC <em><strong>last-level cache</strong></em> 是指内存分层结构中主内存之前的最后一级</li>
<li>LLC-loads：命中的指标</li>
<li>LLC-load-misses：未命中指标，显示这个周期内尚未处理的比率</li>
<li>LLC-stores</li>
<li>LLC-prefetches：事件发生在的 L2 硬件预取中</li>
</ul>
<p>示例：</p>
<pre><code class="language-bash"># 使用原始 PMC 计数器，例如，计算未暂停的核心周期： 

# 使用原始PMC计数器，例如，计数未改变的核心周期:
perf stat -e r003c -a sleep 5 

# 统计系统范围内每秒的系统调用： 
perf stat -e cycles -e cpu/event=0x0e,umask=0x01,inv,cmask=0x01/ -a sleep 5 

# 统计系统范围内每秒的系统调用：
perf stat -e raw_syscalls:sys_enter -I 1000 -a 

# 按类型计算指定PID的系统调用，直到Ctrl-C结束
perf stat -e 'syscalls:sys_enter_*' -p &lt;PID&gt; 

# 按类型统计整个系统范围内的系统调用，持续 5 秒： 
perf stat -e 'syscalls:sys_enter_*' -a sleep 5 

# 按类型计数整个系统的系统调用，持续5秒:
perf stat -e 'syscalls:sys_enter_*' -a sleep 5

# 记录指定PID进程的调度器事件直到Ctrl-C结束
perf stat -e 'sched:*' -p PID

# 记录指定PID进程的调度器事件，持续10s
perf stat -e 'sched:*' -p PID sleep 10

# 记录整个系统内的ext4事件，持续10s
perf stat -e 'ext4:*' -a sleep 10

# 统计整个系统的块设备 I/O 事件，持续10s
perf stat -e 'block:*' -a sleep 10

# 统计所有 vmscan 事件，每秒打印一份报告：
perf stat -e 'vmscan:*' -a -I 1000
</code></pre>
<h3 id="record---将cpu事件记录到文件">record - 将CPU事件记录到文件</h3>
<p><strong>导出事件记录到文件</strong></p>
<p>perf的子命令 <code>record</code> 是可以将事件记录到 perf.data，例如要CPU周期事件，可以使用record子命令并通过 tag <code>-e</code> 来指定事件名称</p>
<pre><code class="language-bash"># 通过perf list 可以看出 CPU周期事件为 cpu-cycles OR cycles
perf record -e cycles sleep 10
</code></pre>
<p><strong>通过查看文件的记录</strong></p>
<p>结果将保存到 perf.data 文件中，如果需要查看 perf.data 需要使用子命令 <code>report</code> 查看，report 子命令默认查找当前目录下的 perf.data 文件，如果需要指定特定目录的需要使用tag <code>-i</code></p>
<pre><code class="language-bash">perf report -i ./perf.data
</code></pre>
<p><strong>修改样本文件输出的结果格式</strong></p>
<p>report 子命令也可以改变要显示的结果样式，例如想输出为标准输出，可以使用 <code>--stdio</code></p>
<pre><code class="language-bash">$ perf report --stdio
# To display the perf.data header info, please use --header/--header-only options.
#
#
# Total Lost Samples: 0
#
# Samples: 18  of event 'cycles'
# Event count (approx.): 440
#
# Overhead  Command  Shared Object      Symbol              
# ........  .......  .................  ....................
#
    90.91%  sleep    [kernel.kallsyms]  [k] native_write_msr
     9.09%  perf_5.  [kernel.kallsyms]  [k] native_write_msr


#
# (Tip: Order by the overhead of source file name and line number: perf report -s srcline)
#
</code></pre>
<p>如果想显示事件的编号以及对特定列排序可以使用下面域名</p>
<pre><code class="language-bash">$ perf report -n --sort comm,symbol --stdio
# To display the perf.data header info, please use --header/--header-only options.
#
#
# Total Lost Samples: 0
#
# Samples: 18  of event 'cycles'
# Event count (approx.): 440
#
# Overhead       Samples  Command  Symbol                IPC   [IPC Coverage]
# ........  ............  .......  ....................  ....................
#
    90.91%             9  sleep    [k] native_write_msr  -      -            
     9.09%             9  perf_5.  [k] native_write_msr  -      -            


#
# (Tip: Show current config key-value pairs: perf config --list)
#
</code></pre>
<h3 id="script---trace做了什么">script - trace做了什么</h3>
<p>perf 子命令 script 可以trace perf.data 中所有的事件；例如上面的 perf.data 最终两个事件展开为</p>
<p>perf script 子命令也是作为一个后期处理数据的一个命令</p>
<pre><code class="language-bash">$ perf script 
       perf_5.10  2730 28762.537401:          1 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
       perf_5.10  2730 28762.537540:          1 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
       perf_5.10  2730 28762.537670:          1 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
       perf_5.10  2730 28762.537798:          2 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
       perf_5.10  2730 28762.537901:          3 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
       perf_5.10  2730 28762.538003:          4 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
       perf_5.10  2730 28762.538105:          6 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
       perf_5.10  2730 28762.538207:          9 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
       perf_5.10  2730 28762.538320:         13 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
           sleep  2730 28772.542839:         26 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
           sleep  2730 28772.543041:         26 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
           sleep  2730 28772.543233:         26 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
           sleep  2730 28772.543421:         30 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
           sleep  2730 28772.543558:         35 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
           sleep  2730 28772.543683:         41 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
           sleep  2730 28772.543806:         53 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
           sleep  2730 28772.543929:         70 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
           sleep  2730 28772.544065:         93 cycles:  ffffffffbd46b466 native_write_msr+0x6 ([kernel.kallsyms])
</code></pre>
<p>输出显示文件的头信息，例如跟踪何时开始、持续了多长时间、CPU信息以及获取数据的命令。 事件列表在头信息之后。</p>
<p><strong>显示trace的头信息</strong></p>
<p>使用tag <code>--header</code> 可以显示文件的头信息，例如跟何时开始trace、持续的事件、CPU信息以及获取数据的命令。 事件列表在头信息之后。事件头信息是由 <code># ========</code> 包含著的信息</p>
<pre><code class="language-bash"># ========
# captured on    : Tue Dec  6 04:44:38 2022
# header version : 1
# data offset    : 256
# data size      : 11528
# feat offset    : 11784
# hostname : debian-template
# os release : 5.10.0-16-amd64
# perf version : 5.10.149
# arch : x86_64
# nrcpus online : 2
# nrcpus avail : 2
# cpudesc : AMD Ryzen 7 5800U with Radeon Graphics
# cpuid : AuthenticAMD,25,80,0
# total memory : 1996352 kB
# cmdline : /usr/bin/perf_5.10 record -e cycles sleep 10 
# event : name = cycles, , id = { 471, 472 }, size = 120, { sample_period, sample_freq } = 2250, sample_type = IP|TID|TIME|PERIOD, read_forma&gt;
# CPU_TOPOLOGY info available, use -I to display
# NUMA_TOPOLOGY info available, use -I to display
# pmu mappings: software = 1, power = 9, uprobe = 7, cpu = 4, breakpoint = 5, tracepoint = 2, kprobe = 6, msr = 8
# CACHE info available, use -I to display
# time of first sample : 28762.537401
# time of last sample : 28772.544065
# sample duration :  10006.663 ms
# MEM_TOPOLOGY info available, use -I to display
# bpf_prog_info 3: bpf_prog_47dd357395126b0c addr 0xffffffffc00eb59c size 309
# bpf_prog_info 4: bpf_prog_6deef7357e7b4530 addr 0xffffffffc00f2168 size 54
# bpf_prog_info 5: bpf_prog_6deef7357e7b4530 addr 0xffffffffc00f40e0 size 54
# bpf_prog_info 6: bpf_prog_b73cbcf8b8c71a5b addr 0xffffffffc02591c8 size 307
# bpf_prog_info 7: bpf_prog_6deef7357e7b4530 addr 0xffffffffc025b584 size 54
# bpf_prog_info 8: bpf_prog_6deef7357e7b4530 addr 0xffffffffc025db10 size 54
# bpf_prog_info 9: bpf_prog_ee0e253c78993a24 addr 0xffffffffc0534640 size 255
# bpf_prog_info 10: bpf_prog_ce28cc67158d681f addr 0xffffffffc04947f0 size 447
# bpf_prog_info 11: bpf_prog_6deef7357e7b4530 addr 0xffffffffc052fe4c size 54
# bpf_prog_info 12: bpf_prog_6deef7357e7b4530 addr 0xffffffffc0531224 size 54
# cpu pmu capabilities: max_precise=0
# missing features: TRACING_DATA BRANCH_STACK GROUP_DESC AUXTRACE STAT CLOCKID DIR_FORMAT COMPRESSED CLOCK_DATA 
# ========
</code></pre>
<p><strong>导出16进制的原生数据</strong></p>
<p>导出原生数据是ASIIC格式事件信息</p>
<pre><code class="language-bash">$ perf script -D
0x100 [0x50]: event: 1
.
. ... raw event: size 80 bytes
.  0000:  01 00 00 00 01 00 50 00 ff ff ff ff 00 00 00 00  ......P.........
.  0010:  00 00 40 bd ff ff ff ff f7 1d c0 00 00 00 00 00  ..@.............
.  0020:  00 00 40 bd ff ff ff ff 5b 6b 65 72 6e 65 6c 2e  ..@.....[kernel.
.  0030:  6b 61 6c 6c 73 79 6d 73 5d 5f 74 65 78 74 00 00  kallsyms]_text..
.  0040:  00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................

0 0x100 [0x50]: PERF_RECORD_MMAP -1/0: [0xffffffffbd400000(0xc01df7) @ 0xffffffffbd400000]: x [kernel.kallsyms]_text

0x150 [0x78]: event: 1
.
. ... raw event: size 120 bytes
.  0000:  01 00 00 00 01 00 78 00 ff ff ff ff 00 00 00 00  ......x.........
.  0010:  00 10 0a c0 ff ff ff ff 00 00 04 00 00 00 00 00  ................
.  0020:  00 00 00 00 00 00 00 00 2f 6c 69 62 2f 6d 6f 64  ......../lib/mod
.  0030:  75 6c 65 73 2f 35 2e 31 30 2e 30 2d 31 36 2d 61  ules/5.10.0-16-a
.  0040:  6d 64 36 34 2f 6b 65 72 6e 65 6c 2f 64 72 69 76  md64/kernel/driv
.  0050:  65 72 73 2f 73 63 73 69 2f 73 63 73 69 5f 6d 6f  ers/scsi/scsi_mo
.  0060:  64 2e 6b 6f 00 00 00 00 00 00 00 00 00 00 00 00  d.ko............
.  0070:  00 00 00 00 00 00 00 00
</code></pre>
<h3 id="trace---更高性能的strace的替代品">trace - 更高性能的strace的替代品</h3>
<p>trace是linux 3.7 增加的功能，可以用作strace命令的替代品，因为不需要用户-内核空间切换，所以性能将更快</p>
<pre><code class="language-bash"> perf trace &lt;command&gt;
</code></pre>
<p>也可以使用tag <code>-e</code> 来指定仅对指定事件trace</p>
<pre><code class="language-bash">perf trace -e read,write &lt;command&gt;
</code></pre>
<p>可以看到对应事件将只有 read 与 write</p>
<pre><code class="language-bash">$ perf trace -e read,write ls
     0.000 (1					 nginx-1.22.0		       nginx_1.22.0.orig.tar.gz		 perf.data
1.c					 nginx_1.22.0-1.debian.tar.xz  nginx-1.22.0.tar.gz		 perf.data.old
deb-multimedia-keyring_2016.8.1_all.deb  nginx_1.22.0-1.dsc	       paping_1.5.5_x86-64_linux.tar.gz
 0.058 ms): ls/3126 read(fd: 3, buf: 0x7ffcd2548068, count: 832)                          = 832
     0.132 ( 0.034 ms): ls/3126 read(fd: 3, buf: 0x7ffcd2548048, count: 832)                          = 832
     0.232 ( 0.033 ms): ls/3126 read(fd: 3, buf: 0x7ffcd2548028, count: 832)                          = 832
     0.324 ( 0.032 ms): ls/3126 read(fd: 3, buf: 0x7ffcd2548008, count: 832)                          = 832
     0.416 ( 0.032 ms): ls/3126 read(fd: 3, buf: 0x7ffcd2547fc8, count: 832)                          = 832
     0.828 ( 0.048 ms): ls/3126 read(fd: 3, buf: 0x55c4bb555500, count: 1024)                         = 361
     0.907 ( 0.028 ms): ls/3126 read(fd: 3, buf: 0x55c4bb555500, count: 1024)                         = 0
     1.127 ( 0.060 ms): ls/3126 write(fd: 1, buf: 0x55c4bb555500, count: 65)                          = 65
     1.219 ( 0.385 ms): ls/3126 write(fd: 1, buf: 0x55c4bb555500, count: 75)                          = 75
     1.638 ( 0.049 ms): ls/3126 write(fd: 1, buf: 0x55c4bb555500, count: 100)                         = 100
</code></pre>
<h3 id="probe---动态追踪">probe - 动态追踪</h3>
<p>perf probe子命令是可以动态的在linux内核中自定义追踪事件（追踪点），追踪点的运行时可以在被放置任何任何地方，并且每次通过该追踪点时，都可以记录其值。</p>
<p><strong>如何使用 perf probe</strong>？</p>
<p><strong>查看可探测的函数</strong></p>
<p><code>perf probe -F</code> 可以找到可用的追踪点，如果模糊查找可以使用filter</p>
<pre><code class="language-bash">perf probe -F -–filter dev*xmit*
</code></pre>
<p><strong>probe参数</strong></p>
<table>
<thead>
<tr>
<th>Option</th>
<th>describe</th>
</tr>
</thead>
<tbody>
<tr>
<td>-L</td>
<td>显示源代码</td>
</tr>
<tr>
<td>-x</td>
<td>可执行文件的名称或路径</td>
</tr>
<tr>
<td>-l</td>
<td>列出所有probe探测事件</td>
</tr>
<tr>
<td>-k</td>
<td>指定vmlinux文件</td>
</tr>
<tr>
<td>-a</td>
<td>**`&lt;[EVENT=]FUNC[@SRC][+OFF</td>
</tr>
<tr>
<td></td>
<td>EVENT 事件名称</td>
</tr>
<tr>
<td></td>
<td>FUNC  函数名</td>
</tr>
<tr>
<td></td>
<td>+OFF  函数入口的偏移量</td>
</tr>
<tr>
<td></td>
<td>%return 探针位置为函数返回处</td>
</tr>
<tr>
<td></td>
<td>SRC  源代码路径</td>
</tr>
<tr>
<td></td>
<td>RL  相对函数入口处的行号</td>
</tr>
<tr>
<td></td>
<td>AL  在文件内的绝对行号</td>
</tr>
<tr>
<td></td>
<td>ARG:    探测参数（局部变量名 或 <code>kprobe-tracer</code> 参数格式。</td>
</tr>
</tbody>
</table>
<pre><code>perf probe -x tst --add 'out=func%return $retval'
perf record -g -e probe_tst:out -aR ./tst
</code></pre>
<p><strong>一些使用示例</strong></p>
<pre><code class="language-bash"># 添加一个追踪点到linux内核函数tcp_sendmsg()至入口
perf probe --add tcp_sendmsg

# 删除linux内核tcp_sendmsg()函数上的追踪点
perf probe -d tcp_sendmsg

# 列出现有的追踪点
perf probe -l

# 添加一个追踪点到linux内核函数tcp_sendmsg()返回部分
perf probe 'tcp_sendmsg%return'
</code></pre>
<h4 id="通过probe检测内核函数">通过probe检测内核函数</h4>
<p><strong>probe使用示例说明</strong></p>
<ul>
<li>内核函数：<strong>tcp_sendmsg()</strong></li>
</ul>
<p>在内核函数上 tcp_sendmsg 添加一个事件</p>
<pre><code class="language-bash">perf probe --add tcp_sendmsg
</code></pre>
<p>此时会存在一个追踪点，通过 <code>perf probe -l</code> 可以查看</p>
<p>trace此追踪点5s，记录堆栈信息</p>
<pre><code class="language-bash">perf record -e probe:tcp_sendmsg -a -g -- sleep 5 
</code></pre>
<p>通过 report 子命令可以查看对应信息</p>
<pre><code class="language-bash">$ perf report --stdio  -i perf.data
# To display the perf.data header info, please use --header/--header-only options.
#
#
# Total Lost Samples: 0
#
# Samples: 13  of event 'probe:tcp_sendmsg'
# Event count (approx.): 13
#
# Children      Self  Command  Shared Object     Symbol                            
# ........  ........  .......  ................  ..................................
#
   100.00%   100.00%  sshd     [kernel.vmlinux]  [k] tcp_sendmsg
            |          
            |--92.31%--0
            |          getnetbyaddr_r@@GLIBC_2.2.5
            |          entry_SYSCALL_64_after_hwframe
            |          do_syscall_64
            |          ksys_write
            |          vfs_write
            |          new_sync_write
            |          sock_write_iter
            |          sock_sendmsg
            |          tcp_sendmsg
            |          
             --7.69%--0x1b81475c085
                       getnetbyaddr_r@@GLIBC_2.2.5
                       entry_SYSCALL_64_after_hwframe
                       do_syscall_64
                       ksys_write
                       vfs_write
                       new_sync_write
                       sock_write_iter
                       sock_sendmsg
                       tcp_sendmsg

   100.00%     0.00%  sshd     libc-2.31.so      [.] getnetbyaddr_r@@GLIBC_2.2.5
            |
            ---getnetbyaddr_r@@GLIBC_2.2.5
               entry_SYSCALL_64_after_hwframe

</code></pre>
<p>删除对应跟踪点</p>
<pre><code class="language-bash">perf probe -d &lt;probe_name&gt;
</code></pre>
<p><strong>也可以通过内核函数的变量进行检查</strong></p>
<p>查看内核函数参数，可以看到存在三个参数 <code>size</code> int类型, <code>msg</code> 结构体指针，<code>sk</code> 结构体指针</p>
<pre><code class="language-bash">$ perf probe -V tcp_sendmsg 
Available variables at tcp_sendmsg
        @&lt;tcp_sendmsg+0&gt;
                size_t  size
                struct msghdr*  msg
                struct sock*    sk
</code></pre>
<p>使用 <code>size</code> 变量作为 <code>tcp_sendmsg</code> 探测点的探测器</p>
<pre><code class="language-bash">perf probe --add 'tcp_sendmsg size'
</code></pre>
<h4 id="通过probe检测用户空间程序-supa-href22asup">通过probe检测用户空间程序 <sup><a href="#2">[2]</a></sup></h4>
<p>准备一段代码，即每次循环，打印该值并打印该值+5</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int func(int xxx)
{
    int zzz = xxx;

    printf(&quot;zzz: %d\n&quot;, zzz);
    return zzz+5;
}
int main(int argc, char* argv[])
{
    int i=0;
    for( i=0; i&lt;10; i++)
        printf(&quot;yyy: %d\n&quot;, func(argc + i));

    return 0;
}
</code></pre>
<p>这里使用环境为 debian11，内核 5.10，需要注意的是，在新内核中版本中传参的命令与老内核有少许差别</p>
<p>运行编译后的程序可以看到结果</p>
<pre><code class="language-bash">$ gcc -g -o tst tst.c &amp;&amp; ./tst
zzz: 1
yyy: 6
zzz: 2
yyy: 7
zzz: 3
yyy: 8
zzz: 4
yyy: 9
zzz: 5
yyy: 10
zzz: 6
yyy: 11
zzz: 7
yyy: 12
zzz: 8
yyy: 13
zzz: 9
yyy: 14
zzz: 10
yyy: 15
</code></pre>
<p>这里编译时使用了 <code>-g</code> 选项，<code>-g</code> 是一个编译选项，即在源代码编译的过程中起作用，让gcc把更多调试信息（也就包括符号信息）收集起来并将存放到最终的可执行文件</p>
<p>接下来为程序创建一个追踪事件，</p>
<pre><code class="language-bash">perf probe -x tst --add 'out=func%return $retval'
# 格式将严格遵循 &lt;[EVENT=]FUNC[@SRC][+OFF|%return|:RL|;PT]|SRC:AL|SRC;PT [[NAME=]ARG ...]&gt;
# out=func%return %retval
# EVENT=FUNC%return ARG
# EVENT 探测事件名
# FUNC  函数名
# %return 在函数return处放置探针
# ARG 参数
</code></pre>
<p>此时可以执行这个程序，让probe可以追踪到数据</p>
<pre><code class="language-bash">$ perf record -g -e probe_tst:out__return -aR ./tst
Lowering default frequency rate to 2750.
Please consider tweaking /proc/sys/kernel/perf_event_max_sample_rate.
zzz: 1
yyy: 6
zzz: 2
yyy: 7
zzz: 3
yyy: 8
zzz: 4
yyy: 9
zzz: 5
yyy: 10
zzz: 6
yyy: 11
zzz: 7
yyy: 12
zzz: 8
yyy: 13
zzz: 9
yyy: 14
zzz: 10
yyy: 15
[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.163 MB perf.data (10 samples) ]
</code></pre>
<p>执行的结果保存在 <code>perf.data</code> 中</p>
<pre><code class="language-bash">$ perf report --stdio
# To display the perf.data header info, please use --header/--header-only options.
#
#
# Total Lost Samples: 0
#
# Samples: 10  of event 'probe_tst:out__return'
# Event count (approx.): 10
#
# Children      Self  Command  Shared Object     Symbol                
# ........  ........  .......  ................  ......................
#
   100.00%   100.00%  tst      tst               [.] main
            |
            ---0x5541d68949564100
               cancel_handler
               main

   100.00%     0.00%  tst      [unknown]         [.] 0x5541d68949564100
            |
            ---0x5541d68949564100
               cancel_handler
               main

   100.00%     0.00%  tst      libc-2.31.so      [.] cancel_handler
            |
            ---cancel_handler
               main
</code></pre>
<p>使用 <code>script</code> 子命令查看这个程序的trace记录，可以看到</p>
<pre><code class="language-bash">perf script 
tst  2272 [000] 28276.947273: probe_tst:out__return: (55dc41f11135 &lt;- 55dc41f11192) arg1=0x6
            55dc41f11192 main+0x2e (/root/tst)
            7f67337bed0a cancel_handler+0x3a (/usr/lib/x86_64-linux-gnu/libc-2.31.so)
        5541d68949564100 [unknown] ([unknown])

tst  2272 [000] 28276.947282: probe_tst:out__return: (55dc41f11135 &lt;- 55dc41f11192) arg1=0x7
            55dc41f11192 main+0x2e (/root/tst)
            7f67337bed0a cancel_handler+0x3a (/usr/lib/x86_64-linux-gnu/libc-2.31.so)
        5541d68949564100 [unknown] ([unknown])

tst  2272 [000] 28276.947288: probe_tst:out__return: (55dc41f11135 &lt;- 55dc41f11192) arg1=0x8
            55dc41f11192 main+0x2e (/root/tst)
            7f67337bed0a cancel_handler+0x3a (/usr/lib/x86_64-linux-gnu/libc-2.31.so)
        5541d68949564100 [unknown] ([unknown])

tst  2272 [000] 28276.947294: probe_tst:out__return: (55dc41f11135 &lt;- 55dc41f11192) arg1=0x9
            55dc41f11192 main+0x2e (/root/tst)
            7f67337bed0a cancel_handler+0x3a (/usr/lib/x86_64-linux-gnu/libc-2.31.so)
        5541d68949564100 [unknown] ([unknown])

tst  2272 [000] 28276.947300: probe_tst:out__return: (55dc41f11135 &lt;- 55dc41f11192) arg1=0xa
            55dc41f11192 main+0x2e (/root/tst)
            7f67337bed0a cancel_handler+0x3a (/usr/lib/x86_64-linux-gnu/libc-2.31.so)
        5541d68949564100 [unknown] ([unknown])

tst  2272 [000] 28276.947306: probe_tst:out__return: (55dc41f11135 &lt;- 55dc41f11192) arg1=0xb
            55dc41f11192 main+0x2e (/root/tst)
            7f67337bed0a cancel_handler+0x3a (/usr/lib/x86_64-linux-gnu/libc-2.31.so)
        5541d68949564100 [unknown] ([unknown])

tst  2272 [000] 28276.947311: probe_tst:out__return: (55dc41f11135 &lt;- 55dc41f11192) arg1=0xc
            55dc41f11192 main+0x2e (/root/tst)
            7f67337bed0a cancel_handler+0x3a (/usr/lib/x86_64-linux-gnu/libc-2.31.so)
        5541d68949564100 [unknown] ([unknown])

tst  2272 [000] 28276.947317: probe_tst:out__return: (55dc41f11135 &lt;- 55dc41f11192) arg1=0xd
            55dc41f11192 main+0x2e (/root/tst)
            7f67337bed0a cancel_handler+0x3a (/usr/lib/x86_64-linux-gnu/libc-2.31.so)
        5541d68949564100 [unknown] ([unknown])

tst  2272 [000] 28276.947322: probe_tst:out__return: (55dc41f11135 &lt;- 55dc41f11192) arg1=0xe # 14
            55dc41f11192 main+0x2e (/root/tst)
            7f67337bed0a cancel_handler+0x3a (/usr/lib/x86_64-linux-gnu/libc-2.31.so)
        5541d68949564100 [unknown] ([unknown])

tst  2272 [000] 28276.947328: probe_tst:out__return: (55dc41f11135 &lt;- 55dc41f11192) arg1=0xf # 15
            55dc41f11192 main+0x2e (/root/tst)
            7f67337bed0a cancel_handler+0x3a (/usr/lib/x86_64-linux-gnu/libc-2.31.so)
        5541d68949564100 [unknown] ([unknown])
</code></pre>
<p>可以通过上面看到，这里制作的探针在用户空间程序 tst.func 函数中，当他返回时，记录了要返回的值作为arg1，也就是每行返回的 <code>0xf</code> 这类16进制值，也可以看到每次命中该探针的部分</p>
<h3 id="troubleshooting">Troubleshooting</h3>
<h4 id="uhhuh-nmi-received-for-unknown-reason">Uhhuh. NMI received for unknown reason</h4>
<pre><code class="language-bash">Message from syslogd@phab1 at Dec 26 19:16:16 ...
kernel:Uhhuh. NMI received for unknown reason 30 on CPU 0.

Message from syslogd@phab1 at Dec 26 19:16:16 ...
kernel:Do you have a strange power saving mode enabled?

Message from syslogd@phab1 at Dec 26 19:16:16 ...
kernel:Dazed and confused, but trying to continue
</code></pre>
<p>上述问题通常发生于虚拟化环境</p>
<p>Solve solution: disable c-state in bios</p>
<h4 id="failed-to-find-the-path-for-kernel-invalid-elf-file">Failed to find the path for kernel: Invalid ELF file</h4>
<pre><code class="language-bash">Failed to find the path for kernel: Invalid ELF file
  Error: Failed to show vars.
</code></pre>
<p>这个错误通常使用 <code>perf probe -V</code> 时出现，这里需要内核支持 <em><strong>debug symbols</strong></em>，即使用公开发行版需要安装对应内核包</p>
<ul>
<li>RHEL/CentOS：安装 <code>kernel-debuginfo-common</code> 与 <code>kernel-debuginfo package</code></li>
<li>Debian/Ubuntu：安装 <code>linux-image-&lt;kernel_version&gt;-amd64-dbg</code> debian下保持需要至少5G空间 <sup><a href="#3">[3]</a></sup></li>
</ul>
<h4 id="failed-to-find-source-file-path">Failed to find source file path</h4>
<pre><code class="language-bash">$ perf probe -L tcp_sendmsg
Failed to find source file path.
  Error: Failed to show lines.
</code></pre>
<p>思路：可以通过 <code>strace</code> 命令看看为什么报错</p>
<p>原因：<code>perf probe -L</code> 将显示对应内核探测点的源代码，此时perf会寻找构建的内核目录，而操作系统发行版供应商对于系统都是通过包管理，包括内核，并未提供这些源码，此状态为正确的，如果非要解决，可以自行编译内核。</p>
<h2 id="dmesg">dmesg</h2>
<p><em><strong>dmesg</strong></em> 是来自内核的一个环形缓冲区，而通过 <em><strong>dmesg</strong></em> 命令可以看到来自该缓冲区的消息，而该消息也被称为 ”<em><strong>driver message</strong></em>“ 或 ”<em><strong>display message</strong></em>“</p>
<h3 id="示例1对dmesg输出着色">示例1：对dmesg输出着色</h3>
<pre><code class="language-bash">$ dmesg -L
</code></pre>
<h3 id="示例2dmesg输出消息增加时间">示例2：dmesg输出消息增加时间</h3>
<pre><code class="language-bash">$ dmesg -T
</code></pre>
<h3 id="示例3过滤相关级别信息">示例3：过滤相关级别信息</h3>
<p>可以通过 <code>--level</code> 来进行过滤出不同级别的日志，可用级别有</p>
<ul>
<li>emerg,</li>
<li>alert,</li>
<li>crit,</li>
<li>err,</li>
<li>warn,</li>
<li>notice,</li>
<li>info</li>
<li>debug</li>
</ul>
<pre><code class="language-bash">$ dmesg --level=err

$ dmesg --level=warn
</code></pre>
<h3 id="示例4过滤相关事件信息">示例4：过滤相关事件信息</h3>
<p>dmesg 可以通过参数指定 <code>--facility</code> 来指定对应事件的日志，可用的设施有：</p>
<ul>
<li>kern</li>
<li>user</li>
<li>mail</li>
<li>daemon</li>
<li>auth</li>
<li>lpr</li>
<li>news</li>
</ul>
<pre><code class="language-bash">$  dmesg --facility=daemon
[    1.793879] systemd[1]: Inserted module 'autofs4'
[    1.807871] systemd[1]: systemd 247.3-7 running in system mode. (+PAM +AUDIT +SELINUX +IMA +APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ +LZ4 +ZSTD +SECCOMP +BLKID +ELFUTILS +KMOD +IDN2 -IDN +PCRE2 default-hierarchy=unified)
[    1.807925] systemd[1]: Detected virtualization vmware.
[    1.807927] systemd[1]: Detected architecture x86-64.
[    1.808612] systemd[1]: Set hostname to &lt;debian-template&gt;.
[    1.881058] systemd[1]: Queued start job for default target Graphical Interface.
[    1.882132] systemd[1]: Created slice system-getty.slice.
[    1.882337] systemd[1]: Created slice system-modprobe.slice.
[    1.882724] systemd[1]: Created slice system-systemd\x2dfsck.slice.
[    1.882869] systemd[1]: Created slice User and Session Slice.
[    1.882902] systemd[1]: Started Dispatch Password Requests to Console Directory Watch.
[    1.882920] systemd[1]: Started Forward Password Requests to Wall Directory Watch.
[    1.883019] systemd[1]: Set up automount Arbitrary Executable File Formats File System Automount Point.
[    1.883036] systemd[1]: Reached target Local Encrypted Volumes.
[    1.883049] systemd[1]: Reached target Paths.
[    1.883054] systemd[1]: Reached target Remote File Systems.
[    1.883058] systemd[1]: Reached target Slices.
[    1.883080] systemd[1]: Reached target Swap.
[    1.883152] systemd[1]: Listening on Syslog Socket.
[    1.883193] systemd[1]: Listening on fsck to fsckd communication Socket.
[    1.883218] systemd[1]: Listening on initctl Compatibility Named Pipe.
[    1.883285] systemd[1]: Listening on Journal Audit Socket.
[    1.883322] systemd[1]: Listening on Journal Socket (/dev/log).
[    1.883364] systemd[1]: Listening on Journal Socket.
[    1.883422] systemd[1]: Listening on udev Control Socket.
[    1.883456] systemd[1]: Listening on udev Kernel Socket.
[    1.883961] systemd[1]: Mounting Huge Pages File System...
</code></pre>
<h3 id="示例5实时打印dmesg日志">示例5：实时打印dmesg日志</h3>
<pre><code class="language-bash">$ dmesg --follow
</code></pre>
<h3 id="示例6显示dmesg原生信息">示例6：显示dmesg原生信息</h3>
<pre><code class="language-bash">$ dmesg -r
</code></pre>
<h3 id="示例7dmesg信息重定向到syslog">示例7：dmesg信息重定向到syslog</h3>
<p>dmesg本身只是一个用户空间命令，而 ”<em><strong>driver message</strong></em>“ 是内存中一个缓冲器，在Linux标识为 <code>/dev/kmsg</code>，而这个缓冲区是存在与内存中，如果需要将其重定向到syslog，可以通过参数 <code>-S</code> 实现，<code>-s</code> 则是设置这个环形buffer的大小</p>
<h3 id="示例8过滤硬件设备相关信息">示例8：过滤硬件设备相关信息</h3>
<pre><code class="language-bash"># usb设备
$ dmesg | grep -i usb
# 还可以通过grep查看其它硬件设备相关信息
$ dmesg | grep -i dma
$ dmesg | grep -i scsi
$ dmesg | grep -i acpi
$ dmesg | grep -i memory
$ dmesg | grep -i tty
$ dmesg | grep sda
</code></pre>
<h3 id="示例9清空buffer">示例9：清空buffer</h3>
<pre><code class="language-bash"># 直接清空
dmesg -C
# 读取并清空
dmesg -c
</code></pre>
<h2 id="vmstat">vmstat</h2>
<p>vmstat 命令是Linux虚拟内存统计信息的命令，带来的是与进程有关的信息，如processes, memory, paging, block IO</p>
<p><strong>没有任何参数的vmstat</strong></p>
<pre><code class="language-bash">$ vmstat 
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 1246808  24308 507656    0    0     5     0   60  130  0  0 100  0  0
</code></pre>
<p>vmstat输出包含的字段</p>
<ul>
<li>Procs – r: 等待运行的数量</li>
<li>Procs – b: 忙碌进程的数量</li>
<li>Memory – swpd: 已使用的虚拟内存</li>
<li>Memory – free: 空闲的虚拟内存</li>
<li>Memory – buff: 用作buffer的内存</li>
<li>Memory – cache: 用作cache的内存</li>
<li>Swap – si: 从磁盘交换至内存 (for every second)</li>
<li>Swap – so: 内存交换到磁盘 (for every second)</li>
<li>IO – bi (<em>Blocks in</em>). i.e 从设备接受到的块(for every second)</li>
<li>IO – bo (<em>Blocks out</em>). i.e 发送到设备的块 (for every second)</li>
<li>System – in (<em>Interrupts per second</em>) 每秒的中断</li>
<li>System – cs (<em>Context switches</em>) 上下文切换</li>
<li>CPU – us, sy, id, wa, st: CPU user time, system time, idle time, wait time</li>
</ul>
<h3 id="示例1显示活动和非活动内存">示例1：显示活动和非活动内存</h3>
<pre><code class="language-bash">$ vmstat -a
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free  inact active   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 1247060 294352 314540    0    0     5     0   60  130  0  0 100  0  0
</code></pre>
<h3 id="示例2显示启动系统后所有fork系统调用">示例2：显示启动系统后所有fork系统调用</h3>
<p>显示所有 fork、vfork 和 clone 系统调用计数</p>
<pre><code class="language-bash">$ vmstat -f
         2889 forks
</code></pre>
<h3 id="示例3动态展示">示例3：动态展示</h3>
<p>展示结果将以 x 秒刷新，直到 crtl - c 退出</p>
<pre><code class="language-bash">$ vmstat 2
</code></pre>
<p>也可以接俩个参数，一个是刷新时间，一个是刷新多少次，例如，2秒刷新一次，一共刷新10次，完成后退出命令</p>
<pre><code class="language-bash">$ vmstat 2 10
</code></pre>
<h3 id="示例4打印时间">示例4：打印时间</h3>
<pre><code class="language-bash">$ vmstat -t 1 2
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- -----timestamp-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st                 PST
 1  0      0 1247424  24396 507656    0    0     5     0   60  130  0  0 100  0  0 2022-12-10 08:10:03
 1  0      0 1247416  24396 507656    0    0     0     8  130  277  0  0 100  0  0 2022-12-10 08:10:04
</code></pre>
<h3 id="示例5显示slab相关信息">示例5：显示slab相关信息</h3>
<p>slab是一种内存管理机制，目的是为了更有效的分配内存对象</p>
<pre><code class="language-bash">vmstat -m
Cache                       Num  Total   Size  Pages
nf_conntrack                102    102    320     51
ovl_inode                    94     94    688     47
ext4_groupinfo_1k           120    120    136     60
fuse_request                  0      0    152     53
fuse_inode                    0      0    832     39
ext4_groupinfo_4k           112    112    144     56
ext4_fc_dentry_update         0      0     80     51
ext4_inode_cache          13554  13554   1184     27
ext4_system_zone            204    204     40    102
ext4_io_end                 128    128     64     64
ext4_extent_status         3060   3060     40    102
jbd2_journal_handle         146    146     56     73
...
</code></pre>
<h3 id="场景6输出格式为表格形式">场景6：输出格式为表格形式</h3>
<pre><code class="language-bash">$ vmstat -s
      1996352 K total memory
       216852 K used memory
       314636 K active memory
       294352 K inactive memory
      1247416 K free memory
        24428 K buffer memory
       507656 K swap cache
            0 K total swap
            0 K used swap
            0 K free swap
         3635 non-nice user cpu ticks
            2 nice user cpu ticks
         8204 system cpu ticks
      9759423 idle cpu ticks
          310 IO-wait cpu ticks
            0 IRQ cpu ticks
          320 softirq cpu ticks
            0 stolen cpu ticks
       498371 pages paged in
        45598 pages paged out
            0 pages swapped in
            0 pages swapped out
      5866212 interrupts
     12709713 CPU context switches
   1670639441 boot time
         2922 forks
</code></pre>
<h3 id="场景7磁盘相关信息">场景7：磁盘相关信息</h3>
<pre><code class="language-bash">$ vmstat -d 1 20
disk- ------------reads------------ ------------writes----------- -----IO------
       total merged sectors      ms  total merged sectors      ms    cur    sec
sda     7835   2737  996742    2134   5719   2598   91620    6219      0      9
sda     7835   2737  996742    2134   5747   2598   91908    6230      0      9
</code></pre>
<h3 id="场景8输出格式增加宽度">场景8：输出格式增加宽度</h3>
<pre><code class="language-bash">vmstat -w 1 3
--procs-- -----------------------memory---------------------- ---swap-- -----io---- -system-- --------cpu--------
   r    b         swpd         free         buff        cache   si   so    bi    bo   in   cs  us  sy  id  wa  st
   0    0            0      1247440        24468       507656    0    0     5     0   60  130   0   0 100   0   0
   0    0            0      1247440        24468       507656    0    0     0     0  135  265   0   0 100   0   0
   0    0            0      1247440        24468       507656    0    0     0     0  126  262   0   0 100   0   0
</code></pre>
<h3 id="场景9输出单位格式化">场景9：输出单位格式化</h3>
<pre><code class="language-bash">vmstat -S k
vmstat: -S requires k, K, m or M (default is KiB)
</code></pre>
<h2 id="mpstat">mpstat</h2>
<p>mpstat是统计CPU相关信息的命令</p>
<p><strong>各系统下的包名与安装</strong></p>
<ul>
<li>Ubuntu/Debian/Mint：<code>apt install sysstat -y</code></li>
<li>RHEL/CentOS/Fedora：<code>yum install -y sysstat</code></li>
</ul>
<pre><code class="language-bash">$ mpstat

08:22:07 AM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
08:22:07 AM  all    0.04    0.00    0.09    0.00    0.00    0.00    0.00    0.00    0.00   99.87
</code></pre>
<p>看懂 mpstat 输出结果</p>
<ul>
<li><strong>CPU</strong>：处理器编号. all为所有CPU在一段时间内的平均统计信息.</li>
<li><strong>%usr</strong>：在用户级别（应用程序）执行时的CPU平均使用率。</li>
<li><strong>%nice</strong>：具有良好级别的用户级别（应用程序）执行时的CPU平均使用率。</li>
<li><strong>%sys</strong>：显示在内核级别执行时发生的CPU使用率。 这里不包括耗时的硬/软中断服务</li>
<li><strong>%iowait</strong>：CPU 或 CPU 处于空闲状态期间系统有未完成的磁盘 I/O 请求。</li>
<li><strong>%irq</strong>：一个或多个 CPU 在中断时，硬中断所花费的时间的百分比。</li>
<li><strong>%soft</strong>： 一个或多个CPU用于中断时，软中断所花费的时间百分比。</li>
<li><strong>%steal</strong>： 一个或多个虚拟CPU当在虚拟机管理器服务与另一个虚拟处理器时非自愿等待时间所花费的百分比</li>
<li><strong>%guest</strong>：一个或多个CPU在运行一个虚拟处理器使用时间的百分比</li>
<li><strong>%idle</strong> : 一个或多个CPU处于idle状态，并且系统没有尚未完成的磁盘 I/O 请求</li>
</ul>
<pre><code class="language-bash"># 显示所有信息
mpstat -A

# 按照独立核心展示
mpstat -P ALL

# 使用编号指定单独的CPU编号
mpstat -P 1

# 第一个参数表示刷新时间，第二个参数表示刷新次数
mpstat 2 10

# CPU利用率
mpstat -u %usr

# CPU中断信息
mpstat -I { SUM | CPU | SCPU | ALL }
</code></pre>
<h2 id="pidstat">pidstat</h2>
<p><em><strong>pidstat</strong></em> 是 <em><strong>sysstat</strong></em> 包的一部分，可以统计单个进程并生成报告。用以通过 PID 来评估资源的使用率</p>
<p><strong>各系统下的包名与安装</strong></p>
<ul>
<li>Ubuntu/Debian/Mint：<code>apt install sysstat -y</code></li>
<li>RHEL/CentOS/Fedora：<code>yum install -y sysstat</code></li>
</ul>
<pre><code class="language-bash"># 显示所有进程
pidstat -p ALL

# 查看特定进程
pidstat -p 514

# 根据进程名称来查看
pidstat -C &quot;mysql&quot;

# 指定实时刷新
pidstat -p 23493 1

# 显示指定进程的I/O统计信息
pidstat -p &lt;pid&gt; -d

# 显示指定进程的活动分页统计信息
pidstat -p &lt;pid&gt; -r

# 显示结果时加上进程程序所在路径、参数等信息
pidstat -C java -l

# 第一个参数表示刷新时间，第二个参数表示刷新次数
pidstat 2 5

# 显示进程的子进程信息
# -T: CHILD, or TASKS, or ALL.
pidstat -p 1 -T CHILD

# 显示为依赖进程树格式
pidstat -t -C &quot;ssh&quot;

# 展示一个水平线上的性能
# option “r”  page faults and memory utilization
# option “d”  I/O statistics
# option “u”  CPU utilization
# 展示结果将按照 r d u 依次输出
pidstat -rud
</code></pre>
<h2 id="iostat">iostat</h2>
<p><em><strong>iostat</strong></em> 是 <em><strong>sysstat</strong></em> 包的一部分，可以通过命令来统计CPU使用率, I/O, （设备，分区）, 网络文件系统等</p>
<p><strong>各系统下的包名与安装</strong></p>
<ul>
<li>Ubuntu/Debian/Mint：<code>apt install sysstat -y</code></li>
<li>RHEL/CentOS/Fedora：<code>yum install -y sysstat</code></li>
</ul>
<p><strong>iostat命令参数</strong></p>
<ul>
<li><strong>-c</strong>: 显示CPU使用率</li>
<li><strong>-d</strong>: 显示设备使用率</li>
<li><strong>-k</strong>: 以kb为单位统计（每秒）</li>
<li><strong>-m</strong>: 以mb为单位统计（每秒）</li>
<li><strong>-x</strong>: 展示一些扩展的统计文件</li>
</ul>
<p>iostat结果为两部分，avg-cpu 与 Device，均是指自开机以来的统计</p>
<p>avg-cpu部分：</p>
<ul>
<li><strong>%user</strong>：在用户级别（应用程序）执行时的CPU平均使用率。</li>
<li><strong>%nice</strong>：具有良好级别的<strong>用户</strong>级别（应用程序）执行时的CPU平均使用率。</li>
<li><strong>%system</strong>：显示在<strong>内核</strong>级别执行时发生的CPU使用率。 这里不包括耗时的硬/软中断服务</li>
<li><strong>%iowait</strong>：CPU 或 CPU 处于空闲状态期间系统有未完成的磁盘 I/O 请求。</li>
<li><strong>%steal</strong>： 一个或多个虚拟CPU当在虚拟机管理器服务与另一个虚拟处理器时非自愿等待时间所花费的百分比</li>
<li><strong>%idle</strong> : 一个或多个CPU处于idle状态，并且系统没有尚未完成的磁盘 I/O 请求</li>
</ul>
<p>Device部分：</p>
<ul>
<li><strong>tps</strong> - 表示每秒发送给设备的传输次数。</li>
<li><strong>Blk_read/s (kB_read/s, MB_read/s)</strong> - 表示每秒从设备读取的数据量，以块（KB、MB）表示。</li>
<li><strong>Blk_wrtn/s (kB_read/s, MB_read/s)</strong> - 表示每秒写入设备的数据量，以块（KB、MB）表示。</li>
<li><strong>Blk_read (kB_read, MB_read)</strong> - 读取块总数（KB、MB）</li>
<li><strong>Blk_wrtn (kB_read, MB_read)</strong>- 写入块总数（KB、MB）</li>
</ul>
<pre><code class="language-bash">$ iostat
Linux 5.10.0-16-amd64 (debian-template) 	12/11/2022 	_x86_64_	(2 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.04    0.00    0.09    0.00    0.00   99.87

Device             tps    kB_read/s    kB_wrtn/s    kB_dscd/s    kB_read    kB_wrtn    kB_dscd
sda               0.26         8.22         1.88         0.00     578135     131934          0
</code></pre>
<p><strong>使用示例</strong></p>
<pre><code class="language-bash"># 显示CPU使用率
iostat -c

# 显示CPU使用率 按照周期刷新 sec
iostat -c N

# 设备使用率
iostat -d

# 以人类可读方式展示
iostat -h

# 显示一些扩展选项
iostat -x

# 以kb为单位展示
iostat -k

# 以mb为单位展示
iostat -m

# 显示设备与分区的使用率
iostat -p

# 显示指定设备的使用率
iostat -p &lt;device_name&gt;

# 忽略非活跃设备
iostat -z
</code></pre>
<h2 id="htop">htop</h2>
<p>htop可以理解为linux中的与windows任务管理器相同的产品，与top不同的是，htop是一个支持交互式的top命令</p>
<p><strong>各系统下的包名与安装</strong></p>
<ul>
<li>Ubuntu/Debian/Mint：<code>apt install htop -y</code></li>
<li>RHEL/CentOS/Fedora：<code>yum install -y htop</code></li>
</ul>
<h3 id="cpu和内存使用状态">CPU和内存使用状态</h3>
<p>htop上部屏幕，为CPU和存储使用详情</p>
<h3 id="显示的颜色">显示的颜色</h3>
<p><strong>默认模式</strong></p>
<ul>
<li>蓝色：低优先级进程（nice&gt; 0）</li>
<li>绿色：正常（用户）流程</li>
<li>红色：内核时间（内核，iowait，irqs &hellip;）</li>
<li>橙色：有效时间（窃取时间+访客时间）</li>
</ul>
<p><strong>详细模式</strong></p>
<ul>
<li>蓝色：低优先级线程（nice&gt; 0）</li>
<li>绿色：正常（用户）流程</li>
<li>红色：系统进程</li>
<li>橙色：IRQ时间</li>
<li>洋红色：IRQ时间较慢</li>
<li>灰色：IO等待时间</li>
<li>青色：偷时间</li>
<li>青色：访客时间</li>
</ul>
<p><strong>内存计量</strong>器更简单：</p>
<ul>
<li>绿色：已用内存页</li>
<li>蓝色：缓冲页</li>
<li>橙色：缓存页面</li>
</ul>
<blockquote>
<p>可以通过f1查看帮助对于颜色的说明</p>
</blockquote>
<h2 id="ldd">ldd</h2>
<h2 id="sar">sar</h2>
<p>sar <strong>S</strong>ystem <strong>A</strong>ctivity <strong>R</strong>eport的简写，可以用于收集、报告或保存系统活动的统计信息，如 Linux 系统中的 CPU 利用率、内存使用情况、I/O 设备使用情况。 sar 命令显示自系统启动以来的平均统计信息。它在输出中生成报告，也可以保存在文件中。</p>
<p><strong>各系统下的包名与安装</strong></p>
<ul>
<li>Ubuntu/Debian/Mint：<code>apt install sysstat -y</code></li>
<li>RHEL/CentOS/Fedora：<code>yum install -y sysstat</code></li>
</ul>
<blockquote>
<p>Notes：sar是服务，需要开启收集才可以查询到，配置 <code>/etc/default/sysstat </code> 修改为 <code>ENABLED=&quot;false&quot;</code> 然后重启服务 <code>systemctl restart sysstat.service</code></p>
</blockquote>
<p>sar语法</p>
<pre><code class="language-bash">$ sar [option] [interval] [count]
</code></pre>
<p>更多可以参考 <sup><a href="#5">[5]</a></sup></p>
<h2 id="ioping">ioping</h2>
<p>ioping是一款磁盘延迟监控工具</p>
<ul>
<li>Ubuntu/Debian/Mint：<code>apt install -y ioping</code></li>
<li>RHEL/CentOS/Fedora：<code>yum install -y ioping</code></li>
</ul>
<table>
<thead>
<tr>
<th>Option</th>
<th>describe</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>-c</strong> <em>count</em></td>
<td>ping的次数</td>
</tr>
<tr>
<td><strong>-i</strong> <em>interval</em></td>
<td>每次请求的间隔</td>
</tr>
<tr>
<td><strong>-t</strong> <em>time</em></td>
<td>最大有效的请求事件，太慢的请求将被忽略</td>
</tr>
<tr>
<td><strong>-s</strong> <em>size</em></td>
<td>请求大小</td>
</tr>
<tr>
<td><strong>-S</strong> <em>wsize</em></td>
<td></td>
</tr>
<tr>
<td><strong>-o</strong> <em>offset</em></td>
<td>在 file/device 开始的偏移量</td>
</tr>
<tr>
<td><strong>-w</strong> <em>deadline</em></td>
<td>在多少时间后停止</td>
</tr>
<tr>
<td><strong>-p</strong> <em>period</em></td>
<td>打印每秒请求的原生统计数据</td>
</tr>
<tr>
<td><strong>-A</strong></td>
<td>使用异步IO (syscalls <strong><a href="https://www.systutorials.com/docs/linux/man/2-io_submit/" target="_blank"
   rel="noopener nofollow noreferrer" >io_submit</a></strong>(2), <strong><a href="https://www.systutorials.com/docs/linux/man/2-io_submit/" target="_blank"
   rel="noopener nofollow noreferrer" >io_submit</a></strong>(2),</td>
</tr>
<tr>
<td><strong>-B</strong></td>
<td>批量模式，以安静的原始数据方式统计最终的数据</td>
</tr>
<tr>
<td><strong>-C</strong></td>
<td>使用 cached I/O 在posix_fadvise(2)读取之前 和写入 fdatasync(2)之后，来抑制缓存失效。</td>
</tr>
<tr>
<td><strong>-D</strong></td>
<td>使用direct I/O (<strong>O_DIRECT</strong> in <strong><a href="https://www.systutorials.com/docs/linux/man/2-open/" target="_blank"
   rel="noopener nofollow noreferrer" >open</a></strong>(2)).</td>
</tr>
<tr>
<td><strong>-L</strong></td>
<td>使用序列操作而不是随机操作，这相当于设置了默认大小，例如 <code>-s 256k</code> 与这个是相同的</td>
</tr>
<tr>
<td><strong>-R</strong></td>
<td>磁盘查找速度测试，这个选项将以人类可读模式输出每个请求<br>设置默认间隔为0, -i=0<br/>停止测量将在3秒后停止 -w=3<br/>设置工作集大小为64m -S=64m</td>
</tr>
<tr>
<td><strong>-W</strong></td>
<td>写而不是读。目录目标安全。写入 I/O 为不支持或在某种级别缓存非缓存读取从而提供更可靠的结果。对于file/device来说是<em>危险的</em>：这将会粉碎数据。</td>
</tr>
<tr>
<td><strong>-Y</strong></td>
<td>使用同步IO (<strong>O_SYNC</strong> in <strong><a href="https://www.systutorials.com/docs/linux/man/2-open/" target="_blank"
   rel="noopener nofollow noreferrer" >open</a></strong>(2)).</td>
</tr>
<tr>
<td><strong>-y</strong></td>
<td>使用数据同步IO  (<strong>O_DSYNC</strong> in <strong><a href="https://www.systutorials.com/docs/linux/man/2-open/" target="_blank"
   rel="noopener nofollow noreferrer" >open</a></strong>(2)).</td>
</tr>
<tr>
<td><strong>-k</strong></td>
<td>重用临时工作目录文件 &ldquo;ioping.tmp&rdquo; （仅对于目标目录生效）</td>
</tr>
<tr>
<td><strong>-q</strong></td>
<td>Suppress periodical human-readable output.</td>
</tr>
</tbody>
</table>
<p>使用示例</p>
<p>RAW STATISTICS</p>
<pre><code class="language-bash">$ ioping -p 100 -c 200 -i 0 -q .
100 16282962 6141 25155128 130599 162830 328499 37909 101 17115660
</code></pre>
<p>上面输出的结果意思为：</p>
<ul>
<li>统计请求的计数</li>
<li>运行时间 <strong>usec</strong> 微秒</li>
<li>每秒请求 (iops)</li>
<li>传输速率 (bytes/sec)</li>
<li>最小请求时间 (usec)</li>
<li>平均请求时间 (usec)</li>
<li>最大请求时间 (usec)</li>
<li>请求时间偏差 (usec)</li>
<li>总请求 （包含很慢和很快的）</li>
<li>总共运行时间 (usec)</li>
</ul>
<pre><code class="language-bash"># 使用默认值和当前目录 测试磁盘 I/O 延迟，ctrl - c 中断。
ioping .

# 测量/tmp设备的延迟，总计使用10个请求，每个请求1MB
ioping -c 10 -s 1M /tmp

# 测量 设备  /dev/sda 的查找速度
ioping -R /dev/sda

# 测试设备磁盘序列速度
ioping -RL /dev/sda

# 获取磁盘序列的速度（每秒多少字节）
ioping -RLB . | awk '{print $4}'
</code></pre>
<h2 id="vnstat">vnstat</h2>
<p>vnstat是 Linux 中用于监控网络参数的命令，通常查看带宽消耗或一些流入或流出的流量，与网络接口上的流量。</p>
<p><strong>各系统下的包名与安装</strong></p>
<ul>
<li>Ubuntu/Debian/Mint：<code>apt install -y vnstat</code></li>
<li>RHEL/CentOS/Fedora：epel <code>yum install -y vnstat</code></li>
</ul>
<p>vnstat是一个守护进程，如果需要记录需要启动这个服务才可以，而不是一个单独的命令</p>
<pre><code class="language-bash"># 以小时显示流量
vnstat -h

# 以天显示流量
vnstat -d

# 以月为单位展示
vnstat -m

# 计算接口多长时间内的流量（这个是实时的，可以不用启动服务）
vnstat -tr 10 # 10 sec

# 指定一个接口
vnstat -i eth0

# 指定输出格式
vnstat --json
vnstat --xml
</code></pre>
<h2 id="ifstat">ifstat</h2>
<p>ifstat是Linux下网络接口统计的命令</p>
<ul>
<li>Ubuntu/Debian/Mint：<code>apt install -y ifstat</code></li>
<li>RHEL/CentOS/Fedora：<code>yum install -y ifstat</code></li>
</ul>
<pre><code class="language-bash"># 指定接口名
ifstat eth0

# 查看全部接口
ifstat -a

# 清除网络接口的数据
ifstat -z &lt;interface_name&gt;

# 展示x秒内网络数据的平均值
ifstat -t 10
</code></pre>
<h2 id="iptraf">iptraf</h2>
<p>iptraf是Linux 中交互式的网络监控命令，通过交互式实现展示</p>
<p><strong>各系统下的包名与安装</strong></p>
<ul>
<li>Ubuntu/Debian/Mint：<code>apt install -y iptraf-ng</code></li>
<li>RHEL/CentOS/Fedora：<code>yum install -y iptraf-ng</code></li>
</ul>
<h2 id="iftop">iftop</h2>
<p><strong>各系统下的包名与安装</strong></p>
<ul>
<li>Ubuntu/Debian/Mint：<code>apt install -y iftop</code></li>
<li>RHEL/CentOS/Fedora：epel <code>yum install -y iftop</code></li>
</ul>
<pre><code class="language-bash"># 指定端口的带宽统计
iftop -i enp0s8

# 隐藏顶部的流量刻度栏
iftop -b

# 不使用域名解析
iftop -n -i enp0s8

# 直接输出为文字，而不是交互式
iftop -t

# 显示指定子网的流量
iftop -F 192.168.2.0/24

# 根据source addr排序
iftop -o source

# 根据destnation addr排序
iftop -o destination

# 显示使用的带宽
iftop -B -i enp0s8
</code></pre>
<h2 id="arpwatch">arpwatch</h2>
<p>arpwatch是Linux上用于监视ARP记录的</p>
<p><strong>各系统下的包名与安装</strong></p>
<ul>
<li>Ubuntu/Debian/Mint：<code>apt install -y arpwatch</code></li>
<li>RHEL/CentOS/Fedora：epel <code>yum install -y arpwatch</code></li>
</ul>
<table>
<thead>
<tr>
<th>Option</th>
<th>describe</th>
</tr>
</thead>
<tbody>
<tr>
<td>-d</td>
<td>debug模式</td>
</tr>
<tr>
<td>-f</td>
<td>设置用于存储 ethernet/ip address 的文件，默认在  /var/arpwatch/arp.dat</td>
</tr>
<tr>
<td>-i</td>
<td>指定默认接口</td>
</tr>
<tr>
<td>-n</td>
<td>指定本地网络</td>
</tr>
<tr>
<td>-u</td>
<td>指定用户或用户组</td>
</tr>
<tr>
<td>-Q</td>
<td>The  flags prevents arpwatch from sending reports by mail</td>
</tr>
<tr>
<td>-z</td>
<td>设置忽略的 IP范围，IP和掩码用 &ldquo;/&rdquo; 化为，如 <code>-z 192.168.10.0/255.255.255.0</code></td>
</tr>
</tbody>
</table>
<pre><code class="language-bash"># 指定一个接口，命令并没有输出，当有新IP或MAC被改变时，会保存到/var/log/messages
arpwatch -i eth0
</code></pre>
<h2 id="reference">Reference</h2>
<blockquote>
<p><sup id="1">[1]</sup> <a href="https://www.brendangregg.com/perf.html" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>perf Examples</strong></em></a></p>
<p><sup id="2">[2]</sup> <a href="http://notes.secretsauce.net/notes/2015/01/28_user-space-introspection-with-linux-perf.html" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>User-space introspection with Linux perf</strong></em></a></p>
<p><sup id="3">[3]</sup> <a href="https://drgn.readthedocs.io/en/latest/getting_debugging_symbols.html" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>Getting Debugging Symbols</strong></em></a></p>
<p><sup id="4">[4]</sup> <a href="http://oliveryang.net/2016/07/linux-perf-tools-tips/" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>Linux Perf Tools Tips</strong></em></a></p>
<p><sup id="5">[5]</sup> <a href="https://www.golinuxcloud.com/sar-command-in-linux/" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>20 sar command examples in Linux</strong></em></a></p>
<p><sup id="6">[6]</sup> <a href="https://www.linuxfordevices.com/tutorials/linux/htop-command-in-linux" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>A Guide to the htop command in Linux</strong></em></a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>bash shell常用示例</title>
      <link>https://www.oomkill.com/2021/10/awesome-bash-shell/</link>
      <pubDate>Fri, 22 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2021/10/awesome-bash-shell/</guid>
      <description></description>
      <content:encoded><![CDATA[<p>该文整理一些常用的shell用法，及语法，并非介绍如何使用</p>
<h2 id="变量">变量</h2>
<p>变量可分为两类：环境变量ENV（全局）和局部变量。</p>
<p>bash环境变量</p>
<table>
<thead>
<tr>
<th>变量名</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>_=</td>
<td>上一条命令的最后一个参数</td>
</tr>
<tr>
<td>BASH_VERSION=&ldquo;4.1.2(1)-release&rdquo;</td>
<td>当前bash实例的版本号</td>
</tr>
<tr>
<td>COLORS=&quot;/etc/DIR_COLORS&quot;</td>
<td></td>
</tr>
<tr>
<td>COLUMNS=80</td>
<td>设置该变量就给shell编辑模式和选择命令定义了编辑窗口的宽度</td>
</tr>
<tr>
<td>CVS_RSH=&ldquo;ssh&rdquo;</td>
<td></td>
</tr>
<tr>
<td>DIRSTACK</td>
<td>代表目录栈当前的内容</td>
</tr>
<tr>
<td>EUID=0</td>
<td>为在shell启动时被初始化的当前用户的有效ID</td>
</tr>
<tr>
<td>G_BROKEN_FILENAMES=1</td>
<td></td>
</tr>
<tr>
<td>GROUPS=()</td>
<td>当前用户所属组</td>
</tr>
<tr>
<td>HISTFILE=/root/.bash_history</td>
<td>历史记录文件的全路径</td>
</tr>
<tr>
<td>HISTFILESIZE=50</td>
<td>历史文件能包含的最大行数</td>
</tr>
<tr>
<td>HISTSIZE=50</td>
<td>记录在命令行历史文件中的命令行数</td>
</tr>
<tr>
<td>HOME=/root</td>
<td>当前用户家目录</td>
</tr>
<tr>
<td>HOSTNAME=</td>
<td>当前主机机器名称</td>
</tr>
<tr>
<td>HOSTTYPE=x86_64</td>
<td></td>
</tr>
<tr>
<td>IFS=$&rsquo;\t\n'</td>
<td>内容字段分隔符，一般是空格符、制表符、和换行符，用于由命令替换，循环结构中的表和读取的输入产生的词的字段划分。</td>
</tr>
<tr>
<td>INPUTRC=/etc/inputrc</td>
<td>readline启动文件的文件名。取代默认的~/.inputrc</td>
</tr>
<tr>
<td>JAVA_HOME=/app/jdk1.6</td>
<td></td>
</tr>
<tr>
<td>KDENIR=/usr</td>
<td></td>
</tr>
<tr>
<td>KDE IS PRELINKED=1</td>
<td></td>
</tr>
<tr>
<td>LANG=zh_CN.GB18030</td>
<td></td>
</tr>
<tr>
<td>LESSONPEN</td>
<td></td>
</tr>
<tr>
<td>LINES=36</td>
<td></td>
</tr>
<tr>
<td>LONGNAME=root</td>
<td>登陆的用户名</td>
</tr>
<tr>
<td>LS_COLORS=xx</td>
<td></td>
</tr>
<tr>
<td>MACHTYPE=x86_64-redhat-linux-gnu</td>
<td>包含一个描述正在运行bash的系统串</td>
</tr>
<tr>
<td>MAILCHECK=60</td>
<td>这个参数定义shell将隔多长时间（以秒为单位检查一次由参数MAILPATH或MAILFILE）指定的文件，看看是否有邮件到达。默认600秒</td>
</tr>
<tr>
<td>MAIL=/var/spool/mail/root</td>
<td>邮件全路径</td>
</tr>
<tr>
<td>OLDPWD=/root</td>
<td>前一个当前工作目录</td>
</tr>
<tr>
<td>OPTERR=1</td>
<td>如果设置为1，秒年十时毫，来自getopts内置命令的错误信息。</td>
</tr>
<tr>
<td>OPTIND=1</td>
<td>下一个有getopts内置命令处理的参数序号</td>
</tr>
<tr>
<td>OSTYPE=linux-gnu</td>
<td>自动设置称一个串，该串标书正在运行bash的操作系统，默认值有系统决定</td>
</tr>
<tr>
<td>PATH</td>
<td>全局PATH路径。命令搜索路径。一个有冒号分隔的目录列表，shell用它来搜索命令。默认路径有系统决定，并且由安装bash的管理员设置。</td>
</tr>
<tr>
<td>PIPESTATUS=([0]=0 [1]=1)</td>
<td>一个数组，包含一列最进在管道执行的前台作业的进程退出状态值。</td>
</tr>
<tr>
<td>PPID=1112</td>
<td>父进程的进程ID</td>
</tr>
<tr>
<td>PS1=[\u@\h \W]$</td>
<td>主提示符串，默认值是$</td>
</tr>
<tr>
<td>PS2= &gt;</td>
<td>次提示符串，默认值是&gt;</td>
</tr>
<tr>
<td>PS4=+</td>
<td>当开启追踪时使用的调试提示符串，默认值是+，追踪可用set-x开启。</td>
</tr>
<tr>
<td>PWD</td>
<td>当前用户家目录。</td>
</tr>
<tr>
<td>SHELL=/bin/bash</td>
<td></td>
</tr>
<tr>
<td>SHLVL=1</td>
<td>每启动一个bash实例就将其加1</td>
</tr>
<tr>
<td>TMOUT=3600</td>
<td>退出前等待超时的秒数。</td>
</tr>
<tr>
<td>UID=0</td>
<td>当前用户的UID，在shell启动时初始化。</td>
</tr>
<tr>
<td>USER=root</td>
<td>当前用户的用户名，在shell启动时初始化。</td>
</tr>
</tbody>
</table>
<p>自定义环境变量 <code>export</code></p>
<p>默认的环境变量 <code>env</code>（<code>printenv</code>）或<code>set</code></p>
<p>消除本地变量和环境变量 <code>unset </code></p>
<p>定义变量：<em><strong>习惯：数字不加引号，其他默认加双引号</strong></em></p>
<h3 id="引号">引号</h3>
<table>
<thead>
<tr>
<th>名称</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>单引     号</td>
<td>可以说是所见即所得：即将单引号内的所有内容都原样输出，或者描述为单引号里面看到的是什么就会输出什么。</td>
</tr>
<tr>
<td>双引号</td>
<td>把双引号内的所有内容都输出出来；如果内容中有命令（要反引下）、变量、特殊转义符等，会先把变量、命令解析出结果，然后再输出最终内容来。</td>
</tr>
<tr>
<td>无引号</td>
<td>把内容输出出来前，会将含有空格的字符串视为一个整体输出，如果内容中有命令、变量等，会先把变量、命令解析出结果，然后在输出最终内容来，如果字符串中带有空格等特殊字符，则不能完整的输出，需要改加双引号，一般连续的字符串，数字，路径等可以不加任何引号，不过无引号的情况最好用双引号替代之。</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="变量的命名规范">变量的命名规范</h3>
<ul>
<li>
<p><strong>变量名要统一</strong>，使用全部大写字母，如<code>APCHE_ERR_NUM</code>；语义要清晰，能够正确表达变量内容含义，过长的英文单词可采用前几个字符代替，多个单词连接用“_”连接，引用时，最好以<code>${APACHE_ERR_NUM}</code>或&quot;<code>${APACHE_ERR_NUM}</code>&ldquo;的方式引用变量。</p>
</li>
<li>
<p><strong>避免无意义字符或数字</strong>：例如下面的COUNT，并不知道其确切含义</p>
</li>
<li>
<p>范例1：COUNT的不确切定义  <code>COUNT=$(grep keywords file)</code></p>
</li>
<li>
<p>全局变量和局部变量命名</p>
<ul>
<li><strong>脚本中的全局变量定义</strong>，如<code>USER_HOME</code>或<code>USERHOME</code>，在变量使用时，使用 <code>{ }</code>将变量括或&rdquo;<code>${APACHE_ERR_NUM}&quot;</code>了；变量后还有字符串隔不开的情况下，用大括号扩一下 <code>${金庸}</code>新著作</li>
<li><strong>脚本中局部变量定义</strong>：存在于脚本函数<code>（function）</code>中的变量称为局部变量，要以local方式进行生命，使之只在本函数作用域内有效，防止变量在函数中的命名于变量外部程序中变量重名造成程序异常。下面是函数中的变量定义例子：</li>
</ul>
</li>
</ul>
<h3 id="特殊变量">特殊变量</h3>
<table>
<thead>
<tr>
<th>No</th>
<th>位置变量</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>$0</code></strong></td>
<td>当前执行的shell脚本的文件名，如果执行脚本带路径则包括脚本路径。</td>
</tr>
<tr>
<td><strong><code>$n</code></strong></td>
<td>当前执行的shell脚本的第n个参数值，n=1..9，当n为0时表示脚本文件名，如果n大于9用大括号括起来<code>${10}</code>.</td>
</tr>
<tr>
<td><strong><code>$#</code></strong></td>
<td>当前执行的shell脚本后面接的参数的总个数</td>
</tr>
<tr>
<td><strong><code>$*</code></strong></td>
<td>当前shell的所有传参的参数，将所有的参数视为单个字符串，相当于<code>“$1$2$3..</code>”注意$与#的区别</td>
</tr>
<tr>
<td><strong><code>$@</code></strong></td>
<td>这个程序的所有参数<code>“$1” “$​2” “$3” ....”</code>，这是将参数传递给其他程序的最佳方式，因为会保留所有内嵌在每个参数里的任何空白。</td>
</tr>
<tr>
<td></td>
<td><font color="red"><strong>进程状态变量</strong></font></td>
</tr>
<tr>
<td><strong><code>$$</code></strong></td>
<td>获得当前shell脚本的进程号（PID）</td>
</tr>
<tr>
<td><strong><code>$?</code></strong></td>
<td>执行上一个指令的返回值（0为成功，非0为失败）</td>
</tr>
<tr>
<td><strong><code>$!</code></strong></td>
<td>执行上一个指令的PID</td>
</tr>
<tr>
<td><strong><code>$_</code></strong></td>
<td>在此之前执行的命令或脚本的最后一个参数。</td>
</tr>
</tbody>
</table>
<p><code>$?</code>  返回值参考</p>
<table>
<thead>
<tr>
<th>no</th>
<th>意思</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>表示允许成功</td>
</tr>
<tr>
<td>2</td>
<td>权限拒绝</td>
</tr>
<tr>
<td>1~125</td>
<td>表示运行失败，脚本命令、系统命令错误或参数传递错误</td>
</tr>
<tr>
<td>126</td>
<td>找到该命令了，但是无法运行</td>
</tr>
<tr>
<td>127</td>
<td>为找打要运行的命令<code>$ zhangsan-bash: zhangsan: command not found</code> <code>$ echo $? 127</code></td>
</tr>
<tr>
<td>&gt;128</td>
<td>命令被系统强制结束<code>$ sleep 100000^C</code> <code>$ echo $?130</code></td>
</tr>
</tbody>
</table>
<h3 id="变量子串">变量子串</h3>
<table>
<thead>
<tr>
<th>表达式</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>${#string}</code></td>
<td>返回$string的长度</td>
</tr>
<tr>
<td><code>${string:position}</code></td>
<td>在$string中，从位置$position之后开始提取子串</td>
</tr>
<tr>
<td><code>${string:position:length}</code></td>
<td>在$string中，从位置position之后开始提取长度为length的子串</td>
</tr>
<tr>
<td><code>${string#sub}</code></td>
<td>从变量string开头开始删除最短匹配sub子串</td>
</tr>
<tr>
<td><code>${string##sub}</code></td>
<td>从变量开头开始删除最长匹配子串</td>
</tr>
<tr>
<td><code>${string%sub}</code></td>
<td>从变量string结尾开始删除最短匹配sub子串</td>
</tr>
<tr>
<td><code>${string%%sub}</code></td>
<td>从变量string结尾开始删除最长匹配sub子串</td>
</tr>
<tr>
<td><code>${string/sub/rep}</code></td>
<td>使用rep，来代替第一个匹配的sub</td>
</tr>
<tr>
<td><code>${string/#sub/rep}</code></td>
<td>如果string前缀匹配sub就用rep代替匹配sub</td>
</tr>
</tbody>
</table>
<h3 id="变量替换">变量替换</h3>
<table>
<thead>
<tr>
<th>运算符号</th>
<th>替换</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>${value:-word}</code></td>
<td>如果变量名存在且非null，则返回变量的值。否则，返回word字符串。用途：如果变量未定义，则返回默认值。范例：<code>${value:-word}</code>，如果value未定义，则表达式的值为word</td>
</tr>
<tr>
<td><code>${value:=word}</code></td>
<td>如果变量名存在且非null，则返回变量值。否则，设置这个变量值未word，并返回其值。用途：如果变量未定义，则设置变量为默认值，并返回默认值。范例：<code>${value:=word}</code>，如果value未定义，则设置value的值为word，返回表达式的值也为word。</td>
</tr>
<tr>
<td><code>${value:?&quot;not defined&quot;}</code></td>
<td>如果变量名存在且非null，则返回变量的值。否则显示变量名：msg，并退出当前的命令或脚本。用途：用于捕捉由于变量未定义而导致的错误，并退出程序。范例：<code>${value:?&quot;not defined&quot;}</code>如果value未定义，则显示<code>-bash:value:not defined</code>并退出。</td>
</tr>
<tr>
<td><code>${value:+word}</code></td>
<td>如果变量名存在且非null，则返回word。否则返回null。用途：测试变量是否存在。范例：<code>${value:+word}</code> 如果value已经定义，返回word（也是就是真）。</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="数值整数计算">数值（整数）计算</h2>
<h3 id="-">(( ))</h3>
<p>如果要执行简单的整数运算，只需将特定的算数表达式用 <code>(( </code> 和  <code>))</code> 括起来即可。</p>
<p>shell的算数运算符号常置于<code>$((</code> 和  <code>))</code>的语法中。这一语法如同双引号用能，除了内嵌双引号无需转义。</p>
<table>
<thead>
<tr>
<th>运算符</th>
<th>意义</th>
</tr>
</thead>
<tbody>
<tr>
<td>++ &ndash;</td>
<td>增加及减少，可前置也可放在结尾</td>
</tr>
<tr>
<td>+ - ！~</td>
<td>一元的正号与负号；逻辑与位的取反</td>
</tr>
<tr>
<td>* / %</td>
<td>乘法、除法、与取余</td>
</tr>
<tr>
<td>+ -</td>
<td>加法、减法</td>
</tr>
<tr>
<td>&lt; &lt;= &gt; &gt;=</td>
<td>比较负号</td>
</tr>
<tr>
<td>== !=</td>
<td>相等与不相等，一个“=”赋值</td>
</tr>
<tr>
<td>&laquo; &raquo;</td>
<td>向左位移 向右位移</td>
</tr>
<tr>
<td>&amp;</td>
<td>位的AND</td>
</tr>
<tr>
<td>^</td>
<td>位的异或</td>
</tr>
<tr>
<td>|</td>
<td>位的或</td>
</tr>
<tr>
<td>&amp;&amp;</td>
<td>逻辑的AND（make &amp;&amp; mak install）</td>
</tr>
<tr>
<td>||</td>
<td>逻辑的OR（make || make install）</td>
</tr>
<tr>
<td>?:</td>
<td>条件表达式</td>
</tr>
<tr>
<td>= += -= *= /= &amp;= ^= &laquo;= &raquo;= |=</td>
<td>赋值运算符 a+=1都相当a=a+1</td>
</tr>
</tbody>
</table>
<ul>
<li><code>**</code> 为幂运算：<code>%</code> 为取模运算（就是除法当中取余数）。</li>
<li>上面涉及到的参数变量必须位整数（==整型==）。不能是小数（浮点数）或者字符串。后面的bc命令可以进行浮点数运算，但一般较少用到。</li>
<li><code>echo $((a++))</code> 和 <code>$((a--))</code> 表示先输出a自身的值，然后在进行 <code>++-- </code>的运算，<code>echo$((++a))</code> 和 <code>echo$((--a))</code> 表示先进行 <code>++--</code> 的运算，在输出a自身的值。</li>
</ul>
<p><em><strong>记忆方法：变量在前，先输出变量值，变量在后，就是先运算后输出变量的值</strong></em></p>
<h3 id="let">let</h3>
<p>let赋值表达式，【注】let赋值表达式功能等同于<code>((赋值表达式))</code>  ，例如 <code>let i=i+8</code></p>
<h3 id="expr">expr</h3>
<p><strong>expr（evaluate（求值）expressions（表达式））命令</strong>：</p>
<p>expr命令一般用于整数值，但也可用于字符串，用来求表达式变量的值，同时expr是一个手工命令行计算器。</p>
<ul>
<li><code>expr 2 + 2</code></li>
<li><code>expr 2 - 1</code></li>
<li><code>expr 2 * 1</code></li>
<li><code>expr 2 \* 1</code></li>
<li><code>expr 3 % 2</code></li>
</ul>
<blockquote>
<p>expr$[$a+$b]表达式形式</p>
<pre><code class="language-bash"># expr $[2+3]
5
# expr $[2**3]
8
# echo $[2**3]
8
2、
# a=1
# b=2
# expr $[$a+$b]
3
expr 将其后的串解释为表达式计算其值，运算符前后需有空格
</code></pre>
</blockquote>
<h3 id="bc">bc</h3>
<p>bc是UNXI下的计算器，它也可以用在命令行中，bc支持科学计算，所以这种方法功能非常强大</p>
<pre><code class="language-bash"># 一般工作中不这么用
$ bc
bc 1.06.95
Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006 Free Software Foundation, Inc.
This is free software with ABSOLUTELY NO WARRANTY.
For details type `warranty'. 
1*5
5
1/5
0
5/3
1
10+2
12

# 
$ echo 5+10|bc
15
$ echo 5*20|bc
100
$ echo 10%3|bc
1
$ echo 10.5+3.1|bc
13.6
# 与expr的区别
$ echo `expr 1+1`
1+1
$ echo `expr 1 + 1`
2
$ echo `expr 1 + 1.2`
expr: 参数数目错误

$ echo 1+1|bc
2
$ echo 1 + 1|bc
2
# 保留小数位数
$ echo &quot;scale=2;10.45246/2.2315&quot;|bc
4.68
$ echo &quot;10.45246/2.2315&quot;|bc        
4
$ echo 10.45246/2.2315|bc  
4
# 进制转换
$ echo &quot;obase=2;2&quot;|bc
10
$ echo &quot;obase=10;10&quot;|bc
10
$ echo &quot;obase=8;10&quot;|bc 
12
范例：通过命令输出1+2+3+4..+10=XX的表达式，并计算出结果
$ echo `seq -s &quot;+&quot; 10`=`seq -s '+' 10|bc` 
1+2+3+4+5+6+7+8+9+10=55
$ echo `seq -s &quot;+&quot; 10`=$((`seq -s &quot;+&quot; 10`))
1+2+3+4+5+6+7+8+9+10=55
$ echo `seq -s &quot;+&quot; 10`=`seq -s ' + ' 10|xargs expr` 
1+2+3+4+5+6+7+8+9+10=55
$ echo {1..10}|tr &quot; &quot; &quot;+&quot;
1+2+3+4+5+6+7+8+9+10
$ echo {1..10}|tr &quot; &quot; &quot;+&quot;|bc
55
</code></pre>
<h3 id="heading">$[]</h3>
<pre><code class="language-bash"># echo $[2+3]
5
# echo $[  2  * 3  ]
6
</code></pre>
<h2 id="条件测试">条件测试</h2>
<p>​</p>
<h3 id="测试语句">测试语句</h3>
<table>
<thead>
<tr>
<th>语法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>语法1：<code>test &lt;测试表达式&gt;</code></td>
<td>利用test命令进行条,<strong>test后有一个空格</strong></td>
</tr>
<tr>
<td>语法2：<code>[ &lt;测试表达式&gt; ]</code></td>
<td>通过单中括号进行,<strong>单中括号中的内容前后都有一个空格</strong></td>
</tr>
<tr>
<td>语法3：<code>[[ &lt;测试表达式&gt; ]]</code></td>
<td>通过双中括号进行,<strong>双中括号中的内容前后都有一个空格</strong></td>
</tr>
<tr>
<td>语法4：<code>((&lt;测试表达式&gt;))</code></td>
<td>通过双小括号进行,<strong>双小括号中的内容前后无空格</strong></td>
</tr>
</tbody>
</table>
<p>在<code>[[ ]]</code>中可以使用通配符进行模式匹配。<code>&amp;&amp; || &gt; &lt;</code>等操作符可以应用于<code>[[ ]]</code>中，不能应用于<code>[ ]</code>中。<code>[]</code>中一般用<code>-a、-o、-gt</code> 等替代对整数进行关系运算，也可以使用Shell的算数运算符 <code>(( ))</code></p>
<h3 id="文件测试操作符"><strong>文件测试操作符</strong></h3>
<table>
<thead>
<tr>
<th>测试操作符</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>-f 文件file</td>
<td>若文件存在且为普通文件则真</td>
</tr>
<tr>
<td>-d 文件 directory</td>
<td>若文件存在且为目录文件则真</td>
</tr>
<tr>
<td>-s 文件 size</td>
<td>若文件存在切不为空（文件大小非0）则真</td>
</tr>
<tr>
<td>-e 文件 exist</td>
<td>若文件存在则真，要区别-f</td>
</tr>
<tr>
<td>-r 文件 read</td>
<td>若文件存在且可读则真</td>
</tr>
<tr>
<td>-w 文件write</td>
<td>若文件存在且可写则真</td>
</tr>
<tr>
<td>-x 文件 excute</td>
<td>若文件存在且可执行则真</td>
</tr>
<tr>
<td>-L 文件link</td>
<td>若文件存在且为链接文件则真</td>
</tr>
<tr>
<td>f1 -nt f2 never than</td>
<td>若文件f1比文件f2新则真</td>
</tr>
<tr>
<td>f1 -ot f2 older than</td>
<td>若文件f1比文件f2旧则真</td>
</tr>
<tr>
<td>f1 -ef f2</td>
<td>两个文件具有同样的设备号和i结点号</td>
</tr>
<tr>
<td>-k file</td>
<td>文件是否設置了粘着位(Sticky Bit)，如果是，則返回 true。 [ -k $file ] 返回 false。</td>
</tr>
<tr>
<td>-u file</td>
<td>文件是否設置了 SUID 位，如果是，則返回 true。 [ -u $file ] 返回 false。</td>
</tr>
<tr>
<td>-x file</td>
<td>文件是否可執行，如果是，則返回 true。</td>
</tr>
<tr>
<td>-p file</td>
<td>文件是否是有名管道，如果是，則返回 true。     [ -p $file ] 返回 false。</td>
</tr>
<tr>
<td>-w file</td>
<td>文件是否可寫，如果是，則返回 true。           [ -w $file ] 返回 true。</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="字符串测试操作符"><strong>字符串测试操作符</strong></h3>
<table>
<thead>
<tr>
<th>常用字符串测试操作符</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>-z &ldquo;string&rdquo;</td>
<td>若串长度为0则真，-z可以理解为zero</td>
</tr>
<tr>
<td>-n &ldquo;string&rdquo;</td>
<td>若长度不为0则真，-n可以理解为no zero</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>&ldquo;string1&rdquo;=&ldquo;string2&rdquo;</td>
<td>若串1等于串2则真，可使用“==”代替“=”</td>
</tr>
<tr>
<td>&ldquo;string1&rdquo; != &ldquo;string2&rdquo;</td>
<td>若串1不等于串2则真。但不能用“!==”代替“!=”</td>
</tr>
</tbody>
</table>
<h3 id="二元比较操作符">二元比较操作符</h3>
<table>
<thead>
<tr>
<th>在[]中使用的比较符</th>
<th>在[[ ]]中使用的比较符</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>-eq</td>
<td>==</td>
<td>equal的缩写，相等返回真</td>
</tr>
<tr>
<td>-ne</td>
<td>!=</td>
<td>not equal的缩写，不相等返回真</td>
</tr>
<tr>
<td>-gt</td>
<td>&gt;</td>
<td>大于greater than</td>
</tr>
<tr>
<td>-ge</td>
<td>&gt;=</td>
<td>大于等于 greate equal</td>
</tr>
<tr>
<td>-lt</td>
<td>&lt;</td>
<td>小于类似less than</td>
</tr>
<tr>
<td>-le</td>
<td>&lt;=</td>
<td>小于等于less equal</td>
</tr>
</tbody>
</table>
<h3 id="逻辑操作符">逻辑操作符</h3>
<table>
<thead>
<tr>
<th>在[ ]中使用的比较符</th>
<th>在[[ ]]中使用的比较符</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>-a</td>
<td>&amp;&amp;</td>
<td>and 与，两端都为真，则真</td>
</tr>
<tr>
<td>-o</td>
<td>||</td>
<td>or 或，两端有一个为真则真</td>
</tr>
<tr>
<td>!</td>
<td>!</td>
<td>not 非，相反则为真</td>
</tr>
</tbody>
</table>
<h2 id="字体颜色">字体颜色</h2>
<p>颜色范围：30-37</p>
<pre><code class="language-bash">echo -e &quot;\033[30m 黑字体 test \033[0m&quot;
echo -e &quot;\033[31m 红字体 test \033[0m&quot;
echo -e &quot;\033[32m 绿字体 test \033[0m&quot;
echo -e &quot;\033[33m 黄字体 test \033[0m&quot;
echo -e &quot;\033[34m 蓝字体 test \033[0m&quot;
echo -e &quot;\033[35m 紫字体 test \033[0m&quot;
echo -e &quot;\033[36m 天蓝字 test \033[0m&quot;
echo -e &quot;\033[37m 白色字 test \033[0m&quot;
</code></pre>
<p>40-47</p>
<pre><code class="language-bash">echo -e &quot;\033[40;37m 黑底白字 welcome \033[0m&quot;
echo -e &quot;\033[41;37m 红底白字 welcome \033[0m&quot; 
echo -e &quot;\033[42;37m 绿底白字 welcome \033[0m&quot; 
echo -e &quot;\033[43;37m 黄底白字 welcome \033[0m&quot; 
echo -e &quot;\033[44;37m 蓝底白字 welcome \033[0m&quot; 
echo -e &quot;\033[45;37m 紫底白字 welcome \033[0m&quot; 
echo -e &quot;\033[46;37m 天蓝底白字 welcome \033[0m&quot; 
echo -e &quot;\033[47;37m 白底白字 welcome \033[0m&quot; 
echo -e &quot;\033[47;30m 白底黑字 welcome \033[0m&quot; 
</code></pre>
<h3 id="通过定义变量方式给字体加颜色">通过定义变量方式给字体加颜色</h3>
<pre><code class="language-bash">#!/bin/bash
red='\033[31m'
green='\033[32m'
yellow='\033[33m'
blue='\033[34m'
pink='\E[1;35m'
end='\E[0m'

echo -e &quot;${red} ======red======${end}&quot;
echo -e &quot;${yellow} =====yellow=====${end}&quot;
</code></pre>
<h2 id="循环">循环</h2>
<h3 id="当型循环和直到型循环">当型循环和直到型循环</h3>
<pre><code class="language-bash">while条件句
语法：
while 条件
do
指令...
done
</code></pre>
<p>until</p>
<pre><code class="language-bash">until 条件.
do
指令...
done
</code></pre>
<p>for循环</p>
<pre><code>for varName in 变量取值列表
do
 	指令...
done
</code></pre>
<h3 id="读取文件">读取文件</h3>
<pre><code class="language-bash">1. 
cat.log|while read line
do
done
2.
while read line
do
done&lt;a.log
3)
exec &lt;a.log
while read line
do
done
</code></pre>
<h3 id="linux产生随机数的">linux产生随机数的</h3>
<ul>
<li>
<p>系统环境变量<code>$RANDAM</code> 范围 ==0-32767==</p>
<ul>
<li>
<p>随机数01-99之间的数字</p>
<pre><code class="language-bash">$[RANDOM%99+1] # 一个数和一个数取余这个数，这个数一定小于这个数
</code></pre>
</li>
</ul>
</li>
<li>
<p>openssl: <code> openssl rand -base64 8</code></p>
</li>
<li>
<p>通过时间获得随机数（date）: <code>date +%s%N</code></p>
</li>
<li>
<p><code>/dev/random</code>设备：/dev/random设备，存储着系统当前运行的环境的实时数据。它可以看作是系统某个时候，唯一值数据，因此可以用作随机数元数据。我们可以通过文件读取方式，读得里面数据。我们可以通过文件读取方式，读得里面数据。/dev/urandom这个设备数据与random里面一样。只是，他是非阻塞的随机数发生器，读取操作不会产生阻塞。</p>
</li>
<li>
<p>UUID：<code>cat /proc/sys/kernel/random/uuid</code></p>
</li>
<li>
<p><code>mkpasswd -l 8</code></p>
</li>
</ul>
<h2 id="数组">数组</h2>
<p>Shell 数组用==括号==来表示，元素用==&ldquo;空格&rdquo;==符号分割开：<code>array=(value1 value2 ... valuen)</code></p>
<ul>
<li>使用下标来定义数组: 	<code>array[0]=value0</code></li>
<li>读取数组：<code>${array[index]}</code></li>
<li>数组中的所有元素：<code>${array[*]}&quot;</code> 或  <code>${array[@]}&quot;</code></li>
<li>数组的长度：<code> ${#array[*]}</code> 或  <code> ${#array[@]}</code></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>如何将systemd服务的输出重定向到指定文件</title>
      <link>https://www.oomkill.com/2020/11/systemd-output/</link>
      <pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2020/11/systemd-output/</guid>
      <description></description>
      <content:encoded><![CDATA[<p>　　有一种更优雅的方法可以解决systemd输出到指定文件而非<code>/var/log/message</code>，需要使用systemd参数与rsyslog过滤器。并指示syslog过滤器按程序名称拆分其输出。</p>
<h2 id="systemd所需参数为">systemd所需参数为</h2>
<ul>
<li><strong><code>SyslogIdentifier</code></strong>：<em>required</em>，设置日志标识符(发送日志消息时加在行首的字符串)(&ldquo;syslog tag&rdquo;)。 默认值是进程的名称。此选项仅在 StandardOutput= 或 StandardError= 的值包含 journal(+console), syslog(+console), kmsg(+console) 之一时才有意义， 并且仅适用于输出到标准输出或标准错误的日志消息。</li>
<li><strong><code>StandardOutput</code></strong>：<em>required</em>，设置进程的标准输出(STDOUT)。 可设为 inherit, null, tty, journal, syslog, kmsg, journal+console, syslog+console, kmsg+console, file:path, append:path, socket, fd:name 之一。</li>
<li><strong><code>StandardError</code></strong>：设置进程的标准错误(STDERR)。 取值范围及含义与 StandardOutput= 相同。但有如下例外： (1) inherit 表示使用 StandardOutput= 的值。 (2) fd:name 的默认文件描述符名称为 &ldquo;stderr&rdquo;</li>
</ul>
<h2 id="rsyslog过滤器设置">rsyslog过滤器设置</h2>
<p>　　使用rsyslog条件选择器。如果不改变rsyslog目前工作模式，按照如下操作：</p>
<ol>
<li>
<p><strong>新建<code>/etc/rsyslog.d/xx.conf</code>文件</strong>。</p>
</li>
<li>
<p><strong>在新建文件内写入内容如下</strong></p>
</li>
</ol>
<p>单一条件处理。</p>
<pre><code class="language-conf">if $programname == 'programname' then /var/log/programname.log
# 停止往其他文件内写入，如果不加此句，会继续往/var/log/message写入。
if $programname == 'programname' then stop  
</code></pre>
<p>多条件处理</p>
<p>　　会根据不同应用名称将不同的输出日志重定向到不同的文件内。</p>
<pre><code class="language-conf">if ($programname == 'apiserver') then {
   action(type=&quot;omfile&quot; file=&quot;/var/log/apiserver.log&quot;)
   stop
} else if ($programname == 'scheduler') then {
   action(type=&quot;omfile&quot; file=&quot;/var/log/scheduler.log&quot;)
   stop
} else if ($programname == 'controller-manager') then {
   action(type=&quot;omfile&quot; file=&quot;/var/log/controller-manager.log&quot;)
   stop
} else if ($programname == 'etcd') then {
   action(type=&quot;omfile&quot; file=&quot;/var/log/etcd.log&quot;)
   stop
}
</code></pre>
<ol start="3">
<li>
<p><strong>检查语法是否正确</strong> <code>rsyslogd -N1 -f file_name.conf</code></p>
</li>
<li>
<p><strong>重新启动rsyslog</strong></p>
</li>
</ol>
<p>　　完成以上步骤后，应用的 <code>stdout</code> <code>stderr</code>被重定向到对应的日志文件内了，而非<code>/var/log/message</code>，并且仍然可以通过通过<code>journalctl</code>获得对应的<code>stdout</code> <code>stderr</code> （systemd参数机制）。</p>
<blockquote>
<p><strong>reference</strong></p>
<p><a href="http://www.jinbuguo.com/systemd/systemd.exec.html#StandardOutput=" target="_blank"
   rel="noopener nofollow noreferrer" >systemd</a></p>
<p><a href="https://rsyslog-mm.readthedocs.io/en/v7.4_stable/config/conditionals.html" target="_blank"
   rel="noopener nofollow noreferrer" >rsyslog-conditional</a></p>
<p><a href="https://stackoverflow.com/questions/44772640/redirecting-specific-logs-from-systemd-service-to-a-separate-file-doesnt-work" target="_blank"
   rel="noopener nofollow noreferrer" >rsyslog</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>centos配置</title>
      <link>https://www.oomkill.com/2020/09/centos-configration/</link>
      <pubDate>Thu, 17 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2020/09/centos-configration/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="centos7--centos8-设置终端屏幕分辨率">CentOS7 / CentOS8 设置终端屏幕分辨率</h2>
<h3 id="centos7">Centos7</h3>
<p>修改文件 <code>/boot/grub2/grub.cfg</code></p>
<p>搜索 <code>linux16</code></p>
<pre><code class="language-conf">vmlinuz-3.10.0-123.el7.x86_64 root=UUID=881ac4e6-4a55-47b1-b864-555de7051763 ro 
rd.lvm.lv=centos/swap vconsole.font=latarcyrheb-sun16 rd.lvm.lv=centos/root crashkernel=auto vconsole.keymap=us rhgb quiet LANG=en_US.UTF-8
</code></pre>
<p>添加如下,???具体看下表</p>
<pre><code>vga=0x???

vga=0x340
</code></pre>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/1380340-20200917113910028-1954088030.png" alt="" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="centos-8">CentOS 8</h3>
<p>CentOS8 使用了 blsgcfg来解析文件生成菜单项。菜单项配置文件在<code>/boot/loader/entries/</code>下，每一个文件表示一个启动项。</p>
<p>这里需要修改启动项的参数，这里修改<code>options</code>，实际上是修改了 <code>/boot/grub2/grubenv</code>对应的值。</p>
<pre><code>options $kernelopts $tuned_params
</code></pre>
<p>可以直接修改<code>/etc/sysconfig/grub</code>中的<code>GRUB_CMDLINE_LINUX</code>值后增加=加<code>vga=0x???</code> （对照分辨率表修改???）。</p>
<p>修改完成后执行 <code>grub2-mkconfig -o /boot/grub2/grub.cfg</code> 重启即修改了<code>/boot/grub2/grubenv</code>对应的值。</p>
<h2 id="centos7-启动引导顺序">centos7 启动引导顺序</h2>
<ol>
<li>查看默认启动项 <code>grub2-editenv list</code></li>
<li>查看启动项列表 <code>awk -F\' '$1==&quot;menuentry &quot; {print $2}' /etc/grub2.cfg</code></li>
<li>设置默认引导 <code>grub2-set-default 'Windows 10' </code></li>
<li>设置默认启动项 <code>grub2-set-default 2</code> 需要按照启动项列表顺序</li>
<li>重新生成grub2.cfg <code> grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg</code></li>
<li>修改对应配置 <code>cat /etc/default/grub</code></li>
</ol>
<h2 id="centos7-精简开机自启动">centos7 精简开机自启动</h2>
<p>centos7 精简开机自启动</p>
<p>ntsysv rsyslog crond sshd network</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/1380340-20190208145546642-1078238986.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>named主从部署</title>
      <link>https://www.oomkill.com/2020/02/dns/</link>
      <pubDate>Mon, 17 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2020/02/dns/</guid>
      <description></description>
      <content:encoded><![CDATA[<pre><code class="language-conf">//
// named.conf
//
// Provided by Red Hat bind package to configure the ISC BIND named(8) DNS
// server as a caching only nameserver (as a localhost DNS resolver only).
//
// See /usr/share/doc/bind*/sample/ for example named configuration files.
//
// See the BIND Administrator's Reference Manual (ARM) for details about the
// configuration located in /usr/share/doc/bind-{version}/Bv9ARM.html

options {
	listen-on port 53 { any; };
//	listen-on-v6 port 53 { ::1; };
	directory 	&quot;/data/named&quot;;
	dump-file 	&quot;/data/named/data/cache_dump.db&quot;;
	statistics-file &quot;/data/named/data/named_stats.txt&quot;;
	memstatistics-file &quot;/data/named/data/named_mem_stats.txt&quot;;
	recursing-file  &quot;/data/named/data/named.recursing&quot;;
	secroots-file   &quot;/data/named/data/named.secroots&quot;;
	allow-query     { any; };
	allow-query-cache { any; };
	/* 
	 - If you are building an AUTHORITATIVE DNS server, do NOT enable recursion.
	 - If you are building a RECURSIVE (caching) DNS server, you need to enable 
	   recursion. 
	 - If your recursive DNS server has a public IP address, you MUST enable access 
	   control to limit queries to your legitimate users. Failing to do so will
	   cause your server to become part of large scale DNS amplification 
	   attacks. Implementing BCP38 within your network would greatly
	   reduce such attack surface 
	*/
	recursion yes;

	dnssec-enable no;
	dnssec-validation no;

	/* Path to ISC DLV key */
	bindkeys-file &quot;/etc/named.root.key&quot;;

	managed-keys-directory &quot;/data/named/dynamic&quot;;

	pid-file &quot;/run/named/named.pid&quot;;
	session-keyfile &quot;/run/named/session.key&quot;;
};
statistics-channels {

       inet 127.0.0.1 port 53 allow { 127.0.0.1; };

};

logging {
        channel default_debug {
                file &quot;/data/logs/named/named.run&quot;;
                severity dynamic;
        };
	channel warning {
          file &quot;/data/logs/named/named.log&quot; versions 100 size10m;
          severity warning;
          print-category yes;
          print-severity yes;
          print-time yes;
         };
         channel query {
           file &quot;/data/logs/named/query.log&quot; versions 100 size 10m;
           severity info;
           print-category yes;
           print-severity yes;
           print-time yes;
         };
         category default { warning; };
         category queries { query; };
};

zone &quot;.&quot; IN {
	type hint;
	file &quot;named.ca&quot;;
};

key &quot;rndc-key&quot; {
    algorithm hmac-md5;
    secret &quot;R+pzomztOItyduEqVF2gjA==&quot;;
};

include &quot;/etc/named.rfc1912.zones&quot;;
include &quot;/etc/named.root.key&quot;;
</code></pre>
<pre><code class="language-conf">zone &quot;tvbshare.com&quot; IN {
	type master;
	file &quot;tvbshare.com.zone&quot;;
	allow-transfer { 10.11.17.90; 10.11.17.89; };
        allow-update { 10.11.17.89; };
};

zone &quot;r_tvbshare_prod.service.tvbshare&quot; IN {
	type forward;
        forwarders { 10.11.11.5;  10.11.11.6; };
         forward only;
};

zone &quot;w_tvbshare_prod.service.tvbshare&quot; IN {
        type forward;
        forwarders { 10.11.11.4; };
        forward only;
};

</code></pre>
<p>slave</p>
<pre><code class="language-conf">zone &quot;tvbshare.com&quot; IN {
	type slave;
	masters { 10.11.17.89; };
	masterfile-format text;
	file &quot;slaves/tvbshare.com.zone&quot;;
};

zone &quot;r_tvbshare_prod.service.tvbshare&quot; IN {
        type forward;
        forwarders { 10.11.11.5;  10.11.11.6; };
         forward only;
};

zone &quot;w_tvbshare_prod.service.tvbshare&quot; IN {
        type forward;
        forwarders { 10.11.11.4; };
        forward only;
};

</code></pre>
<p><a href="http://www.361way.com/bind-master-slave/4811.html" target="_blank"
   rel="noopener nofollow noreferrer" >http://www.361way.com/bind-master-slave/4811.html</a></p>
<p><a href="https://www.cnblogs.com/fuhai0815/p/8459670.html" target="_blank"
   rel="noopener nofollow noreferrer" >https://www.cnblogs.com/fuhai0815/p/8459670.html</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Unix归档模式 cpio - 深入剖析与构建rpm包</title>
      <link>https://www.oomkill.com/2018/09/rpm-package/</link>
      <pubDate>Sat, 15 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2018/09/rpm-package/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="rpm概述">RPM概述</h2>
<p>RPM (<em><strong>Red Hat Package Manager</strong></em>)，几乎所有的 Linux 发行版本都使用这种形式的软件包管理安装、更新和卸载软件。对于最终用户来说，使用RPM所提供的功能来维护系统是比较容易和轻松的。安装、卸载和升级RPM软件包只需一条命令就可以搞定。RPM维护了一个所有已安装的软件包和文件的数据库，可以让用户进行查询和验证工作。在软件包升级过程中，RPM会对配置文件进行特别处理，绝对不会丢失以往的定制信息。对于程序员RPM可以让我们连同软件的源代码打包成源代码和二进制软件包供最终用户使用。</p>
<p>一般而言制作一个RPM包包含以下几个步骤</p>
<ul>
<li>计划你想要建立什么</li>
<li>收集软件包</li>
<li>根据需要修补软件</li>
<li>计划升级旧有的包</li>
<li>创建可重现的软件构建</li>
<li>概述任何依赖关系</li>
<li>构建rpm</li>
<li>测试rpm（能否安装、升级）</li>
</ul>
<p>RPM capability 能力
运行或安装需要依赖于其他的RPM包本身或所提供的文件为基础的现象被称之为依赖关系。但在制作RPM包时，依赖关系有两类<code>编译依赖</code>与<code>安装依赖</code>。</p>
<ul>
<li>自身名字所包含的意义</li>
<li>它提供的文件也有可能被其他软件所依赖，文件本身也能识别成一种能力</li>
</ul>
<p>编译依赖和安装依赖</p>
<p>每一个RPM包都提供一种能够完成任务的功能，此种能力很可能被其他RPM所依赖，此能力大多数情况下和RPM名字是相同的。</p>
<p>制作RPM包的纲要有如下四部</p>
<ul>
<li>设定RPM包制作的目录结构（制作车间）</li>
<li>将原材料（源码包、配置文件、补丁包）放置规划好的目录当中。</li>
<li>创建spec文件，指挥如何使用原材料将其制作成rpm包。</li>
<li>编译源代码生成rpm包</li>
</ul>
<p>在一个特定的目录中提供如下5个子目录 redhat上默认在<code>/usr/src/reahat </code></p>
<ul>
<li><code>BUILD</code> 源代码解压以后放置的位置，仅需提供目录。</li>
<li><code>RPMS</code>  放置制作完成后的RPM包</li>
<li><code>SOURCES</code> 原材料放置目录（配置文件、源码包、补丁包）</li>
<li><code>SPECS</code> 放置spec文件（纲领性文件）的。</li>
<li><code>SRPMS</code> SRC rpm包存放位置</li>
</ul>
<h2 id="rpm优缺点">RPM优缺点</h2>
<p>优点：</p>
<ol>
<li>集中管理：RPM可以集中管理安装、升级和删除软件包，保证系统的干净和稳定。</li>
<li>精确控制：RPM提供详细的软件包信息，可以对软件包的安装路径、依赖关系、版本等进行精确控制，使得软件安装更加灵活便捷。</li>
<li>简单易用：RPM提供了一套完整的命令行工具和图形化管理工具，对于普通用户来说，使用起来非常方便。</li>
<li>更新机制：RPM可以根据用户需要进行更新，包括安全更新、功能更新和修复错误等，可以更好地保证系统安全与稳定性。</li>
</ol>
<p>缺点：</p>
<ol>
<li>依赖管理：RPM虽然可以管理软件包的依赖关系，但其解决依赖的方式容易出现问题，可能会出现某些软件包的依赖关系无法解决的情况。</li>
<li>更新速度：由于需要对软件包进行依赖检查等操作，升级软件包可能需要较长时间，特别是当软件包依赖比较复杂时。</li>
<li>存在问题：有时候使用RPM安装的软件包出现问题，需要手动卸载并重新安装，这会导致一些无法预测的麻烦。</li>
<li>兼容性：RPM采用了特定的软件包管理标准，要求安装的软件包必须符合这些标准。因此，RPM可能不太适用于其他Linux系统或自定义的软件包格式。</li>
</ol>
<h2 id="spec文件">SPEC文件</h2>
<p>制作RPM软件包的关键在于编写SPEC软件包描述文件。要想制作一个rpm软件包就必须写一个软件包描述文件（SPEC）。这个文件中包含了软件包的诸多信息，如软件包的名字、版本、类别、说明摘要、创建时要执行什么指令、安装时要执行什么操作、以及软件包所要包含的文件列表等等。</p>
<p><strong>SPEC文件通常包括以下几个部分</strong>：</p>
<ol>
<li>
<p>头文件：包括软件包的名称、版本、发布号、授权等信息。</p>
</li>
<li>
<p>%description：包括软件包的描述、依赖关系、构建环境等信息。</p>
</li>
<li>
<p>%prep：指定源代码的来源和如何解压缩及准备源代码。</p>
</li>
<li>
<p>%build：指定如何编译源代码。</p>
</li>
<li>
<p>%install：指定如何安装编译好的软件包。</p>
</li>
<li>
<p>%check：指定测试源代码的特定部分，通常是用来运行单元测试。</p>
</li>
<li>
<p>%clean：指定清除构建过程中产生的临时文件和目录的方法。</p>
</li>
<li>
<p>%files：指定哪些文件应该包括在最终的RPM文件中。</p>
</li>
<li>
<p>%changelog：记录软件包的变更历史。</p>
</li>
</ol>
<h3 id="spec文件中常用的宏变量">SPEC文件中常用的宏变量</h3>
<table>
<thead>
<tr>
<th>宏变量</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>%{name}</td>
<td>软件包的名称，如 myapp。</td>
</tr>
<tr>
<td>%{version}</td>
<td>软件包的版本号，如 1.0.0。</td>
</tr>
<tr>
<td>%{release}</td>
<td>软件包的发布号，如 1。</td>
</tr>
<tr>
<td>%{buildroot}</td>
<td>RPM 构建过程中的临时根目录目，模拟真实的rootfs。</td>
</tr>
<tr>
<td>%{_bindir}</td>
<td>系统安装二进制程序的目录，通常是 /usr/bin。</td>
</tr>
<tr>
<td>%{_docdir}</td>
<td>man dbus 查看帮助的文档的目录，通常是 /usr/share/doc</td>
</tr>
<tr>
<td>%{_datadir}</td>
<td>系统安装数据文件的目录，通常是 /usr/share。</td>
</tr>
<tr>
<td>%{_includedir}</td>
<td>系统安装头文件的目录，通常是 /usr/include。</td>
</tr>
<tr>
<td>%{_libdir}</td>
<td>系统安装库文件的目录，通常是 /usr/lib，64位为 /usr/lib64</td>
</tr>
<tr>
<td>%{_datarootdir}</td>
<td>系统安装数据的根目录，通常是 /usr/share。</td>
</tr>
<tr>
<td>%{_prefix}</td>
<td>软件的安装路径前缀，通常是 /usr。</td>
</tr>
<tr>
<td>%{_sysconfdir}</td>
<td>系统配置文件的目录，通常是 /etc。</td>
</tr>
<tr>
<td>%{_var}</td>
<td>系统的/var目录路径</td>
</tr>
</tbody>
</table>
<p>通常情况下在封装包时使用这些宏变量，封装对应目录下的内容而不用考虑每种 Linux 系统的路径差异。例如，我们可以使用 <code>%{_bindir}</code> 来指定安装软件的二进制程序所在目录，而不需要考虑不同系统中二进制程序目录的具体路径，这样可以确保软件在不同系统中能够正确安装和运行。</p>
<h3 id="spec参数解释">SPEC参数解释</h3>
<h4 id="文件头部分">文件头部分</h4>
<table>
<thead>
<tr>
<th>参数</th>
<th>详解</th>
</tr>
</thead>
<tbody>
<tr>
<td>Name</td>
<td>软件的名称，<font color="#f8070d" size=3>构成RPM文件的文件名构成之一</font></td>
</tr>
<tr>
<td>Version</td>
<td>软件的版本号，<font color="#f8070d" size=3>构成RPM文件的文件名构成之一</font></td>
</tr>
<tr>
<td>Release</td>
<td>该版本打包的次数说明，<font color="#f8070d" size=3>构成RPM文件的文件名构成之一</font></td>
</tr>
<tr>
<td>Group</td>
<td>软件开发团体名称</td>
</tr>
<tr>
<td>Source</td>
<td>软件的来源，可以是URl或者文件。可以有多个，如：<br>Source: php-5.3.29.tar.gz<br>Source1:php.ini<br>Source2:php-fpm</td>
</tr>
<tr>
<td>Patch</td>
<td>作为软件的补丁。</td>
</tr>
<tr>
<td>BuildRoot</td>
<td>设置编译时，临时存放中间文件的路径。</td>
</tr>
<tr>
<td>License</td>
<td>软件授权模式。一般使用GPL。</td>
</tr>
<tr>
<td>Requires</td>
<td>这个软件的依赖程序。</td>
</tr>
</tbody>
</table>
<h4 id="description">description</h4>
<p>软件的尖端说明。<font style="background:#fee904;" size=2>这个是必须的</font>。<code>rpm -qi software name</code>显示的基础说明。</p>
<h4 id="prep">prep</h4>
<p>prepare的简写，此段的意思为，尚未进行设置或安装之前，你要编译完成的PRM帮你事先做的事情。一般情况有如下事项：</p>
<ol>
<li>进行软件的补丁相关工作。</li>
<li>寻找软件需要的目录是否存在。</li>
<li>事先创建软件所需要的目录，或事先进行的任务。</li>
<li>备份可能会替换的文件。</li>
</ol>
<pre><code class="language-bash">id nginx || useradd nginx -s /sbin/nologin -M
%setup -q
</code></pre>
<h4 id="setup">setup</h4>
<p>此选项类似于解压之类的工作，常用选项如下表所示：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>%setup</td>
<td>不加任何选项，仅将软件包打开。</td>
</tr>
<tr>
<td>%setup -n newdir</td>
<td>将软件包解压在newdir目录。</td>
</tr>
<tr>
<td>%setup -c</td>
<td>解压缩之前先产生目录。</td>
</tr>
<tr>
<td>%setup -b num</td>
<td>将第num个source文件解压缩。</td>
</tr>
<tr>
<td>%setup -T</td>
<td>不使用default的解压缩操作。</td>
</tr>
<tr>
<td>%setup -T -b 0</td>
<td>将第0个源代码文件解压缩。</td>
</tr>
<tr>
<td>%setup -c -n newdir</td>
<td>指定目录名称newdir，并在此目录产生rpm套件。</td>
</tr>
<tr>
<td>%setup -q</td>
<td>提取源码到 BUILD 目录; -q 指不显示输出（quietly）</td>
</tr>
</tbody>
</table>
<h4 id="build-构建区域">build 构建区域</h4>
<p>所要执行的命令为生成软件包服务，如configure、make等操作。</p>
<pre><code class="language-bash">./configure
make -j 4
</code></pre>
<h4 id="install-安装区域">install 安装区域</h4>
<p>其中的命令在安装软件包时将执行，如make install命令。在spec文件中的make install后面加上<code>DESTDIR=%{buildroot}</code>
DESTDIR是Makefile文件中定义的一个安装路径的变量，根据实际情况修改，<font style="background:#fee904;" size=2> 例如mysql和nginx的是DESTDIR</font>，而<font style="background:#02fa3c;" size=2>php的是INSTALL_ROOT</font>。</p>
<pre><code class="language-bash">%install
make INSTALL_ROOT=%{buildroot} install  #&lt;==php
make install DESTDIR=%{buildroot} #&lt;==nginx
</code></pre>
<h4 id="files-打包文件区域">files 打包文件区域</h4>
<p>定义哪些文件将被打包入RPM中，分为三类&ndash;说明文档（doc），配置文件（config）及执行程序，还可定义文件存取权限，拥有者及组别。</p>
<ul>
<li><code>%defattr (-,root,root)</code> 指定包装文件的属性，分别是(mode,owner,group)，<code>-</code> 表示默认值，对文本文件是0644，可执行文件是0755</li>
<li>%exclude 列出不想打包到rpm中的文件。</li>
<li>%dir 来指定空目录</li>
<li>%config  配置文件</li>
<li>%doc 文档</li>
</ul>
<pre><code class="language-bash">%files
%defattr(-,root,root,-)
/usr/share/php-5.3.29/*
</code></pre>
<hr>
<p><font color=#0215cd size=3> <strong>注：这里是在虚拟根目录下进行，千万不要写绝对路径，而应用宏或变量表示相对路径。</strong></font></p>
<hr>
<h4 id="changelog-修改日志区域">changelog 修改日志区域</h4>
<p>语法：第一行是：<code>* 星期 月 日 年 修改人 电子信箱</code>；其中：星期、月份均用英文形式的前3个字母，用中文会报错。
接下来的行写的是修改了什么地方，<font color="#f8070d" size=2><strong>一般以&quot; - &ldquo;号开始，可写多行。</strong></font></p>
<pre><code class="language-bash">* Tue Dec 29 1998 lc &lt;lc.com@gmail.com&gt;
- minimum spec and patches changes for openssl
- modified for openssl sources
</code></pre>
<p>附录：</p>
<ol>
<li><strong>12个月简写</strong></li>
</ol>
<table>
<thead>
<tr>
<th>全称</th>
<th>简写</th>
</tr>
</thead>
<tbody>
<tr>
<td>January</td>
<td>Jan</td>
</tr>
<tr>
<td>February</td>
<td>Feb</td>
</tr>
<tr>
<td>March</td>
<td>Ma</td>
</tr>
<tr>
<td>April</td>
<td>Apr</td>
</tr>
<tr>
<td>May</td>
<td>-</td>
</tr>
<tr>
<td>June</td>
<td>-</td>
</tr>
<tr>
<td>July</td>
<td>-</td>
</tr>
<tr>
<td>August</td>
<td>Aug</td>
</tr>
<tr>
<td>September</td>
<td>Sept</td>
</tr>
<tr>
<td>October</td>
<td>Oct</td>
</tr>
<tr>
<td>November</td>
<td>Nov</td>
</tr>
<tr>
<td>December</td>
<td>Dec</td>
</tr>
</tbody>
</table>
<ol start="2">
<li><strong>一星期7日简写</strong></li>
</ol>
<table>
<thead>
<tr>
<th>全称</th>
<th>简写</th>
</tr>
</thead>
<tbody>
<tr>
<td>Monday</td>
<td>Mon</td>
</tr>
<tr>
<td>Tuesday</td>
<td>Tues</td>
</tr>
<tr>
<td>Wednesday</td>
<td>Wed</td>
</tr>
<tr>
<td>Thurday</td>
<td>Thur</td>
</tr>
<tr>
<td>Friday</td>
<td>Fri</td>
</tr>
<tr>
<td>Saturday</td>
<td>Sat</td>
</tr>
<tr>
<td>Sunday</td>
<td>Sun</td>
</tr>
</tbody>
</table>
<h4 id="clean-清理区域">clean 清理区域</h4>
<p>用来清理 build 后的临时文件,主要是怕这些旧的文件影响以后编译。主要是要删除 $RPM_BUILD_ROOT 和运行 make clean 。</p>
<h4 id="d-bus0-scriptlets">D-Bus0 Scriptlets</h4>
<p>这些选项可以让你动态的使用 shell 脚本来控制安装和删除，</p>
<ul>
<li>%pre    rpm安装前执行的脚本</li>
<li>%post   rpm安装后执行的脚本</li>
<li>%preun  rpm卸载前执行的脚本</li>
<li>%postun rpm卸载后执行的脚本</li>
</ul>
<hr>
<p>%preun 在升级的时候会执行， %postun在升级rpm包的时候不会执行</p>
<hr>
<pre><code class="language-bash">rpm -q --scripts packagename # 查看脚本的信息  SERVER_BIN_DIR	 CLIENT_BIN_DIR
</code></pre>
<h3 id="示例nginxspec">示例nginx.spec</h3>
<pre><code class="language-bash">Name: nginx
Version: 1.13.9
Release: 1%{?dist}
Summary: nginx
Group: nginx
License: GPL
URL: http://dangjian.chinamoblie.com
Packager: nginx
Vendor: nginx
Source0: nginx-1.13.9.tar.gz
Source1: nginx.service
Requires: openssl-devel,pcre-devel
BuildRoot: %{_tmppath}/%{name}-%{version}-buildroot
%description 
nginx

%prep
id nginx || useradd nginx -s /sbin/nologin -M
%setup -q
chmod +x ./configure

%build
./configure --prefix=/usr/share/nginx \
--sbin-path=/usr/sbin/nginx \
--with-stream \
--conf-path=/etc/nginx/nginx.conf \
--error-log-path=/data/nginx/log/error.log \
--pid-path=/data/nginx/run/nginx.pid \
--lock-path=/data/nginx/lock/nginx.lock \
--user=nginx --group=nginx \
--with-http_ssl_module \
--with-http_stub_status_module \
--with-http_flv_module \
--with-http_gzip_static_module \
--http-log-path=/data/nginx/log/access.log --http-client-body-temp-path=/data/nginx/tmp/client/ \
--http-proxy-temp-path=/data/nginx/tmp/proxy/ \
--http-fastcgi-temp-path=/data/nginx/tmp/fcgi/ \
--http-scgi-temp-path=/data/nginx/tmp/scgi \
--http-uwsgi-temp-path=/data/nginx/tmp/uwsgi

make

%install
make install DESTDIR=$RPM_BUILD_ROOT
%{__install} -p -D %{SOURCE1} %{buildroot}/usr/lib/systemd/system/nginx.service
%{__mkdir_p} /data/nginx/tmp/{client,uwsgi,scgi,fcgi,proxy}

%files
%defattr(-,root,root,-)
%attr(0644,root,root) /usr/share/nginx/*
%attr(0755,root,root) /usr/sbin/nginx
%attr(0644,root,root) /etc/nginx/*
%attr(0744,nginx,nginx) /data/nginx/*
%attr(0744,root,root) /usr/lib/systemd/system/nginx.service

%clean
rm -rf $RPM_BUILD_DIR/%{name}-%{version}

%pre
id nginx || useradd nginx -s /sbin/nologin -M

%preun
systemctl stop nginx

%postun
rm -fr /data/nginx/
userdel nginx

%changelog
* Sun Aug 24 2015 LC 1.15-1
- package libiconv-1.15
</code></pre>
<h2 id="rpmbuild">rpmbuild</h2>
<p>rpmbuild 是用于构建 RPM 包的工具。RPM 是一种软件包管理格式，它可以简化软件的分发，使其在不同的 Linux 系统上易于安装和使用。rpmbuild 工具可以帮助我们构建这样的 RPM 包。</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>-ba</td>
<td>既生成src.rpm又生成二进制rpm</td>
</tr>
<tr>
<td>-bs</td>
<td>只生成src的rpm</td>
</tr>
<tr>
<td>-bb</td>
<td>只生二进制的rpm</td>
</tr>
<tr>
<td>-bp</td>
<td>执行到pre</td>
</tr>
<tr>
<td>-bc</td>
<td>执行到 build段</td>
</tr>
<tr>
<td>-bi</td>
<td>执行install段</td>
</tr>
<tr>
<td>-bl</td>
<td>检测有文件没包含</td>
</tr>
</tbody>
</table>
<h3 id="rpmbuild-安装">rpmbuild 安装</h3>
<p>rpm包并不仅仅限制于 Fedora/Redhat ，也可以使用在其他的发行版中</p>
<p>对于 CentOS：</p>
<pre><code class="language-bash">sudo yum install -y rpm-build redhat-rpm-config rpmdevtools
</code></pre>
<p>对于 Fedora：</p>
<pre><code class="language-bash">sudo dnf install -y rpm-build redhat-rpm-config rpmdevtools
</code></pre>
<p>对于 Ubuntu：</p>
<pre><code class="language-bash">sudo apt install -y rpm
</code></pre>
<p>查看默认宏</p>
<pre><code class="language-bash"> rpmbuild --showrc
</code></pre>
<h3 id="创建-rpm-构建目录">创建 RPM 构建目录</h3>
<p>要开始构建 RPM 包，您需要先创建 RPM 构建目录和相关文件。使用以下命令创建 RPM 构建目录和必要的子目录：</p>
<pre><code class="language-bash">cd ~
mkdir -p rpmbuild/{BUILD,RPMS,SOURCES,SPECS,SRPMS}
</code></pre>
<p>上述命令创建了 5 个子目录：</p>
<ul>
<li>BUILD: 构建 RPM 包所需的源码和二进制文件存放的目录。</li>
<li>RPMS: 二进制 RPM 包保存的目录。</li>
<li>SOURCES: 存储软件包的源代码，rpmbuild 根据该代码创建 RPM 包。</li>
<li>SPECS: INCLUDE metadata and build instructions files for creating RPM files</li>
<li>SRPMS: 用于存储源 RPM 包的目录。</li>
</ul>
<h2 id="rpmbuild示例如何使用rpmbuild制作php-rpm包">rpmbuild示例：如何使用rpmbuild制作php rpm包</h2>
<pre><code class="language-sh">mkdir -pv ~/rpmbuild/{BUILD,RPMS,SOURCES,SPECS,SRPMS}
</code></pre>
<p>php有一个依赖库，在yum源于epel源中都没有需要自己打包<code>libiconv</code></p>
<blockquote>
<p><strong>编写  libiconv 的spec文件</strong></p>
</blockquote>
<pre><code class="language-bash">%define __os_install_post %{nil}
%define debug_package %{nil}
Name: libiconv
Version: 1.15
Release: 1%{?dist}
Summary: liconv
Group: liconv
License: GPL
URL: http://www.test.net
Packager: test
Vendor: test
Source0: libiconv-1.15.tar.gz
BuildRoot: %{_tmppath}/%{name}-%{version}-buildroot
%description 
iconv

%prep
%setup -q

%build
./configure --prefix=/usr/share/libiconv-1.15 \

make

%install
make install DESTDIR=%{buildroot}


%files
%defattr(-,root,root,-)
%attr(0655,root,root) /usr/share/libiconv-1.15/*
%attr(0755,root,root) /usr/share/libiconv-1.15/bin/*


%clean
rm -rf $RPM_BUILD_DIR/%{name}-%{version}

%post
ln -sv /usr/share/libiconv-1.15/ /usr/share/libiconv

%changelog
* Sun Aug 24 2015 LC 1.15-1
- package libiconv-1.15

</code></pre>
<h3 id="打包libiconv遇到的错误">打包libiconv遇到的错误</h3>
<pre><code class="language-bash">Binary file /root/rpmbuild/BUILDROOT/libiconv-1.15.el7.centos.x86_64/usr/share/libiconv-1.15/bin/iconv matches
Found '/root/rpmbuild/BUILDROOT/libiconv-1.15-1.el7.centos.x86_64' in installed files; aborting
error: Bad exit status from /var/tmp/rpm-tmp.6AgqPk (%install)


RPM build errors:
    Bad exit status from /var/tmp/rpm-tmp.6AgqPk (%install)
</code></pre>
<p><strong>问题原因</strong>：</p>
<p>在rpm构建过程中，在％install阶段结束时，运行 <code>/usr/lib/rpm/check-buildroot</code>脚本以检查构建根目录中的文件。此脚本扫描构建根目录中的所有文件，以获取<code>${RPM_BUILD_ROOT}</code>路径的任何引用。</p>
<p>也就是说libiconv已经编译完成。一般情况下，是可以正常使用的。所以不需要他检查构建根目录。</p>
<p><strong>解决方法</strong>：通过报错信息可以得到如下提示</p>
<pre><code class="language-bash">RPM build errors:
    Bad exit status from /var/tmp/rpm-tmp.6AgqPk (%install)
</code></pre>
<p>根据保存信息查看文件的执行过程。<code>/var/tmp/rpm-tmp.6AgqPk</code>，并发现脚本在执行到<code>/usr/lib/rpm/check-buildroot</code>时停止了。也就是说，执行这个脚本检查构建根目录时<code>$?</code>不为0</p>
<pre><code class="language-bash">cd 'libiconv-1.15'

make install DESTDIR=/root/rpmbuild/BUILDROOT/libiconv-1.15-1.el7.centos.x86_64

    /usr/lib/rpm/check-buildroot
</code></pre>
<p>查看<code>/usr/lib/rpm/check-buildroot</code>脚本，发现只有此段检查才<code>$?</code>返回的是1。</p>
<pre><code class="language-bash">test -s &quot;$tmp&quot; &amp;&amp; {
    cat &quot;$tmp&quot;
    echo &quot;Found '$RPM_BUILD_ROOT' in installed files; aborting&quot;
    exit 1
} || :  
</code></pre>
<p>由于压根不知道 <code>$tmp</code> 在哪里传入的。又压根可以不检查构建根目录的。直接在 <code>/usr/lib/rpm/check-buildroot</code> 脚本最前面加上 <code>exit 0</code> 让构建RPM包时跳过此步骤。之后成功完成rpm构建。</p>
<p><strong>参考文档</strong>：
<a href="http://pktechpage.blogspot.com/2015/09/found-rpmbuildroot-in-installed-files.html" target="_blank"
   rel="noopener nofollow noreferrer" >pk&rsquo;s Tech Page: Found &lsquo;${RPM_BUILD_ROOT}&rsquo; in installed files; aborting</a></p>
<p><a href="https://stackoverflow.com/questions/35511053/what-does-usr-lib-rpm-check-buildroot-do" target="_blank"
   rel="noopener nofollow noreferrer" >c++ - What does /usr/lib/rpm/check-buildroot do? - Stack Overflow</a></p>
<h3 id="编写spec文件">编写spec文件</h3>
<pre><code class="language-bash">Name: php
Version: 7.1.17
Release: 1%{?dist}
Summary: php
Group: php
License: GPL
URL: http://php.org
Packager: php
Vendor: php
Source0: php-7.1.17.tar.bz2
Source1: php.ini
BuildRoot: %{_tmppath}/%{name}-%{version}-buildroot
Requires: libiconv,zlib-devel,libxml2-devel,libjpeg-devel,libjpeg-turbo-devel,freetype-devel,libpng-devel,gd-devel,curl-devel,libxslt-devel,bzip2-devel,gmp-devel,readline-devel,mcrypt,mhash,libmcrypt-devel
%description 
php

%prep
id nginx || useradd nginx -s /sbin/nologin -M
%setup -q

%build
./configure \
--prefix=/usr/share/php-7.1.17 \
--with-config-file-path=/etc/php/ \
--exec-prefix=/usr \
--bindir=/usr/bin \
--sbindir=/usr/sbin \
--mandir=/usr/share/man \
--sysconfdir=/etc/php/ \
--with-mysqli=mysqlnd \
--with-iconv-dir=/usr/share/libiconv \
--with-jpeg-dir \
--with-png-dir \
--with-zlib-dir \
--with-libxml-dir \
--enable-xml \
--disable-rpath \
--enable-safe-mode \
--enable-bcmath \
--enable-shmop \
--enable-sysvsem \
--enable-inline-optimization \
--with-curl \
--enable-mbregex \
--enable-fpm \
--enable-mbstring \
--with-mcrypt \
--with-gd \
--enable-gd-native-ttf \
--with-openssl \
--with-mhash \
--enable-pcntl \
--enable-sockets \
--with-xmlrpc \
--enable-zip \
--enable-soap \
--enable-short-tags \
--enable-zend-multibyte \
--enable-static \
--with-xsl \
--with-fpm-user=nginx \
--with-fpm-group=nginx 

make -j 4

%install
rm -rf %{buildroot}
make INSTALL_ROOT=%{buildroot} install
%{__install} -p -D %{SOURCE1} %{buildroot}/etc/php/php.ini

%files
%defattr(-,root,root,-)
/usr/share/php-7.1.17/*
%attr(0744,root,root) /usr/bin/*
%attr(0744,root,root) /usr/sbin/*
/usr/share/man/*
/etc/php/*


%pre
id nginx || useradd nginx -s /sbin/nologin -M

%post
cp /etc/php/php-fpm.conf.default /etc/php/php-fpm.conf
cp /etc/php/php-fpm.d/www.conf.default /etc/php/php-fpm.d/www.conf

%postun
userdel nginx

%changelog
* Sun Aug 10 2018 lc zhoushilong
- package php-7.1.71
</code></pre>
<h3 id="构建php-rpm包遇到的问题">构建PHP RPM包遇到的问题</h3>
<pre><code class="language-bash">RPM build errors:
    bogus date in %changelog: Sun Aug 10 2018 lc zhoushilong
    Explicit %attr() mode not applicaple to symlink: /root/rpmbuild/BUILDROOT/php-7.1.17-1.el7.centos.x86_64/usr/bin/phar
    Installed (but unpackaged) file(s) found:
   /.channels/.alias/pear.txt
   /.channels/.alias/pecl.txt
   /.channels/.alias/phpdocs.txt
   /.channels/__uri.reg
   /.channels/doc.php.net.reg
   /.channels/pear.php.net.reg
   /.channels/pecl.php.net.reg
   /.depdb
   /.depdblock
   /.filemap
   /.lock
</code></pre>
<p><strong>解决方法如下</strong>：</p>
<blockquote>
<p><strong>方法1</strong>：生成的rpm包里有前面在%files里添加的这个文件，如下：</p>
</blockquote>
<pre><code class="language-bash">/usr/local/php/.channels
</code></pre>
<blockquote>
<p><strong>方法2</strong>：下面是直接删除的解决办法，实践OK（视具体情况是删除还是添加选一个即可）</p>
</blockquote>
<pre><code class="language-bash">rm -rf %{buildroot}/{.channels,.depdb,.depdblock,.filemap,.lock} 
</code></pre>
<blockquote>
<p><strong>方法三</strong>： <code>/usr/lib/rpm/macros</code> 修改宏</p>
</blockquote>
<pre><code class="language-bash"># 构建根目录中的未打包文件是否应终止构建？
%_unpackaged_files_terminate_build 1 # 把1改为0只警告

%__check_files   %{_rpmconfigdir}/check-files %{buildroot} # 这一行，把这一行注释掉，然后重新编译
</code></pre>
<p><strong><code>%__check_files</code>说明</strong>：</p>
<blockquote>
<p>Build configuration macros. Script gets packaged file list on input and buildroot as first parameter. Returns list of unpackaged files, i.e. files in $RPM_BUILD_ROOT not packaged. Note: Disable (by commenting out) for legacy compatibility.</p>
</blockquote>
<p>构建配置宏。 脚本在输入和buildroot上获取打包文件列表作为第一个参数。 返回未打包文件的列表，即 $ RPM_BUILD_ROOT 中未打包的文件。 注意：禁用（通过注释掉）旧版兼容性。</p>
<h3 id="打包报错">打包报错</h3>
<pre><code class="language-sh">+ '%{__debug_install_post}'
/var/tmp/rpm-tmp.o0N7t4: line 45: fg: no job control
error: Bad exit status from /var/tmp/rpm-tmp.o0N7t4 (%install)


RPM build errors:
    bogus date in %changelog: Sun Aug 24 2018 YB 1.14.2
    Bad exit status from /var/tmp/rpm-tmp.o0N7t4 (%install)
</code></pre>
<p>解决：使用以下命令禁用check-buildroot</p>
<pre><code>%define __arch_install_post %{nil}
%define __os_install_post %{nil}
</code></pre>
<p>关闭调试信息：</p>
<pre><code>%global debug_package %{nil}
</code></pre>
<h2 id="参考网址">参考网址</h2>
<blockquote>
<p><a href="https://phpor.net/blog/post/5670" target="_blank"
   rel="noopener nofollow noreferrer" >rpmbuild 之 /usr/lib/rpm/check-buildroot</a></p>
<p><a href="https://stackoverflow.com/questions/47838041/rpmbuild-how-to-disable-check-buildroot" target="_blank"
   rel="noopener nofollow noreferrer" >rpmbuild - how to disable check-buildroot?</a></p>
<p><a href="http://jackxiang.com/post/8633/" target="_blank"
   rel="noopener nofollow noreferrer" >[实践OK]rpmbuild报error: Installed (but unpackaged) file(s) found的解决办法</a></p>
<p><a href="http://www.nongzusa.com/blog/2014/10/14/rpmbuild-da-bao-rpmshi-zhan/" target="_blank"
   rel="noopener nofollow noreferrer" >rpmbuild 打包rpm实战</a></p>
<p><a href="http://www.jinbuguo.com/redhat/rpmbuild.html" target="_blank"
   rel="noopener nofollow noreferrer" >rpmbuild 中文手册</a></p>
<p><a href="https://docs.fedoraproject.org/en-US/quick-docs/creating-rpm-packages/index.html" target="_blank"
   rel="noopener nofollow noreferrer" >Creating RPM packages :: Fedora Docs Site</a></p>
<p><a href="https://fedoraproject.org/wiki/How_to_create_an_RPM_package/zh-cn#.25files_.E5.9F.BA.E7.A1.80" target="_blank"
   rel="noopener nofollow noreferrer" >How to create an RPM package/zh-cn - Fedora Project Wiki</a></p>
<p><a href="https://fedoraproject.org/wiki/Packaging:Guidelines?rd=Packaging/Guidelines" target="_blank"
   rel="noopener nofollow noreferrer" >Fedora Packaging Guidelines - Fedora Project Wiki</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>同步工具rsync使用指南</title>
      <link>https://www.oomkill.com/2017/05/rsync/</link>
      <pubDate>Sun, 07 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2017/05/rsync/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="overview">Overview</h2>
<p>官方网站：https://www.samba.org/ftp/rsync/rsync.html</p>
<p>rsync特性</p>
<ul>
<li>
<p>rsync类似于scp的功能</p>
</li>
<li>
<p>rsync还可以在本地的不同分区和目录之间进行全量及增量的复制数据，类似cp又优于cp</p>
</li>
<li>
<p>rsync可以实现文件的删除</p>
</li>
</ul>
<p>一个rsync相当于 scp cp rm，但是还优于他们每一个</p>
<ul>
<li>支持拷贝特殊文件如链接文件，设备等</li>
<li>可以有排除指定文件或目录的权限、时间、软硬链接、属主、组所有属性均不改变-p</li>
<li>可以有排除指定文件或目录的功能，相当于打包命令tar的排除功能</li>
<li>可以实现增量同步，即只同步发生变化的数据，因此数据传输效率很高tar。</li>
<li>可以使用rcp rsh ssh等方式来配合传输文件（rsync本身不对数据加密）</li>
<li>可以通过socket（进程方式）传输文件和数据</li>
<li>支持匿名的或认证（无须系统用户）的进程模式传输，可实现方便安全的进行数据备份及镜像</li>
</ul>
<h2 id="安装rsync">安装rsync</h2>
<h3 id="linux上安装rsync">linux上安装rsync</h3>
<table>
<thead>
<tr>
<th>Platform</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>Debian/Ubuntu &amp; Mint</td>
<td>sudo apt-get install rsync</td>
</tr>
<tr>
<td>Arch Linux</td>
<td>pacman -S rsync</td>
</tr>
<tr>
<td>Gentoo</td>
<td>emerge sys-apps/rsync</td>
</tr>
<tr>
<td>Fedora/CentOS/RHEL and Rocky Linux/AlmaLinux</td>
<td>sudo yum install rsync</td>
</tr>
<tr>
<td>openSUSE</td>
<td>sudo zypper install rsync</td>
</tr>
</tbody>
</table>
<h3 id="windows安装rsync">windows安装rsync</h3>
<p>官网下载cwRsync的服务端和客户端软件，cwRsync官网为：www.itefix.net/cwrsync</p>
<blockquote>
<p>Notes：由于伟大的 people‘s leader president xi 网站已经无法中国地区访问（<a href="https://tcp.ping.pe/www.itefix.net:443" target="_blank"
   rel="noopener nofollow noreferrer" >点击测试</a>），伟大的俄罗斯因为俄乌战争，也不对俄罗斯访问了（俄乌战争开始后，西方大量学术网站禁止了俄罗斯地区的访问）</p>
</blockquote>
<p>所以目前只能下载到一些镜像站上4.x版本，截止到2022年11月的6.2.7相差很多，windows客户端版本可以通过<code>chocolate</code> 安装</p>
<h3 id="rsync使用说明">rsync使用说明</h3>
<p>rsync命令语法</p>
<table>
<thead>
<tr>
<th>选项</th>
<th>注释说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>rsync</td>
<td>rsync同步命令</td>
</tr>
<tr>
<td>option</td>
<td>为同步时的选项参数</td>
</tr>
<tr>
<td>src</td>
<td>为源，及待拷贝的分区、文件或目录等</td>
</tr>
<tr>
<td>dest</td>
<td>为目标分区、文件或目录等</td>
</tr>
</tbody>
</table>
<p>rsync参数说明</p>
<table>
<thead>
<tr>
<th>参数选项</th>
<th>注释说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>-v &ndash;verbose</td>
<td>详细模式输出，传输时的进度信息</td>
</tr>
<tr>
<td>-z &ndash;compress</td>
<td>传输时进行压缩以提高传输效率，<code>--compress-level=NUM</code> 可按级别压缩</td>
</tr>
<tr>
<td>-a &ndash;archive</td>
<td>归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rtopgDl</td>
</tr>
<tr>
<td>r &ndash;recursive</td>
<td>对子目录进行递归模式，即目录下的所有目录都同样传输</td>
</tr>
<tr>
<td>t &ndash;times</td>
<td>保持文件时间信息</td>
</tr>
<tr>
<td>o &ndash;owner</td>
<td>保持文件属主信息</td>
</tr>
<tr>
<td>p &ndash;perms</td>
<td>保持文件权限</td>
</tr>
<tr>
<td>g &ndash;group</td>
<td>保持文件属主信息</td>
</tr>
<tr>
<td>P &ndash;progress</td>
<td>显示同步的过程及传输时的进度等信息</td>
</tr>
<tr>
<td>D &ndash;devices</td>
<td>爆出设备文件信息</td>
</tr>
<tr>
<td>l &ndash;links</td>
<td>保留软连接</td>
</tr>
<tr>
<td>-e &ndash;rsh=<strong>COMMAND</strong></td>
<td>使用的信道协议，制定替代rsh的shell程序，例如ssh</td>
</tr>
<tr>
<td>-exclude=<strong>PATTERN</strong></td>
<td>制定排除不需要传输的文件模式</td>
</tr>
<tr>
<td>&ndash;bwlimit=<strong>RATE</strong></td>
<td>限制socket I/O带宽</td>
</tr>
<tr>
<td>&ndash;password-file=<strong>PATH</strong></td>
<td>指定密码文件，可避免多次输入密码</td>
</tr>
<tr>
<td>&ndash;delete</td>
<td>如果服务器端为空，而客户端有文件，加上这个参数就会删除客户端目录下所有文件，相当于rm</td>
</tr>
<tr>
<td>&ndash;exclude</td>
<td>排除单/多个文件</td>
</tr>
<tr>
<td>&ndash;timeout=<strong>秒</strong></td>
<td>超时参数</td>
</tr>
<tr>
<td>&ndash;port</td>
<td>指定端口</td>
</tr>
<tr>
<td>-R &ndash;relative</td>
<td>使用相对路径信息</td>
</tr>
<tr>
<td>-u &ndash;update</td>
<td>仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件。(不覆盖更新的文件)</td>
</tr>
</tbody>
</table>
<h3 id="rsync配置文件说明">rsync配置文件说明</h3>
<pre><code class="language-conf"># 每一个程序的进程都要依赖一个用户，默认为nobody，给默认为rsync
uid = rsync
gid = rsync
# 防止出现安全问题的，一般为局域网
use chroot = no
# 有多少个客户端可以连接服务器 同时连接的客户端
max connections = 200
# 客户端连接多少时间超时（如连接了不穿数据，多少时间踢掉）
timeout = 300
# linux中每个进程都对应一个进程号pid ，pid所在的文件就是pidfile，将来处理进程的时候不用再找了，直接杀pid文件就行
pid file = /var/run/rsyncd.pid
# rsync 在传输数据时，双方都在穿可能出错，在一个用户改的时候，其他用户不能改
lock file = /var/run/rsync.lock
# 日志，出错
log file = /var/log/rsyncd.log
# 模块 相当于nfs共享的目录 可以理解为nfs的
[oldboy]
path = /oldboy/
# 在传输过程中遇到错误自动忽略
ignore errors
# 可读可写 
read only = false
# 允不允许你列表 false不允许
list = false
# 允许的主机
hosts allow = 10.0.0.0/24
# 拒绝 rsync支持虚拟用户，不是系统用户，这
hosts deny = 0.0.0.0/32
# 传输时验证的用户
auth users = rsync_backup
# 用户对应的密码文件，如果指定密码文件，就得来回输入密码，在内网中不需要重复输入密码，就将密码写入文件
secrets file = /etc/rsync.password
</code></pre>
<h2 id="rsync的工作模式">rsync的工作模式</h2>
<p>rsync提供了三种同步模式：</p>
<ul>
<li>Rsync over SSH</li>
<li>Rsync Daemon</li>
<li>Local</li>
</ul>
<h2 id="local">Local</h2>
<p>rsync如果不使用远程模式类似于cp命令，例如</p>
<ul>
<li><code>rsync /etc/hosts /opt/</code> ==  <code>cp /etc/hosts/ /opt/</code></li>
</ul>
<hr>
<p>注：目录结尾加 <code>/</code> 与不加 <code>/</code> 的区别，不加斜线表示目录以及目录里面的东西，加斜线表示目录里面的东西</p>
<hr>
<h3 id="rsync作为damon模式运行">rsync作为damon模式运行</h3>
<p>如果主机没有运行 SSH服务，可以使用 <code>rsync --daemon</code> 配置并作为守护进程运行。这种场景下 <code>rsync</code> 监听端口 873 以获取来自其他使用 <code>rsync client</code> 的同步，这种模式下数据是未加密的。</p>
<h4 id="配置daemon端">配置daemon端</h4>
<p><strong>配置rsync daemon位置文件</strong></p>
<p>rsync damon模式配置文件默认在 <code>/etc/rsyncd.conf</code> 如果没有可以自行创建</p>
<pre><code class="language-conf">lock file = /var/run/rsync.lock
log file = /var/log/rsyncd.log
pid file = /var/run/rsyncd.pid

[documents]
    path = /home/juan/Documents
    comment = The documents folder of Juan
    uid = juan
    gid = juan
    read only = no
    list = yes
    auth users = rsyncclient
    secrets file = /etc/rsyncd.secrets
    hosts allow = 192.168.1.0/255.255.255.0
</code></pre>
<p>rsyncd配置文件分为两部分，<strong>全局参数</strong>与<strong>模块</strong>。</p>
<ul>
<li><code>lock file</code> 是 <code>rsync</code> 用于处理最大连接数的文件</li>
<li><code>log file</code> 是 <code>rsync</code> 同步时的日志；汇集路开始运行的时间, 其他客户端连接的时间与任何错误</li>
<li><code>pid file</code> 是 <code>rsync</code> 记录了进程ID，可以使用这个文件来kill进程</li>
</ul>
<p>在全局参数之后，<code>[]</code> 中的是模块部分，代表的是要同步的一个目录，每个模块都是要共享的文件夹</p>
<ul>
<li><code>[name]</code> 分配给模块的名称，每个模块代表一个目录，不能包含斜杠或右方括号</li>
<li><code>path</code> 同步的文件夹的路径</li>
<li><code>comment</code> 当客户端获取所有可用模块的时，获取出的列表内模块名称旁边的注释</li>
<li><code>uid</code> 当 rsync守护进程以root 身份运行时，可以指定以哪个用户拥有文件的权限</li>
<li><code>gid</code> 同上</li>
<li><code>read only</code> 决定rsync 客户端是否可以上传文件，默认所有模块为 true</li>
<li><code>list</code> 允许客户端请求可用模块列表，false 为从列表中隐藏模块。</li>
<li><code>auth users</code> 允许访问该模块内容的用户列表，用户以逗号分隔。用户不需要存在于系统中，他们由密钥文件定义</li>
<li><code>secrets file</code> 定义包含rsync同步时用户的用户名和密码的文件</li>
<li><code>hosts allow</code> 允许连接到rsync daemon的网段，默认允许所有主机连接</li>
</ul>
<p><strong>创建rsync用户</strong></p>
<pre><code class="language-bash">$ useradd rsync -s /sbin/nologin -M
</code></pre>
<p><strong>修改共享的目录的所属权限</strong></p>
<pre><code class="language-bash">$ chown -R rsync.rsync /data  
</code></pre>
<p><strong>创建密码文件</strong></p>
<p>该文件中，每行代表一个rsync用户，账号和密码用冒号分隔</p>
<pre><code class="language-bash">$ echo &quot;rsync_backup:111111&quot;&gt; /etc/rsync.password
# 因密码可读，所以要降低权限
$ chmod 600 /etc/rsync.password
</code></pre>
<p>最后，更改此文件的权限，使其不能被其他用户读取或修改。如果此文件的权限设置不正确，<code>rsync</code> 会报错</p>
<pre><code class="language-bash">sudo chmod 600 /etc/rsyncd.secrets
</code></pre>
<p><strong>启动 rsync daemon</strong></p>
<p>直接使用 <code>--daemon</code> 启动即可</p>
<pre><code class="language-bash">sudo rsync --daemon
</code></pre>
<h4 id="使用rsync连接daemon一端">使用rsync连接daemon一端</h4>
<p>使用 <code>rsync</code> 命令连接 rsync daemon时，不可以像使用 SSH 时那样使用冒号，我们需要使用双冒号 ”::“，后跟模块名，以及同步的文件或文件夹，例如</p>
<pre><code class="language-bash">rsync -rtv user@host::module/source/ destination/
</code></pre>
<p>另一种方法是增加 <code>rsync://</code> 协议，例如</p>
<pre><code class="language-bash">rsync -rtv rsync://user@host/module/source/ destination/
</code></pre>
<p>如果不想输入密码可以指定参数 <code>--password-file=</code> 提供密码文件，密码文件就是创建的secret file，例如</p>
<pre><code class="language-bash">$ rsync -avz rsync_backup@192.168.59.121::data \
	/test \
	--password-file=/etc/rsync.password 
</code></pre>
<p>使用rsync命令推与拉</p>
<ul>
<li>
<p>Pull <code>rsync [OPTION...] [USER@]HOST::SRC... [DEST]</code></p>
<pre><code class="language-bash">rsync -avz rsync_backup@192.168.59.121::data /test/ --password-file=/etc/rsync.password
</code></pre>
</li>
<li>
<p>Push <code>rsync [OPTION...] SRC... [USER@]HOST::DEST</code> || <code> rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST</code></p>
<pre><code class="language-bash">rsync -avz /test/ rsync://rsync_backup@192.168.59.121/data/  --password-file=/etc/rsync.password
</code></pre>
</li>
</ul>
<h3 id="rsync-over-ssh">Rsync Over SSH</h3>
<p>除了daemon模式，也可以使用ssh模式进行传输，例如使用Over SSH命令</p>
<ul>
<li>Push  <code>rsync [OPTION]... -e ssh [SRC]... [USER@]HOST:DEST</code></li>
<li>Pull  <code>rsync [OPTION]... -e ssh [USER@]HOST:SRC... [DEST]</code></li>
</ul>
<p>较新版本的 rsync  SSH 为默认，可以省略该<code>-e ssh</code>选项，但 over ssh 与 over daemon的区别还是 一个冒号与两个冒号</p>
<h2 id="rsync使用实例">rsync使用实例</h2>
<h3 id="over-ssh">Over SSH</h3>
<ul>
<li>Pull    <code>rsync -avz -e 'ssh -p &lt;port&gt;' &lt;user&gt;@&lt;host&gt;:/&lt;remote_dir&gt; /&lt;local_dir&gt;</code></li>
<li>Push  <code>rsync -avz -e 'ssh -p &lt;port&gt;' /&lt;local_dir&gt; &lt;user&gt;@&lt;host&gt;:/&lt;remote_dir&gt; </code></li>
</ul>
<h3 id="local-to-remote">Local to Remote</h3>
<ul>
<li>Push  <code>rsync -avzh &lt;local_dir&gt; &lt;system_user&gt;@&lt;host&gt;:&lt;remote_dir&gt;</code></li>
<li>Pull    <code>rsync -avzh &lt;system_user&gt;@&lt;host&gt;:&lt;remote_dir&gt; &lt;local_dir&gt;</code></li>
</ul>
<h3 id="显示进度条">显示进度条</h3>
<ul>
<li><code>rsync -avzhe ssh --progress &lt;local_dir&gt; &lt;system_user&gt;@&lt;host&gt;:&lt;remote_dir&gt;</code></li>
</ul>
<h3 id="include-and-exclude">Include and exclude</h3>
<p>排除和包含可以使用文件，也可以使用正则表达式，例如</p>
<ul>
<li>包含R开头文件： <code>rsync -avze  --include 'R*' &lt;system_user&gt;@&lt;host&gt;:&lt;remote_dir&gt; &lt;local_dir&gt;</code></li>
<li>排除所有文件： <code>rsync -avze  --exclude '*' &lt;system_user&gt;@&lt;host&gt;:&lt;remote_dir&gt; &lt;local_dir&gt;</code></li>
<li>仅上传R开头的文件：<code>rsync -avze ssh --include 'R*' --exclude '*' &lt;system_user&gt;@&lt;host&gt;:&lt;remote_dir&gt; &lt;local_dir&gt;</code></li>
<li><code>--exclude-from</code> 是同步时排除文件中指定的文件</li>
</ul>
<h3 id="已存在文件的处理策略">已存在文件的处理策略</h3>
<p>如果想保证 <code>&lt;Src&gt;</code> 与 <code>&lt;DST&gt;</code>  保持一致可以使用 <code>--delete</code> 来删除 <code>&lt;Src&gt;</code> 现有文件或目录（只存在于目标目录不存在于源目标的文件）</p>
<pre><code class="language-bash">rsync -avz --delete &lt;system_user&gt;@&lt;host&gt;:&lt;remote_dir&gt; &lt;local_dir&gt;
</code></pre>
<p>当在删除或更新目标目录已经存在的文件时，不想删除而想备份，可以指定参数 <code>-b</code>, <code>--backup</code></p>
<h3 id="限制传输文件大小">限制传输文件大小</h3>
<p>可以使用 “ <strong>-–max-size</strong> ” 选项指定要传输或同步的<strong>最大文件大小</strong>。例如限制最大为200k</p>
<pre><code class="language-bash">rsync -avzhe ssh --max-size='200k' &lt;local_dir&gt; &lt;system_user&gt;@&lt;host&gt;:&lt;remote_dir&gt;
</code></pre>
<h3 id="同步成功后自动删除源文件">同步成功后自动删除源文件</h3>
<p>删除发送方的文件：如果不想将备份的本地副本保留在服务器中，可以使用参数 “ <strong>&ndash;remove-source-files</strong> ” 来自动删除 <code>&lt;src&gt;</code> 的文件吗，一般用于Push场景中。</p>
<pre><code class="language-bash">rsync --remove-source-files -zvh &lt;local_dir&gt; &lt;system_user&gt;@&lt;host&gt;:&lt;remote_dir&gt;
</code></pre>
<h3 id="dry-run">dry run</h3>
<p>与kubectl一样，rsync也支持 <code>--dry-run</code> ，该选项不会对文件进行更改但会显示命令的输出，可以与 <code>-v</code> 参数配合，这样就可以看到哪些内容会被同步</p>
<pre><code class="language-bash">rsync --dry-run --remove-source-files -zvh &lt;local_dir&gt; &lt;system_user&gt;@&lt;host&gt;:&lt;remote_dir&gt;
</code></pre>
<h3 id="限制传输时带宽">限制传输时带宽</h3>
<p>传输时，可以使用选项 “ <strong>&ndash;bwlimit</strong> ” 选项限制<strong>I/O</strong>带宽（默认单位KB），例如</p>
<pre><code class="language-bash">rsync --bwlimit=100 -avzhe ssh &lt;local_dir&gt; &lt;system_user&gt;@&lt;host&gt;:&lt;remote_dir&gt;
</code></pre>
<h3 id="忽略存在">忽略存在</h3>
<p>如果目标目录中已经该文件，则忽略，例如</p>
<pre><code class="language-bash">rsync --ignore-existing -zvh &lt;local_dir&gt; &lt;system_user&gt;@&lt;host&gt;:&lt;remote_dir&gt;
</code></pre>
<h3 id="同步策略">同步策略</h3>
<p>默认rsync 只检查文件的大小和最后修改日期是否发生变化，如果发生变化，就重新传输；参数 <code>-c</code>，<code>--checksum</code> 可以改变<code>rsync</code> 的校验方式，会通过判断文件内容的校验和，决定是否重新传输。</p>
<p>参数 <code>--size-only</code> 可以使rsync只同步大小有变化的文件，不考虑文件修改时间的差异。</p>
<h2 id="troubleshooting">troubleshooting</h2>
<pre><code>rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1039) [sender=3.0.6]
</code></pre>
<p>问题原因：服务器端目录不存在。</p>
<p>解决：在服务器端创建目录即可解决</p>
<p>日志：<code>2017/05/07 08:02:16 [2852] rsync: chdir /data1 failed:No such file or directory (2)</code></p>
<hr>
<pre><code>rsync: failed to set times on &quot;.&quot; (in data1): Operation not permitted (1)
</code></pre>
<p>问题原因：服务器端模块目录权限不对</p>
<p>解决方法：将服务器模块目录权限更改为rsyncd.conf中的uid与gid</p>
<p>日志：<code>2017/05/07 08:07:49 [2862] rsync: mkstemp &quot;.paichu.log.yOhm5e&quot; (in data1) failed: Permission denied</code></p>
<hr>
<pre><code>rsync: failed to connect to 192.168.59.121: No route to host (113)
rsync error: error in socket IO (code 10) at clientserver.c(124) [sender=3.0.6]
</code></pre>
<p>问题原因：防火墙处于开启状态</p>
<p>解决方法：关闭防火墙 <code>/etc/init.d/iptables stop</code></p>
<hr>
<pre><code>@ERROR: auth failed on module data1

rsync error: error starting client-server protocol (code 5) at main.c(1503) [sender=3.0.6]
</code></pre>
<p>错误原因：</p>
<ul>
<li>配置文件语法错误</li>
<li>密码与用户名错误</li>
<li>密码文件权限过大</li>
</ul>
<p>解决方法：查看日志，查找具体问题</p>
<p>日志文件：<code>secrets file must not be other-acessible (see strict modes option)</code></p>
<hr>
<pre><code>rsync: failed to connect to 192.168.59.121: Connection refused (111)
rsync error: error in socket IO (code 10) at clientserver.c(124) [receiver=3.0.6]
</code></pre>
<p>原因：rsync服务没开启</p>
<hr>
<pre><code>*** Skipping any contents from this failed directory ***

sent 485 bytes  received 14 bytes  332.67 bytes/sec
total size is 45994  speedup is 92.17
rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1039) [sender=3.0.6]
</code></pre>
<p>原因：服务器同步目录权限不够或所属组</p>
<p>解决 chown rsync:rsync</p>
<hr>
<p>原因：磁盘cache导致拷贝速度逐渐下降  <sup id="keywords"><a href="#1">[1]</a></sup></p>
<p>rsync拷贝数据过程中发现一个现象：开始拷贝的时候速度很快，每秒有40MB左右，但拷贝几十分钟之后就降到10MB左右了，两边机器都没有跑什么应用，网络用netcat测也没有问题</p>
<p>然后我观察到的一个问题是两边的 <code>free</code> 命令都显示出内存占用很高，并且是<code>buffered/cache</code>一栏很高，因为这个缓存是可以手工释放的</p>
<pre><code class="language-bash">sync; echo 3 &gt; /proc/sys/vm/drop_caches
ssh root@new-repos 'sh -c &quot;sync; echo 3 &gt; /proc/sys/vm/drop_caches&quot;'
</code></pre>
<p>补充说明</p>
<ul>
<li>linux操作系统会将文件系统的内容缓存起来，以便后面用到时加速，但在数据迁移场景下，基本上没有“后面用到时”这个场景，这个缓存反而碍事（TODO: 为什么导致网络io下降）</li>
<li>对于本机内大量拷贝文件，有人提供了一个 <a href="https://github.com/Feh/nocache" target="_blank"
   rel="noopener nofollow noreferrer" >nocache命令</a>  <a href="Debian/Ubuntu">Debian/Ubuntu </a>已经收录了这个工具。它的功能是临时禁用cache，用法是将要执行的命令用 <code>nocache</code> 包住，比如: <code>nocache cp -a ~/ /mnt/backup/home-$(hostname)</code>，但rsync会使用网络通讯，所以<code>nocache rsync</code> 对远端没有作用（ *Note however, that rsync uses sockets, so if you try a nocache rsync, only the local process will be intercepted.）</li>
<li>也有人在多年以前给rsync提交了一个<a href="https://bugzilla.samba.org/show_bug.cgi?id=9560" target="_blank"
   rel="noopener nofollow noreferrer" >补丁</a>，增加了 <code>--drop-cache</code> 选项，但遗憾的是没被接纳，说是过于 linux-specific，开发人员的意见（<a href="https://bugzilla.samba.org/show_bug.cgi?id=9560#c3" target="_blank"
   rel="noopener nofollow noreferrer" >见comment 3</a> ）是改用<code>nocache</code>: <code>nocache rsync -aiv --rsync-path='nocache rsync' some-host:/src/ /dest/</code>.  P.S. nocache工具的主页最后在<a href="https://github.com/Feh/nocache#acknowledgements" target="_blank"
   rel="noopener nofollow noreferrer" >acknowledgements部分</a> 说，其实它是衍生自rsync的这个补丁的。</li>
</ul>
<hr>
<h2 id="reference">Reference</h2>
<blockquote>
<p><sup id="1">[1]</sup> <a href="https://www.cnblogs.com/bamanzi/p/rsync-gotchas.html" target="_blank"
   rel="noopener nofollow noreferrer" >rsync用于数据迁移/备份的几个细节</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>使用fpm制作rpm包与搭建本地yum源</title>
      <link>https://www.oomkill.com/2016/12/fpm/</link>
      <pubDate>Fri, 16 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2016/12/fpm/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="rpm与fpm">rpm与fpm</h2>
<h3 id="软件的安装方式">软件的安装方式</h3>
<ul>
<li><strong>编译安装</strong>：优点是可以定制化安装目录、按需开启功能等，缺点是需要查找并实验出适合的编译参数，诸如MySQL之类的软件编译耗时过长</li>
<li><strong>yum安装</strong>：优点是全自动化安装，不需要为依赖问题发愁，缺点是自主性太差，软件的功能、存放位置都已经固定好了，不易变更。</li>
<li><strong>编译源码</strong>：根据自己的需求做成 RMP包 ==&gt; 搭建yum仓库 ==&gt; yum安装。结合前两者的优点，暂未发现什么缺点。可能的缺点就是RPM包的通用性差，一般人不会定制RPM包。</li>
</ul>
<h3 id="rpm概述">RPM概述</h3>
<p>RPM全称是Red Hat Package Manager(RedHat包管理器)。几乎所有的Linux发型版本都使用这种形式的软件包管理安装、更新和卸载软件。</p>
<p>rpm命令有5种基本功能（不包括创建软件包）：安装、卸载、升级、查询和验证。</p>
<p>关于rpm命令的使用可以用rpm &ndash;help来获得</p>
<h3 id="rpmbuild">rpmbuild</h3>
<p>rpmbuild是reahat系的原声打包命令，这个命令的使用难点主要在于spec文件编写，一个类似于kickstart的ks.cfg文件。</p>
<p>作为一个使用工具，种种繁琐，在没有替代品时还能存活。当有了其他简易工具时，他就到了完蛋的时候</p>
<h3 id="fpm">fpm</h3>
<p><a href="https://github.com/jordansissel/fpm" target="_blank"
   rel="noopener nofollow noreferrer" >fpm</a> 是将一种类型的包转换成另一种类型</p>
<p>支持的源类型包</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>dir</td>
<td>将目录打包成所需要的类型，可以用于源码编译安装的软件包</td>
</tr>
<tr>
<td>rpm</td>
<td>对rpm进行转换</td>
</tr>
<tr>
<td>gem</td>
<td>对rubygem包进行转换</td>
</tr>
<tr>
<td>python</td>
<td>将python模块打包成相对应的类型</td>
</tr>
<tr>
<td>支持目标类型包</td>
<td></td>
</tr>
<tr>
<td>rpm</td>
<td>转换为rpm包</td>
</tr>
<tr>
<td>deb</td>
<td>转换为deb包</td>
</tr>
<tr>
<td>solaris</td>
<td>装环卫solaris包</td>
</tr>
<tr>
<td>puppet</td>
<td>转换为puppet模块</td>
</tr>
</tbody>
</table>
<h2 id="fpm安装">fpm安装</h2>
<p>fpm是ruby写的，因此系统环境需要ruby，而且ruby版本号大于bshards运行的版本。</p>
<h3 id="yum安装ruby模块">yum安装ruby模块</h3>
<pre><code class="language-bash">yum install ruby rubygems ruby-devel -y
</code></pre>
<p>查看ruby的版本</p>
<pre><code class="language-bash">$ rpm -qa|grep ruby
ruby-libs-1.8.7.374-4.el6_6.x86_64
rubygems-1.3.7-5.el6.noarch
ruby-1.8.7.374-4.el6_6.x86_64
ruby-rdoc-1.8.7.374-4.el6_6.x86_64
ruby-devel-1.8.7.374-4.el6_6.x86_64
ruby-irb-1.8.7.374-4.el6_6.x86_64
</code></pre>
<h3 id="替换gem源">替换gem源</h3>
<p>ruby中国镜像：https://ruby-china.org/</p>
<pre><code class="language-bash">gem source -a http://gems.ruby-china.org
</code></pre>
<ul>
<li>-r remove xx 删除一个gem源列表</li>
<li>-l list gem源列表</li>
</ul>
<h3 id="安装错误">安装错误</h3>
<p>此问题提示 ruby的版本至少要求为1.9.3，在我们yum安装的ruby为1.8.7</p>
<pre><code class="language-bash">$ gem install fpm
Building native extensions.  This could take a while...
Building native extensions.  This could take a while...
ERROR:  Error installing fpm:
        ruby-xz requires Ruby version &gt;= 1.9.3.
</code></pre>
<p>解决方法：</p>
<ol>
<li>
<p>升级ruby版本</p>
</li>
<li>
<p>安装低版本fpm</p>
</li>
</ol>
<p><code>ERROR:  Could not find a valid gem 'fpm' (&gt;= 0) in any repository</code></p>
<p>原因：gem源失效，替换gem源即可</p>
<pre><code class="language-bash">ERROR:  Could not find a valid gem 'fpm' (&gt;= 0) in any repository
</code></pre>
<h3 id="升级ruby">升级ruby</h3>
<ol>
<li>下载rvm</li>
</ol>
<pre><code class="language-bash">gpg --keyserver hkp://keys.gnupg.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3
curl -sSL https://get.rvm.io | bash -s stable
# 如果上面的连接失败，可以尝试: 
curl -L https://raw.githubusercontent.com/wayneeseguin/rvm/master/binscripts/rvm-installer | bash -s stable
</code></pre>
<p>rvm会下载安装到/usr/local/rvm下</p>
<ol start="2">
<li>列出已知的ruby版本</li>
</ol>
<pre><code class="language-bash">$ /usr/local/rvm/bin/rvm list known
# MRI Rubies
[ruby-]1.8.6[-p420]
[ruby-]1.8.7[-head]$  security released on head
[ruby-]1.9.1[-p431]
[ruby-]1.9.2[-p330]
[ruby-]1.9.3[-p551]
...
[ruby-]2.3[.3]
[ruby-]2.4[.0]
ruby-head
...
# IronRuby
ironruby[-1.1.3]
ironruby-head
</code></pre>
<ol start="3">
<li>按照提示安装ruby1.9.3</li>
</ol>
<pre><code class="language-bash">/usr/local/rvm/bin/rvm install ruby-1.9.3
</code></pre>
<ol start="4">
<li>将安装的ruby切换为默认</li>
</ol>
<p>如果想设置为默认版本，这样一来以后新打开的控制台默认的 Ruby 就是这个版本</p>
<p><strong>错误：RVM is not a function</strong></p>
<pre><code class="language-bash">$ /usr/local/rvm/bin/rvm use 1.9.3 --default
RVM is not a function, selecting rubies with 'rvm use ...' will not work.

You need to change your terminal emulator preferences to allow login shell.
Sometimes it is required to use `/bin/bash --login` as the command.
Please visit https://rvm.io/integration/gnome-terminal/ for an example.
</code></pre>
<p>原因：需要添加到系统变量</p>
<pre><code class="language-bash">[[ -s &quot;$HOME/.rvm/scripts/rvm&quot; ]] &amp;&amp; . &quot;$HOME/.rvm/scripts/rvm&quot; 
source /etc/profile 
</code></pre>
<h3 id="安装低版本fpm">安装低版本fpm</h3>
<p>指定版本安装</p>
<pre><code class="language-bash">gem install fpm -v 1.4
</code></pre>
<p>查看安装完的fpm版本号</p>
<pre><code class="language-bash">$ fpm --version
1.4.0
</code></pre>
<p>卸载一个安装版本</p>
<pre><code class="language-bash">rvm remove 1.9.2
</code></pre>
<p><a href="https://www.ruby-lang.org/zh_cn/downloads/" target="_blank"
   rel="noopener nofollow noreferrer" >https://www.ruby-lang.org/zh_cn/downloads/</a></p>
<p>编译安装ruby</p>
<p>参考资料：</p>
<ul>
<li>
<p><a href="https://rubygems.org/pages/download" target="_blank"
   rel="noopener nofollow noreferrer" >Download RubyGems</a></p>
</li>
<li>
<p><a href="http://ritto.blog.51cto.com/427838/737824" target="_blank"
   rel="noopener nofollow noreferrer" >ruby的升级过程</a></p>
</li>
<li>
<p><a href="https://ruby-china.org/wiki/install_ruby_guide" target="_blank"
   rel="noopener nofollow noreferrer" >如何快速正确的安装 Ruby, Rails 运行环境</a></p>
</li>
<li>
<p><a href="https://www.cnblogs.com/Ray-liang/p/5012637.html" target="_blank"
   rel="noopener nofollow noreferrer" >RVM 解决 Ruby 的版本问题 </a></p>
</li>
</ul>
<h2 id="fpm使用">fpm使用</h2>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>-s</td>
<td>指定源类型</td>
</tr>
<tr>
<td>-t</td>
<td>指定目标类型，即想要制作为什么包</td>
</tr>
<tr>
<td>-n</td>
<td>指定包的名字</td>
</tr>
<tr>
<td>-v</td>
<td>指定包的版本号</td>
</tr>
<tr>
<td>-C</td>
<td>指定打包的相对路径</td>
</tr>
<tr>
<td>-d</td>
<td>指定依赖于哪些包</td>
</tr>
<tr>
<td>-f</td>
<td>第二次包时目录下如果有同名安装包存在，则覆盖它</td>
</tr>
<tr>
<td>-p</td>
<td>输出的安装包的目录，不想放在当前目录下就需要指定</td>
</tr>
<tr>
<td>&ndash;post-install</td>
<td>软件包安装完成之后所要运行的脚本；同&ndash;offer-install</td>
</tr>
<tr>
<td>&ndash;pre-install</td>
<td>软件包安装完成之前所要运行的脚本；同&ndash;before-install</td>
</tr>
<tr>
<td>&ndash;post-uninstall</td>
<td>软件包卸载完成之后所要运行的脚本；同&ndash;offer-remove</td>
</tr>
<tr>
<td>&ndash;pre-uninstall</td>
<td>软件包卸载完成之前所要运行的脚本；同—before-remove</td>
</tr>
</tbody>
</table>
<h3 id="yum安装是如何解决依赖问题的">yum安装是如何解决依赖问题的？</h3>
<p>在使用yum安装软件A时，yum会在下载完A的rpm包后，对该rpm包进行检查（rpm包会给出安装该rpm包所依赖的基础库和软件）。如果检查出A的安装还要依赖软件B，那么此时yum就会自动下载并安装B。B安装完毕后，就会继续安装A。如果是内网yum源的话，我们只需要把B放在内网yum源即可。如果检查出A的安装不需要其他软件的支持，那么yum会自动安装A。因此使用rpm -d添加依赖关系</p>
<h3 id="打包fpm">打包fpm</h3>
<pre><code class="language-bash">fpm -s dir -t rpm -n sphinx -v 5.5.54 -d 'libaio-devel,ncurses-devel' --post-install /app/mysql.sh /app/mysql
</code></pre>
<p>相对路径问题</p>
<p>使用相对路径打包，会直接保存为/目录。这样就不会是我们指定的目录了。</p>
<pre><code class="language-bash">$ rpm -pql sphinx-1.0-1.x86_64.rpm       
/bin/indexer
/bin/indextool
/bin/searchd
...
/var/data/test1stemmed.spp
/var/data/test1stemmed.sps
/var/log
</code></pre>
<p>制定依赖包</p>
<pre><code class="language-bash">fpm -d 'libaio-devel,ncurses-devel'
</code></pre>
<p>在安装时就会检测依赖包，如无此包就报错</p>
<pre><code class="language-bash">$ rpm -ivh mysql-5.5.54-1.x86_64.rpm 
error: Failed dependencies:
        libaio-devel is needed by mysql-5.5.54-1.x86_64
        ncurses-devel is needed by mysql-5.5.54-1.x86_64
</code></pre>
<p>安装完成后指定要执行的脚本</p>
<pre><code class="language-bash">fpm --post-install 'mysql.sh'
</code></pre>
<p>本地模拟yum安装自己打包的软件</p>
<pre><code class="language-bash">$ yum localinstall mysql-5.5.54-1.x86_64.rpm 
已加载插件：fastestmirror, security
设置本地安装进程
诊断 mysql-5.5.54-1.x86_64.rpm: mysql-5.5.54-1.x86_64
mysql-5.5.54-1.x86_64.rpm 将被安装
....
....
Non-fatal POSTIN scriptlet failure in rpm package mysql-5.5.54-1.x86_64
useradd: user 'mysql' already exists # 安装后执行脚本中创建的用户，因已创建用户，故提示
warning: %post(mysql-5.5.54-1.x86_64) scriptlet failed, exit status 9

已安装:
  mysql.x86_64 0:5.5.54-1                                                                                       

作为依赖被安装:
libaio-devel.x86_64 0:0.3.107-10.el6   ncurses-devel.x86_64 0:5.7-4.20090207.el6                

作为依赖被升级:
ncurses-base.x86_64 0:5.7-4.20090207.el6  ncurses-libs.x86_64 0:5.7-4.20090207.el6
</code></pre>
<p>初始化后启动MySQL并登陆</p>
<pre><code class="language-bash">$ /etc/init.d/mysqld start
Starting MySQL.. SUCCESS! 
$ bin/mysql
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 1
..
mysql&gt; 
</code></pre>
<h3 id="打包错误">打包错误</h3>
<p>原因未知</p>
<p>解决方法：可能是打包时会产生大量的缓存，导致空间不够，删除一些文件后问题再没出现过</p>
<pre><code class="language-bash">$ fpm -s dir -t rpm -n mysqld -v 5.5.54 -f --post-install /app/m.in.sh --post-uninstall /app/un.m.sh /app/mariadb-5.5.54/
Process failed: rpmbuild failed (exit code 1). Full command was:[&quot;rpmbuild&quot;, &quot;-bb&quot;, &quot;--define&quot;, &quot;buildroot /tmp/package-rpm-build-2570d4ce573d6b34f9153009975231fe511bee89c64018c2c7e219355d61/BUILD&quot;, &quot;--define&quot;, &quot;_topdir /tmp/package-rpm-build-2570d4ce573d6b34f9153009975231fe511bee89c64018c2c7e219355d61&quot;, &quot;--define&quot;, &quot;_sourcedir /tmp/package-rpm-build-2570d4ce573d6b34f9153009975231fe511bee89c64018c2c7e219355d61&quot;, &quot;--define&quot;, &quot;_rpmdir /tmp/package-rpm-build-2570d4ce573d6b34f9153009975231fe511bee89c64018c2c7e219355d61/RPMS&quot;, &quot;--define&quot;, &quot;_tmppath /tmp&quot;, &quot;/tmp/package-rpm-build-2570d4ce573d6b34f9153009975231fe511bee89c64018c2c7e219355d61/SPECS/mysqld.spec&quot;] {:level=&gt;:error}
</code></pre>
<h2 id="yum">YUM</h2>
<h3 id="什么是yum">什么是yum</h3>
<p>yum主要用于自动安装、升级rpm软件包，他能自动查找并解决rpm包之间的依赖关系。要成功的使用yum工具安装更新软件或系统，就需要有一个包含各种rpm软件包的repository（软件仓库），这个软件仓库我们习惯称为yum源，网络上有大量的yum源，但由于收到网络环境的限制，导致软件安装耗时过长甚至失败。特别是当有大量服务器大量软件包需要安装时，缓慢的进度条令人难以忍受。因此我们在优化系统时，都会更换国内的源。</p>
<p>相比较而言，本地yum源服务器最大优点是局域网的快速网络连接和稳定性。有了局域网中的yum源服务器，即使在internet连接中断的情况下，也不会影响其他yum客户端的软件安装和升级</p>
<h3 id="创建yum源">创建yum源</h3>
<p>上传rpm包到此目录，此目录下面还可以包括文件夹</p>
<pre><code class="language-bash">mkdir -p /tools/yum/centos6/x86_64
</code></pre>
<p>yum下载的文件缓存在</p>
<pre><code class="language-bash">/var/cache/yum/x86_64/6/base/
</code></pre>
<h3 id="安装createrepo工具">安装createrepo工具</h3>
<pre><code class="language-bash">yum install -y createrepo
</code></pre>
<p>初始化repodata索引文件</p>
<pre><code class="language-bash">$ createrepo -pdo /tools/yum/centos6/x86_64/ /tools/yum/centos6/x86_64/
Spawning worker 0 with 4 pkgs
Workers Finished
Gathering worker results

Saving Primary metadata
Saving file lists metadata
Saving other metadata
Generating sqlite DBs
Sqlite DBs complete

$ cd /tools/yum/centos6/x86_64/

$ ls
libaio-devel-0.3.107-10.el6.i686.rpm
libaio-devel-0.3.107-10.el6.x86_64.rpm
ncurses-devel-5.7-4.20090207.el6.i686.rpm
ncurses-devel-5.7-4.20090207.el6.x86_64.rpm
repodata

$ ls repodata/.
1453d96f9216e7c230abfe7921a2fd1dd11541568934832306342c89ad04ff1d-other.sqlite.bz2
2475630f1247fc6ac2b822541d6ad71ed83d733792c7d52de580fdebd3abda2c-filelists.sqlite.bz2
9e22eb60f06501a3f4399dc3c2d3e3858567804e7ab352679fa650b93d279fb9-other.xml.gz
c3ee9c8d8508c55c77f3f058f056bdd617587ee5a906f22bc9a512bc8b950ded-filelists.xml.gz
d9d57f7733cb42831001e915ddd51bb126b67c26bca64bf6c7e7390eed9a54d9-primary.sqlite.bz2
e9616244b93c46350e33dc04d4cb442e49ae375b7400a262bd72e8ba90a1f4a8-primary.xml.gz
repomd.xml
</code></pre>
<h3 id="提供yum服务">提供yum服务</h3>
<p>可以用apache或nginx提供web服务，但用Python的http模块更简单，适用于内网环境。CentOS 6最小化安装后自带python。</p>
<ol>
<li>利用python的http模块提供服务</li>
</ol>
<pre><code class="language-bash">python -m SimpleHTTPServer 80 &amp;&gt;/dev/null
# 提供服务的目录是执行命令时的目录
</code></pre>
<ol start="2">
<li>利用nginx提供yum源服务</li>
</ol>
<pre><code class="language-bash">location / {
    root   /tools;
    index  index.html index.htm;
	autoindex on; # 当找不到首页文件时，会展示目录结构，这个功能一般不要用除非有需求。
# 如没有此选项，会报403
}
</code></pre>
<h3 id="添加新的rpm包">添加新的rpm包</h3>
<pre><code class="language-bash"># 只下载软件不安装
yumdownlocaler pcre-devel openssl-devel
</code></pre>
<p>每当该目录新增软件包需要更新源</p>
<pre><code class="language-bash">createrepo --update /tools
</code></pre>
<h3 id="本地客户端配置">本地客户端配置</h3>
<pre><code class="language-conf">/etc/yum.repos.d/test.repo
[test]
name=Server
baseurl=http://192.168.2.110
enable=1
gpgchek=0
</code></pre>
<p>使用配置的自定义的源安装PHP</p>
<pre><code class="language-bash">yum --enablerepo=test --disablerepo=base,extras,updates install php
# --enbalerepo使用的源
# --disablerepo禁用源
</code></pre>
<h3 id="yum命令">yum命令</h3>
<table>
<thead>
<tr>
<th>选项</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>install</td>
<td>安装软件包 yum install httpd</td>
</tr>
<tr>
<td>list</td>
<td>列出yum仓库内文件 yum list httpd，可搜索带名称的特定软件包</td>
</tr>
<tr>
<td>search</td>
<td>不急的软件报的确切名称，可以使用search函数，搜索与指定软件包的名称相匹配的所有可用软件包yum search httpd</td>
</tr>
<tr>
<td>provides</td>
<td>查找某个特定文件属于哪个软件包。yum provides /app/apache/confi/http.conf</td>
</tr>
<tr>
<td>grouplist</td>
<td>列出所有可用群组</td>
</tr>
<tr>
<td>groupinstall</td>
<td>安装群组软件包yum groupinstall develment-tools</td>
</tr>
<tr>
<td>repolist</td>
<td>列出启用的软件库</td>
</tr>
<tr>
<td>repolist all</td>
<td>列出所有软件库，包括禁用的也列出</td>
</tr>
<tr>
<td>&ndash;enablerepo</td>
<td>安装来自特定软件库的软件包</td>
</tr>
<tr>
<td>&ndash;disablerepo</td>
<td>不安装来自指定软件库的软件包yum &ndash;enablerepo=test &ndash;disablerepo=base,extras&hellip; install httpd</td>
</tr>
<tr>
<td>chean all</td>
<td>清理yum缓存内容</td>
</tr>
<tr>
<td>history</td>
<td>查看yum历史记录</td>
</tr>
</tbody>
</table>
<h2 id="yum源">yum源</h2>
<p>Yum源分为三大类：</p>
<ul>
<li>Base：就是你下载的光盘镜像里面的DVD1</li>
<li>Extra：就是你下载光盘镜像的DVD2</li>
<li>Epel：属于额外的，得到Epel官方获取</li>
</ul>
<p>将光盘挂载到系统上，你会发现里面有个packages目录，里面全是rpm包</p>
<pre><code class="language-bash">$ ls
CentOS_BuildTag  
images                    
...          
Packages                  
RPM-GPG-KEY-CentOS-Security-6

$ ll|wc -l
4186
</code></pre>
<h3 id="配置yum源">配置yum源</h3>
<p>找一个镜像站点，国内常用镜像站点</p>
<ul>
<li>
<p><a href="http://mirrors.aliyun.com" target="_blank"
   rel="noopener nofollow noreferrer" >http://mirrors.aliyun.com</a></p>
</li>
<li>
<p><a href="http://mirrors.163.com" target="_blank"
   rel="noopener nofollow noreferrer" >http://mirrors.163.com</a></p>
</li>
</ul>
<p>系统yum源路径，执行yum时，它只会读取yum.repo.d下这个目录下的所有以.repo结尾的文件。</p>
<pre><code class="language-bash">$ ls /etc/yum.repos.d/
CentOS-Base.repo       
CentOS-fasttrack.repo  
CentOS-Vault.repo  
CentOS-Debuginfo.repo  
CentOS-Media.repo      
epel.repo
</code></pre>
<p>repo文件的写入是有其特殊格式的，如下：</p>
<pre><code class="language-bash">[aaa]
name=aaa
baseurl=http://192.168.2.110
enable=1
gpgchek=0
[bbb]
name=bbb
baseurl=http://192.168.2.110
enable=1
gpgchek=0
[ccc]
name=ccc
baseurl=http://192.168.2.110
enable=1
gpgchek=0
</code></pre>
<p>所谓的自己配置Yum仓库就是把网上那些程序包全下载下来，在本地(内网)提供Yum。除了epel提供的所有包外，还有镜像光盘DVD1,DVD2！</p>
<h2 id="yum服务配置文件">yum服务配置文件</h2>
<p>配置文件分为两部分main和repository</p>
<p>配置本地yum源</p>
<p>禁用默认的yum网络源，将yum网络源配置文件改名为CentOS-Base.repo.bak，否则会现在网络源中寻找适合的包，改名之后直接从本地源读取。也可以向上面一样自己写一个文件。</p>
<h3 id="全局配置文件">全局配置文件</h3>
<p>main部分定义了全局配置选项，整个yum配置文件应该只有一个main，/etc/yum.conf</p>
<pre><code class="language-conf"># /etc/yum.conf
[main]
# cachedir：yum缓存的目录，yum在此存储下载的rpm包和数据库，一般是/var/cache/yum/$basearch/$releasever。
cachedir=/var/cache/yum/$basearch/$releasever
# 设置 keepcache=1，yum 在成功安装软件包之后保留缓存的头文件 (headers) 和软件包。默认值为 keepcache=0 不保存
keepcache=[1 or 0]
# debuglevel：除错级别，0──10,默认是2 貌似只记录安装和删除记录
debuglevel=2
logfile=/var/log/yum.log
# pkgpolicy： 包的策略。一共有两个选项，newest和last，这个作用是如果你设置了多个repository，而同一软件在不同的repository中同时存 在，yum应该安装哪一个，如果是newest，则yum会安装最新的那个版本。如果是last，则yum会将服务器id以字母表排序，并选择最后的那个 服务器上的软件安装。一般都是选newest。
pkgpolicy=newest
# 指定一个软件包，yum会根据这个包判断你的发行版本，默认是RedHat-release，也可以是安装的任何针对自己发行版的rpm包
distroverpkg=CentOS-release
# tolerent，也有1和0两个选项，表示yum是否容忍命令行发生与软件包有关的错误，比如你要安装1,2,3三个包，而其中3此前已经安装了，如果你设为1,则yum不会出现错误信息。默认是0。
tolerant=1
# exactarch，有两个选项1和0,代表是否只升级和你安装软件包cpu体系一致的包，如果设为1，则如你安装了一个i386的rpm，则yum不会用1686的包来升级。
exactarch=1
# retries，网络连接发生错误后的重试次数，如果设为0，则会无限重试。
retries=20
obsoletes=1
# gpgchkeck= 有1和0两个选择，分别代表是否是否进行gpg校验，如果没有这一项，默认是检查的。
gpgcheck=1
# 该选项用户指定 .repo 文件的绝对路径。.repo 文件包含软件仓库的信息 (作用与 /etc/yum.conf 文件中的 [repository] 片段相同)。
reposdir=[包含 .repo 文件的目录的绝对路径] # 默认是 /etc/yum.repos.d/ 低下的 xx.repo后缀文件
# exclude 排除某些软件在升级名单之外，可以用通配符，列表中各个项目要用空格隔开，这个对于安装了诸如美化包，中文补丁的朋友特别有用。
exclude=xxx
</code></pre>
<h3 id="第二部分repoitory">第二部分repoitory</h3>
<p>repoitory部分定义了每个源/服务器的具体配置，可以有一到多个，位于/etc/yum.repos.d/目录下的各文件中。这个字段其实也可以在yum.conf里面直接配置</p>
<p>repo文件的格式</p>
<pre><code class="language-bash"># serverid用于区别各个不同的repository，必须有一个独一无二的名称。 重复了前面覆盖后面--还是反过来呢？？？用enabled 测试是后面覆盖前面
[serverid]
# name是对repository的描述，支持像$releasever $basearch这样的变量; name=Fedora Core $releasever - $basearch - Released Updates
name=Some name for this server
# baseurl是服务器设置中最重要的部分，只有设置正确，才能从上面获取软件。它的格式是：
# 其中url支持的协议有 http:// ftp:// file://三种。baseurl后可以跟多个url，你可以自己改为速度比较快的镜像站，但baseurl只能有一个，也就是说不能像如下格式：
baseurl=url://server1/path/to/repository/
baseurl=url://server2/path/to/repository/
baseurl=url://server3/path/to/repository/
其中url指向的目录必须是这个repository header目录的上一级，它也支持$releasever $basearch这样的变量。
baseurl=url://path/to/repository/
baseurl=url://server1/path/to/repository/
url://server2/path/to/repository/
url://server3/path/to/repository/
# 这一行是指定一个镜像服务器的地址列表，通常是开启的，本例中加了注释符号禁用了，我们可以试试，将$releasever和$basearch替换成自己对应的版本和架构，例如10和i386，在浏览器中打开，我们就能看到一长串镜可用的镜像服务器地址列表。
mirrorlist=http://mirrors.fedoraproject.org/mirrorlist?repo=fedora-$releasever&amp;arch=$basearch
url之后可以加上多个选项，如gpgcheck、exclude、failovermethod等，比如：
# 其中gpgcheck，exclude的含义和[main]部分相同，但只对此服务器起作用
gpgcheck=1
exclude=gaim
# failovermethode 有两个选项roundrobin和priority，意思分别是有多个url可供选择时，yum选择的次序，roundrobin是随机选择，如果连接失 败则使用下一个，依次循环，priority则根据url的次序从第一个开始。如果不指明，默认是roundrobin。
failovermethod=priority
# 当某个软件仓库被配置成 enabled=0 时，yum 在安装或升级软件包时不会将该仓库做为软件包提供源。使用这个选项，可以启用或禁用软件仓库。
# 通过 yum 的 --enablerepo=[repo_name] 和 --disablerepo=[repo_name] 选项，或者通过 PackageKit 的&quot;添加/删除软件&quot;工具，也能够方便地启用和禁用指定的软件仓库
enabled=[1 or 0]
</code></pre>
<p>变量</p>
<pre><code class="language-conf">$releasever，发行版的版本，从[main]部分的distroverpkg获取，如果没有，则根据redhat-release包进行判断。
$arch，cpu体系，如i686,athlon等
$basearch，cpu的基本体系组，如i686和athlon同属i386，alpha和alphaev6同属alpha。
</code></pre>
]]></content:encoded>
    </item>
    
    <item>
      <title>长期总结 - Linux日志查询命令</title>
      <link>https://www.oomkill.com/2016/08/awesome-linux-log-command/</link>
      <pubDate>Fri, 12 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2016/08/awesome-linux-log-command/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="sed">sed</h2>
<p>语法</p>
<pre><code class="language-bash">sed  '/过滤的内容/处理的命令' 文件
</code></pre>
<table>
<thead>
<tr>
<th>参数</th>
<th>注释说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>n</td>
<td>取消sed默认的输出</td>
</tr>
<tr>
<td>i</td>
<td>替换文件内容</td>
</tr>
<tr>
<td>r</td>
<td>如果有特殊字符不用转义（正则）</td>
</tr>
<tr>
<td>g</td>
<td>全局替换</td>
</tr>
<tr>
<td>d</td>
<td>删除</td>
</tr>
<tr>
<td>p</td>
<td>print打印</td>
</tr>
</tbody>
</table>
<p># 为分隔符可以用其他符号替换（最好用$ @ /）替换内容中如果有分隔符，需要将分隔符替换为别的分隔符，如果不换可将内容转义  s 为search  g为globla全局替换，不加的话只替换一列</p>
<p><strong>打印</strong></p>
<pre><code class="language-bash">$ sed -n '2p' 3.txt
1

$ sed -n '1,20p' 3.txt
0
1
2
3
4
5
6

8
9
10
11
12
13
14
15
16
17
18
19
</code></pre>
<p><strong>问：已知一个文件内容为 aaa  bbb  ccc  lisi 请打印出不包含lisi的内容</strong></p>
<p>文件原内容</p>
<pre><code class="language-bash">$ cat 1.txt          
-bash: ech: command not found
-bash: ech: command not found
-bash: ech: command not found
dasda
aaa
bbb
ccc
ddd
eee
fff

ggg
</code></pre>
<p><strong>替换功能</strong>：</p>
<pre><code class="language-bash">$ sed -i 's#aaa#cylon#g' 1.txt

$ cat 1.txt                           
-bash: ech: command not found
-bash: ech: command not found
-bash: ech: command not found
dasda
cylon
bbb
ccc
ddd
eee
fff

ggg
</code></pre>
<p>默认不加参数会将文件原内容打印再将符合的内容打印</p>
<pre><code class="language-bash">$ sed '/aaa/p' 1.txt  
-bash: ech: command not found
-bash: ech: command not found
-bash: ech: command not found
dasda
aaa
aaa
bbb
ccc
ddd
eee
fff

ggg
</code></pre>
<p><strong>在指定文件中指定行插入数据</strong></p>
<pre><code class="language-bash">$ cat test.txt 
1
2
3
4
5

# $为行尾  a\为行后追加 i\为行前追加 c\为替换 不加$为行首
$ sed -i &quot;3a zhangsan&quot; test.txt   
$ cat test.txt 
1
2
3
zhangsan
4
</code></pre>
<p><strong>-n取消默认的输出</strong></p>
<pre><code class="language-bash">$ sed -n '/aaa/p' 1.txt 
aaa
</code></pre>
<p>将符合的内容删除后输出，并不操作文件</p>
<pre><code class="language-bash">$ sed  '/aaa/d' 1.txt    
-bash: ech: command not found
-bash: ech: command not found
-bash: ech: command not found
dasda
bbb
ccc
ddd
eee
fff

ggg
</code></pre>
<p>删除文件中一部分内容</p>
<pre><code class="language-bash"># 删除首行
sed '1d' nginx.conf

# 删除1-102行
sed '1,102d' nginx.conf

# 正则表达式
# 删除每行中 on
sed '/on/d' nginx.conf

# 删除偶数行删除偶数行
sed '0~2d' nginx.conf

# 删除奇数行
sed '1~2d' nginx.conf
</code></pre>
<h2 id="wc">wc</h2>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>c</td>
<td>统计字节数</td>
</tr>
<tr>
<td>l</td>
<td>统计行数</td>
</tr>
<tr>
<td>m</td>
<td>统计字符数，不能与c一起用</td>
</tr>
<tr>
<td>w</td>
<td>统计字数，一个字被定义为由空白、跳格、或换行字符分割的字符串</td>
</tr>
<tr>
<td>L</td>
<td>打印最长行的字符数量</td>
</tr>
<tr>
<td>&ndash;help</td>
<td>帮助信息</td>
</tr>
<tr>
<td>&ndash;version</td>
<td>版本信息</td>
</tr>
</tbody>
</table>
<pre><code class="language-bash">$ cat -n a.html
     1  000
     2  111
     3  222
     4  333
     5  444
     6  555
     7  666
     8  777
     9  888
    10  999
    11  aaa
    12  bbb
    13  ccc
    14  ddd
    15  eee
    16

$ wc -c a.html
61 a.html

$ wc -l a.html
16 a.html

$ wc -w a.html
15 a.html

$ wc -L a.html
3 a.html
</code></pre>
<h2 id="sort-">sort ★★★★</h2>
<p>将文件进行排序，并将排序结果标准输出。sort命令既可以从特定的文件，也可以从stdin中获取输入</p>
<table>
<thead>
<tr>
<th>参数选项</th>
<th>注释说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>-b</td>
<td>忽略每行前面开始出的空格字符；</td>
</tr>
<tr>
<td>-c</td>
<td>检查文件是否已经按照顺序排序；</td>
</tr>
<tr>
<td>-d</td>
<td>排序时，处理英文字母、数字及空格字符外，忽略其他的字符；</td>
</tr>
<tr>
<td>-f</td>
<td>排序时，将小写字母视为大写字母；</td>
</tr>
<tr>
<td>-n</td>
<td>依照数值的大小排序</td>
</tr>
<tr>
<td>-r</td>
<td>以相反的顺序来排序</td>
</tr>
</tbody>
</table>
<p><strong>实例</strong>：sort将 文件/文本 的每一行作为一个单位，相互比较，比较原则是从首字符向后，依次按ASCII码值进行比较，最后将他们按升序输出。</p>
<pre><code class="language-bash">$ cat sort.txt 
aaa:10:1.1 
ccc:30:3.3 
ddd:40:4.4 
bbb:20:2.2 
eee:50:5.5 
eee:50:5.5 

$ sort sort.txt 
aaa:10:1.1 
bbb:20:2.2 
ccc:30:3.3 
ddd:40:4.4 
eee:50:5.5 
eee:50:5.5 
</code></pre>
<p>忽略相同行使用-u选项或者uniq：</p>
<pre><code class="language-bash">$ cat sort.txt 
aaa:10:1.1 
ccc:30:3.3 
ddd:40:4.4 
bbb:20:2.2 
eee:50:5.5 
eee:50:5.5 

$ sort -u sort.txt 
aaa:10:1.1 
bbb:20:2.2 
ccc:30:3.3 
ddd:40:4.4 
eee:50:5.5

# 
$ uniq sort.txt 
aaa:10:1.1 
ccc:30:3.3 
ddd:40:4.4 
bbb:20:2.2 
eee:50:5.5 
</code></pre>
<p>sort的-n、-r、-k、-t选项的使用：</p>
<pre><code class="language-bash">$ cat sort.txt 
AAA:BB:CC 
aaa:30:1.6 
ccc:50:3.3 
ddd:20:4.2 
bbb:10:2.5 
eee:40:5.4 
eee:60:5.1 
# 将BB列按照数字从小到大顺序排列 

$ sort -nk 2 -t: sort.txt 
AAA:BB:CC 
bbb:10:2.5 
ddd:20:4.2 
aaa:30:1.6 
eee:40:5.4 
ccc:50:3.3 
eee:60:5.1 
# 将CC列数字从大到小顺序排列

$ sort -nrk 3 -t: sort.txt 
eee:40:5.4 
eee:60:5.1 
ddd:20:4.2 
ccc:50:3.3 
bbb:10:2.5 
aaa:30:1.6 
AAA:BB:CC 
# -n是按照数字大小排序，-r是以相反顺序，-k是指定需要排序的栏位，-t指定栏位分隔符为冒号
</code></pre>
<h2 id="uniq">uniq</h2>
<p>用于报告或忽略文件中的重复行，一般与sort命令结合使用</p>
<table>
<thead>
<tr>
<th>参数选项</th>
<th>注释说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>-c</td>
<td>在每行前面显示改行重复的次数</td>
</tr>
<tr>
<td>-d</td>
<td>仅打印重复出现的行</td>
</tr>
<tr>
<td>-u</td>
<td>仅打印不重复的行</td>
</tr>
</tbody>
</table>
<p><strong>实例</strong>：删除重复行</p>
<pre><code class="language-bash">$ uniq a.txt     
a
b
c
d
e
f
g
h
i
g
k
</code></pre>
<p>在文件中找出重复的行：</p>
<pre><code class="language-bash">sort file.txt | uniq -d
</code></pre>
<p>查找重复次数</p>
<pre><code class="language-bash">$ uniq -c a.txt 
      5 a
      1 b
      2 c
      2 d
      1 e
      1 f
      1 g
      3 h
      2 i
      1 g
      1 k

$ uniq -d a.txt  
a
c
d
h
i

$ uniq -u a.txt  
b
e
f
g
g
k
</code></pre>
<h2 id="cut">cut</h2>
<p>用来显示行中的指定部分，删除文件中指定字段。cut经常用来显示文件的内容</p>
<table>
<thead>
<tr>
<th>参数选项</th>
<th>注释说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>-b</td>
<td>以字节为单位进行分割。这些字节位置将忽略多字节字符边界，除非也指定了 -n 标志。</td>
</tr>
<tr>
<td>-c</td>
<td>以字符为单位进行分割</td>
</tr>
<tr>
<td>-f</td>
<td>与-d一起使用，取第几列</td>
</tr>
<tr>
<td>-d</td>
<td>指定分隔符</td>
</tr>
</tbody>
</table>
<p><strong>实例</strong></p>
<pre><code class="language-bash">$ cat 1.log
i am a protester myqq is 1112222

$ cut -d &quot; &quot; -f4,7 1.log   
protester 1112222
</code></pre>
<ol>
<li>以字节取，我们想去who命令的第三个字节</li>
</ol>
<pre><code class="language-bash">$ who
root     pts/0        2010-02-02 04:09 (192.168.88.1)
root     pts/1        2010-02-02 08:34 (192.168.88.1)
lc       pts/2        2010-02-02 08:44 (192.168.88.1)

$ who|cut -b 3
o
o
</code></pre>
<ol start="2">
<li>取第1、2、3和第23个字节</li>
</ol>
<pre><code class="language-bash">$  who|cut -b 1-3,23
roo2
roo2
lc 2
</code></pre>
<ol start="3">
<li>如果取中文的话，-c 与 -b就有差异了，-c取的是字节，而-b取得是8位2进制来计算输出的是乱码或空</li>
</ol>
<pre><code class="language-bash">$ cat a.txt 
星期一
星期二
星期三
星期四
星期五
星期六
星期日

$ cut -b 3 a.txt
�
�

$ cut a.txt -c 3
一
二
三
四
五
六
日
</code></pre>
<h2 id="grep">grep</h2>
<p><em><strong>Global search Regular Expression(RE) and Print out the line</strong></em>，全面搜索正则表达式并把行打印出来；是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。</p>
<p>过滤，将想要的和不想要的去除</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>==-E==</td>
<td>同egrep同时过滤多个字符串，使grep可以使用正则表达式</td>
</tr>
<tr>
<td>-v</td>
<td>翻转查找，查找除了匹配到结果之外的信息</td>
</tr>
<tr>
<td>-B <strong>Num</strong></td>
<td>除了显示匹配的一行之外，并显示该行之前的num行</td>
</tr>
<tr>
<td>-A <strong>Num</strong></td>
<td>除了显示匹配的一行之外，并显示改行之后的num行</td>
</tr>
<tr>
<td>-C <strong>Num</strong></td>
<td>除了显示匹配的一行之外，并显示改行之前后各num行</td>
</tr>
<tr>
<td>-o</td>
<td>输出匹配字符，而不是默认的整行输出</td>
</tr>
<tr>
<td>-i</td>
<td>不区分大小写</td>
</tr>
<tr>
<td>-n</td>
<td>讲匹配出的结果在文件所在的行号打印</td>
</tr>
<tr>
<td>-c</td>
<td>打印匹配到的行数</td>
</tr>
<tr>
<td>-H</td>
<td>在匹配到符合行之前打印文件名</td>
</tr>
<tr>
<td>&ndash;color=auto</td>
<td>给匹配倒的字符串加颜色（不是整行。关键字高亮显示）</td>
</tr>
</tbody>
</table>
<p>实例</p>
<ol>
<li>显示/etc/services 下3306和1521 端口信息</li>
</ol>
<pre><code class="language-bash">$ grep -E &quot;3306|1521&quot; /etc/services 
mysql           3306/tcp                        # MySQL
mysql           3306/udp                        # MySQL
ncube-lm        1521/tcp                # nCube License Manager
ncube-lm        1521/udp                # nCube License Manager
</code></pre>
<ol start="2">
<li>过滤出文件内指定字符串</li>
</ol>
<pre><code class="language-bash">$ cat text.txt
zhangsan
lisi
oldbl

$ grep &quot;lisi&quot; text.txt
lisi
</code></pre>
<ol start="3">
<li>排除指定字符</li>
</ol>
<pre><code class="language-bash">$ grep -v &quot;lisi&quot; text.txt
zhangsan
oldbl

$ grep  -n &quot;555&quot; a.html
6:555
</code></pre>
<ol start="4">
<li>一个文件有100行，只看20~30行</li>
</ol>
<pre><code class="language-bash"># 方法1
$ grep 30 -B 10 test.txt
20
21
22
23
24
25
26
27
28
29
30

# 方法2
$ head -30 3.txt|tail -11
20
21
22
23
24
25
26
27
28
29
30
</code></pre>
<ol start="5">
<li>列出文件名</li>
</ol>
<pre><code class="language-bash">$ grep -H root /etc/passwd 
/etc/passwd:root:x:0:0:root:/root:/bin/bash
/etc/passwd:operator:x:11:0:operator:/root:/sbin/nologin
</code></pre>
<h2 id="日志查询中常用命令">日志查询中常用命令</h2>
<p><strong>打印一段时间的日志</strong></p>
<pre><code class="language-bash">sed -n '/2019-12-28 11:26/,/2019-12-28 12:13/p' nohup.out
</code></pre>
<p><strong>输出日志文件中的某个日期中的ERROR的行</strong></p>
<pre><code class="language-bash">sed -n '/^2016-06-21.*ERROR/p' nohup.out
</code></pre>
<p><strong>统计http相应状态码</strong></p>
<pre><code class="language-bash">cat looklinix.com_access.log | cut -d '&quot;' -f3 | cut -d ' ' -f2 | sort | uniq -c | sort
</code></pre>
<p>使用awk</p>
<pre><code class="language-bash">awk '{print $9}' looklinix.com_access.log | sort | uniq -c | sort
</code></pre>
<p><strong>列出404的接口</strong></p>
<pre><code class="language-bash">awk '($9 ~ /404/)' looklinix.com_access.log | awk '{print $7}' | sort | uniq -c | sort -r
</code></pre>
<p><strong>检查404请求来自哪里</strong></p>
<pre><code class="language-bash">awk -F \&quot; '($2 ~ &quot;/survey/report/na&quot;){print $1}' looklinix.com_access.log | awk '{print $1}' | sort | uniq -c | sort –r
</code></pre>
<p><strong>查询x 分钟内访问最多的前 10 个IP</strong></p>
<p>day hour minutes</p>
<pre><code class="language-bash">awk -vDate=`date -d'now-30 minutes' +[%d/%b/%Y:%H:%M:%S` '$4 &gt; Date {print $1}' /var/log/nginx/access.log | sort | uniq -c | sort -nr | head -n 10
</code></pre>
<p><strong>查询请求URL数量排行</strong></p>
<pre><code class="language-bash">awk '{print $7}' /var/log/nginx/access.log | sort | uniq -c | sort -nr | head -n 50
</code></pre>
<p><strong>统计所有的IP请求量</strong></p>
<pre><code class="language-bash">awk '{print $1}' access.log | sort -n | uniq | wc -l
</code></pre>
<p><strong>统计某一时间段的IP请求量</strong></p>
<pre><code class="language-bash">grep &quot;07/Apr/2017:0[4-5]&quot; access.log | awk '{print $1}' | sort | uniq -c| sort -nr | wc -l  
</code></pre>
<p><strong>统计IP请求数量大于一个值的排行</strong></p>
<pre><code class="language-bash">awk '{print $1}' access.log | sort -n |uniq -c |awk '{if($1 &gt;100) print $0}'|sort -rn
</code></pre>
<p><strong>列出请求时间超过3s的接口</strong></p>
<pre><code class="language-bash">cat access.log|awk '($NF &gt; 3){print $7}'|sort -n|uniq -c|sort -nr|head -20
</code></pre>
<p><strong>获取每分钟的请求数量并输出成csv文件</strong></p>
<pre><code class="language-bash">cat access.log | awk '{print substr($4,14,5)}' | uniq -c | awk '{print $2&quot;,&quot;$1}' &gt; access.csv
</code></pre>
<p><strong>查看搜索引擎爬虫</strong></p>
<pre><code class="language-bash"># 百度爬虫 降序
cat access.log | grep &quot;Baiduspider&quot; | awk '{print $7}' | sort | uniq -c | sort -r

# 谷歌爬虫降序
cat access.log | grep &quot;Googlebot&quot; | awk '{print $7}' | sort | uniq -c | sort -r

# 谷歌爬虫404的次数
grep 'Googlebot' access.log |grep '404' | wc -l
</code></pre>
]]></content:encoded>
    </item>
    
    <item>
      <title>Linux服务管理 - systemd</title>
      <link>https://www.oomkill.com/2016/04/systemd/</link>
      <pubDate>Thu, 21 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2016/04/systemd/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="关于linux服务管理">关于Linux服务管理</h2>
<p>Linux系统从启动到提供服务的过程是这样，先是机器加电，然后通过MBR或者UEFI加载GRUB，再启动内核，内核启动服务，然后开始对外服务。
SysV init UpStart systemd主要是解决服务引导管理的问题。</p>
<ul>
<li>CentOS 5：SysV init</li>
<li>CentOS 6：Upstart</li>
<li>CentOS 7：Systemd <a href="http://www.linuxidc.com/Linux/2015-04/115937.htm" target="_blank"
   rel="noopener nofollow noreferrer" >http://www.linuxidc.com/Linux/2015-04/115937.htm</a></li>
</ul>
<h3 id="11-sysv-init的优缺点">1.1 SysV init的优缺点</h3>
<p>SysV init是最早的解决方案，依靠划分不同的运行级别，启动不同的服务集，服务依靠脚本控制，并且是顺序执行的。</p>
<p>SysV init方案的优点：</p>
<ul>
<li>1.原理简单，易于理解；</li>
<li>2.依靠shell脚本控制，编写服务脚本门槛比较低。</li>
</ul>
<p>缺点是：</p>
<ul>
<li>1.服务顺序启动，启动过程比较慢。</li>
<li>2.不能做到根据需要来启动服务，比如通常希望插入U盘的时候，再启动USB控制的服务，这样可以更好的节省系统资源。</li>
</ul>
<h3 id="12-upstart的改进">1.2 UpStart的改进</h3>
<p>为了解决系统服务的即插即用，UpStart应运而生，在CentOS6系统中，SysV init和UpStart是并存的，UpStart主要解决了服务的即插即用。服务顺序启动慢的问题，UpStart的解决办法是把相关的服务分组，组内的服务是顺序启动，组之间是并行启动。</p>
<h3 id="13-systemd的诞生">1.3 systemd的诞生</h3>
<p>SysV init服务启动慢，在以前并不是一个问题，尤其是Linux系统以前主要是在服务器系统上，常年也难得重启一次。有的服务器光硬件检测都需要5分钟以上，相对来说系统启动已经很快了。</p>
<p>但是随着移动互联网的到来，SysV init服务启动慢的问题显得越来越突出，许多移动设备都是基于Linux内核，比如安卓。移动设备启动比较频繁，每次启动都要等待服务顺序启动，显然难以接受，systemd就是为了解决这个问题诞生的。</p>
<p><strong>systemd的设计思路是</strong>：</p>
<ul>
<li>尽可能的快速启动服务。</li>
<li>尽可能的减少系统资源占用。</li>
</ul>
<h3 id="14-为什么systemd能做到启动很快">1.4 为什么systemd能做到启动很快</h3>
<p>systemd使用并行的方法启动服务，不像SysV init是顺序执行的，所以大大节省了系统启动时间。</p>
<p>使用并行启动，最大的难点是要解决服务之间的依赖性，systemd的解决办法是使用类似缓冲池的办法。比如对TCP有依赖的服务，在启动的时候会检查依赖服务的TCP端口，systemd会把对TCP端口的请求先缓存起来，当依赖的服务器启动之后，在将请求传递给服务，使两个服务通讯。同样的进程间通讯的D-BUS也是这样的原理，目录挂载则是先让服务以为目录被挂载了，到真正访问目录的时候，才去真正操作。</p>
<h2 id="systemd的特性">systemd的特性</h2>
<p><strong>systemd解决了那些问题？</strong></p>
<ul>
<li>按需启动服务，减少系统资源消耗；</li>
<li>尽可能并行启动进程，减少系统启动等待时间；</li>
<li>提供一个一致的配置环境，不光是服务配置；</li>
<li>提供服务状态快照，可以恢复特定点的服务状态。</li>
</ul>
<h2 id="centos-7的systemd特性">CentOS 7的systemd特性</h2>
<h3 id="31-套接字服务保持激活功能">3.1 套接字服务保持激活功能</h3>
<p>在系统启动的时候，systemd为所有支持套接字激活功能的服务创建监听端口，当服务启动后，就将套接字传给这些服务。这种方式不仅可以允许服务在启动的时候平行启动，也可以保证在服务重启期间，试图连接服务的请求，不会丢失。对服务端口的请求被保留，并且存放到队列中。</p>
<h3 id="32-进程间通讯保持激活功能">3.2 进程间通讯保持激活功能</h3>
<p>当有客户端应用第一次通过D-Bus方式请求进程间通讯时，systemd会立即启动对应的服务。systemd依据D-Bus的配置文件使用进程间通讯保持激活功能。</p>
<h3 id="33-设备保持激活功能">3.3 设备保持激活功能</h3>
<p>当特定的硬件插入时，systemd启动对应的硬件服务支持。systemd依据硬件服务单元配置文件保持硬件随时被激活。</p>
<h3 id="34-文件路径保持激活功能">3.4 文件路径保持激活功能</h3>
<p>当特定的文件或者路径状态发生改变的时候，systemd会激活对应的服务。systemd依据路径服务单元配置文件保证服务被激活。</p>
<h3 id="35-系统状态快照">3.5 系统状态快照</h3>
<p>systemd可以临时保存当前所有的单元配置文件，或者从前一个快照中恢复单元配置文件。为了保存当前系统服务状态，systemd可以动态的生成单元文件快照。</p>
<h3 id="36-挂载和自动挂载点管理">3.6 挂载和自动挂载点管理</h3>
<p>systemd监控和管理挂载和自动挂载点，并根据挂载点的单元配置文件进行挂载。</p>
<h3 id="37-闪电并行启动">3.7 闪电并行启动</h3>
<p>因为使用套接字保持激活功能，systemd可以并行的启动所以套接字监听服务，大大减少系统启动时间。</p>
<h3 id="38-单元逻辑模拟检查">3.8 单元逻辑模拟检查</h3>
<p>当激活或者关闭一个单元，systemd会计算依赖行，产生一个临时的模拟检查，并且校验一直性。如果不一致，systemd会尝试自动修正，并且移除报错的不重要的任务。</p>
<h3 id="39-和sysv-init向后兼容">3.9 和SysV init向后兼容</h3>
<p>systemd完全支持SysV init Linux标准的基础核心规范脚本，这样的脚本易于升级到systemd服务单元。</p>
<h2 id="核心概念unit">核心概念:unit</h2>
<h3 id="41-什么是单元">4.1 什么是单元</h3>
<p>在RHEL7之前，服务管理是分布式的被SysV init或UpStart通过 <font color="#f8070d" size=3><code>/etc/rc.d/init.d</code></font> 下的脚本管理。这些脚本是经典的Bash脚本，允许管理员控制服务的状态。在RHEL7中，这些脚本被服务单元文件替换。</p>
<p>在systemd中，服务、挂载等资源统一被称为单元，所以systemd中有许多单元类型，服务单元文件的扩展名是.service，同脚本的功能相似。例如有查看、启动、停止、重启、启用或者禁止服务的参数。</p>
<p>配置文件进行标识和配置：文件中主要包含了系统服务、监听socket、保存的系统快照及其他与init相关的信息。</p>
<p><strong>systemd单元文件放置位置</strong>：</p>
<pre><code class="language-sh">/usr/lib/systemd/system/systemd		# 默认单元文件安装目录
/run/systemd/system					      # 单元运行时创建，这个目录优先于安装目录
/etc/systemd/system					      # 系统管理员创建和管理的单元目录，优先级最高。
</code></pre>
<h3 id="42-unit类型">4.2 Unit类型</h3>
<table>
<thead>
<tr>
<th>类型</th>
<th>详解-</th>
</tr>
</thead>
<tbody>
<tr>
<td>Service unit</td>
<td>文件扩展名为service，用于定义系统服务。</td>
</tr>
<tr>
<td>Target unit</td>
<td>文件扩展名为.target，用于模拟实现“运行级别”</td>
</tr>
<tr>
<td>Device unit</td>
<td>文件扩展名为.device，用于定义内核识别的设备。</td>
</tr>
<tr>
<td>Mount unit</td>
<td>文件扩展名为.mount，定义文件系统挂载点</td>
</tr>
<tr>
<td>Socket unit</td>
<td>文件扩展名为.socket，用于表示进程间通信用的socket文件</td>
</tr>
<tr>
<td>Snapshot unit</td>
<td>文件扩展名为.sanpshot，管理系统快照</td>
</tr>
<tr>
<td>Swap unit</td>
<td>文件扩展名为.swap，用于表示swap设备</td>
</tr>
<tr>
<td>Automount unit</td>
<td>文件扩展名为.automount，文件系统的自动挂载点</td>
</tr>
<tr>
<td>Path unit</td>
<td>文件扩展名为.path，用于定义文件系统中的一个文件或目录</td>
</tr>
</tbody>
</table>
<p><code>.service</code> 与服务对应的后缀名为service的unit、文件，无需执行权限，仅仅为systemd的配置文件。当systemd探测到有进程访问时，按需激活这个服务的机制，任何依赖与这个服务的其他服务想启动的话，</p>
<p>服务的并行启动：</p>
<p><code>.device</code> 在某个硬件设备被激活或变得可用时，从而激活服务</p>
<p><code>.path</code>：某个文件路径变得可用或里面有文件时（文件发生变动）激活某个服务</p>
<p><strong>系统快照</strong>：</p>
<p>systemd能将所有unit当前状态保存到临时文件中（临时保存到一个持久设备上）。启动时，可从保存的快照开始继续向后运行。 必要时能自动载入。</p>
<p><strong>向后兼容</strong>：</p>
<p>sysV init脚本。（能够兼容 start、stop restart status至少这4个服务脚本）以前启动服务的脚本放到centos7里直接可以用。</p>
<h2 id="centos-7的systemd向后兼容">CentOS 7的systemd向后兼容</h2>
<p>systemd被设计成尽可能向后兼容SysV init和Upstart，下面是一些特别要注意的和之前主要版本的RHEL不再兼容的部分。</p>
<h3 id="51-systemd对运行级别支持有限">5.1 systemd对运行级别支持有限</h3>
<p>为了保存兼容，systemd提供有限target单元，“模拟”一些运行级别，也可以被早期的分布式的运行级别命令支持。不是所有的target都可以被映射到运行级别，在这种情况下，使用runlevel命令有可能会返回一个为N的不知道的运行级别，所以推荐尽量避免在RHEL7中使用runlevel命令。</p>
<h3 id="52-systemd不支持像init脚本那样的个性化命令">5.2 systemd不支持像init脚本那样的个性化命令。</h3>
<p>除了一些标准命令参数例如：start、stop、status，SysV init脚本可以根据需要支持想要的任何参数，通过参数提供附加的功能，因为SysV init的服务器脚本实际上就是shell脚本，命令参数实际上就是shell子函数。</p>
<p>举个例子，RHEL6的iptables服务脚本可以执行panic命令行参数，这个参数可以让系统立即进入紧急模式，丢弃所有的进入和发出的数据包。但是类似这样的命令行参数在systemd中是不支持的，systemd只支持在配置文件中指定命令行参数。</p>
<h3 id="53-systemd不支持和没有从systemd启动的服务通讯">5.3 systemd不支持和没有从systemd启动的服务通讯。</h3>
<p>当systemd启动服务的时候，他保存进程的主ID以便于追踪，systemctl工具使用进程PID查询和管理服务。相反的，如果用户从命令行启动特定的服务，systemctl命令是没有办法判断这个服务的状态是启动还是运行的。</p>
<h3 id="54-systemd可以只停止运行的服务">5.4 systemd可以只停止运行的服务</h3>
<p>在RHEL6及之前的版本，当关闭系统的程序启动之后，RHEL6的系统会执行/etc/rc0.d/下所有服务脚本的关闭操作，不管服务是处于运行或者根本没有运行的状态。而systemd可以做到只关闭在运行的服务，这样可以大大节省关机的时间。</p>
<h3 id="55-不能从标准输出设备读到系统服务信息">5.5 不能从标准输出设备读到系统服务信息。</h3>
<p>systemd启动服务的时候，将标准输出信息定向到/dev/null，以免打扰用户。</p>
<h3 id="56-systemd不继承任何上下文环境">5.6 systemd不继承任何上下文环境。</h3>
<p>systemd不继承任何上下文环境，如用户或者会话的HOME或者PATH的环境变量。每个服务得到的是干净的上下文环境。</p>
<h3 id="57-sysv-init脚本依赖性">5.7 SysV init脚本依赖性</h3>
<p>当systemd启动SysV init脚本，systemd在运行的时候，从LinuxStandardBase(LSB)Linux标准库头文件读取服务的依赖信息并继承。</p>
<h3 id="58-超时机制">5.8 超时机制</h3>
<p>为了防止系统被卡住，所有的服务有5分钟的超时机制。</p>
<h2 id="systemd服务管理">systemd服务管理</h2>
<p>使用systemcl命令可以控制服务，service命令和chkconfig命令依然可以使用，但是主要是出于兼容的原因，应该尽量避免使用service命令和chkconfig命令。</p>
<p>使用systemctl命令的时候，服务名字的扩展名可以写全，例如：</p>
<pre><code class="language-sh">systemctl stop httpd.service
</code></pre>
<p>也可以忽略，例如：</p>
<pre><code class="language-sh">systemctl stop httpd
</code></pre>
<h3 id="61-常用命令">6.1 常用命令</h3>
<h3 id="62-服务管理">6.2 服务管理</h3>
<table>
<thead>
<tr>
<th>说明</th>
<th>命令</th>
</tr>
</thead>
<tbody>
<tr>
<td>启动服务</td>
<td>service name start ==	systemctl start name.service</td>
</tr>
<tr>
<td>停止服务</td>
<td>service name stop	== systemctl stop name.service</td>
</tr>
<tr>
<td>重启服务</td>
<td>service name restart	== systemctl restart name.service</td>
</tr>
<tr>
<td>查看服务状态</td>
<td>service name status == systemctl status name.service</td>
</tr>
<tr>
<td>条件式重启</td>
<td>service name condrestart == systemctl try-restart name.service</td>
</tr>
<tr>
<td>重载或重启服务</td>
<td>systemctl reload-or-restart name.service</td>
</tr>
<tr>
<td>重载或条件式重启</td>
<td>systemctl reload-or-try-restart name.service</td>
</tr>
<tr>
<td>禁止设定为开机自启动</td>
<td>systemctl mask name.service</td>
</tr>
<tr>
<td>取消设定为开机自启动</td>
<td>systemctl unmask name.service</td>
</tr>
<tr>
<td>查看服务当前激活与否的状态</td>
<td>systemctl is-active name.service</td>
</tr>
<tr>
<td>允许服务开机启动</td>
<td>systemctl enable name.service</td>
</tr>
<tr>
<td>禁止服务开机启动</td>
<td>systemclt disable name.service</td>
</tr>
<tr>
<td>级别切换</td>
<td>systemctl list-units &ndash;type target</td>
</tr>
<tr>
<td>获取默认运行级别</td>
<td>systemctl get-default</td>
</tr>
<tr>
<td>修改默认级别</td>
<td>systemctl set-default name.service</td>
</tr>
<tr>
<td>切换至紧急救援模式</td>
<td>systemctl rescue</td>
</tr>
<tr>
<td>切换至emergency模式</td>
<td>systemctl emergency</td>
</tr>
<tr>
<td>关机</td>
<td>systemctl halt systemctl poweroff</td>
</tr>
<tr>
<td>重启</td>
<td>systemctl reboot</td>
</tr>
<tr>
<td>挂起</td>
<td>systemctl suspend</td>
</tr>
<tr>
<td>快照</td>
<td>systemctl hibernate</td>
</tr>
<tr>
<td>快照并挂起</td>
<td>systemctl hybrid-sleep</td>
</tr>
</tbody>
</table>
<h3 id="63-查看服务详细信息">6.3 查看服务详细信息</h3>
<p>查看所有已激活的服务。默认只列出处于激活状态的服务，如果希望看到所有的服务，使用&ndash;all或-a参数：</p>
<pre><code class="language-sh">systemctl list-units --type service
</code></pre>
<p>查看所有的服务</p>
<pre><code class="language-sh">systemctl list-units --type service --all
</code></pre>
<p>检查服务开机启动状态</p>
<pre><code class="language-sh">systemctl status name.service
systemctl is-enabled name.service
</code></pre>
<p>列出所有服务并且检查是否开机启动</p>
<pre><code class="language-sh">systemctl list-unit-files --type service
</code></pre>
<p>选项重新加载所以单元文件并重新创建依赖书，在需要立即应用单元文件改变的时候使用。另外，也可以使用init q的命令达到同样的目的。还有，如果修改的是一个正在运行服务的单元文件，服务需要被重启下：</p>
<pre><code class="language-sh">systemct lrestart name.service
systemctl daemon-reload
</code></pre>
<p>查看服务依赖关系</p>
<pre><code class="language-sh">systemctl list-dependencies
</code></pre>
<h2 id="systemd-target">systemd target</h2>
<p>在RHEL7之前的版本，使用运行级别代表特定的操作模式。运行级别被定义为七个级别，用数字0到6表示，每个级别可以启动特定的一些服务。RHEL7使用target替换运行基本。</p>
<p>systemd target使用target单元文件描述，target单位文件扩展名是.target，target单元文件的唯一目标是将其他systemd单元文件通过一连串的依赖关系组织在一起。举个例子，graphical.target单元，用于启动一个图形会话，systemd会启动像GNOME显示管理(gdm.service)、帐号服务（axxounts-daemon）这样的服务，并且会激活multi-user.target单元。相似的multi-user.target单元，会启动必不可少NetworkManager.service、dbus.service服务，并激活basic.target单元。</p>
<p>RHEL7预定义了一些target和之前的运行级别或多或少有些不同。为了兼容，systemd也提供一些target映射为SysV init的运行级别，具体的对应信息如下：</p>
<table>
<thead>
<tr>
<th>代码</th>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>runlevel0.target,poweroff.targe</td>
<td>关闭系统。</td>
</tr>
<tr>
<td>1</td>
<td>runlevel1.target,rescue.target</td>
<td>进入救援模式。</td>
</tr>
<tr>
<td>2</td>
<td>runlevel2.target,multi-user.target</td>
<td>进入非图形界面的多用户方式。</td>
</tr>
<tr>
<td>3</td>
<td>runlevel3.target,multi-user.target</td>
<td>进入非图形界面的多用户方式。</td>
</tr>
<tr>
<td>4</td>
<td>runlevel4.target,multi-user.target</td>
<td>进入非图形界面的多用户方式。</td>
</tr>
<tr>
<td>5</td>
<td>runlevel5.target,graphical.target</td>
<td>进入图形界面的多用户方式。</td>
</tr>
<tr>
<td>6</td>
<td>runlevel6.target,reboot.target</td>
<td>重启系统。</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<hr>
<p>注：对于systemd来说 234没有区别</p>
<hr>
<h3 id="71-target管理">7.1 target管理</h3>
<p>使用如下命令查看目前可用的target：</p>
<pre><code class="language-sh">systemctl list-units --type target
</code></pre>
<p>改变当前的运行基本使用如下命令：</p>
<pre><code class="language-sh">systemctl isolate name.target
systemctl isolate rescue.target
$ runlevel 
1 3
</code></pre>
<h3 id="72-修改默认的运行级别">7.2 修改默认的运行级别</h3>
<p>使用systemctl get-default命令得到默认的运行级别：</p>
<pre><code class="language-sh">$ systemctl get-default 
multi-user.target
</code></pre>
<p>使用systemctl set-default name.target修改默认的运行级别：</p>
<pre><code class="language-sh">systemctl set-default graphical.target 
# 可以看到。默认级别就是操作如下两步骤
rm '/etc/systemd/system/default.target'
ln-s'/usr/lib/systemd/system/graphical.target''/etc/systemd/system/default.target'
</code></pre>
<p>使用 Target 的时候，systemctl list-dependencies命令和systemctl isolate命令也很有用。
查看 multi-user.target 包含的所有服务</p>
<pre><code class="language-sh">systemctl list-dependencies multi-user.target
</code></pre>
<p>一般来说，常用的 Target 有两个：一个是multi-user.target，表示多用户命令行状态；另一个是graphical.target，表示图形用户状态，它依赖于multi-user.target。官方文档有一张非常清晰的 Target 依赖关系图。</p>
<h3 id="73-target-的配置文件">7.3 Target 的配置文件</h3>
<p>Target 也有自己的配置文件。</p>
<pre><code class="language-sh">[Unit]
Description=Multi-User System
Documentation=man:systemd.special(7)
Requires=basic.target		# Requires字段：要求basic.target一起运行。

# 冲突字段。如果rescue.service或rescue.target正在运行，multi-user.target就不能运行，反之亦然。
Conflicts=rescue.service rescue.target

# 表示multi-user.target在basic.target 、 rescue.service、 rescue.target之后启动，如果它们有启动的话。
After=basic.target rescue.service rescue.target

# 允许使用systemctl isolate命令切换到multi-user.target。
AllowIsolate=yes
</code></pre>
<p>注意，Target 配置文件里面没有启动命令。</p>
<h3 id="74-救援模式和紧急模式">7.4 救援模式和紧急模式</h3>
<p>使用进入救援模式，如果连救援模式都进入不了，可以进入紧急模式：</p>
<pre><code class="language-sh">systemctl rescue 	  # 救援模式（进入救援模式，如果连救援模式都进入不了，可以进入紧急模式）
systtmctl emergency # 紧急模式
</code></pre>
<p>紧急模式进入最小的系统环境，以便于修复系统。紧急模式根目录以只读方式挂载，不激活网络，只启动很少的服务，进入紧急模式需要root密码。</p>
<h2 id="关闭暂停休眠系统">关闭、暂停、休眠系统</h2>
<p>RHEL7中，使用systemctl替换一些列的电源管理命令，原有的命令依旧可以使用，但是建议尽量不用使用。systemctl和这些命令的对应关系为：</p>
<table>
<thead>
<tr>
<th>说明</th>
<th>SysV/Upstart</th>
<th>system</th>
</tr>
</thead>
<tbody>
<tr>
<td>停止系统（关机）</td>
<td>halt</td>
<td>systemctl hatl</td>
</tr>
<tr>
<td>关闭系统，关闭系统电源</td>
<td>poweroff</td>
<td>systemctl poweroff</td>
</tr>
<tr>
<td>重启系统</td>
<td>reboot</td>
<td>systemctl reboot</td>
</tr>
<tr>
<td>暂停系统</td>
<td>pm-suspend</td>
<td>systemctl suspend</td>
</tr>
<tr>
<td>休眠系统</td>
<td>pm-hibernate</td>
<td>systemct lhibernate</td>
</tr>
<tr>
<td>暂停并休眠系统</td>
<td>pm-suspend-hybrid</td>
<td>systemctl hybrid-sleep</td>
</tr>
</tbody>
</table>
<h2 id="通过systemd管理远程系统">通过systemd管理远程系统</h2>
<p>不光是可以管理本地系统，systemd还可以控制远程系统，管理远程系统主要是通过SSH协议，只有确认可以连接远程系统的SSH，在systemctl命令后面添加-H或者&ndash;host参数，加上远程系统的ip或者主机名就可以。</p>
<h2 id="创建和修改systemd单元文件">创建和修改systemd单元文件</h2>
<h3 id="101-单元文件概述">10.1 单元文件概述</h3>
<p>一个服务怎么启动，完全由它的配置文件决定。下面就来看，配置文件有些什么内容。</p>
<p>配置文件主要放在/usr/lib/systemd/system目录，也可能在/etc/systemd/system目录。找到配置文件以后，使用文本编辑器打开即可。</p>
<p>下面以sshd.service文件为例，它的作用是启动一个 SSH 服务器，供其他用户以 SSH 方式登录。</p>
<pre><code class="language-sh">[Unit]
Description=OpenSSH server daemon
Documentation=man:sshd(8) man:sshd_config(5)
After=network.target sshd-keygen.service
Wants=sshd-keygen.service

[Service]
EnvironmentFile=/etc/sysconfig/sshd
ExecStart=/usr/sbin/sshd -D $OPTIONS
ExecReload=/bin/kill -HUP $MAINPID
Type=simple
KillMode=process
Restart=on-failure
RestartSec=42s

[Install]
WantedBy=multi-user.target
</code></pre>
<pre><code class="language-sh">$ systemctl status rsyncd
rsyncd.service - fast remote file copy program daemon
   Loaded: loaded (/usr/lib/systemd/system/rsyncd.service; disabled) 
   # loaded 服务已经被加载，显示单元文件绝对路径，标志单元文件可用。
   # disabled表示开机不允许启动Status服务的附件信息。
   Active: active (running) since 四 2017-01-26 21:59:41 CST; 5min ago
   # active表示当前状态  从什么时间被激活
 Main PID: 1360 (rsync) # main pid 与进程名字一致的PID，主进程PID。进程可能有多个进程可能有一组
   CGroup: /system.slice/rsyncd.service
           └─1360 /usr/bin/rsync --daemon --no-detach
# cgroup表示资源组，启动命令是/usr/bin/rsync --daemon --no-detach
1月 26 21:59:41 lnmp systemd[1]: Starting fast remote file copy program daemon...
1月 26 21:59:41 lnmp systemd[1]: Started fast remote file copy program daemon.

$ systemctl status rsyncd
rsyncd.service - fast remote file copy program daemon
   Loaded: loaded (/usr/lib/systemd/system/rsyncd.service; disabled)
   Active: inactive (dead)/
</code></pre>
<p>上面的输出结果含义如下:&quot;&quot;</p>
<ul>
<li>Loaded行：配置文件的位置，是否设为开机启动</li>
<li>Active行：表示正在运行</li>
<li>Main PID行：主进程ID</li>
<li>Status行：由应用本身（这里是 httpd ）提供的软件当前状态</li>
<li>Cgroup块：应用的所有子进程</li>
<li>日志块：应用的日志</li>
</ul>
<h3 id="102-理解单元文件结构">10.2 理解单元文件结构</h3>
<h3 id="103-单元文件概述">10.3 单元文件概述</h3>
<p>可以看到，配置文件分成几个区块，每个区块包含若干条键值对。
典型的单元文件包含三节：</p>
<ul>
<li>
<p><strong>[Unit]</strong>：包含不依赖单元类型的一般选项，这些选型提供单元描述，知道单元行为，配置单元和其他单元的依赖性。</p>
</li>
<li>
<p><strong>[unittype]</strong>：如果单元有特定的类型指令，在unittype节这些指令被组织在一起。举个例子，服务单元文件包含[Service]节，里面有经常使用的服务配置。</p>
</li>
<li>
<p><strong>[Install]</strong>：包含systemctl enable或者disable的命令安装信息。</p>
</li>
</ul>
<h4 id="1031-unit节选项">10.3.1 [Unit]节选项</h4>
<table>
<thead>
<tr>
<th>字段</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Description</td>
<td>字段给出当前服务的简单描述</td>
</tr>
<tr>
<td>Documentation</td>
<td>给出文档位置。</td>
</tr>
<tr>
<td></td>
<td>启动顺序 <strong><font color="#0215cd" size=2> 注意:After和Before字段只涉及启动顺序，不涉及依赖关系</font></strong></td>
</tr>
<tr>
<td>After</td>
<td>表示sshd.service应该在network.target sshd-keygen.service之后启动。</td>
</tr>
<tr>
<td>Before</td>
<td>定义sshd.service应该在哪些服务之前启动。</td>
</tr>
<tr>
<td></td>
<td>举例来说，某 Web 应用需要 postgresql 数据库储存数据。在配置文件中，它只定义要在 postgresql 之后启动，而没有定义依赖 postgresql 。上线后，由于某种原因，postgresql 需要重新启动，在停止服务期间，该 Web 应用就会无法建立数据库连接。</td>
</tr>
<tr>
<td></td>
<td><strong><font color="#0215cd" size=2> 设置依赖关系，需要使用Wants字段和Requires字段。</font></strong></td>
</tr>
<tr>
<td>Wants</td>
<td>表示sshd.service与sshd-keygen.service之间存在<font style="background:#ffff00;" size=2> &ldquo;弱依赖&rdquo; </font>关系，即如果&quot;sshd-keygen.service&quot;启动失败或停止运行，不影响sshd.service继续执行。</td>
</tr>
<tr>
<td>Requires</td>
<td>表示<font style="background:#ffff00;" size=2> &ldquo;强依赖&rdquo; </font>关系，即如果该服务启动失败或异常退出，那么sshd.service也必须退出。</td>
</tr>
<tr>
<td></td>
<td><strong><font color="#0215cd" size=2>注意，Wants字段与Requires字段只涉及依赖关系，与启动顺序无关，默认情况下是同时启动的。</font></strong></td>
</tr>
</tbody>
</table>
<h4 id="1032-service-区块启动行为">10.3.2 [Service] 区块：启动行为</h4>
<p> Service区块定义如何启动当前服务。</p>
<blockquote>
<p><strong>启动命令</strong></p>
</blockquote>
<p> 许多软件都有自己的环境参数文件，该文件可以用EnvironmentFile字段读取。</p>
<pre><code>  EnvironmentFile字段：指定当前服务的环境参数文件。该文件内部的key=value键值对，可以用$key的形式，在当前配置文件中获取。
</code></pre>
<p> 上面的例子中，sshd 的环境参数文件是<font color="#f8070d" size=3><code>/etc/sysconfig/sshd</code></font>。</p>
<p> 配置文件里面最重要的字段是ExecStart。</p>
<pre><code>  ExecStart：定义启动进程时执行的命令。
</code></pre>
<p>上面的例子中，启动sshd，执行的命令是<font color="#f8070d" size=3><code>/usr/sbin/sshd -D $OPTIONS</code></font>，其中的变量$OPTIONS就来自EnvironmentFile字段指定的环境参数文件。</p>
<p>与之作用相似的，还有如下这些字段：</p>
<table>
<thead>
<tr>
<th>选项</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>ExecStart</td>
<td>指定启动单元的命令或者脚本，ExecStartPre和ExecStartPost节指定在ExecStart之前或者之后用户自定义执行的脚本。Type=oneshot允许指定多个希望顺序执行的用户自定义命令。</td>
</tr>
<tr>
<td>ExecStop</td>
<td>指定单元停止时执行的命令或者脚本。</td>
</tr>
<tr>
<td>ExecReload</td>
<td>指定单元重新加载是执行的命令或者脚本。</td>
</tr>
<tr>
<td>ExecStartPre</td>
<td>启动服务之前执行的命令</td>
</tr>
<tr>
<td>ExecStartPost</td>
<td>启动服务之后执行的命令</td>
</tr>
<tr>
<td>ExecStopPost</td>
<td>停止服务之后执行的命令</td>
</tr>
<tr>
<td>Restart</td>
<td>这个选项如果被允许，服务重启的时候进程会退出，会通过systemctl命令执行清除并重启的操作。</td>
</tr>
<tr>
<td>RemainAfterExit</td>
<td>如果设置这个选择为真，服务会被认为是在激活状态，即使所以的进程已经退出，默认的值为假，这个选项只有在Type=oneshot时需要被配置。</td>
</tr>
</tbody>
</table>
<p>请看下面的例子。</p>
<pre><code class="language-sh">[Service]
ExecStart=/bin/echo execstart1
ExecStart=
ExecStart=/bin/echo execstart2
ExecStartPost=/bin/echo 1
ExecStartPost=/bin/echo 2
</code></pre>
<p>上面这个配置文件，第二行ExecStart设为空值，等于取消了第一行的设置，运行结果如下。</p>
<pre><code class="language-sh">$ systemctl start test 
$ systemctl status test
test.service - test daemon
   Loaded: loaded (/usr/lib/systemd/system/test.service; disabled)
   Active: inactive (dead)

1月 30 07:11:16 lnmp systemd[1]: Starting test daemon...
1月 30 07:11:16 lnmp systemd[1]: Started test daemon.
1月 30 07:11:16 lnmp echo[1822]: test1_start
1月 30 07:11:16 lnmp echo[1824]: test1_stop
</code></pre>
<p>所有的启动设置之前，都可以加上一个连词号（-），表示<font style="background:#ffff00;" size=2>&ldquo;抑制错误&rdquo;</font>，即发生错误的时候，不影响其他命令的执行。比如，<font color="#f8070d" size=3><code>EnvironmentFile=-/etc/sysconfig/sshd</code></font>（注意等号后面的那个连词号），就表示即使/etc/sysconfig/sshd 文件不存在，也不会抛出错误。</p>
<blockquote>
<p><strong>启动类型</strong></p>
</blockquote>
<p>Type字段定义启动类型。它可以设置的值如下。</p>
<table>
<thead>
<tr>
<th>选项值</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>simple</td>
<td>默认值，ExecStart字段启动的进程为主进程</td>
</tr>
<tr>
<td>forking</td>
<td>进程作为服务主进程的一个子进程启动，父进程在完全启动之后退出。</td>
</tr>
<tr>
<td>oneshot</td>
<td>类似于simple，但只执行一次，进程在启动单元之后随之退出。</td>
</tr>
<tr>
<td>dbus</td>
<td>类似于simple，但随着单元启动后只有主进程得到D-BUS名字。</td>
</tr>
<tr>
<td>notify</td>
<td>类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务</td>
</tr>
<tr>
<td>idle</td>
<td>类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>下面是一个oneshot的例子，笔记本电脑启动时，要把触摸板关掉，配置文件可以这样写。</p>
<pre><code class="language-sh">[Unit]
Description=Switch-off Touchpad

[Service]
Type=oneshot
ExecStart=/usr/bin/touchpad-off

[Install]
WantedBy=multi-user.target
</code></pre>
<p>上面的配置文件，启动类型设为oneshot，就表明这个服务只要运行一次就够了，不需要长期运行。</p>
<p>如果关闭以后，将来某个时候还想打开，配置文件修改如下。</p>
<pre><code class="language-sh">[Unit]
Description=Switch-off Touchpad

[Service]
Type=oneshot
ExecStart=/usr/bin/touchpad-off start
ExecStop=/usr/bin/touchpad-off stop
RemainAfterExit=yes

[Install]
WantedBy=multi-user.target
</code></pre>
<p>上面配置文件中，RemainAfterExit字段设为yes，表示进程退出以后，服务仍然保持执行。这样的话，一旦使用systemctl stop命令停止服务，ExecStop指定的命令就会执行，从而重新开启触摸板。</p>
<blockquote>
<p><strong>重启行为</strong></p>
</blockquote>
<p> Service区块有一些字段，定义了重启行为。</p>
<pre><code class="language-sh">  KillMode字段：定义 Systemd 如何停止 sshd 服务。
</code></pre>
<p>上面这个例子中，将KillMode设为process，表示只停止主进程，不停止任何sshd 子进程，即子进程打开的 SSH session 仍然保持连接。这个设置不太常见，但对sshd很重要，否则你停止服务的时候，会连自己打开的SSH session一起杀掉。</p>
<p>KillMode字段可以设置的值如下：</p>
<table>
<thead>
<tr>
<th>选项值</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>control-group</td>
<td>（默认值）	当前控制组里面的所有子进程，都会被杀掉</td>
</tr>
<tr>
<td>process</td>
<td>只杀主进程</td>
</tr>
<tr>
<td>mixed</td>
<td>主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号</td>
</tr>
<tr>
<td>none</td>
<td>没有进程会被杀掉，只是执行服务的 stop 命令。</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>Restart字段。</strong></p>
</blockquote>
<p> Restart字段：定义了 sshd 退出后，Systemd 的重启方式。</p>
<p>上面的例子中，Restart设为on-failure，表示任何意外的失败，就将重启sshd。如果 sshd 正常停止（比如执行systemctl stop命令），它就不会重启。</p>
<p>Restart字段可以设置的值如下。</p>
<table>
<thead>
<tr>
<th>选项值</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>no</td>
<td>默认值；退出后不会重启</td>
</tr>
<tr>
<td>on-success</td>
<td>只有正常退出时（退出状态码为0），才会重启</td>
</tr>
<tr>
<td>on-failure</td>
<td>非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启</td>
</tr>
<tr>
<td>on-abnormal</td>
<td>只有被信号终止和超时，才会重启</td>
</tr>
<tr>
<td>on-abort</td>
<td>只有在收到没有捕捉到的信号终止时，才会重启</td>
</tr>
<tr>
<td>on-watchdog</td>
<td>超时退出，才会重启</td>
</tr>
<tr>
<td>always</td>
<td>不管是什么退出原因，总是重启</td>
</tr>
</tbody>
</table>
<p> 对于守护进程，推荐设为on-failure。对于那些允许发生错误退出的服务，可以设为on-abnormal。</p>
<blockquote>
<p><strong>RestartSec字段。</strong></p>
</blockquote>
<p> RestartSec字段：表示 Systemd 重启服务之前，需要等待的秒数。上面的例子设为等待42秒。</p>
<h5 id="10.2.3">[Install] 区块
&nbsp;说明：Install区块，定义如何安装这个配置文件，即怎样做到开机启动。
WantedBy字段：表示该服务所在的 Target。
<p>Target的含义是服务组，表示一组服务。WantedBy=multi-user.target指的是，sshd 所在的 Target 是multi-user.target。</p>
<p>这个设置非常重要，因为执行systemctl enable sshd.service命令时，sshd.service的一个符号链接，就会放在/etc/systemd/system目录下面的multi-user.target.wants子目录之中。</p>
<p>Systemd 有默认的启动 Target。</p>
<pre><code class="language-sh">$ systemctl get-default
multi-user.target
</code></pre>
<p>上面的结果表示，默认的启动 Target 是multi-user.target。在这个组里的所有服务，都将开机启动。这就是为什么systemctl enable命令能设置开机启动的原因。</p>
<blockquote>
<p><strong>修改配置文件后重启</strong></p>
</blockquote>
<p>修改配置文件以后，需要重新加载配置文件，然后重新启动相关服务。</p>
<pre><code class="language-sh"># 重新加载配置文件
systemctl daemon-reload
</code></pre>
<h3 id="104-一个postfix服务的例子">10.4 一个postfix服务的例子：</h3>
<p>单元文件位于<font color="#f8070d" size=3><code>/usr/lib/systemd/system/postifix.service</code></font>，内容如下：</p>
<pre><code class="language-sh">[Unit] 
Description=PostfixMailTransportAgent 
After=syslog.targetnetwork.target 
Conflicts=sendmail.serviceexim.service 

[Service] 
Type=forking 
PIDFile=/var/spool/postfix/pid/master.pid 
EnvironmentFile=-/etc/sysconfig/network
ExecStartPre=-/usr/libexec/postfix/aliasesdb
ExecStartPre=-/usr/libexec/postfix/chroot-update
ExecStart=/usr/sbin/postfixstart
ExecReload=/usr/sbin/postfixreload
ExecStop=/usr/sbin/postfixstop

[Install] 
WantedBy=multi-user.target
</code></pre>
<h4 id="105-创建自定义的单元文件">10.5 创建自定义的单元文件</h4>
<p>以下几种场景需要自定义单元文件：</p>
<ul>
<li>希望自己创建守护进程；</li>
<li>为现有的服务创建第二个实例；</li>
<li>引入SysV init脚本。</li>
</ul>
<p>另外一方面，有时候需要修改已有的单元文件。下面介绍创建单元文件的步骤：</p>
<blockquote>
<ol>
<li>准备自定义服务的执行文件。</li>
</ol>
</blockquote>
<p>可执行文件可以是脚本，也可以是软件提供者的的程序，如果需要，为自定义服务的主进程准备一个PID文件，一保证PID保持不变。另外还可能需要的配置环境变量的脚本，确保所以脚本都有可执行属性并且不需要交互。</p>
<blockquote>
<p>2.在<font color="#f8070d" size=3><code>/etc/systemd/system/</code></font>目录创建单元文件，并且保证只能被root用户编辑</p>
</blockquote>
<pre><code class="language-sh">touch /etc/systemd/system/mariadb.service
chmod 644 /etc/systemd/system/mariadb.service
</code></pre>
<hr>
<p><strong><font color="#f8070d" size=3>注：文件不需要执行权限</font>。</strong></p>
<hr>
<blockquote>
<ol start="3">
<li>打开name.service文件，添加服务配置，各种变量如何配置视所添加的服务类型而定，下面是一个依赖网络服务的配置例子：</li>
</ol>
</blockquote>
<pre><code class="language-sh">[Unit] 
Description=mariadb multi demo 3306
After=network.target

[Service] 
ExecStart=/data/3306/mysql start
ExecReload=/data/3306/mysql restart
ExecStop=/data/3306/mysql stop
Type=forking
PIDFile=/data/3306/mysqld.pid

[Install] 
WantedBy=multi-user.target
</code></pre>
<blockquote>
<p>4.通知systemd有个新服务添加：</p>
</blockquote>
<pre><code class="language-sh">systemctl daemon-reload 
systemctl start name.service
</code></pre>
<h4 id="10.5">10.5 创建第二个sshd服务的例子
<blockquote>
<p><strong>1.拷贝sshd_config文件</strong></p>
</blockquote>
<pre><code class="language-sh">cp /etc/ssh/sshd{,-second}_config
# {,second} 等于 和second ，类似与 {a,c}的用法
</code></pre>
<blockquote>
<p><strong>2.编辑sshd-second_config文件，添加22220的端口，和PID文件</strong>：</p>
</blockquote>
<pre><code>Port 22220 
PidFile /var/run/sshd-second.pid
</code></pre>
<p>如果还需要修改其他参数，请阅读帮助。</p>
<blockquote>
<p><strong>3.拷贝单元文件</strong>：</p>
</blockquote>
<pre><code class="language-sh"> cp /usr/lib/systemd/system/sshd{,-second}.service
</code></pre>
<blockquote>
<p><strong>4.编辑单元文件sshd-second.service</strong></p>
</blockquote>
<pre><code class="language-sh">[Unit] 
Description=OpenSSH server second instance daemon 
After=syslog.target network.targe tauditd.service sshd.service 

[Service] 
EnvironmentFile=/etc/sysconfig/sshd
ExecStart=/usr/sbin/sshd -D -f /etc/ssh/sshd-second_config $OPTIONS 
ExecReload=/bin/kill -HUP $MAINPID 
KillMode=process 
Restart=on-failure 
RestartSec=42s 

[Install] 
WantedBy=multi-user.target
</code></pre>
<blockquote>
<p><strong>5.如果使用SELinux，添加tcp端口，负责第二sshd服务的端口就会被拒绝绑定</strong>：</p>
</blockquote>
<pre><code class="language-sh">semanage port -a -tssh_port_t -p tcp22220
</code></pre>
<blockquote>
<blockquote>
<p><strong>6.设置开机启动并测试</strong>：</p>
</blockquote>
</blockquote>
<pre><code class="language-sh">systemctl enable sshd-second.service 
ssh -p 22220 user@server
</code></pre>
<h4 id="106-修改已经存在的单元文件">10.6 修改已经存在的单元文件</h4>
<p>systemd unit配置文件默认保存在/usr/lib/systemd/system/目录，不建议直接修改这个目录下的文件，自定义的文件在/etc/systemd/system/目录下，如果有扩展的需求，可以使用以下方案：</p>
<p>创建一个目录/etc/systemd/system/unit.d/，这个是最推荐的一种方式，可以参考初始的单元文件，通过附件配置文件来扩展默认的配置，对默认单元文件的升级会被自动升级和应用。</p>
<p>从/usr/lib/systemd/system/拷贝一份原始配置文件到/etc/systemd/system/，然后修改。复制的版本会覆盖原始配置，这种方式不能增加附件的配置包，用于不需要附加功能的场景。</p>
<p>如果需要恢复到默认的配置文件，只需要删除/etc/systemd/system/下的配置文件就可以了，不需要重启机器。</p>
<h2 id="reference">Reference</h2>
<blockquote>
<p>[CentOS7/RHEL7 systemd详解](CentOS7/RHEL7 systemd详解)</p>
<p><a href="http://www.jinbuguo.com/systemd/systemd.index.html" target="_blank"
   rel="noopener nofollow noreferrer" >systemd.index 中文手册</a></p>
<p><a href="https://web.archive.org/web/20230204201903/https://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-part-two.html" target="_blank"
   rel="noopener nofollow noreferrer" >Systemd 入门教程：实战篇</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>Linux日志管理 - syslog</title>
      <link>https://www.oomkill.com/2016/04/syslog/</link>
      <pubDate>Thu, 21 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2016/04/syslog/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="rsyslog介绍">rsyslog介绍</h2>
<p>syslog守护进程，内部有两个进程，syslogd主要负责用户空间的用户进程记录日志；klog负责内核所发生的各种时间记录日志。两者合并后形成syslog。</p>
<p>rsyslog是syslog下一代升级产品，依然有syslogd klogd提供服务。</p>
<p>rsyslog可以开通远程机制监听在某个套接字上，其他任何主机所产生的日志信息由本机的rsyslog收集起来，收集完后不负责记录，而是建立一个tcp或udp连接发送给专门的日志服务器，由专门的日志服务器负责记录。默认情况下是明文的。</p>
<h3 id="rsyslog特性">rsyslog特性</h3>
<ol>
<li>多线程。</li>
<li>支持UDP,TCP协议，基于ssl tls加密完成远程日志传输。支持RELP协议</li>
<li>实现将日志存储到MySQL PGSQL等关系型数据库中。</li>
<li>强大的过滤器，可实现过滤日志信息中任何部分，支持自定义输出格式。</li>
</ol>
<h2 id="日志格式">日志格式</h2>
<p>事件产生的事件  主机  进程pid  事件</p>
<pre><code class="language-bash">Jun  6 23:36:58 Lamp-02 NET[1838]: /etc/sysconfig/network-scripts/ifup-post: updated /etc/resolv.conf
Jun  6 23:46:15 Lamp-02 yum[1963]: Updated: mysql-libs-5.1.73-8.el6_8.x86_64
Jun  6 23:46:16 Lamp-02 yum[1963]: Installed: mysql-5.1.73-8.el6_8.x86_64
</code></pre>
<p>有些日志记录二进制日志 <code>/var/log/wtmp /var/log/btmp</code></p>
<p>last：<code>/var/log/wtmp</code> 当前系统中成功登陆的日志</p>
<p>lastb：<code>/var/log/btmp</code> 当前系统中失败的登陆尝试</p>
<p>lastlog：显示当前系统每一个用户最近一次登陆时间</p>
<h3 id="日志等级">日志等级</h3>
<p>日志级别：事件的关键性程度</p>
<p>lev	|说明</p>
<table>
<thead>
<tr>
<th>lev</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>none</td>
<td>不记录</td>
</tr>
<tr>
<td>debug</td>
<td>调试信息</td>
</tr>
<tr>
<td>info</td>
<td>正常信息，仅是一些基本信息说明</td>
</tr>
<tr>
<td>notice</td>
<td>比info还需要注意的一些信息内容</td>
</tr>
<tr>
<td>warning,warn</td>
<td>警告信息，可能有些问题，但是还不至于影响到某个服务运作的信息</td>
</tr>
<tr>
<td>err,error</td>
<td>一些重大的错误信息</td>
</tr>
<tr>
<td>crit</td>
<td>临界状态，比error还要严重的错误信息，橙色警报</td>
</tr>
<tr>
<td>alert</td>
<td>红色警报，已经很有问题的等级，比crit还要严重</td>
</tr>
<tr>
<td>emerg,panic</td>
<td>疼痛等级，意指系统已经要宕机的状态！很严重的错误信息</td>
</tr>
</tbody>
</table>
<h3 id="设施类型">设施类型</h3>
<p>facility：把某一类具有相同特性的由各个应用程序所产生的日志数据流归类到用一个数据收集管道中，这个收集管道称之为facility。</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>auth(authpriv)</td>
<td>与认证有关的机制，例如login ssh su等需要账号密码</td>
</tr>
<tr>
<td>cron</td>
<td>例行性工作调度cron/at等生成信息日志的地方</td>
</tr>
<tr>
<td>daemon</td>
<td>与各个daemon有关的信息。</td>
</tr>
<tr>
<td>kern</td>
<td>内核产生信息地方</td>
</tr>
<tr>
<td>lpr</td>
<td>打印相关信息</td>
</tr>
<tr>
<td>mail</td>
<td>邮件收发有关的信息</td>
</tr>
<tr>
<td>news</td>
<td>新闻组服务器有关信息</td>
</tr>
<tr>
<td>syslog</td>
<td>自身产生日志</td>
</tr>
<tr>
<td>user</td>
<td>用户</td>
</tr>
<tr>
<td>security</td>
<td>与安全相关信息</td>
</tr>
<tr>
<td>local0-local7</td>
<td>用户自定义8个设置</td>
</tr>
</tbody>
</table>
<h3 id="通配机制">通配机制</h3>
<table>
<thead>
<tr>
<th>通配符</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.</td>
<td>代表【比后面还要高的等级（含该等级）都被记录下来】 例如：mail.info代表只要是mail信息，而且该信息等级高于info（含info）时，就会被记录下来。</td>
</tr>
<tr>
<td>.=</td>
<td>代表所需要的等级就是后面接的等级而已，其他的不要。例如：main.=info代表的只要是mail信息，而且该信息等于info级别，就会被记录下来。</td>
</tr>
<tr>
<td>.!</td>
<td>代表不等于（取反），亦是除了该等级外的其他等级都记录。</td>
</tr>
<tr>
<td>*</td>
<td>所有；例如：*.info代表所有设施的info级别</td>
</tr>
<tr>
<td>none</td>
<td>不记录</td>
</tr>
</tbody>
</table>
<h3 id="日志的输出位置">日志的输出位置</h3>
<table>
<thead>
<tr>
<th>位置</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>文件</td>
<td>/var/log/messages</td>
</tr>
<tr>
<td>打印机或其他设备</td>
<td>/dev/lp0这个打印机装置</td>
</tr>
<tr>
<td>使用者名称</td>
<td>显示给用户，*代表目前在线所有的人</td>
</tr>
<tr>
<td>远程主机</td>
<td>@10.0.0.2 远程日志服务器，@代表udp协议，@@代表tcp协议</td>
</tr>
<tr>
<td>管道</td>
<td>|command</td>
</tr>
</tbody>
</table>
<pre><code class="language-bash">$ rpm -ql rsyslog
/etc/logrotate.d/syslog
/etc/pki/rsyslog
/etc/rsyslog.conf &lt;==配置文件
/etc/rsyslog.d
/etc/sysconfig/rsyslog
/usr/bin/rsyslog-recover-qi.pl
/usr/lib/systemd/system/rsyslog.service &lt;==单元文件
/usr/lib64/rsyslog
/usr/lib64/rsyslog/imdiag.so &lt;==收集日志接受日志流输入时的输入过滤工具
/usr/lib64/rsyslog/omjournal.so &lt;==
/var/lib/rsyslog
</code></pre>
<h2 id="rsyslog配置文件详解">rsyslog配置文件详解</h2>
<p>rsyslog配置文件分为3个模块，<font style="background:#fee904;" size=3> 每段的配置必须严格写在#### xxx ####位置内</font></p>
<pre><code class="language-bash">$ grep '##' /etc/rsyslog.conf
#### MODULES ####   #&lt;==加载的模块
#### GLOBAL DIRECTIVES ####  #&lt;==定义日志格式默认模板
#### RULES ####  #&lt;==转发规则
# ### begin forwarding rule ###
# ### end of the forwarding rule ###
</code></pre>
<h3 id="常用参数">常用参数</h3>
<pre><code class="language-bash">$ModLoad imklog #&lt;==加载模块
mail.*  -/var/log/maillog #&lt;==将mail所有类型的日志异步写入maillog文件中
</code></pre>
<h2 id="rsyslog案例">rsyslog案例</h2>
<h3 id="设置ssh日志为其他设施">设置ssh日志为其他设施</h3>
<h4 id="修改ssh配置文件">修改ssh配置文件</h4>
<pre><code class="language-bash">#SyslogFacility AUTHPRIV
SyslogFacility local1
</code></pre>
<h4 id="修改rsyslog配置文件">修改rsyslog配置文件</h4>
<p>将ssh日志写入到ssh.log中</p>
<pre><code class="language-bash">local1.*    -/var/log/ssh.log
</code></pre>
<p>使用ssh登陆查看日志生成结果</p>
<pre><code class="language-bash">$ cat /var/log/ssh.log
Jun  7 00:15:17 Lamp-02 sshd[2966]: Accepted password for root from 192.168.2.1 port 57670 ssh2
</code></pre>
<h3 id="将日志记录到远程服务器">将日志记录到远程服务器</h3>
<p>在客户端配置</p>
<pre><code class="language-bash">*.info;mail.none;authpriv.none;cron.none;local0.none;          @192.168.2.82
</code></pre>
<p>服务端开启配置</p>
<pre><code class="language-bash">$ModLoad imudp
$UDPServerRun 514
</code></pre>
<p>查看服务端的日志记录情况</p>
<pre><code class="language-bash">$ cat /var/log/messages
Jun  2 05:47:59 lnmp yum[128171]: Updated: httpd-tools-2.4.6-45.el7.centos.4.x86_64
Jun  2 05:48:03 lnmp yum[128171]: Updated: httpd-2.4.6-45.el7.centos.4.x86_64
Jun  2 05:48:03 lnmp systemd: Reloading.
Jun  2 05:48:04 lnmp systemd: Configuration file /usr/lib/systemd/system/auditd.service is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
</code></pre>
<h3 id="基于mysql存储日志">基于MySQL存储日志</h3>
<p>将日志存储到数据库中需要加载相对应的模块</p>
<pre><code class="language-bash">rsyslog.x86_64                5.8.10-10.el6_6 base
rsyslog-gnutls.x86_64        	5.8.10-10.el6_6 base
rsyslog-gssapi.x86_64        	5.8.10-10.el6_6 base
rsyslog-mysql.x86_64         	5.8.10-10.el6_6 base
rsyslog-pgsql.x86_64          5.8.10-10.el6_6 base
rsyslog-relp.x86_64           5.8.10-10.el6_6 base
rsyslog-snmp.x86_64           5.8.10-10.el6_6 base
...
</code></pre>
<h4 id="安装rsyslog程序包">安装rsyslog程序包</h4>
<pre><code class="language-bash">$ rpm -ql rsyslog-mysql
/lib64/rsyslog/ommysql.so
/usr/share/doc/rsyslog-mysql-5.8.10
/usr/share/doc/rsyslog-mysql-5.8.10/createDB.sql
</code></pre>
<h4 id="配置服务器端参数">配置服务器端参数</h4>
<pre><code class="language-bash">$Modload ommysql
*.info;mail.none;authpriv.none;cron.none :ommysql:localhost,Syslog,syslog,111
</code></pre>
<h4 id="导入数据库并授权">导入数据库并授权</h4>
<pre><code class="language-sql">mysql &lt; /usr/share/doc/rsyslog-mysql-5.8.10/createDB.sql
grant all privileges on syslog.* to syslog@'localhost' identified by '111';
</code></pre>
<p>查看结果</p>
<pre><code class="language-sql">mysql&gt; select count(*) from systemevents;
+----------+
| count(*) |
+----------+
|        3 |
+----------+
1 row in set (0.00 sec)
</code></pre>
<h4 id="安装loganalyzer">安装loganalyzer</h4>
<p>下载 <a href="http://loganalyzer.adiscon.com/downloads/" target="_blank"
   rel="noopener nofollow noreferrer" >loganalyzer</a></p>
<pre><code class="language-bash">sh configure.sh
sh secure.sh
chmod 666 config.php
</code></pre>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
