<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>monitor on Cylon&#39;s Collection</title>
    <link>https://www.oomkill.com/categories/monitor/</link>
    <description>Recent content in monitor on Cylon&#39;s Collection</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 17 Jul 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://www.oomkill.com/categories/monitor/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>PromQL复杂使用示例</title>
      <link>https://www.oomkill.com/2024/07/promql-advanced/</link>
      <pubDate>Wed, 17 Jul 2024 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2024/07/promql-advanced/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="查询结果删除某些指标">查询结果删除某些指标</h2>
<h3 id="without">without</h3>
<p>without 属于聚合查询的子句，必须在聚合查询中使用</p>
<p>语法：</p>
<pre><code class="language-bash">&lt;aggr-op&gt; [without|by (&lt;label list&gt;)] ([parameter,] &lt;vector expression&gt;)
</code></pre>
<p>可以看到属于 &lt;aggr-op&gt;</p>
<p>例如</p>
<pre><code>sum without(instance) (http_requests_total)
</code></pre>
<h3 id="ignoring">ignoring</h3>
<p>ignoring 属于 “向量匹配” (<em><strong>Vector matching</strong></em>) 关键词，可以在 一对多，和多对多查询中使用</p>
<p>语法</p>
<pre><code class="language-bash">&lt;vector expr&gt; &lt;bin-op&gt; ignoring(&lt;label list&gt;) &lt;vector expr&gt;
</code></pre>
<p>例如</p>
<pre><code class="language-bash">method_code:http_errors:rate5m{code=&quot;500&quot;} / ignoring(code) method:http_requests:rate5m
</code></pre>
<h2 id="与查询">与查询</h2>
<p>可以查询满足多个条件的指标，例如下列是查询 jvm 内存 $\frac{used}{committed} &gt; 80%$ 并且 Pod WSS 使用大于 80% 的指标</p>
<pre><code class="language-promql">sum by(pod) (jvm_memory_used_bytes{}) / sum by(pod) (jvm_memory_committed_bytes{}) &gt; .8 
and
sum(node_namespace_pod_container:container_memory_working_set_bytes{}) by (pod) 
/ on(pod) 
group_left 
sum(kube_pod_container_resource_limits{resource=&quot;memory&quot;})  by (pod) &gt; .8
</code></pre>
<h2 id="向量查询">向量查询</h2>
<p>向量查询关键词为 <code>on</code> 和 <code>ignoring</code></p>
<p>on 仅考虑表达式内提供的标签相同的，ignoring 允许在匹配时间序列时忽略指定的标签。</p>
<h3 id="语法">语法</h3>
<p>一对一</p>
<pre><code class="language-bash">&lt;vector expr&gt; &lt;bin-op&gt; ignoring(&lt;label list&gt;) &lt;vector expr&gt;
&lt;vector expr&gt; &lt;bin-op&gt; on(&lt;label list&gt;) &lt;vector expr&gt;
</code></pre>
<p>多对一或一对多</p>
<pre><code class="language-bash">&lt;vector expr&gt; &lt;bin-op&gt; ignoring(&lt;label list&gt;) group_left(&lt;label list&gt;) &lt;vector expr&gt;
&lt;vector expr&gt; &lt;bin-op&gt; ignoring(&lt;label list&gt;) group_right(&lt;label list&gt;) &lt;vector expr&gt;
&lt;vector expr&gt; &lt;bin-op&gt; on(&lt;label list&gt;) group_left(&lt;label list&gt;) &lt;vector expr&gt;
&lt;vector expr&gt; &lt;bin-op&gt; on(&lt;label list&gt;) group_right(&lt;label list&gt;) &lt;vector expr&gt;
</code></pre>
<h3 id="向量查询的高级用法">向量查询的高级用法</h3>
<p>通过一个 metrcs 上的 label 的值去查询另外一个 metric 上这个标签的值</p>
<pre><code class="language-bash">container_memory_rss{container=~&quot;.*$module.*&quot;} on(pod) vm_memory_used_bytes{instance=~&quot;$module.*&quot;}
</code></pre>
<p>查询不同标签上的相同标签值的内容，例如，我想通过 **jvm_memory_used_bytes **指标上 pod label 为 “<em><strong>aaaa</strong></em>” 的 label，去查询 <strong>container_memory_rss</strong> 上 container label 为 “<em><strong>aaaa</strong></em>” 的指标内容，这个时候可以使用 <em><strong>label_replace</strong></em> 来重写不同的 label 为相同的值，on() 函数中添加相同指标的值即可完成查询。</p>
<p>如下所示</p>
<pre><code class="language-promeql">sum without(
	node,instance,job,name,id,image,metrics_path,endpoint,service,pod)(
		label_replace(
			container_memory_rss{container=~&quot;.*$module.*&quot;,}
			,&quot;ints&quot;,&quot;$1&quot;,&quot;pod&quot;, &quot;(.*)&quot;
		)
) 
!= on(ints) 
group_left() 
sum by(ints) 
	(sum without (job,pod,container) (
		label_replace(
			jvm_memory_used_bytes{instance=&quot;$instance&quot;}
			,&quot;ints&quot;,&quot;$1&quot;,&quot;pod&quot;, &quot;(.*)&quot;
		)
	)
)
</code></pre>
<h2 id="reference">Reference</h2>
<ul>
<li><sup id="1">[1]</sup> <a href="https://blog.devops.dev/advanced-promql-understanding-optimizing-and-logical-grouping-of-queries-11220e80ba0d" target="_blank"
   rel="noopener nofollow noreferrer" >Optimizing, and Logical Grouping of Queries</a></li>
<li><sup id="2">[2]</sup> <a href="https://www.robustperception.io/using-group_left-to-calculate-label-proportions" target="_blank"
   rel="noopener nofollow noreferrer" >Using group_left to calculate label proportions</a></li>
<li><sup id="3">[3]</sup> <a href="https://fiberplane.com/blog/inside-some-complex-prometheus-queries" target="_blank"
   rel="noopener nofollow noreferrer" >Inside some complex Prometheus queries</a></li>
<li><sup id="4">[4]</sup> <a href="https://prometheus.io/docs/prometheus/latest/querying/operators/" target="_blank"
   rel="noopener nofollow noreferrer" >Operators</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>深入解析Kubernetes监控体系与prometheus-adapter</title>
      <link>https://www.oomkill.com/2024/05/prometheus-adapter-intro/</link>
      <pubDate>Fri, 31 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2024/05/prometheus-adapter-intro/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="kubernetes监控架构设计">Kubernetes监控架构设计</h2>
<h3 id="k8s监控设计背景说明">k8s监控设计背景说明</h3>
<p>根据 Kubernetes监控架构 <sup><a href="#1">1</a></sup>，Kubernetes 集群中的 metrcis 可以分为 <strong>系统指标</strong> (Core Metrics) 和 <strong>服务指标</strong> (service metrics) ; 系统指标(System metrics) 是通用的指标，通常可以从每一个被监控的实体中获得（例如，容器和节点的CPU和内存使用情况）。服务指标(Service metrics) 是在应用程序代码中显式定义并暴露的 (例如，API Server 处理的 500 错误数量)。</p>
<p>Kubernetes将系统指标分为两部分：</p>
<ul>
<li>核心指标 (core metrics) 是 Kubernetes 理解和用于其内部组件和核心工具操作的指标，例如：用于调度的指标 (包括资源估算算法的输入, 初始资源/VPA (vertical autoscaling)，集群自动扩缩 (cluster autoscaling)，水平Pod自动扩缩 (horizontal pod autoscaling ) 除自定义指标之外的指标)；Kube Dashboard 使用的指标，以及 “kubectl top” 命令使用的指标。</li>
<li>非核心指标 (non-core metrics) 是指不被 Kubernetes 解释的指标。我们一般假设这些指标包含核心指标 (但不一定是 Kubernetes 可理解的格式)，以及其他额外的指标。</li>
</ul>
<p>所以，kubernetes monitoring 的架构被设计拥有如下特点：</p>
<ul>
<li>通过标准的主 API (当前为主监控 API) 提供关于Node, Pod 和容器的核心系统指标，使得核心 Kubernetes 功能不依赖于非核心组件</li>
<li>kubelet 只导出有限的指标集，即核心 Kubernetes 组件正常运行所需的指标。</li>
<li>&hellip;</li>
</ul>
<h3 id="监控管道">监控管道</h3>
<p>Kubernetes 监控管道分为两个：</p>
<ul>
<li>核心指标管道 (<strong>core metrics pipeline</strong>) 由 Kubelet、资源估算器, 一个精简版 Heapster (metrics-server)，以及 api-server 中 master metrics API 组成。这些指标被核心系统组件使用，例如调度逻辑（如调度器和基于系统指标的HPA）和一些简单 UI 组件（如 kubectl top），这个管道并不打算与第三方监控系统集成。</li>
<li>监控管道：一个用于收集系统中的各种指标并将其暴露给最终用户端，以及通过适配器暴露给 HPA(用于自定义指标) 和  Infrastore 的。用户可以选择多种监控系统供应商（例如 Prometheus, metric-server），也可以完全不使用。</li>
</ul>
<h4 id="core-metrics-pipeline">Core Metrics Pipeline</h4>
<p>根据 kubernetes 监控设计文档可以得知，核心指标指</p>
<ul>
<li>使用这组核心指标，由Kubelet收集，并仅供 Kubernetes 系统组件使用，支持&quot;第一类资源隔离和利用特性&quot;。</li>
<li>不设计成面向用户的 API，而是尽可能通用，以支持未来的用户级组件。</li>
</ul>
<p>核心指标的包含三类：</p>
<ul>
<li>CpuUsage: 记录从创建对象开始的累计CPU使用时间。</li>
<li>MemoryUsage: 记录工作集内存使用量。</li>
<li>FilesystemUsage: 记录文件系统使用情况,包括已用字节数和已用Inode数。</li>
</ul>
<h4 id="monitoring-pipeline">Monitoring Pipeline</h4>
<p>根据 Kubernetes 监控设计文档 <sup><a href="#1">1</a></sup> 得知，监控管道用于与核心Kubernetes组件分开的系统，可以更加灵活。并且监控管道可以收集不同类型的指标：</p>
<ul>
<li>Core system metrics</li>
<li>Non-core system metrics</li>
<li>Service metrics from user application containers</li>
<li>Service metrics from Kubernetes infrastructure containers (using Prometheus instrumentation)</li>
</ul>
<p>监控管道主要用于根据自定义指标进行 HPA，监控管道提供了一个无状态的 API Adapter，用于拉去监控给 HPA</p>
<h3 id="指标api">指标API</h3>
<h4 id="api类别">API类别</h4>
<p>根据监控架构设计文档，Kubernetes 定义了两套指标 API，资源指标 API 和 自定义指标 API；Kubernetes 为资源指标 API 提供了两种实现：Heapster 和 metrics-server，而自定义指标 API 由不同的监控供应商实现。下面将详细描述每个 API。</p>
<ul>
<li>
<p>资源指标 API (Resource Metrics API)：该 API 允许消费者访问 Pod 和 Node 的资源指标（CPU &amp; Memory）</p>
<ul>
<li>The API is implemented by metrics-server and prometheus-adapter.</li>
</ul>
</li>
<li>
<p>自定义指标 API (Custom Metrics API)：该 API 允许消费者访问描述 Kubernetes 资源的任意指标。</p>
<ul>
<li>用户可以根据 <a href="https://github.com/kubernetes-sigs/custom-metrics-apiserver" target="_blank"
   rel="noopener nofollow noreferrer" >kubernetes-sigs/custom-metrics-apiserver </a> 仓库来自定义 API-server</li>
</ul>
</li>
</ul>
<h4 id="api的访问">API的访问</h4>
<p>资源指标，该 API 是在 <code>/apis/metrics.k8s.io/</code> ，可以使用 <code>kubectl proxy --port 8080</code> 代理后进行访问，</p>
<pre><code class="language-bash">$ kubectl proxy --port=8080
$ curl localhost:8080/apis/metrics.k8s.io/v1beta1/nodes
</code></pre>
<p>或者使用 <code>kubectl get --raw</code> 进行获取</p>
<pre><code class="language-bash">$ kubectl get --raw &quot;/apis/metrics.k8s.io/v1beta1/nodes&quot; | jq 
</code></pre>
<p>自定义指标，该 API 是在 <code>/apis/custom.metrics.k8s.io/</code> ，访问的方式相同，用户通过该 PATH 进行访问。</p>
<pre><code class="language-bash"># 查看有哪些指标可用
$ kubectl get --raw &quot;/apis/custom.metrics.k8s.io/v1beta1/&quot; | jq
</code></pre>
<h2 id="prometheus-adapter">Prometheus-adapter</h2>
<p>通过上一章节介绍了kubernetes监控体系，这已经可以了解到了 prometheus-adapter 的定位；prometheus-adapter 是通过 kubernetes custom-metrics-apiserver 标准实现的一个 custom.metrics.k8s.io API，用于提供给 HPA 的一种指标适配器，可以将任何指标转化为 HPA 可用的指标。他全名为 <strong>Kubernetes Custom Metrics Adapter for Prometheus</strong>。</p>
<h3 id="prometheus-adapter配置文件详解">prometheus-adapter配置文件详解</h3>
<p>prometheus-adapter负责确定哪些指标以及如何去发现这些指标，根据这个标准，配置文件分为四个步骤来完成这套 “发现” 规则</p>
<p>每一个指标可以大致分为四个部分，对应在配置文件中：</p>
<ul>
<li><em>Discovery</em>  ，用于指定 adapter 应如何查找此规则的所有Prometheus指标。</li>
<li><em>Association</em>  ，用于指定 adapter 应如何确定特定指标与哪些 Kubernetes 资源相关联。</li>
<li><em>Naming</em> ，用于指定 adapter 应如何在自定义指标 API 中公开该指标。</li>
<li><em>Querying</em> ，用于指定如何将针对一个或多个 Kubernetes 对象的特定指标请求转换为对 Prometheus 的查询。</li>
</ul>
<p>配置文件如下所示，这是官方给出的样板<a href="https://github.com/kubernetes-sigs/prometheus-adapter/blob/v0.12.0/docs/sample-config.yaml" target="_blank"
   rel="noopener nofollow noreferrer" >配置文件</a>（文章编写时版本为0.12）</p>
<pre><code class="language-yaml">rules:
# Each rule represents a some naming and discovery logic.
# Each rule is executed independently of the others, so
# take care to avoid overlap.  As an optimization, rules
# with the same `seriesQuery` but different
# `name` or `seriesFilters` will use only one query to
# Prometheus for discovery.

# some of these rules are taken from the &quot;default&quot; configuration, which
# can be found in pkg/config/default.go

# this rule matches cumulative cAdvisor metrics measured in seconds
- seriesQuery: '{__name__=~&quot;^container_.*&quot;,container!=&quot;POD&quot;,namespace!=&quot;&quot;,pod!=&quot;&quot;}'
  resources:
    # skip specifying generic resource&lt;-&gt;label mappings, and just
    # attach only pod and namespace resources by mapping label names to group-resources
    overrides:
      namespace: {resource: &quot;namespace&quot;}
      pod: {resource: &quot;pod&quot;}
  # specify that the `container_` and `_seconds_total` suffixes should be removed.
  # this also introduces an implicit filter on metric family names
  name:
    # we use the value of the capture group implicitly as the API name
    # we could also explicitly write `as: &quot;$1&quot;`
    matches: &quot;^container_(.*)_seconds_total$&quot;
  # specify how to construct a query to fetch samples for a given series
  # This is a Go template where the `.Series` and `.LabelMatchers` string values
  # are available, and the delimiters are `&lt;&lt;` and `&gt;&gt;` to avoid conflicts with
  # the prometheus query language
  metricsQuery: &quot;sum(rate(&lt;&lt;.Series&gt;&gt;{&lt;&lt;.LabelMatchers&gt;&gt;,container!=&quot;POD&quot;}[2m])) by (&lt;&lt;.GroupBy&gt;&gt;)&quot;

# this rule matches cumulative cAdvisor metrics not measured in seconds
- seriesQuery: '{__name__=~&quot;^container_.*_total&quot;,container!=&quot;POD&quot;,namespace!=&quot;&quot;,pod!=&quot;&quot;}'
  resources:
    overrides:
      namespace: {resource: &quot;namespace&quot;}
      pod: {resource: &quot;pod&quot;}
  seriesFilters:
  # since this is a superset of the query above, we introduce an additional filter here
  - isNot: &quot;^container_.*_seconds_total$&quot;
  name: {matches: &quot;^container_(.*)_total$&quot;}
  metricsQuery: &quot;sum(rate(&lt;&lt;.Series&gt;&gt;{&lt;&lt;.LabelMatchers&gt;&gt;,container!=&quot;POD&quot;}[2m])) by (&lt;&lt;.GroupBy&gt;&gt;)&quot;

# this rule matches cumulative non-cAdvisor metrics
- seriesQuery: '{namespace!=&quot;&quot;,__name__!=&quot;^container_.*&quot;}'
  name: {matches: &quot;^(.*)_total$&quot;}
  resources:
    # specify an a generic mapping between resources and labels.  This
    # is a template, like the `metricsQuery` template, except with the `.Group`
    # and `.Resource` strings available.  It will also be used to match labels,
    # so avoid using template functions which truncate the group or resource.
    # Group will be converted to a form acceptible for use as a label automatically.
    template: &quot;&lt;&lt;.Resource&gt;&gt;&quot;
    # if we wanted to, we could also specify overrides here
  metricsQuery: &quot;sum(rate(&lt;&lt;.Series&gt;&gt;{&lt;&lt;.LabelMatchers&gt;&gt;,container!=&quot;POD&quot;}[2m])) by (&lt;&lt;.GroupBy&gt;&gt;)&quot;

# this rule matches only a single metric, explicitly naming it something else
# It's series query *must* return only a single metric family
- seriesQuery: 'cheddar{sharp=&quot;true&quot;}'
  # this metric will appear as &quot;cheesy_goodness&quot; in the custom metrics API
  name: {as: &quot;cheesy_goodness&quot;}
  resources:
    overrides:
      # this should still resolve in our cluster
      brand: {group: &quot;cheese.io&quot;, resource: &quot;brand&quot;}
  metricsQuery: 'count(cheddar{sharp=&quot;true&quot;})'

# external rules are not tied to a Kubernetes resource and can reference any metric
# https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-metrics-not-related-to-kubernetes-objects
externalRules:
- seriesQuery: '{__name__=&quot;queue_consumer_lag&quot;,name!=&quot;&quot;}'
  metricsQuery: sum(&lt;&lt;.Series&gt;&gt;{&lt;&lt;.LabelMatchers&gt;&gt;}) by (name)
- seriesQuery: '{__name__=&quot;queue_depth&quot;,topic!=&quot;&quot;}'
  metricsQuery: sum(&lt;&lt;.Series&gt;&gt;{&lt;&lt;.LabelMatchers&gt;&gt;}) by (name)
  # Kubernetes metric queries include a namespace in the query by default
  # but you can explicitly disable namespaces if needed with &quot;namespaced: false&quot;
  # this is useful if you have an HPA with an external metric in namespace A
  # but want to query for metrics from namespace B
  resources:
    namespaced: false

# TODO: should we be able to map to a constant instance of a resource
# (e.g. `resources: {constant: [{resource: &quot;namespace&quot;, name: &quot;kube-system&quot;}}]`)?
</code></pre>
<h4 id="discovery">Discovery</h4>
<p>Discovery 部分控制了查找要在自定义指标 API 中公开的指标的过程。其中有两个关键字段：<code>seriesQuery</code> 和 <code>seriesFilters</code>。</p>
<p><strong>seriesQuery</strong> 指定了用于查找某些 Prometheus series 的 Prometheus series 查询(作为传递给  Prometheus  <code> /api/v1/series</code>)。适配器将从这些系列中剥离标签值，然后在后续步骤中使用得到的“指标名称—标签名称”的组合。</p>
<p>在许多情况下，seriesQuery 就足以缩小 Prometheus series 的列表。但有时(特别是当两个规则可能重叠时)，对指标名称进行额外的过滤是很有用的。在这种情况下,可以使用  seriesFilters。在从 seriesQuery 返回 series  列表后，每个 series 的指标名称都会通过指定的任何过滤器进行过滤。</p>
<p>过滤器可以是以下两种形式之一:</p>
<ul>
<li>is: <regex>，匹配名称符合指定正则表达式的任何序列。</li>
<li>isNot: <regex>，匹配名称不符合指定正则表达式的任何序列。</li>
</ul>
<p>例如</p>
<pre><code class="language-yaml"># match all cAdvisor metrics that aren't measured in seconds
seriesQuery: '{__name__=~&quot;^container_.*_total&quot;,container!=&quot;POD&quot;,namespace!=&quot;&quot;,pod!=&quot;&quot;}'
seriesFilters:
  - isNot: &quot;^container_.*_seconds_total&quot;
</code></pre>
<h4 id="association">Association</h4>
<p>Association 部分控制了确定序列指标可以附加到哪些 Kubernetes 资源的过程。resources 字段控制了这个过程。</p>
<p>有两种方式来关联资源与特定指标。在这两种情况下,标签的值都会成为特定对象的名称。</p>
<p>一种方式是指定，任何符合某个特定模式的标签名称都指向基于标签名称的某个“group_resource”。这可以使用 template 字段来完成。pattern 被指定为一个 Go 模板，其中 Group 和 Resource 字段分别代表“组”和“资源”。</p>
<pre><code class="language-yaml"># any label `kube_&lt;group&gt;_&lt;resource&gt;` becomes &lt;group&gt;.&lt;resource&gt; in Kubernetes
resources:
  template: &quot;kube_&lt;&lt;.Group&gt;&gt;_&lt;&lt;.Resource&gt;&gt;&quot;
</code></pre>
<p>另一种方式是指定某个特定标签代表某个特定的 Kubernetes 资源。这可以使用 overrides 字段来完成。每个 override 将一个 Prometheus 标签映射到一个 Kubernetes group-resource。例如:</p>
<pre><code class="language-yaml"># the microservice label corresponds to the apps.deployment resource
resources:
  overrides:
    microservice: 
      group: &quot;apps&quot;
      resource: &quot;deployment&quot;
</code></pre>
<p>Association 部分提供了两种关联 Prometheus 指标和 Kubernetes 资源的方式，可以根据需要灵活地组合使用。这是实现自定义指标 API 的关键一环。</p>
<h4 id="naming">Naming</h4>
<p>Naming 部分控制了将 Prometheus 指标名称转换为自定义指标 API 中的指标，这是通过 name 字段来实现的。</p>
<p>Naming 的控制通过指定一个从 Prometheus 名称中提取 API 名称的模式，以及对提取值进行的可选转换来实现。</p>
<p>模式由 <code>matches</code> 字段指定，这是一个正则表达式。如果没有指定,它默认为 .* 。</p>
<p>转换由 <code>as</code> 字段指定。你可以使用 <code>matches</code> 字段中定义的任何捕获组。如果 <code>matches</code> 字段没有捕获组，as 字段默认为 <code>$0</code> 。如果只包含一个捕获组，as 字段默认为 <code>$1</code> 。否则，如果没有指定 as 字段就会出错。例如</p>
<pre><code class="language-yaml"># match turn any name &lt;name&gt;_total to &lt;name&gt;_per_second
# e.g. http_requests_total becomes http_requests_per_second
name:
  matches: &quot;^(.*)_total$&quot;
  as: &quot;${1}_per_second&quot;
</code></pre>
<h4 id="querying">Querying</h4>
<p>Querying 部分控制了实际获取特定指标值的过程。它由 <code>metricsQuery</code> 字段来控制。</p>
<p>metricsQuery 字段是一个 Go 模板,它会被转换成一个 Prometheus 查询，使用从特定的自定义指标 API  调用获取的输入数据。对自定义指标 API  的一次调用会被简化为一个指标名称、一个 “group-resource” 和一个或多个该 “group-resource” 的对象。这些会被转换成模板中的以下字段:</p>
<ul>
<li>Series: 指标名称</li>
<li>LabelMatchers: 一个逗号分隔的标签匹配器列表，匹配给定的对象。当前包括特定的 “group-resource” 标签，以及 namespace 标。</li>
<li>GroupBy: 一个逗号分隔的用于分组的标签列表。当前包括用于 LabelMatchers 的组-资源标签。</li>
</ul>
<p>例如，假设我们有一个 <code>http_requests_total</code> 序列 (在 API 中公开为  http_requests_per_second )，具有 service、pod、ingress、namespace 和 verb  标签。前四个对应于 Kubernetes 资源。那么,如果有人请求了 <code>pods/http_request_per_second</code> 指标，那么针对  somens 命名空间中的 pod1 和 pod2，我们会有:</p>
<ul>
<li>Series: &ldquo;http_requests_total&rdquo;</li>
<li>LabelMatchers: <code>&quot;pod=~&quot;pod1|pod2&quot;,namespace=&quot;somens&quot;&quot;</code></li>
<li>GroupBy: pod</li>
</ul>
<p>对应 prometheus promql 如下所示</p>
<pre><code class="language-bash">sum(http_requests_total{pod=~&quot;pod1|pod2&quot;,namespace=&quot;somens&quot;}) by (pod)
</code></pre>
<p>此外,还有两个高级字段是其他字段的&quot;原始&quot;形式:</p>
<ul>
<li>LabelValuesByName: 映射。将 LabelMatchers 字段中的标签和值对应起来。值是用 <code>|</code> 预先连接的 (用于在 Prometheus 中使用 =~ 匹配器)。</li>
<li>GroupBySlice: GroupBy 字段的切片形式。</li>
</ul>
<p>通常，我们可能会想使用 Series、LabelMatchers 和 GroupBy 字段。其他两个是用于高级用法的。</p>
<p>Querying 预计会为每个请求的对象返回一个值。适配器会使用返回的系列上的标签，将给定的系列关联回其相应的对象。例如:</p>
<pre><code class="language-bash"># convert cumulative cAdvisor metrics into rates calculated over 2 minutes
metricsQuery: &quot;sum(rate(&lt;&lt;.Series&gt;&gt;{&lt;&lt;.LabelMatchers&gt;&gt;,container!=&quot;POD&quot;}[2m])) by (&lt;&lt;.GroupBy&gt;&gt;)&quot;
</code></pre>
<h3 id="完整的配置文件实例">完整的配置文件实例</h3>
<p>例如，我们想使用 springboot 的 actuator 提供的 <code>jvm_memory_used_bytes</code> 和 <code>jvm_memory_max_bytes</code> 计算内存使用率，如下所式</p>
<pre><code class="language-yaml">rules:
- seriesQuery: 'jvm_memory_used_bytes'
  resources:
    overrides:
      namespace:
        resource: &quot;namespace&quot;
      pod:
        resource: &quot;pod&quot;
  name:
    matches: 'jvm_memory_used_bytes'
    as: memory_percent
  metricsQuery: 'sum(jvm_memory_used_bytes{&lt;&lt;.LabelMatchers&gt;&gt;}) by (&lt;&lt;.GroupBy&gt;&gt;) / sum(jvm_memory_max_bytes{&lt;&lt;.LabelMatchers&gt;&gt;}) by (&lt;&lt;.GroupBy&gt;&gt;) * 100'
- seriesQuery: 'process_cpu_usage'
  resources:
    overrides:
      namespace:
        resource: &quot;namespace&quot;
      pod:
        resource: &quot;pod&quot;  
  name:
    matches: 'process_cpu_usage'
    as: process_cpu_percent
  metricsQuery: 'sum(avg_over_time(process_cpu_usage{&lt;&lt;.LabelMatchers&gt;&gt;}[1m])) by (&lt;&lt;.GroupBy&gt;&gt;)'
</code></pre>
<p>这里用到了一个技巧，就是使用查询多个指标，这里参考了 prometheus-adapter 的说明 <sup><a href="#4">4</a></sup></p>
<blockquote>
<p>这很好理解,虽然一开始可能看起来不太明显。</p>
<p>基本上，你只需要选择一个指标作为 &ldquo;Discovery&rdquo; 和 &ldquo;naming&rdquo; 指标，然后使用它来配置配置中的 &ldquo;discovery&rdquo; 和 &ldquo;naming&rdquo; 部分。之后，你就可以在 metricsQuery 中写任何你想要的指标了！ ==<strong>Querying 的序列可以包含任何你想要的指标，只要它们有正确的标签集合即可</strong>==。</p>
</blockquote>
<p>例如，假设你有两个指标 foo_total 和 foo_count，它们都有一个标签 <code>system_name</code>，用于表示节点资源，那么如下配置所示</p>
<pre><code class="language-yaml">rules:
- seriesQuery: 'foo_total'
  resources: {overrides: {system_name: {resource: &quot;node&quot;}}}
  name:
    matches: 'foo_total'
    as: 'foo'
  metricsQuery: 'sum(foo_total{&lt;&lt;.LabelMatchers&gt;&gt;}) by (&lt;&lt;.GroupBy&gt;&gt;) / sum(foo_count{&lt;&lt;.LabelMatchers&gt;&gt;}) by (&lt;&lt;.GroupBy&gt;&gt;)'
</code></pre>
<p>由于我们使用了 <code>jvm_memory_used_bytes</code> 和 <code>jvm_memory_max_bytes</code> ，那么我们可以在 &ldquo;discovery&rdquo; 和 &ldquo;naming&rdquo; 部分写任意指标，在 ”quering“ 中使用真是的指标进行替换，就可以完成</p>
<h4 id="查询-kubernetes-的指标">查询 kubernetes 的指标</h4>
<p>完成配置后，可以使用下面命令进行查询</p>
<pre><code class="language-bash">kubectl get --raw &quot;/apis/custom.metrics.k8s.io/v1beta1&quot;|jq
{
  &quot;kind&quot;: &quot;APIResourceList&quot;,
  &quot;apiVersion&quot;: &quot;v1&quot;,
  &quot;groupVersion&quot;: &quot;custom.metrics.k8s.io/v1beta1&quot;,
  &quot;resources&quot;: [
    {
      &quot;name&quot;: &quot;pods/process_cpu_percent&quot;,
      &quot;singularName&quot;: &quot;&quot;,
      &quot;namespaced&quot;: true,
      &quot;kind&quot;: &quot;MetricValueList&quot;,
      &quot;verbs&quot;: [
        &quot;get&quot;
      ]
    },
    {
      &quot;name&quot;: &quot;pods/memory_percent&quot;,
      &quot;singularName&quot;: &quot;&quot;,
      &quot;namespaced&quot;: true,
      &quot;kind&quot;: &quot;MetricValueList&quot;,
      &quot;verbs&quot;: [
        &quot;get&quot;
      ]
    },
    {
      &quot;name&quot;: &quot;namespaces/memory_percent&quot;,
      &quot;singularName&quot;: &quot;&quot;,
      &quot;namespaced&quot;: false,
      &quot;kind&quot;: &quot;MetricValueList&quot;,
      &quot;verbs&quot;: [
        &quot;get&quot;
      ]
    },
    {
      &quot;name&quot;: &quot;namespaces/process_cpu_percent&quot;,
      &quot;singularName&quot;: &quot;&quot;,
      &quot;namespaced&quot;: false,
      &quot;kind&quot;: &quot;MetricValueList&quot;,
      &quot;verbs&quot;: [
        &quot;get&quot;
      ]
    }
  ]
}
</code></pre>
<p>可以通过 custom API 进程查询具体获取的值，如下所示</p>
<pre><code class="language-bash">$ kubectl get --raw &quot;/apis/custom.metrics.k8s.io/v1beta1/namespaces/public/pods/*/process_cpu_percent&quot;|jq
{
  &quot;kind&quot;: &quot;MetricValueList&quot;,
  &quot;apiVersion&quot;: &quot;custom.metrics.k8s.io/v1beta1&quot;,
  &quot;metadata&quot;: {},
  &quot;items&quot;: [
    {
      &quot;describedObject&quot;: {
        &quot;kind&quot;: &quot;Pod&quot;,
        &quot;namespace&quot;: &quot;msg&quot;,
        &quot;name&quot;: &quot;message-gateway-api-78c4d5cdbf-9k2g7&quot;,
        &quot;apiVersion&quot;: &quot;/v1&quot;
      },
      &quot;metricName&quot;: &quot;process_cpu_percent&quot;,
      &quot;timestamp&quot;: &quot;2024-05-31T11:40:25Z&quot;,
      &quot;value&quot;: &quot;404m&quot;,
      &quot;selector&quot;: null
    },
    
    ...
    
    {
      &quot;describedObject&quot;: {
        &quot;kind&quot;: &quot;Pod&quot;,
        &quot;namespace&quot;: &quot;msg&quot;,
        &quot;name&quot;: &quot;message-core-79fdc6fdd-lkpdm&quot;,
        &quot;apiVersion&quot;: &quot;/v1&quot;
      },
      &quot;metricName&quot;: &quot;process_cpu_percent&quot;,
      &quot;timestamp&quot;: &quot;2024-05-31T11:40:25Z&quot;,
      &quot;value&quot;: &quot;31m&quot;,
      &quot;selector&quot;: null
    },
    {
      &quot;describedObject&quot;: {
        &quot;kind&quot;: &quot;Pod&quot;,
        &quot;namespace&quot;: &quot;msg&quot;,
        &quot;name&quot;: &quot;message-push-admin-554f5d96fd-xlnhj&quot;,
        &quot;apiVersion&quot;: &quot;/v1&quot;
      },
      &quot;metricName&quot;: &quot;process_cpu_percent&quot;,
      &quot;timestamp&quot;: &quot;2024-05-31T11:40:25Z&quot;,
      &quot;value&quot;: &quot;487m&quot;,
      &quot;selector&quot;: null
    }
  ]
}
</code></pre>
<p>我们可以看到，返回值是带有 ”m“ 的单位，这里 issue 是这样回答的</p>
<blockquote>
<p>The <code>m</code>-suffix means milli, Quantity Values are explained here: <a href="https://github.com/kubernetes-sigs/prometheus-adapter/blob/master/docs/walkthrough.md#quantity-values" target="_blank"
   rel="noopener nofollow noreferrer" >https://github.com/kubernetes-sigs/prometheus-adapter/blob/master/docs/walkthrough.md#quantity-values</a>  <sup><a href="#5">5</a></sup></p>
</blockquote>
<p>在指标 API 中最常见的是 m 后缀,它表示毫单位，即单位的千分之一；由于我们返回值是一个百分比，例如 4.87%，那么实际值是 0.0487，那么他的毫单位为就是 “487m” ，和上面返回值一样。</p>
<h3 id="prometheus-adapter的安装">Prometheus-adapter的安装</h3>
<p>在这里采用 helm 方式进行安装，只需要修改对应参数即可</p>
<pre><code class="language-bash">helm install prometheus-adapter -n monitoring  prometheus-community/prometheus-adapter \
	--set prometheus.url=http://prometheus.default.svc \
	--set logLevel=2 \
	--set rules.external=xxx # 如果使用外部规则替换默认的config.yaml,则需要提前创建一个configmap，然后这里指定这个名称
</code></pre>
<h2 id="reference">Reference</h2>
<p><sup id="1">[1]</sup> <a href="https://github.com/kubernetes/design-proposals-archive/blob/main/instrumentation/monitoring_architecture.md" target="_blank"
   rel="noopener nofollow noreferrer" >Kubernetes monitoring architecture</a></p>
<p><sup id="2">[2]</sup> <a href="https://github.com/kubernetes/design-proposals-archive/blob/main/instrumentation/core-metrics-pipeline.md" target="_blank"
   rel="noopener nofollow noreferrer" >core-metrics-pipeline</a></p>
<p><sup id="3">[3]</sup> <a href="https://github.com/kubernetes/metrics" target="_blank"
   rel="noopener nofollow noreferrer" >kubernetes/metrics</a></p>
<p><sup id="4">[4]</sup> <a href="https://github.com/kubernetes-sigs/prometheus-adapter/tree/v0.12.0?tab=readme-ov-file#my-query-contains-multiple-metrics-how-do-i-make-that-work" target="_blank"
   rel="noopener nofollow noreferrer" >my-query-contains-multiple-metrics-how-do-i-make-that-work</a></p>
<p><sup id="5">[5]</sup> <a href="https://github.com/kubernetes-sigs/prometheus-adapter/issues/376" target="_blank"
   rel="noopener nofollow noreferrer" >why i request rest-api, returned requeslt for item value has &rsquo;m&rsquo; unit!!  #376</a></p>
<p><sup id="6">[6]</sup> <a href="https://medium.com/@congliu.thu/complete-guide-to-kubernetes-metrics-24a8782c34cd" target="_blank"
   rel="noopener nofollow noreferrer" >Guide to Kubernetes Metrics</a></p>
<p><sup id="7">[7]</sup>  <a href="https://www.geekgame.site/post/k8s/monitoring_arch/" target="_blank"
   rel="noopener nofollow noreferrer" >Kubernetes 监控架构(译)</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>使用keycloak作为grafana的OAuth2认证</title>
      <link>https://www.oomkill.com/2023/12/grafana-keycloak/</link>
      <pubDate>Tue, 19 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2023/12/grafana-keycloak/</guid>
      <description></description>
      <content:encoded><![CDATA[<p>本文使用 helm 方式部署 grafana 9 并同样将 keycloak 部署在 kubernetes 集群之上；接下来使用 keycloak 作为 grafana authentication，并实现 oauth2 的用户权限管理。</p>
<h2 id="在kubernetes-集群之上使用helm部署keycloak">在Kubernetes 集群之上使用helm部署keycloak</h2>
<p>在 kubernetes 集群安装 keycloak 有两种方式：</p>
<ul>
<li><a href="https://artifacthub.io/packages/helm/riftbit/keycloak" target="_blank"
   rel="noopener nofollow noreferrer" >bitnami helm</a></li>
<li><a href="https://www.keycloak.org/getting-started/getting-started-kube" target="_blank"
   rel="noopener nofollow noreferrer" >offical</a></li>
</ul>
<p>下面使用 offical 提供的方式进行部署</p>
<pre><code class="language-bash">kubectl create -f https://raw.githubusercontent.com/keycloak/keycloak-quickstarts/latest/kubernetes/keycloak.yaml
</code></pre>
<p>helm 部署完成后默认密码是存储在 secret 中，上面方式安装的密码默认为 admin/admin</p>
<h2 id="keycloak-configuration">Keycloak configuration</h2>
<h3 id="创建realm">创建realm</h3>
<p>Realm 管理这一组用户(users), 凭据(credentials), 角色(roles) 和 组(groups)，realm之间是相互隔离，一个用户属于并登录到某个 realm，只能管理和验证其控制的用户。</p>
<p>下面为 grafana 创建一个 realm，如果你的环境已经存在通用的 realm，则可以使用这个 realm，默认 keycloak 的 realm 是 master，超级管理员属于这个 realm。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/image-20231219231812810.png" alt="image-20231219231812810" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h2 id="创建-client">创建 client</h2>
<p>Client 是可以请求Keycloak对用户进行身份验证的实体。最常见用途是希望使用Keycloak来保护自己并提供单点登录(SSO)解决方案的应用程序和服务。客户端也可以是只希望请求身份信息或访问令牌的实体，以便它们可以安全地调用由 Keycloak 保护的网络上的其他服务。因此，我们需要为 grafana 创建一个 client</p>
<p>根据 grafana 官方的指南，我们创建标准需如下所示</p>
<ul>
<li>Client ID: <code>grafana-oauth</code></li>
<li>Enabled: <code>ON</code></li>
<li>Client Protocol: <code>openid-connect</code></li>
<li>Access Type: <code>confidential</code></li>
<li>Standard Flow Enabled: <code>ON</code></li>
<li>Implicit Flow Enabled: <code>OFF</code></li>
<li>Direct Access Grants Enabled: <code>ON</code></li>
<li>Root URL: <code>&lt;grafana_root_url&gt;</code></li>
<li>Valid Redirect URIs: <code>&lt;grafana_root_url&gt;/login/generic_oauth</code></li>
<li>Web Origins: <code>&lt;grafana_root_url&gt;</code></li>
<li>Admin URL: <code>&lt;grafana_root_url&gt;</code></li>
<li>Base URL: <code>&lt;grafana_root_url&gt;</code></li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/image-20231219233419049.png" alt="image-20231219233419049" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：创建一个 grafana-oauth client</center>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/image-20231219233506788.png" alt="image-20231219233506788" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：配置 capability config</center>
<p>Realm settings =&gt; Client policies =&gt;  Policies</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/image-20231219233643632.png" alt="image-20231219233643632" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：创建 client policy</center>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/image-20231219233743333.png" alt="image-20231219233743333" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：创建 access type</center>
<h2 id="准备grafana-chart包">准备grafana chart包</h2>
<p>添加 chart repo</p>
<pre><code class="language-bash">helm repo add grafana https://grafana.github.io/helm-charts
</code></pre>
<p>选择 chart 包下载</p>
<pre><code class="language-bash"># 查看仓库中所有版本
helm search repo grafana/grafana -l
# 下载指定版本的chart包
helm pull grafana/grafana --version 6.57.4
</code></pre>
<p>修改 values.yaml 中 grafana.ini 部分，增加</p>
<pre><code class="language-yaml">   server:
    domain: &quot;{{ if (and .Values.ingress.enabled .Values.ingress.hosts) }}{{ .Values.ingress.hosts | first }}{{ else }}''{{ end }}&quot;
  server:
      # The full public facing url you use in browser, used for redirects and emails
    root_url: http://10.0.0.4:30033/
    serve_from_sub_path: false
  auth:
    signout_redirect_url: http://10.0.0.5:30043/auth/realms/sso/protocol/openid-connect/logout?post_logout_redirect_uri=http%3A%2F%210.0.0.5:30033%2Flogin
  auth.generic_oauth:
    enabled: true
    name: grafana-oauth
    allow_sign_up: true
    client_id: grafana-oauth
    client_secret: TF1FjfEfoeBdLa3MfpCjhC1TgChWYyPV
    scopes: openid email profile offline_access roles
    auth_url: http://10.0.0.5:30043/realms/sso/protocol/openid-connect/auth
    token_url: http://10.0.0.5:30043/realms/sso/protocol/openid-connect/token
    api_url: http://10.0.0.5:30043/realms/sso/protocol/openid-connect/userinfo
    role_attribute_path: contains(roles[*], 'admin') &amp;&amp; 'Admin' || contains(roles[*], 'editor') &amp;&amp; 'Editor' || 'Viewer'
</code></pre>
<p>这里主要修改三个部分</p>
<ul>
<li><em>server</em>：
<ul>
<li><em>root_url</em>: 是在使用 keycloak 跳转时，redirect_uri 的地址，默认是 localhost:3000</li>
<li><em>serve_from_sub_path</em>: 从 root_url 设置中指定的子路径提供 Grafana 服务。 出于兼容性原因，默认情况下它设置为 false。</li>
</ul>
</li>
<li><em>auth</em>: 配置登出时请求的 API，这个按照官方给出的配置即可。</li>
<li><em>auth.generic_oauth</em>: keycloak 的配置，这个按照官方给出的配置即可。</li>
</ul>
<h2 id="troubleshooting">troubleshooting</h2>
<h3 id="invalid-redirect-uri">Invalid redirect uri</h3>
<pre><code>Invalid redirect uri for “Valid Redirect URIs
</code></pre>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/image-20231225230735630.png" alt="image-20231225230735630" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Invalid redirect uri错误</center>
<p>遇到 Invalid redirect uri 错误时，检查 Access settings 配置，并将 grafana 的 <em>auth.generic_oauth</em> 按照下面配置即可</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/image-20231225235825426.png" alt="image-20231225235825426" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>server 段</p>
<pre><code class="language-ini">    [server]
    # Protocol (http, https, h2, socket)
    protocol = http

    # The ip address to bind to, empty will bind to all interfaces
    http_addr =

    # The http port to use
    http_port = 3000

    # The public facing domain name used to access grafana from a browser
    domain = 192.168.64.57

    # Redirect to correct domain if host header does not match domain
    # Prevents DNS rebinding attacks
    enforce_domain = false

    # The full public facing url
    # root_url = %(protocol)s://%(domain)s:%(http_port)s/
    root_url = http://192.168.64.57:30606

    # Serve Grafana from subpath specified in `root_url` setting. By default it is set to `false` for compatibility reasons.
    serve_from_sub_path = false

    # Log web requests
    router_logging = false

    # the path relative working path
    static_root_path = public

    # enable gzip
    enable_gzip = false

    # https certs &amp; key file
    cert_file =
    cert_key =

    # Unix socket path
    socket = /tmp/grafana.sock

    # CDN Url
    cdn_url =

    # Sets the maximum time in minutes before timing out read of an incoming request and closing idle connections.
    # `0` means there is no timeout for reading the request.
    read_timeout = 0
</code></pre>
<p>Generic OAuth 部分</p>
<pre><code class="language-#ini"> #################################### Generic OAuth #######################
    [auth.generic_oauth]
    name = OAuth
    enabled = true
    allow_sign_up = true
    client_id = Grafana
    client_secret = ad35e16d-96d1-46ab-88d8-7cdb1512b608
    scopes = openid profile email
    email_attribute_name = email:primary
    email_attribute_path =
    login_attribute_path =
    name_attribute_path =
    role_attribute_path =
    id_token_attribute_name =
    auth_url = http://192.168.64.57:30708/auth/realms/devops/protocol/openid-connect/auth
    token_url = http://192.168.64.57:30708/auth/realms/devops/protocol/openid-connect/token
    api_url = http://192.168.64.57:30708/auth/realms/devops/protocol/openid-connect/userinfo
    allowed_domains =
    team_ids =
    allowed_organizations =
    tls_skip_verify_insecure = false
    tls_client_cert =
    tls_client_key =
    tls_client_ca =
</code></pre>
<h3 id="loginoauthloginstate-mismatch">login.OAuthLogin(state mismatch)</h3>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/image-20231226000413815.png" alt="image-20231226000413815" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：登录后错误</center>
<p>这个错误是没有配置对应user的状态或者没有配置email导致，如果配置了 email，那么吧用户放置到对应组中就恢复了</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/image-20231226000619866.png" alt="image-20231226000619866" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：用户与组</center>
<h3 id="配置权限">配置权限</h3>
<p>如果使用了 <em>role</em> 作为权限分配，那么按照官方的配置即可，如果使用 <em>group</em>，则需要使用下面的规则</p>
<pre><code class="language-ini">role_attribute_path = contains(groups[], 'admin') &amp;&amp; 'Admin' || contains(groups[], 'editer') &amp;&amp; 'Editor' || contains(groups[*], 'viewer') &amp;&amp; 'Viewer' 
</code></pre>
<p>这个表达式是一个条件表达式，用于根据用户所属的组分配角色属性值。下面是对每个字符和子表达式的翻译解释：</p>
<ul>
<li><em>role_attribute_path</em> : 角色属性路径，表示根据条件表达式的结果来确定角色属性值。</li>
<li><code>contains(groups[*], 'admin')</code>: 检查用户所属的组列表中是否包含 <em>admin</em> 组。</li>
<li><em>&amp;&amp;</em>: 逻辑与运算符，用于组合多个条件，表示两个条件都为真时整个表达式为真。</li>
<li>Admin:  如果 <code>contains(groups[*], 'admin')</code> 为真，将角色属性设置为 <em>Admin</em>。</li>
<li><code>||</code>: 逻辑或运算符，用于组合多个条件，表示任意一个条件为真时整个表达式为真。</li>
<li><code>contains(groups[*], 'editer')</code>: 检查用户所属的组列表中是否包含 <em>editer</em> 组。</li>
<li><code>'Editor'</code>: 如果 <code>contains(groups[*], 'editer')</code> 为真，将角色属性设置为 <em>Editor</em>。</li>
<li><code>contains(groups[*], 'viewer')</code>: 检查用户所属的组列表中是否包含 <em>viewer</em> 组。</li>
<li><code>'Viewer'</code>: 如果 <code>contains(groups[*], 'viewer')</code> 为真，将角色属性设置为 <em>Viewer</em>。</li>
</ul>
<h2 id="reference">Reference</h2>
<p><sup id="1">[1]</sup> <a href="https://github.com/cetic/helm-fadi/issues/39" target="_blank"
   rel="noopener nofollow noreferrer" >keycloak redirect_uri is always localhost:3000 #39</a></p>
<p><sup id="2">[2]</sup> <a href="https://github.com/cetic/helm-fadi/commit/aff8f55a98c1b125a6933abc8a5801a70628d628#diff-e03be4b117ea0d0d183a8c866fe1d63dfd164e3addc99d1d7b025f7e750755d4" target="_blank"
   rel="noopener nofollow noreferrer" >templates/keycloak.yaml</a></p>
<p><sup id="3">[3]</sup> <a href="https://grafana.com/docs/grafana/latest/setup-grafana/configure-security/configure-authentication/keycloak/" target="_blank"
   rel="noopener nofollow noreferrer" >Configure Keycloak OAuth2 authentication</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>记录kubernetes node label的面板实施</title>
      <link>https://www.oomkill.com/2023/08/kubernetes-node-label-dashboard/</link>
      <pubDate>Sat, 19 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2023/08/kubernetes-node-label-dashboard/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="背景">背景</h2>
<p>目前的 Kubernetes 集群资源面板是基于集群的使用资源，因为是多集群，业务同时运行字啊不同集群上，如果通过 label 来划分业务使用的资源情况，这个才是真的和每个集群的每个业务使用的资源有关。</p>
<p>对于这种场景的划分，Kubernetes 中有一个专门的名词是 Pod 的拓扑域；基于这些需要做的事情就如下步骤</p>
<ul>
<li>首先确定node label可以搜集到，如果不存在需要收集</li>
<li>当收集到node label 时，需要根据对应的 label 将一个域中的</li>
<li>根据域（label）做变量注入到 对应的查询语句中以生成图表</li>
</ul>
<h2 id="收集-node-label">收集 node label</h2>
<p>在使用 <strong>kube-prometheus-stack</strong> 中收集 kubernetes 的 node label 需要手动启动参数  <code>- --metric-labels-allowlist=nodes=[*]</code> 才可以收集到 node label，手动给Node 打上标签，test 拓扑域 为 aaaa bbbb两个</p>
<pre><code class="language-bash">$ kubectl get node --show-labels
NAME             STATUS   ROLES    AGE   VERSION    LABELS
node01   Ready    &lt;none&gt;   13d   v1.16.10   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node01,kubernetes.io/os=linux,test=bbbb
node01   Ready    &lt;none&gt;   13d   v1.16.10   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node01,kubernetes.io/os=linux,test=aaaa
</code></pre>
<p>开启后，会在 kube_node_labels 收取到 node 的 label，其他 node label 没什么用，使用 relabeing 删除掉</p>
<pre><code class="language-yaml">regex: label_(beta_kubernetes_io_arch|beta_kubernetes_io_os|kubernetes_io_arch|kubernetes_io_os|kubernetes_io_hostname)
action: labeldrop
</code></pre>
<h2 id="使用标签分组">使用标签分组</h2>
<p>因为标签 只存在于 kube_node_label 指标中，需要利用这个指标对每种类型 Pod 分组，首先找到指标的相同标签，可以看到每个 Pod 都会存在一个 node=&ldquo;xxxxxxx&rdquo; 这与 kube_node_labels 上的相符合。</p>
<pre><code class="language-bash">kube_pod_container_resource_requests{container=&quot;alertmanager&quot;, endpoint=&quot;http&quot;, instance=&quot;10.0.130.150:8080&quot;, job=&quot;kube-state-metrics&quot;, namespace=&quot;default&quot;, node=&quot;node003&quot;, pod=&quot;alertmanager-kube-prometheus-stack-alertmanager-0&quot;, resource=&quot;memory&quot;, service=&quot;kube-prometheus-stack-kube-state-metrics&quot;, uid=&quot;12787588-b05e-466a-9f1a-661a05e8b634&quot;, unit=&quot;byte&quot;}

kube_node_labels{container=&quot;kube-state-metrics&quot;, endpoint=&quot;http&quot;, instance=&quot;10.0.130.150:8080&quot;, job=&quot;kube-state-metrics&quot;, label_test=&quot;aaaa&quot;, namespace=&quot;default&quot;, node=&quot;node195&quot;, pod=&quot;kube-prometheus-stack-kube-state-metrics-7fb89968cb-jrrdp&quot;, service=&quot;kube-prometheus-stack-kube-state-metrics&quot;}
</code></pre>
<p>然后使用 promQL 的 join 表达式，对应决定拓扑域的 label 注入到每个 Pod 的标签中</p>
<pre><code class="language-bash">kube_pod_info{node=xxx} 
  * on(node) group_left(test) kube_node_labels{test=&quot;aaa&quot;}
</code></pre>
<p>上面的表达式中，选择了 kube_pod_info 指标，并且使用 node=xxx 进行过滤。然后使用 on(node) 语句指定在 node 标签上进行 join 操作，同时使用 <code>group_left(test)</code> 告诉 Prometheus 把 kube_node_labels 中的 test 标签添加到左侧的指标（即 kube_pod_info）中。</p>
<p>通过这种方式，我们就可以把 kube_node_labels 中的 test=aaa 标签附加到所有 kube_pod_info 上，且它们都是在相同的节点中。具体效果如下图</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/image-2024109141236234.png" alt="image-2024109141236234" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图1：node label指标</center>
<h2 id="grafana-使用-label-做变量">grafana 使用 label 做变量</h2>
<p>有了决定拓扑域的标签，还需要吧这个 label 作为 grafana 的变量</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/image-202410914631411.png" alt="image-202410914631411" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图2：grafana变量配置</center>
<p>这个里可以用  promql 的 by 进行分组</p>
<pre><code class="language-bash">count(kube_pod_info{}
  * on(node) group_left(label_test) kube_node_labels{}) by (label_test)
</code></pre>
<p>如图1所示，这时就知道每个拓扑域中的 Pod 使用了多少资源，以及可以是用 聚合函数 算出每个拓扑域总资源等信息</p>
<p>基于 kube_node_labels 作为变量进行输出面板</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/image-2024109141263453.png" alt="image-2024109141263453" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图3：grafana定义变量</center>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/image-202410914645123.png" alt="image-202410914645123" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图4：promql</center>
]]></content:encoded>
    </item>
    
    <item>
      <title>在 Kubernetes 集群中使用 blackbox exporter监控外部IP</title>
      <link>https://www.oomkill.com/2023/07/blackbox_exporter-in-k8s/</link>
      <pubDate>Wed, 12 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2023/07/blackbox_exporter-in-k8s/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="背景">背景</h2>
<p>在云原生环境中，特别是基于 Kubernetes，集群中的 “服务” 在与外部交互时，例如，一个外部的第三方 Web 服务/API 等，而监控这些不同的 endpoint 诊断服务可用性的一个关键点，这里将阐述基于 Kube-prometheus-stacks 如果做到可以监控外部 IP/URL，例如，HTTP/TCP/ICMP 等。</p>
<p>blackbox_exporter 是 Prometheus 官方维护的 exporter之一，是提供一种用于检测 HTTP/S、DNS、TCP 和 ICMP 端点的可用性。</p>
<h2 id="基于-kube-prometheus-stack-安装-blackbox">基于 kube-prometheus-stack 安装 blackbox</h2>
<p>本文使用了 helm 安装的 <a href="https://github.com/prometheus-community/helm-charts/tree/main/charts/prometheus-blackbox-exporter" target="_blank"
   rel="noopener nofollow noreferrer" >prometheus-community/prometheus-blackbox-exporter </a>，在安装前，需要自行修改要启动的 prober，与是否开启默认的 <em>servicemonitor</em></p>
<pre><code class="language-yaml">secretConfig: false
config:
  modules:
    ping:
      prober: icmp
      timeout: 5s
      icmp:
        preferred_ip_protocol: &quot;ip4&quot;
    http_2xx:
      prober: http
      timeout: 5s
      http:
        valid_http_versions: [&quot;HTTP/1.1&quot;, &quot;HTTP/2.0&quot;]
        follow_redirects: true
        preferred_ip_protocol: &quot;ip4&quot;
</code></pre>
<p>安装</p>
<pre><code class="language-bash">helm install prometheus-blackbox-exporter -n monitoring . -f values.yaml
</code></pre>
<h2 id="配置-servicemonitor">配置 servicemonitor</h2>
<p>blackbox-exporter 实现了多种探针，因此可以传递多个 endpoint 进行探测，下列是 <code>ServiceMonitor</code> 实现的检测外部IP/URL，使用了 icmp 探针，也就是说是在 blackbox-exporter 中配置的模块，探针通过抓取 Kubernetes service 下挂的 endpoint，通过访问 blackbox service 的 <code>/probe</code> 抓取暴露的指标 metrics</p>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: blackbox-exporter-probe
spec:
  endpoints:
  - interval: 1m
    path: /probe
    scrapeTimeout: 10s
    params:
      module: [tcp_prober]
    relabelings:
    - sourceLabels: [__address__]
      targetLabel: __param_target
    - targetLabel: __address__
      replacement:  black-prometheus-blackbox-exporter:9115 # is the name:port of the blackbox exporter service
    - sourceLabels: [__param_target]
      targetLabel: instance
    - action: labelmap
      regex: __meta_kubernetes_service_label_(.+) # specify to monitor kubernets services
  jobLabel: blackbox-exporter
  selector:
    matchLabels:
      app.kubernetes.io/action: probe # monitor the services only with this label
</code></pre>
<p>这个 ServiceMonitor 会通过标签匹配对应的 Kubernets service，标签为  <code>app.kubernetes.io/action: probe</code>所有 namespace 中的存在 这个 Label 的 service。  如果有需要，可以通过指定抓取的 namespace，使用<code>namespaceSelector</code></p>
<h3 id="创建一个外部-service">创建一个外部 service</h3>
<p>这里使用了 Kubernetes 外部 service 方式将外部IP引入到内部</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/action: probe
  name: icmp-prober
spec:
  clusterIP: None
  ports:
  - name: db
    protocol: TCP
    port: 9100
    targetPort: 9100
---
apiVersion: v1
kind: Endpoints
metadata:
  labels:
    app.kubernetes.io/action: probe
  name: rahasak # name is same as service name
subsets:
- addresses:
  - ip: 10.0.0.4
  - ip: 10.0.0.5
  ports:
  - name: db
    protocol: TCP
    port: 9100
</code></pre>
<h3 id="创建-servicemonitor">创建 servicemonitor</h3>
<p>创建一个 ServiceMonitor 来探测每个 endpoint，使用了 icmp 探针来抓取 带有标签 <code>app.kubernetes.io/action: probe</code> 的Kubernets service</p>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: blackbox-exporter
spec:
  endpoints:
  - interval: 1m
    path: /probe
    scrapeTimeout: 10s
    params:
      module: [ping]
    relabelings:
    - sourceLabels: [__address__]
      targetLabel: __param_target
    - targetLabel: __address__
    # blackbox_service_name.namespace:port
      replacement:  prometheus-blackbox-prometheus-blackbox-exporter:9115
    - sourceLabels: [__param_target]
      targetLabel: instance
    - action: labelmap
      regex: __meta_kubernetes_endpoints_label_(.+) # specify to monitor kubernetes endpoints 
  jobLabel: blackbox-exporter
  selector:
    matchLabels:
      app.kubernetes.io/action: probe # monitor endpoints only with the given label
</code></pre>
<h2 id="notes">Notes</h2>
<p>blackbox_exporter 如果想要使用 icmp 探针，必须拥有 root 权限，直接修改 <code>runAsGroup: 0</code> 即可</p>
<p>对于 直接使用 servicemonitor 中的 endpoint 只能识别出一个 IP，原因是，balckbox 暴漏的指标需要带参数访问，下列格式</p>
<pre><code class="language-bash">&quot;http://10.104.202.8:9115/probe?module=ping&amp;target=10.0.0.5&quot;
</code></pre>
<p>而传入多个 target 没有用，只会返回第一个 target 的指标，所以说会出现多个 endpoint 只会出现一个，同样的问题，如果 service 设置为 ClusterIP，也会只有一个指标，必须 <code>type: None</code> 才可以，这就是只有多个 endpoint 才会在拉去指标时请求多个 balckbox exporter 的 API</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20230713005706664.png" alt="image-20230713005706664" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: blackbox-probe-tcp
  namespace: default 
  labels:
    release: kube-prometheus-stacks
spec:
  endpoints:
  - port: http
    path: /probe
    interval: 5s
    scrapeTimeout: 5s
    params:
      module:
      - ping
      target:
      - 10.0.0.4
      - 10.0.0.5
    relabelings:
    - action: replace
      regex: (.*)
      replacement: $1
      sourceLabels:
      - __meta_kubernetes_service_label_cluster
      targetLabel: cluster
    - action: replace
      regex: (.*)
      replacement: $1
      sourceLabels:
      - __param_module
      targetLabel: module
    - action: labelmap
      regex: (.*)
      replacement: $1
      sourceLabels: [__param_target]
      targetLabel: __address__
  selector:
    matchLabels:
      app.kubernetes.io/instance: prometheus-blackbox
</code></pre>
<p>目前暂未找到有效的解决方法，但是在清单配置多个 endpoint 就出现多条 serivcemonitor 记录，持续更进该问题，可能可以通过 <code>additionalScrapeConfigs</code> 可以解决该问题</p>
<h2 id="reference">Reference</h2>
<blockquote>
<p><sup id="1">[1]</sup> <a href="https://medium.com/@lambdaEranga/monitor-kubernets-services-endpoints-with-prometheus-blackbox-exporter-a64e062c05d5" target="_blank"
   rel="noopener nofollow noreferrer" >Monitor Kubernets Services/Endpoints with Prometheus Blackbox Exporter</a></p>
<p><sup id="2">[2] </sup><a href="https://www.voidking.com/dev-prometheus-operator-blackbox-exporter/" target="_blank"
   rel="noopener nofollow noreferrer" >Prometheus Operator + Blackbox exporter</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>使用Thanos强化Prometheus</title>
      <link>https://www.oomkill.com/2023/07/using-thanos-improve-prometheus.md/</link>
      <pubDate>Sun, 02 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2023/07/using-thanos-improve-prometheus.md/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="背景">背景</h2>
<p>Prometheus 是目前云原生架构中监控解决方案中的基石，而对于 “metrics”，“traces” 和 “logs” 是组成云原生架构中“可观测性”的一个基础，当在扩展 Prometheus，那么 Prometheus 提供的基础架构是无法满足需求的（高可用性和可扩展性）， 而高可用性与可扩展性是满足不断增长基础设施的一个基本条件。而 Prometheus 本身并没有提供“弹性”的集群配置，也就是说，多个副本的 Prometheus 实例，对于分布在每个 Pod 上的数据也会不一致，这时也需要保证指标的归档问题。</p>
<p>并且在一定的集群规模下，问题的出现远远大于 Prometheus 本身的能力，例如：</p>
<ul>
<li>如何经济且搞笑的存储历史数据（TB, PB）？如何快速的查询历史数据？</li>
<li>如何合并 Promehtues 多个实例收集来的副本数据？</li>
<li>以及多集群间的监控？</li>
<li>由于 TSDB 的块同步，Prometheus 严重依赖内存，使得 Prometheus 监控项的扩展将导致集群中的CPU/MEM 的使用加大</li>
<li>..</li>
</ul>
<h2 id="解决">解决</h2>
<p>Thanos 是一款可以使 Prometheus 获得 ”长期存储“，并具体有”高可用性“ 的 Prometheus 的功能扩展，“Thanos” 源自希腊语“ Athanasios”，英文意思是”不朽“。这也正是 ”Thanos“ 提供的功能：”无限制的对象存储“，并与原生 Prometheus API 高度兼容，你可以理解为 Thanos API 就是 Prometheus API。</p>
<p>Cortexmetrics 与 Thanos 类似，是用通过将 Prometheus 实例的”存储“和”查询“等功能分离到独立的组件中，实现水平扩展。它使用对象存储来持久化历史指标，块存储（TSDB）是他的存储后端；此外，Cortex 还提供了多租户与多租户隔离等功能</p>
<p>联邦集群，联邦集群是 Prometheus 官方提供的一个概念，使用了联邦将允许 Prometheus 从另一个 Prometheus 中抓取选定的指标。可以使用的一些模型如下：</p>
<ul>
<li>分层联邦：大规模的集群中，Prometheus 部署模型如一个”树形“，高级别的从多个低级实例中抓取指标，并存储聚合</li>
<li>跨服务联邦：Prometheus 从另一个 Prometheus 只抓取指定的数据</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/t3.png" alt="prometheus 联邦" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Prometheus 联邦</center>
<center><em>Source：</em>https://www.improbable.io/blog/thanos-prometheus-at-scale</center><br>
<p>但在这种架构中，仍然还是每个查询只能针对单个 Prometheus 服务器完成。另外 Thanos 可以查询与聚合来自多个 Prometheus 实例的数据，这些数据就类似与联邦中的 ”叶“，这些数据的来源可以单实例也可以是多实例。</p>
<p>在这种架构中，本质上并不是 ”高可用性“ 的，实际上存在潜在故障点，并且数据的查询是通过唯一入口（API）进行查询，并且需要配置复杂的抓取规则才可以使规则不重复。</p>
<h2 id="thanos-架构">Thanos 架构</h2>
<p>Thanos 遵循了 KISS (<em><strong>Keep it simple</strong></em>) 原则，thanos 由多个组件组成，每个组件负责不同的功能，</p>
<p>在与 Prometheus 交互方向，Thanos 使用下列两种方式（组件）：</p>
<ul>
<li>
<p>Sidecar：</p>
<ul>
<li>连接到 Prometheus，读取数据或者将数据上传到对象存储中</li>
<li>也可以部署为传统架构，这里不能完全理解为是 Kubernetes 中的 Sidecar</li>
</ul>
</li>
<li>
<p>Receiver：从 Prometheus 接收数据，暴露或上传到云端</p>
</li>
</ul>
<p>扩展 Prometheus 的功能：</p>
<ul>
<li>
<p>Store/Store Gateway：提供存储在对象存储中的历史数据的查询功能，历史 Chunk 会存储在对象存储中</p>
<ul>
<li>支持基于 “时间/标签” 的分区</li>
</ul>
</li>
<li>
<p>Compactor：对于存储在对象存储中的数据进行压缩，通过将其合并为更大的快，以便提高查询效率</p>
</li>
<li>
<p>Ruler/Rule：类似与 Alertmanager 的功能，他提供了告警功能</p>
</li>
<li>
<p>Querier/Query：实现了 Prometheus API，他可以从 Sidecar 与 对象存储中查询全局查询</p>
</li>
<li>
<p>Query Frontend：实现了 Prometheus API 并将请求代理至 Query 组件；并且支持缓存功能（Redis/Memcached），缓存其查询结果</p>
</li>
</ul>
<blockquote>
<p>Thanos 不是一种 “节省指标存储” 的方案，而是一种提供更大时间间隔，更高可用性的的查询方案，使用Thanos 不会减少磁盘空间，反而会增加磁盘空间。</p>
</blockquote>
<p>通常 Thanos 会按照维度划分为三个级别：raw, 5m, 1h，这是根据时间划分，raw 是从 Prometheus 拿到的原始数据; 5m 压缩为5分钟的快；1h 压缩为 1h的块  <sup><a href="#1">[1]</a></sup> 。不过这些没有在官方找到，引用的其他文章</p>
<h3 id="指标的查询过程">指标的查询过程</h3>
<ol>
<li>PromQL 查询请求到组件 <code>Querier</code></li>
<li>它解释查询并进入预过滤器</li>
<li>查询根据标签和时间范围要求 扇出 (fan-out) 其对 <code>stores</code> 或 <code>prometheuses</code> 的请求
<ol>
<li>store 决定 是否从s3中拉去数据</li>
<li>query 会缓存数据到内存中</li>
</ol>
</li>
<li>Query 发送和接收请求</li>
<li>收集所有响应后，如果启用合并功能，会合并并删除重复数据</li>
<li>最后返回该时间序列</li>
</ol>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/life_of_a_query.png" alt="查询的生命周期" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Thanos查询生命周期</center>
<center><em>Source：</em>https://banzaicloud.com/blog/multi-cluster-monitoring/</center><br>
<h3 id="基于时间的分片">基于时间的分片</h3>
<p>默认 Thanos 的 Store gateway 会查询对象中的所有存储，根据查询时间返回数据，这显然不行，如果此时有大量数据（基于PB级别），此时可以根据时间分片（水平扩展），Store API 可以使用 最大时间 和 最小时间 来缩短查询的时间，</p>
<h3 id="基于标签的分片">基于标签的分片</h3>
<p>基于标签的分片与基于时间的分片类似，这里是使用<code>labels</code>，而 Label 是采集与 Prometheus 的外部 Label ，并基于 Thanos 组件显式重新标记，要记住，Thanos 就是 Prometheus 扩展，功能用法与 Prometheus 是相同的的，例如下列 Thanos relabeling 的操作</p>
<pre><code class="language-yaml">- action: keep
  regex: &quot;eu.*&quot;
  source_labels:
  - region
</code></pre>
<p>这些表示了只保留了以 <code>eu.*</code> 开头的 region label</p>
<h3 id="重复副本的删除">重复副本的删除</h3>
<p>Thanos 对于 Prometheus 的 HA，也就是采集多个 Prometheus 实例的指标，此时 每个实例会产生相同的指标，这种模式来实现的“高可用性”，那么这种架构产生的重复副本就需要 Thanos 来处理了，例如如下所示：<code>up{job=&quot;prometheus&quot;,env=&quot;2&quot;}</code> 的指标， 通过重复数据删除，结果是：</p>
<pre><code>up{job=&quot;prometheus&quot;,env=&quot;2&quot;,cluster=&quot;1&quot;} 1
up{job=&quot;prometheus&quot;,env=&quot;2&quot;,cluster=&quot;2&quot;} 1
</code></pre>
<p>那么如果不删除重复标签，可能结果就很多，是用过 replica 标签来区分副本数量</p>
<pre><code>up{job=&quot;prometheus&quot;,env=&quot;2&quot;,cluster=&quot;1&quot;,replica=&quot;A&quot;} 1
up{job=&quot;prometheus&quot;,env=&quot;2&quot;,cluster=&quot;1&quot;,replica=&quot;B&quot;} 1
up{job=&quot;prometheus&quot;,env=&quot;2&quot;,cluster=&quot;2&quot;,replica=&quot;A&quot;} 1
up{job=&quot;prometheus&quot;,env=&quot;2&quot;,cluster=&quot;2&quot;,replica=&quot;B&quot;} 1
</code></pre>
<h3 id="全局视图查询">全局视图查询</h3>
<p>如图所示，query 是一种无状态的可水平扩展的 Querier 组件，他提供了基于 Prometheus API ，可以相应基于 PromQL 的查询，而中间数据的相应是由 Store 或者</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/t5.jpg" alt="sidecar" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Thanos query组件</center>
<center><em>Source：</em>https://banzaicloud.com/blog/multi-cluster-monitoring/</center><br>
<h2 id="高基数">高基数</h2>
<p>基数 (<em><strong>cardinality</strong></em>) 通俗来说是一个集合中的元素数量 <sup><a href="#1">[1]</a></sup> 基数的来源通常为：</p>
<ul>
<li>label 的数量</li>
<li>series(指标) 的数量</li>
<li>时间：label 或者 series 随时间而流失或增加，通常是增加</li>
</ul>
<p>那么这么看来高基数就是，label, series, 时间这三个集合的笛卡尔积，那么高基数的情况就很正常了。</p>
<p>而高基数带来的则是 Prometheus 资源使用，以及监控的性能。下图是 Grafana Lab 提到的一张图，很好的阐述了高基数这个问题</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/cardinality-spikes-diagram.jpg" alt="image-20220704002227865" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Prometheus中的基数</center>
<center><em>Source：</em>https://grafana.com/blog/2022/02/15/what-are-cardinality-spikes-and-why-do-they-matter</center><br>
<p>如图所示：一个指标 <em>server_responses</em> 他的 label 存在两个 <code>status_code</code> 与 <code>environment</code> ，这代表了一个集合，那他的 label value 是 1~5xx，这个指标的笛卡尔积就是10。</p>
<p>那么此时存在一个问题，如何能定位 基数高不高，Grafana Lab 给出了下面的数据 <sup><a href="#1">[1]</a></sup>，但是我不清楚具体的来源或者如何得到的这些值。也就是 <code>label:value</code></p>
<ul>
<li>低基数：1: 5</li>
<li>标准基数：1: 80</li>
<li>高基数：1: 10000</li>
</ul>
<h3 id="为什么指标会指数级增长">为什么指标会指数级增长</h3>
<p>在以 Kubernetes 为基础的架构中，随着抽象级别的提高（通常为Pod, Label, 以及更多抽象的拓扑），指标的时间序列也越来越多。因为在这种基础架构中，在传统架构中运行的一个应用的单个裸机，被许多运行分散在许多不同节点上的许多不同微服务的 Pod 所取代。在这些抽象层中的每一个都需要一个标签，以便可以唯一地标识它们，并且这些组件中的每一个都会生成自己的指标，从而创建其独特的时间序列集。</p>
<p>此外，在 Kubernetes 中的工作负载的短暂性最终也会创建更多的时间序列。例如 JAVA的 <code>http_request_duration_seconds_bucket</code> 指标，它会每次 pod 更改状态时生成一个新的时间序列，比如从“状态200&quot; 或者 “状态 404” 在到 “每个URL” 再到 “每个请求的时间”，这样大量短时间请求，对一个 Pod 状态可能会生成大量指标。</p>
<p>这是就要考虑到 Prometheus 兼容的格式，而非传统监控的监控指标的格式问题，就例如上面的例子，通过对 URI，请求时长，请求状态码几个维度去监控，那么此时的 exporter 导出的数据势必是非常杂乱的，而这种可能相同的指标就会放大到无穷。</p>
<p>在这种环境中的 Label，就是两组集合的笛卡尔积的选择，就是次优标签 <code>sub-optimal labels</code> ，对付这类高基数的指标，控制基数，以及如何避免使用这类错误，就是解决高基数的根本。</p>
<h3 id="高基数是一个非常重要的问题">高基数是一个非常重要的问题</h3>
<p>高基数的问题，带来的就是基于 Prometheus 的监控带来的是更多的可观测性，反之，随着时间序列的基数增加，那么为了维持某几个特别的指标的观测性，就必须要付出更多的硬件资源，以及影响本身监控系统的性能。比较明显的表现，就是监控的相应下降，极大的拖慢了整个系统的运行速度（包含仪表盘，promQL等）。还会延长系统故障排除时的MTTR (<em>Mean Time to Repair</em>)。</p>
<blockquote>
<p>Notes: 其实这里还有一类型错误，就是这会导致时间序列的乱序，怎么说呢，就是当指标无线放大时，在某一个点 scrap 的指标存储时间，大于了抓取周期，导致新指标存储早于旧指标，这种很容易出现在例如 Prometheus 的从内存到存储的那个点。</p>
</blockquote>
<h3 id="如何控制控制指标的高基数增长">如何控制控制指标的高基数增长</h3>
<p>指标的无序扩张（高基数）是不可避免对监控系统产生非常大的影响（存储和性能），而为此引出了一个如何优化不断增长的指标就是控制高基数增长的关键部分，下面将从几个维度来阐释控制“高基数”问题的步骤</p>
<h4 id="第一步高基数指标是否有价值">第一步：高基数指标是否有价值？</h4>
<p>在任何优化方法的第一步都是去了解哪些指标给系统带来负面影响（这里指高基数），并且还需要确定这些指标中哪些指标是有价值的；所谓的有价值既，在仪表板、告警中是否有被使用。</p>
<p>基于这些信息，我将根据基数问题与监控指标的价值分为四个象限：</p>
<ul>
<li>高价值，低成本：闲置、陈旧、很长时间没有新数据的</li>
<li>低价值，低成本：基本上没有什么影响，但是需要去考虑优化</li>
<li>低价值，高成本：可以考虑删除掉 Label 和 metric</li>
<li>高价值，高成本：你的指标是否过细化，是否需要重新设计 Label 或者聚合数据；或这类指标是否适合使用 Prometheus 这类时间序列</li>
</ul>
<h4 id="第二步如何确定高基数指标">第二步：如何确定高基数指标</h4>
<p>确定高基数指标包含3种方式</p>
<ul>
<li>Prometheus WEB UI 分析，2.14 版本之后</li>
<li>PromQL 分析</li>
<li>Prometheus API 分析</li>
</ul>
<p>通常情况下，WEB UI 就可以满足需求了，通过路径 Prometheus UI -&gt; Status -&gt; TSDB Status -&gt; Head Cardinality Stats。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20230617175638751.png" alt="image-20230617175638751" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Prometheus WEB UI TOP 10 series</center>
<p>由上图可见，在这里体现的高基数问题的指标，通常都是以 <em>bucket</em> 结尾的指标，而这些指标通常包含2个维度，会无线拉长成为高基数指标。如下面指标所示，通常由 le （标识每个 bucket 的上限，这可以确保可以定位到在一个时间范围内相应的请求指标有哪些）</p>
<pre><code>apiserver_request_duration_seconds_bucket{component=&quot;apiserver&quot;, endpoint=&quot;https&quot;, group=&quot;admissionregistration.k8s.io&quot;, instance=&quot;10.0.0.4:6443&quot;, job=&quot;apiserver&quot;, le=&quot;+Inf&quot;, namespace=&quot;default&quot;, resource=&quot;mutatingwebhookconfigurations&quot;, scope=&quot;cluster&quot;, service=&quot;kubernetes&quot;, verb=&quot;DELETE&quot;, version=&quot;v1&quot;}	19

apiserver_request_duration_seconds_bucket{component=&quot;apiserver&quot;, endpoint=&quot;https&quot;, group=&quot;admissionregistration.k8s.io&quot;, instance=&quot;10.0.0.4:6443&quot;, job=&quot;apiserver&quot;, le=&quot;0.05&quot;, namespace=&quot;default&quot;, resource=&quot;mutatingwebhookconfigurations&quot;, scope=&quot;cluster&quot;, service=&quot;kubernetes&quot;, verb=&quot;POST&quot;, version=&quot;v1&quot;}

apiserver_request_duration_seconds_bucket{component=&quot;apiserver&quot;, endpoint=&quot;https&quot;, group=&quot;admissionregistration.k8s.io&quot;, instance=&quot;10.0.0.4:6443&quot;, job=&quot;apiserver&quot;, le=&quot;0.25&quot;, namespace=&quot;default&quot;, resource=&quot;mutatingwebhookconfigurations&quot;, scope=&quot;cluster&quot;, service=&quot;kubernetes&quot;, verb=&quot;PATCH&quot;, version=&quot;v1&quot;}
</code></pre>
<p>例如下面是生产环境中的一个高基数TOP10</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>http_server_requests_seconds_bucket</td>
<td>2017537</td>
</tr>
<tr>
<td>lettuce_command_firstreponse_seconds_bucket</td>
<td>755056</td>
</tr>
<tr>
<td>lettuce_command_completion_seconds_bucket</td>
<td>755056</td>
</tr>
<tr>
<td>http_server_requests_seconds</td>
<td>555575</td>
</tr>
<tr>
<td>nginx_ingress_controller_request_duration_seconds_bucket</td>
<td>475440</td>
</tr>
<tr>
<td>node_ipvs_backend_connections_inactive</td>
<td>148796</td>
</tr>
<tr>
<td>node_ipvs_backend_connections_active</td>
<td>148796</td>
</tr>
<tr>
<td>apiserver_request_duration_seconds_bucket</td>
<td>27896</td>
</tr>
<tr>
<td>etcd_request_duration_seconds_bucket1</td>
<td>22763</td>
</tr>
</tbody>
</table>
<p>至此可以看到实际上 <code>http_server_requests_seconds_bucket</code> 这一个指标占据了 prometheus 总指标的50%+</p>
<p>而其他的一些分析，可以很有效的定位到你需要优化的标签</p>
<ul>
<li>Top 10 label names with high memory usage</li>
<li>Top 10 series count by label value pairs</li>
</ul>
<h4 id="通过-promql-定位-job">通过 promQL 定位 job</h4>
<ul>
<li>查询 top 10 的 series <code>topk(10, count by (__name__)({__name__=~&quot;.+&quot;}))</code></li>
<li><code>sum(scrape_series_added) by (job)</code> 通过 job Label 分析 series 增长</li>
<li><code>sum(scrape_samples_scraped) by (job)</code>  通过 job Label 分析 series 总量</li>
</ul>
<p>可以通过指标属于哪个 job</p>
<h4 id="第三步发现那些指标没有在使用">第三步：发现那些指标没有在使用</h4>
<p>Grafana Mimirtool 是一个开源的命令行工具， 它可以识别 Mimir、Prometheus 或 Prometheus 的存储中未在Dashboard、Alert 或 recording 中使用的指标。通过 Mimirtool 可以快速发现未使用的指标，并且做出操作</p>
<h2 id="优化监控指标">优化监控指标</h2>
<p>优化监控指标来解决高基数问题主要从以下维度进行</p>
<h3 id="增加采集间隔"><strong>增加采集间隔</strong></h3>
<p>Prometheus 的默认值为 <code>scrape_interval: 15s</code>，或 DPM (<em>Data points  Per minute</em>) 4个，但是如果查询语句为 <code>scrape_samples_scraped[1m]</code> 那么可以考虑将这个 job 的 <code>scrape_interval</code> 增加为1m，这样15~60 可以减少近75%的存储成本。</p>
<pre><code class="language-bash">kube-state-metrics:
  namespaceOverride: &quot;&quot;
  rbac:
    create: true
  releaseLabel: true
  prometheus:
    monitor:
      enabled: true

      ## Scrape interval. If not set, the Prometheus default scrape interval is used.
      ##
      interval: &quot;&quot;
</code></pre>
<h2 id="优化-histogram">优化 histogram</h2>
<p>histrogram 是 Prometheus中一种更具有更复杂类型的监控指标，通常用于决定数据的精度，典型的例子就是上面提到的 <code>http_server_requests_seconds_bucket</code> 中的 <code>le</code> ，此时假设 le 代表请求毫秒，那么我们只需要决定你所需要的精度是哪些？例如，如果仅仅需要 1ms, 5ms, 10ms，那么指标 le 标签就控制为3，这样结合 URI 指标，那么这个 histogram 是有限的</p>
<pre><code class="language-yaml"># drop all metric series ending with _bucket and where le=&quot;0.1xxx&quot;
- source_labels: [__name__, le]
  separator: _
  regex: &quot;.+_bucket_(0.1+)&quot;
  action: &quot;drop&quot;
  
# Object labels:
__name__: http_server_requests_seconds_bucket
le: 0.114421
</code></pre>
<p>这里可以通过 <a href="https://relabeler.promlabs.com/" target="_blank"
   rel="noopener nofollow noreferrer" >promlabs</a> 来测试你的规则是否是成功的 <sup><a href="#2">[2]</a></sup></p>
<h3 id="删除不需要的标签">删除不需要的标签</h3>
<p>对于一些指标，删除了未使用的标签后，反而会使这个指标变得没有意义，并且使这个指标变得序列重复，这个时候可以完整删除这个指标</p>
<p>例如在下面的示例中，第一个示例可以安全地删除 ip 标签，因为其余系列都是唯一的。但在第二个示例中，如果删除 ip 标签将产生重复的时间序列，Prometheus 将删除这些时间序列。<code>my_metric_total</code>在此示例中，Prometheus 将接收具有相同时间戳的值 1、3 和 7，并将丢弃其中的 2 个数据点。</p>
<pre><code># You can drop ip label, remaining series are still unique
my_metric_total{env=“dev”, ip=“1.1.1.1&quot;} 12
my_metric_total{env=“tst”, ip=“1.1.1.1&quot;} 14
my_metric_total{env=“prd”, ip=“1.1.1.1&quot;} 18

#Remaining values after dropping ip label
my_metric_total{env=“dev”} 12
my_metric_total{env=“tst”} 14
my_metric_total{env=“prd”} 18

# You can not drop ip label, remaining series are not unique
my_metric_total{env=“dev”, ip=“1.1.1.1&quot;} 1
my_metric_total{env=“dev”, ip=“3.3.3.3&quot;} 3
my_metric_total{env=“dev”, ip=“5.5.5.5&quot;} 7

#Remaining values after dropping ip label are not unique
my_metric_total{env=“dev”} 1
my_metric_total{env=“dev”} 3
my_metric_total{env=“dev”} 7
</code></pre>
<p>如果无法控制删除标签将导致重复序列，通过 Prometheus  sum、avg、min、max等函数可以保留聚合数据，同时删除单个系列。在下面的示例中，我们使用 sum 函数来存储聚合指标，从而允许我们删除单个时间序列。</p>
<pre><code># sum by env
my_metric_total{env=&quot;dev&quot;, ip=&quot;1.1.1.1&quot;} 1
my_metric_total{env=&quot;dev&quot;, ip=&quot;3.3.3.3&quot;} 3
my_metric_total{env=&quot;dev&quot;, ip=&quot;5.5.5.5&quot;} 7

# Recording rule
sum by(env) (my_metric_total{})

my_metric_total{env=&quot;dev&quot;} 11
</code></pre>
<h3 id="使用聚合组">使用聚合组</h3>
<p>例如对于 <code>*_seconds_bucket</code> 类的指标, 通常需要的是一些高纬度的指标，那么这些指标可以通过 <code>recording rules</code> 进行记录和存储</p>
<pre><code class="language-yaml">groups:
  - interval: 3m
    name: kube-apiserver-availability.rules
    rules:
      - expr: &gt;-
          avg_over_time(code_verb:apiserver_request_total:increase1h[30d]) *
          24 * 30
        record: code_verb:apiserver_request_total:increase30d
      - expr: &gt;-
          sum by (cluster, code, verb)
          (increase(apiserver_request_total{job=&quot;apiserver&quot;,verb=~&quot;LIST|GET|POST|PUT|PATCH|DELETE&quot;,code=~&quot;2..&quot;}[1h]))
        record: code_verb:apiserver_request_total:increase1h
      - expr: &gt;-
          sum by (cluster, code, verb)
          (increase(apiserver_request_total{job=&quot;apiserver&quot;,verb=~&quot;LIST|GET|POST|PUT|PATCH|DELETE&quot;,code=~&quot;5..&quot;}[1h]))
        record: code_verb:apiserver_request_total:increase1h
</code></pre>
<p>最后 drop 掉指标</p>
<pre><code class="language-yaml">write_relabel_configs:
  - source_labels: [__name__]
    regex: &quot;apiserver_request_duration_seconds_bucket&quot;
    action: drop
</code></pre>
<p><code>recording rules</code> 是允许预先将经常计算的表达式的结果保存为一组新的时间序列的，这种情况下查询的成本会比每次直接查询原始的表达式要快许多，并且在聚合后，可以将原来的指标删掉</p>
<h2 id="reference">Reference</h2>
<blockquote>
<p><sup id="1">[1]</sup> <a href="https://banzaicloud.com/blog/multi-cluster-monitoring/" target="_blank"
   rel="noopener nofollow noreferrer" >Multi cluster monitoring with Thanos</a></p>
<p><sup id="2">[2]</sup> <a href="https://grafana.com/blog/2022/10/20/how-to-manage-high-cardinality-metrics-in-prometheus-and-kubernetes/" target="_blank"
   rel="noopener nofollow noreferrer" >How to manage high cardinality metrics in Prometheus and Kubernetes</a></p>
<p><sup id="3">[3]</sup> <a href="https://www.xiaowu95.wang/posts/bfccfc4" target="_blank"
   rel="noopener nofollow noreferrer" >精简Prometheus指标减少资源占用</a></p>
<p><sup id="4">[4]</sup> <a href="https://grafana.com/blog/2022/02/15/what-are-cardinality-spikes-and-why-do-they-matter/" target="_blank"
   rel="noopener nofollow noreferrer" >What are cardinality spikes and why do they matter?</a></p>
<p><sup id="5">[5]</sup> <a href="https://promcon.io/2019-munich/slides/containing-your-cardinality.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >Containing your Cardinality</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>我在Prometheus监控中高基数问题中的优化之路</title>
      <link>https://www.oomkill.com/2023/06/impove-prometheus-performance/</link>
      <pubDate>Wed, 14 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2023/06/impove-prometheus-performance/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="背景">背景</h2>
<p>对于整个 Kubernetes 集群来说，随着业务不断地打磨，新增指标，那么对于 Prometheus 特性来说，那么内存 与 存储的使用势必是增加。这是对于存储压力是很重的，通常情况下，使用 Prometheus，都会是用于 Kubernetes 集群中，而 应用于 Kubernetes 集中的存储势必是 PVC 之类的网络存储。</p>
<p>这种场景中，我将尝试拆解如何分析和配置 Prometheus 以显著的减少其资源使用并解决高基数问题</p>
<h2 id="高基数">高基数</h2>
<p>基数 (<em><strong>cardinality</strong></em>) 通俗来说是一个集合中的元素数量 <sup><a href="#1">[1]</a></sup> 基数的来源通常为：</p>
<ul>
<li>label 的数量</li>
<li>series(指标) 的数量</li>
<li>时间：label 或者 series 随时间而流失或增加，通常是增加</li>
</ul>
<p>那么这么看来高基数就是，label, series, 时间这三个集合的笛卡尔积，那么高基数的情况就很正常了。</p>
<p>而高基数带来的则是 Prometheus 资源使用，以及监控的性能。下图是 Grafana Lab 提到的一张图，很好的阐述了高基数这个问题</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/cardinality-spikes-diagram.jpg" alt="image-20220704002227865" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Prometheus中的基数</center>
<center><em>Source：</em>https://grafana.com/blog/2022/02/15/what-are-cardinality-spikes-and-why-do-they-matter</center><br>
<p>如图所示：一个指标 <em>server_responses</em> 他的 label 存在两个 <code>status_code</code> 与 <code>environment</code> ，这代表了一个集合，那他的 label value 是 1~5xx，这个指标的笛卡尔积就是10。</p>
<p>那么此时存在一个问题，如何能定位 基数高不高，Grafana Lab 给出了下面的数据 <sup><a href="#1">[1]</a></sup>，但是我不清楚具体的来源或者如何得到的这些值。也就是 <code>label:value</code></p>
<ul>
<li>低基数：1: 5</li>
<li>标准基数：1: 80</li>
<li>高基数：1: 10000</li>
</ul>
<h3 id="为什么指标会指数级增长">为什么指标会指数级增长</h3>
<p>在以 Kubernetes 为基础的架构中，随着抽象级别的提高（通常为Pod, Label, 以及更多抽象的拓扑），指标的时间序列也越来越多。因为在这种基础架构中，在传统架构中运行的一个应用的单个裸机，被许多运行分散在许多不同节点上的许多不同微服务的 Pod 所取代。在这些抽象层中的每一个都需要一个标签，以便可以唯一地标识它们，并且这些组件中的每一个都会生成自己的指标，从而创建其独特的时间序列集。</p>
<p>此外，在 Kubernetes 中的工作负载的短暂性最终也会创建更多的时间序列。例如 JAVA的 <code>http_request_duration_seconds_bucket</code> 指标，它会每次 pod 更改状态时生成一个新的时间序列，比如从“状态200&quot; 或者 “状态 404” 在到 “每个URL” 再到 “每个请求的时间”，这样大量短时间请求，对一个 Pod 状态可能会生成大量指标。</p>
<p>这是就要考虑到 Prometheus 兼容的格式，而非传统监控的监控指标的格式问题，就例如上面的例子，通过对 URI，请求时长，请求状态码几个维度去监控，那么此时的 exporter 导出的数据势必是非常杂乱的，而这种可能相同的指标就会放大到无穷。</p>
<p>在这种环境中的 Label，就是两组集合的笛卡尔积的选择，就是次优标签 <code>sub-optimal labels</code> ，对付这类高基数的指标，控制基数，以及如何避免使用这类错误，就是解决高基数的根本。</p>
<h3 id="高基数是一个非常重要的问题">高基数是一个非常重要的问题</h3>
<p>高基数的问题，带来的就是基于 Prometheus 的监控带来的是更多的可观测性，反之，随着时间序列的基数增加，那么为了维持某几个特别的指标的观测性，就必须要付出更多的硬件资源，以及影响本身监控系统的性能。比较明显的表现，就是监控的相应下降，极大的拖慢了整个系统的运行速度（包含仪表盘，promQL等）。还会延长系统故障排除时的MTTR (<em>Mean Time to Repair</em>)。</p>
<blockquote>
<p>Notes: 其实这里还有一类型错误，就是这会导致时间序列的乱序，怎么说呢，就是当指标无线放大时，在某一个点 scrap 的指标存储时间，大于了抓取周期，导致新指标存储早于旧指标，这种很容易出现在例如 Prometheus 的从内存到存储的那个点。</p>
</blockquote>
<h3 id="如何控制控制指标的高基数增长">如何控制控制指标的高基数增长</h3>
<p>指标的无序扩张（高基数）是不可避免对监控系统产生非常大的影响（存储和性能），而为此引出了一个如何优化不断增长的指标就是控制高基数增长的关键部分，下面将从几个维度来阐释控制“高基数”问题的步骤</p>
<h4 id="第一步高基数指标是否有价值">第一步：高基数指标是否有价值？</h4>
<p>在任何优化方法的第一步都是去了解哪些指标给系统带来负面影响（这里指高基数），并且还需要确定这些指标中哪些指标是有价值的；所谓的有价值既，在仪表板、告警中是否有被使用。</p>
<p>基于这些信息，我将根据基数问题与监控指标的价值分为四个象限：</p>
<ul>
<li>高价值，低成本：闲置、陈旧、很长时间没有新数据的</li>
<li>低价值，低成本：基本上没有什么影响，但是需要去考虑优化</li>
<li>低价值，高成本：可以考虑删除掉 Label 和 metric</li>
<li>高价值，高成本：你的指标是否过细化，是否需要重新设计 Label 或者聚合数据；或这类指标是否适合使用 Prometheus 这类时间序列</li>
</ul>
<h4 id="第二步如何确定高基数指标">第二步：如何确定高基数指标</h4>
<p>确定高基数指标包含3种方式</p>
<ul>
<li>Prometheus WEB UI 分析，2.14 版本之后</li>
<li>PromQL 分析</li>
<li>Prometheus API 分析</li>
</ul>
<p>通常情况下，WEB UI 就可以满足需求了，通过路径 Prometheus UI -&gt; Status -&gt; TSDB Status -&gt; Head Cardinality Stats。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20230617175638751.png" alt="image-20230617175638751" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Prometheus WEB UI TOP 10 series</center>
<p>查看上图可见，http_server_requests_seconds_bucket 的信息，就这个 bucket 指标占总指标的 25% 左右，在加上其他的  几个 bucket，10个基本上占用了60%；在这里体现的高基数问题的指标，通常都是以 <em>bucket</em> 结尾的指标，而这些指标通常包含2个维度，会无线拉长成为高基数指标。如下面指标所示，通常由 le （标识每个 bucket 的上限，这可以确保可以定位到在一个时间范围内相应的请求指标有哪些）</p>
<pre><code>http_server_requests_seconds_bucket{application=&quot;map-common-api&quot;,exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/api/v1/map&quot;,le=&quot;+Inf&quot;,} 71.0
http_server_requests_seconds_bucket{application=&quot;map-common-api&quot;,exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/api/v1/maplist&quot;,le=&quot;0.001&quot;,} 0.0
http_server_requests_seconds_bucket{application=&quot;map-common-api&quot;,exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/api/v1/maplist&quot;,le=&quot;0.001048576&quot;,} 0.0
http_server_requests_seconds_bucket{application=&quot;map-common-api&quot;,exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/api/v1/maplist&quot;,le=&quot;0.001398101&quot;,} 0.0
http_server_requests_seconds_bucket{application=&quot;map-common-api&quot;,exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/api/v1/maplist&quot;,le=&quot;0.001747626&quot;,} 0.0
http_server_requests_seconds_bucket{application=&quot;map-common-api&quot;,exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/api/v1/maplist&quot;,le=&quot;0.002097151&quot;,} 0.0
http_server_requests_seconds_bucket{application=&quot;map-common-api&quot;,exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/api/v1/maplist&quot;,le=&quot;0.002446676&quot;,} 0.0
http_server_requests_seconds_bucket{application=&quot;map-common-api&quot;,exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/api/v1/maplist&quot;,le=&quot;0.002796201&quot;,} 0.0
http_server_requests_seconds_bucket{application=&quot;map-common-api&quot;,exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/api/v1/maplist&quot;,le=&quot;0.003145726&quot;,} 0.0
http_server_requests_seconds_bucket{application=&quot;map-common-api&quot;,exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/api/v1/maplist&quot;,le=&quot;0.003495251&quot;,} 0.0
http_server_requests_seconds_bucket{application=&quot;map-common-api&quot;,exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/api/v1/maplist&quot;,le=&quot;0.003844776&quot;,} 0.0
http_server_requests_seconds_bucket{application=&quot;map-common-api&quot;,exception=&quot;None&quot;,method=&quot;POST&quot;,outcome=&quot;SUCCESS&quot;,status=&quot;200&quot;,uri=&quot;/api/v1/maplist&quot;,le=&quot;0.004194304&quot;,} 0.0
</code></pre>
<p>例如下面是生产环境中的一个高基数TOP10</p>
<p>DC01 Top 10 series count by metric names</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>http_server_requests_seconds_bucket</td>
<td>1282158</td>
</tr>
<tr>
<td>lettuce_command_completion_seconds_bucket</td>
<td>782680</td>
</tr>
<tr>
<td>lettuce_command_firstresponse_seconds_bucket</td>
<td>782680</td>
</tr>
<tr>
<td>nginx_ingress_controller_response_size_bucket</td>
<td>99840</td>
</tr>
<tr>
<td>nginx_ingress_controller_request_duration_seconds_bucket</td>
<td>99840</td>
</tr>
<tr>
<td>http_server_requests_seconds</td>
<td>92695</td>
</tr>
<tr>
<td>nginx_ingress_controller_request_size_bucket</td>
<td>91520</td>
</tr>
<tr>
<td>nginx_ingress_controller_response_duration_seconds_bucket</td>
<td>74580</td>
</tr>
<tr>
<td>nginx_ingress_controller_bytes_sent_bucket</td>
<td>66560</td>
</tr>
<tr>
<td>node_ipvs_backend_weight</td>
<td>51173</td>
</tr>
</tbody>
</table>
<p>DC02 Top 10 series count by metric names</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>http_server_requests_seconds_bucket</td>
<td>1073571</td>
</tr>
<tr>
<td>lettuce_command_firstresponse_seconds_bucket</td>
<td>755650</td>
</tr>
<tr>
<td>lettuce_command_completion_seconds_bucket</td>
<td>755650</td>
</tr>
<tr>
<td>http_server_requests_seconds</td>
<td>77775</td>
</tr>
<tr>
<td>nginx_ingress_controller_request_duration_seconds_bucket</td>
<td>67440</td>
</tr>
<tr>
<td>nginx_ingress_controller_response_size_bucket</td>
<td>67440</td>
</tr>
<tr>
<td>nginx_ingress_controller_request_size_bucket</td>
<td>61820</td>
</tr>
<tr>
<td>nginx_ingress_controller_response_duration_seconds_bucket</td>
<td>53052</td>
</tr>
<tr>
<td>node_ipvs_backend_connections_inactive</td>
<td>48796</td>
</tr>
<tr>
<td>node_ipvs_backend_connections_active</td>
<td>48796</td>
</tr>
</tbody>
</table>
<p>至此可以看到实际上 <code>http_server_requests_seconds_bucket</code> 这一个指标占据了 prometheus 总指标的50%+；这种指标就会存在多个维度的扩张，URI, outcome, status,uri,le；假设我们有 100个 接口，</p>
<ul>
<li>在什么都不做的情况下，就多出了100个 series</li>
<li>如果状态码是存在变数的，假设为5，此时series 为500</li>
<li>在基于 outcome 的数量，此时一个指标的基数已经为1000</li>
<li>那么 le 将无限放大这个 metric 到 无穷</li>
</ul>
<p>这样就可以定位，影响到 prometheus 存储于性能最大点在哪里，那么此时就需要考虑 le=&ldquo;0.001048576&rdquo; 和 le=&ldquo;0.001&rdquo;  有什么区别，以及此类的指标是否有必要存在？</p>
<ul>
<li>基于我们现有的监控报表来看</li>
<li>结合业务日志将访问信息的监控从 Prometheus 提到 ELK 这种日志层面监控</li>
<li>再通过 将 kube-apiserver 的 bucket 以及负载均衡在线/不在线Pod 这两个 指标清空，基本上可以满足70%左右的监控项删减 通常会删掉 le 这个标签，而不是 http_server_requests_seconds_bucket 的数据，但是也需要考虑，<code>http_server_requests_seconds_bucket</code> 指标是否有用到，如果没有用到， 又是高基数，那么可以删除</li>
</ul>
<p>而其他的一些分析，可以很有效的定位到你需要优化的标签</p>
<ul>
<li>Top 10 label names with high memory usage</li>
<li>Top 10 series count by label value pairs</li>
</ul>
<h4 id="通过-promql-定位-job">通过 promQL 定位 job</h4>
<ul>
<li>查询 top 10 的 series <code>topk(10, count by (__name__)({__name__=~&quot;.+&quot;}))</code></li>
<li><code>sum(scrape_series_added) by (job)</code> 通过 job Label 分析 series 增长</li>
<li><code>sum(scrape_samples_scraped) by (job)</code>  通过 job Label 分析 series 总量</li>
</ul>
<p>可以通过指标属于哪个 job</p>
<h4 id="第三步发现那些指标没有在使用">第三步：发现那些指标没有在使用</h4>
<p>Grafana Mimirtool 是一个开源的命令行工具， 它可以识别 Mimir、Prometheus 或 Prometheus 的存储中未在Dashboard、Alert 或 recording 中使用的指标。通过 Mimirtool 可以快速发现未使用的指标，并且做出操作</p>
<h2 id="优化监控指标">优化监控指标</h2>
<p>优化监控指标来解决高基数问题主要从以下维度进行</p>
<h3 id="增加采集间隔"><strong>增加采集间隔</strong></h3>
<p>Prometheus 的默认值为 <code>scrape_interval: 15s</code>，或 DPM (<em>Data points  Per minute</em>) 4个，但是如果查询语句为 <code>scrape_samples_scraped[1m]</code> 那么可以考虑将这个 job 的 <code>scrape_interval</code> 增加为1m，这样15~60 可以减少近75%的存储成本。</p>
<pre><code class="language-bash">kube-state-metrics:
  namespaceOverride: &quot;&quot;
  rbac:
    create: true
  releaseLabel: true
  prometheus:
    monitor:
      enabled: true

      ## Scrape interval. If not set, the Prometheus default scrape interval is used.
      ##
      interval: &quot;&quot;
</code></pre>
<h2 id="优化-histogram">优化 histogram</h2>
<p>histrogram 是 Prometheus中一种更具有更复杂类型的监控指标，通常用于决定数据的精度，典型的例子就是上面提到的 <code>http_server_requests_seconds_bucket</code> 中的 <code>le</code> ，此时假设 le 代表请求毫秒，那么我们只需要决定你所需要的精度是哪些？例如，如果仅仅需要 1ms, 5ms, 10ms，那么指标 le 标签就控制为3，这样结合 URI 指标，那么这个 histogram 是有限的</p>
<pre><code class="language-yaml"># drop all metric series ending with _bucket and where le=&quot;0.1xxx&quot;
- source_labels: [__name__, le]
  separator: _
  regex: &quot;.+_bucket_(0.1+)&quot;
  action: &quot;drop&quot;
  
# Object labels:
__name__: http_server_requests_seconds_bucket
le: 0.114421
</code></pre>
<p>这里可以通过 <a href="https://relabeler.promlabs.com/" target="_blank"
   rel="noopener nofollow noreferrer" >promlabs</a> 来测试你的规则是否是成功的 <sup><a href="#2">[2]</a></sup></p>
<h3 id="删除不需要的标签">删除不需要的标签</h3>
<p>对于一些指标，删除了未使用的标签后，反而会使这个指标变得没有意义，并且使这个指标变得序列重复，这个时候可以完整删除这个指标</p>
<p>例如在下面的示例中，第一个示例可以安全地删除 ip 标签，因为其余系列都是唯一的。但在第二个示例中，如果删除 ip 标签将产生重复的时间序列，Prometheus 将删除这些时间序列。<code>my_metric_total</code>在此示例中，Prometheus 将接收具有相同时间戳的值 1、3 和 7，并将丢弃其中的 2 个数据点。</p>
<pre><code># You can drop ip label, remaining series are still unique
my_metric_total{env=“dev”, ip=“1.1.1.1&quot;} 12
my_metric_total{env=“tst”, ip=“1.1.1.1&quot;} 14
my_metric_total{env=“prd”, ip=“1.1.1.1&quot;} 18

#Remaining values after dropping ip label
my_metric_total{env=“dev”} 12
my_metric_total{env=“tst”} 14
my_metric_total{env=“prd”} 18

# You can not drop ip label, remaining series are not unique
my_metric_total{env=“dev”, ip=“1.1.1.1&quot;} 1
my_metric_total{env=“dev”, ip=“3.3.3.3&quot;} 3
my_metric_total{env=“dev”, ip=“5.5.5.5&quot;} 7

#Remaining values after dropping ip label are not unique
my_metric_total{env=“dev”} 1
my_metric_total{env=“dev”} 3
my_metric_total{env=“dev”} 7
</code></pre>
<p>如果无法控制删除标签将导致重复序列，通过 Prometheus  sum、avg、min、max等函数可以保留聚合数据，同时删除单个系列。在下面的示例中，我们使用 sum 函数来存储聚合指标，从而允许我们删除单个时间序列。</p>
<pre><code># sum by env
my_metric_total{env=&quot;dev&quot;, ip=&quot;1.1.1.1&quot;} 1
my_metric_total{env=&quot;dev&quot;, ip=&quot;3.3.3.3&quot;} 3
my_metric_total{env=&quot;dev&quot;, ip=&quot;5.5.5.5&quot;} 7

# Recording rule
sum by(env) (my_metric_total{})

my_metric_total{env=&quot;dev&quot;} 11
</code></pre>
<h3 id="使用聚合组">使用聚合组</h3>
<p>例如对于 <code>*_seconds_bucket</code> 类的指标, 通常需要的是一些高纬度的指标，那么这些指标可以通过 <code>recording rules</code> 进行记录和存储</p>
<pre><code class="language-yaml">groups:
  - interval: 3m
    name: kube-apiserver-availability.rules
    rules:
      - expr: &gt;-
          avg_over_time(code_verb:apiserver_request_total:increase1h[30d]) *
          24 * 30
        record: code_verb:apiserver_request_total:increase30d
      - expr: &gt;-
          sum by (cluster, code, verb)
          (increase(apiserver_request_total{job=&quot;apiserver&quot;,verb=~&quot;LIST|GET|POST|PUT|PATCH|DELETE&quot;,code=~&quot;2..&quot;}[1h]))
        record: code_verb:apiserver_request_total:increase1h
      - expr: &gt;-
          sum by (cluster, code, verb)
          (increase(apiserver_request_total{job=&quot;apiserver&quot;,verb=~&quot;LIST|GET|POST|PUT|PATCH|DELETE&quot;,code=~&quot;5..&quot;}[1h]))
        record: code_verb:apiserver_request_total:increase1h
</code></pre>
<p>最后 drop 掉指标</p>
<pre><code class="language-yaml">write_relabel_configs:
  - source_labels: [__name__]
    regex: &quot;apiserver_request_duration_seconds_bucket&quot;
    action: drop
</code></pre>
<p><code>recording rules</code> 是允许预先将经常计算的表达式的结果保存为一组新的时间序列的，这种情况下查询的成本会比每次直接查询原始的表达式要快许多，并且在聚合后，可以将原来的指标删掉</p>
<p>优化后每个块的大小</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/image-20240915210841954.png" alt="image-20240915210841954" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>优化后的每个块的大小</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/cylonchau/imgbed/img/image-20240915210918296.png" alt="image-20240915210918296" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h2 id="reference">Reference</h2>
<p><sup id="1">[1]</sup> <a href="https://grafana.com/blog/2022/02/15/what-are-cardinality-spikes-and-why-do-they-matter/" target="_blank"
   rel="noopener nofollow noreferrer" >What are cardinality spikes and why do they matter?</a></p>
<p><sup id="2">[2]</sup> <a href="https://grafana.com/blog/2022/10/20/how-to-manage-high-cardinality-metrics-in-prometheus-and-kubernetes/" target="_blank"
   rel="noopener nofollow noreferrer" >How to manage high cardinality metrics in Prometheus and Kubernetes</a></p>
<p><sup id="3">[3]</sup> <a href="https://www.xiaowu95.wang/posts/bfccfc4" target="_blank"
   rel="noopener nofollow noreferrer" >精简Prometheus指标减少资源占用</a></p>
<p><sup id="4">[4]</sup> <a href="https://grafana.com/blog/2022/02/15/what-are-cardinality-spikes-and-why-do-they-matter/" target="_blank"
   rel="noopener nofollow noreferrer" >What are cardinality spikes and why do they matter?</a></p>
<p><sup id="5">[5]</sup> <a href="https://promcon.io/2019-munich/slides/containing-your-cardinality.pdf" target="_blank"
   rel="noopener nofollow noreferrer" >Containing your Cardinality</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>prometheus operator使用</title>
      <link>https://www.oomkill.com/2020/11/prometheus-operator/</link>
      <pubDate>Mon, 02 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2020/11/prometheus-operator/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="什么是-operator">什么是 Operator？</h2>
<p><code>Operator</code>是由<code>CoreOS</code>公司开发的，用来扩展<code>kubernetes APi</code>的特定的应用程序控制器，<code>Operator</code>基于Kubernetes的资源和控制器概念之上构建，但同时又包含了对相应应用程序特定的一些专业知识。创建<code>operator</code>的关键是 <code>CRD（CustomResourceDefinition）</code>的设计。</p>
<h3 id="prometheus-operator">Prometheus Operator</h3>
<p><code>Prometheus Operator</code> 是CoreOS公司提供的基于Prometheus及其相关监视组件对Kubernetes集群组件的管理，该Operator目的是简化和自动化针对Kubernetes集群的基于Prometheus的管理及配置。</p>
<h3 id="prometheus-operator架构组件">Prometheus Operator架构组件</h3>
<ul>
<li><strong>Operator</strong>：作为Prometheus Operator的核心组件，也即是自定义的控制器，用来监视和部署管理Prometheus Operator CRD资源对象，监控并维持CRD资源状态。</li>
<li><strong>Prometheus Server</strong>：Operator 根据自定义资源 Prometheus 类型中定义的内容而部署的Prometheus Cluster</li>
<li><strong>Prometheus Operator CRD</strong>：
<ul>
<li><code>Prometheus</code>：以CRD资源提供给Operator的类似于Pod资源清单定位的资源。</li>
<li><code>ServiceMonitor</code>：声明定义对Kubernetes Services资源进行监控，使用标签选择器来选择所需配置的监控，后端是Service的Endpoint，通过Service标签选择器获取EndPoint对象。</li>
<li><code>PodMonitor</code>：使用标签选择器，选择对匹配Pod进行监控</li>
<li><code>Alertmanager</code>：声明定义了Alertmanager在Kubernetes中运行所提供的配置。</li>
<li><code>PrometheusRule</code>: 声明定义了Prometheus在Kubernetes中运行所需的Rule配置。</li>
</ul>
</li>
</ul>
<p>reference</p>
<p><a href="https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/design.md" target="_blank"
   rel="noopener nofollow noreferrer" >Prometheus-Operator-design</a></p>
<h2 id="prometheus-operator监控二进制kubernetes">Prometheus Operator监控二进制kubernetes</h2>
<p>查看<a href="https://github.com/prometheus-operator/kube-prometheus#kubernetes-compatibility-matrix" target="_blank"
   rel="noopener nofollow noreferrer" >兼容性列表</a>选择对应的版本来下载，此处kubernetes集群为1.8.10 。</p>
<p>对应地址为 <code>https://github.com/prometheus-operator/kube-prometheus.git</code> ，可以在域名后添加<code>.cnpmjs.org</code> 访问中国的github加速。</p>
<pre><code class="language-bash">git clone https://github.com.cnpmjs.org/prometheus-operator/kube-prometheus.git
</code></pre>
<p>资源清单在项目目录 <code>manifests</code> CRD在 <code>manifests/setup</code> <strong>需要先安装CRD 和 Operator 对象</strong></p>
<h4 id="kube-controller-manager-和-kube-scheduler-无监控数据">kube-controller-manager 和 kube-scheduler 无监控数据</h4>
<p>二进制部署的Kubernetes集群中部署Prometheus Operator，会发现在<code>prometheus server</code>的页面上发现<code>kube-controller</code>和<code>kube-schedule</code>的target为0/0。匹配不到节点信息，这是因为<code>serviceMonitor</code>是根据<code>label</code>去选取<code>svc</code>的。此处svc并没有<code>kube-controller</code>和<code>kube-schedule</code> 需要手动创建。</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  namespace: kube-system
  name: kube-controller-manager
  labels:
    k8s-app: kube-controller-manager
    component: kube-controller-manager
spec:
  selector:
    k8s-app: kube-controller-manager
    component: kube-controller-manager
  ports:
    - name: https-metrics
      port: 10252
      targetPort: 10252
---
apiVersion: v1
kind: Endpoints
metadata:
  namespace: kube-system
  name: kube-controller-manager
  labels:
    k8s-app: kube-controller-manager
    component: kube-controller-manager
subsets:
- addresses:
  - ip: &quot;10.0.0.5&quot;
    nodeName: &quot;master01&quot;
  ports:
  - port: 10252
    name: https-metrics
---
apiVersion: v1
kind: Service
metadata:
  namespace: kube-system
  name: kube-scheduler
  labels:
    k8s-app: kube-scheduler
    component: kube-scheduler
spec:
  selector:
    k8s-app: kube-scheduler
    component: kube-scheduler
  ports:
    - name: https-metrics
      port: 10251
      targetPort: 10251
---
apiVersion: v1
kind: Endpoints
metadata:
  namespace: kube-system
  name: kube-scheduler
  labels:
    k8s-app: kube-scheduler
    component: kube-scheduler
subsets:
  - addresses:
    - ip: &quot;10.0.0.5&quot;
      nodeName: &quot;master01&quot;
    ports:
    - port: 10251
      name: https-metrics
</code></pre>
<p>此处需要注意的是：需要修改对应的Prometheus Operator资源清单的值一直才能获取到目标</p>
<p><code>Service.spec.ports.name</code>要和<code>ServiceMonitor.spec.endpoints.port</code>的名称对应。</p>
<p><code>Service.metadata.namespace</code>要和<code>ServiceMonitor.namespaceSelector.matchNames</code>对应</p>
<p><code>Service.metadata.labels</code>的key要和<code>ServiceMonitor.JobLabel</code>对应</p>
<p><code>Service.metadata.labels</code> 要和 <code>ServiceMonitor.selector.matchLabels</code>对应</p>
<h2 id="监控第三方的服务及自定义servicemonitor">监控第三方的服务及自定义servicemonitor</h2>
<h3 id="一查看-etcd-信息">一、查看 Etcd 信息</h3>
<p>这里的etcd采用二进制方法安装，可以直接访问 <code>host:2379/metrics</code> 获得。</p>
<h3 id="二将证书存入-kubernetes">二、将证书存入 Kubernetes</h3>
<p>创建secret</p>
<pre><code>kubectl create secret generic hketcd \
--from-file='/etc/etcd/pki/client.crt' \
--from-file='/etc/etcd/pki/client.key' \
--from-file='/etc/etcd/pki/ca.crt' \
-n monitoring
</code></pre>
<h3 id="三将证书挂入-prometheusserver">三、将证书挂入 PrometheusServer</h3>
<p>方法1： <code>kubectl edit prometheus k8s -n monitoring</code></p>
<p>方法2：修改 <code>prometheus-prometheus.yaml</code> 文件</p>
<p>增加内容：</p>
<pre><code class="language-yaml">  replicas: 2
  secrets:
    - hketcd
</code></pre>
<p>挂入后的证书保存在目录 <code>/etc/prometheus/secrets/{secret_name}/</code> 下。</p>
<h3 id="四创建-etcd-service--endpoints">四、创建 Etcd Service &amp; Endpoints</h3>
<pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  namespace: kube-system
  name: etcdmaster
  labels:
    k8s-app: etcd
    component: etcd
spec:
  selector:
    k8s-app: etcd
    component: etcd
  type: ClusterIP
  clusterIP: None # 设置为None，不分配Service IP
  ports:
    - name: https-metrics
      port: 2379
---
apiVersion: v1
kind: Endpoints
metadata:
  namespace: kube-system
  name: etcdmaster
  labels:
    k8s-app: etcd
    component: etcd
subsets:
  - addresses:
      - ip: &quot;10.0.0.5&quot;
        nodeName: &quot;master01&quot;
    ports:
      - port: 2379
        name: https-metrics
---
</code></pre>
<h3 id="五创建-servicemonitor">五、创建 ServiceMonitor</h3>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: etcd
  namespace: monitoring
  labels:
    k8s-app: etcd
spec:
  jobLabel: k8s-app # 匹配工作的标签，这里是servicemonitor即 为service的标签
  endpoints: # 此ServiceMonitor的节点
    - port: https-metrics # k8s service endports的设置的端口的名称
      interval: 30s
      scheme: https
      tlsConfig:
        serverName: hketcd # 访问etcd的名称，因为证书原因需要认证访问的名称
        caFile: &quot;/etc/prometheus/secrets/hketcd/ca.crt&quot; # 这个是在prometheus容器内挂载的证书
        certFile: &quot;/etc/prometheus/secrets/hketcd/client.crt&quot;
        keyFile: &quot;/etc/prometheus/secrets/hketcd/client.key&quot;
        insecureSkipVerify: true
  selector: # 选择匹配到的endpoints
    matchLabels:
      k8s-app: etcd
      component: etcd
    # 与matchExpressions: #进行后端的匹配
  namespaceSelector: # 选择所在资源的名称控件
    matchNames:
      - kube-system
</code></pre>
]]></content:encoded>
    </item>
    
    <item>
      <title>telegram接收altermanager消息</title>
      <link>https://www.oomkill.com/2019/09/telegram-bot-send-post-json/</link>
      <pubDate>Mon, 02 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2019/09/telegram-bot-send-post-json/</guid>
      <description></description>
      <content:encoded><![CDATA[<pre><code>curl -XPOST https://api.telegram.org/bot977657989:AAF0QE88WhxRIdpFLOYO_9ldLun5VtpfCWw/getUpdates

curl -X POST \
     -H 'Content-Type: application/json' \
     -d '{&quot;chat_id&quot;: &quot;850233746&quot;, &quot;text&quot;: &quot;This is a test from curl&quot;, &quot;disable_notification&quot;: true}' \
     https://api.telegram.org/bot$TELEGRAM_BOT_TOKEN/sendMessage
     
curl -X POST \
     -H 'Content-Type: application/json' \
     -d '{&quot;chat_id&quot;: &quot;850233746&quot;, &quot;text&quot;: &quot;This is a test from curl&quot;, &quot;disable_notification&quot;: true}' \
     https://api.telegram.org/bot1009139816:AAGTmFsJDkH9H3E0OVoFi4GyvYp0uMctvcE/sendMessage
</code></pre>
<p><a href="https://api.telegram.org/bot721202655:AAG_kN1IHP93Wmnd90RRaJC-dK9tKQHddRA/sendMessage" target="_blank"
   rel="noopener nofollow noreferrer" >https://api.telegram.org/bot721202655:AAG_kN1IHP93Wmnd90RRaJC-dK9tKQHddRA/sendMessage</a></p>
<pre><code class="language-json">{
	&quot;chat_id&quot;: &quot;-383641009&quot;,
	&quot;text&quot;: &quot;This is a test from curl&quot;, 
	&quot;disable_notification&quot;: true
}
</code></pre>
<p>alertmanager发送的消息类型如下：</p>
<pre><code class="language-json">{
	&quot;receiver&quot;: &quot;webhook&quot;,
	&quot;status&quot;: &quot;firing&quot;,
	&quot;alerts&quot;: [{
		&quot;status&quot;: &quot;firing&quot;,
		&quot;labels&quot;: {
			&quot;alertname&quot;: &quot;InstanceDown&quot;,
			&quot;instance&quot;: &quot;192.168.8.32:9110&quot;,
			&quot;job&quot;: &quot;node&quot;,
			&quot;role&quot;: &quot;api&quot;,
			&quot;service&quot;: &quot;node&quot;
		},
		&quot;annotations&quot;: {
			&quot;description&quot;: &quot;192.168.8.32:9110: job node has been down vlaue==0&quot;,
			&quot;summary&quot;: &quot;192.168.8.32:9110: has been down&quot;
		},
		&quot;startsAt&quot;: &quot;2019-07-25T21:55:13.352482605+08:00&quot;,
		&quot;endsAt&quot;: &quot;0001-01-01T00:00:00Z&quot;,
		&quot;generatorURL&quot;: &quot;http://zy-tw-tianxia-prod-prometheus01:19090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=1&quot;
	}, {
		&quot;status&quot;: &quot;firing&quot;,
		&quot;labels&quot;: {
			&quot;alertname&quot;: &quot;InstanceDown&quot;,
			&quot;instance&quot;: &quot;192.168.8.34:9110&quot;,
			&quot;job&quot;: &quot;node&quot;,
			&quot;role&quot;: &quot;api&quot;,
			&quot;service&quot;: &quot;node&quot;
		},
		&quot;annotations&quot;: {
			&quot;description&quot;: &quot;192.168.8.34:9110: job node has been down vlaue==0&quot;,
			&quot;summary&quot;: &quot;192.168.8.34:9110: has been down&quot;
		},
		&quot;startsAt&quot;: &quot;2019-07-25T21:53:13.352482605+08:00&quot;,
		&quot;endsAt&quot;: &quot;0001-01-01T00:00:00Z&quot;,
		&quot;generatorURL&quot;: &quot;http://zy-tw-tianxia-prod-prometheus01:19090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=1&quot;
	}],
	&quot;groupLabels&quot;: {
		&quot;alertname&quot;: &quot;InstanceDown&quot;
	},
	&quot;commonLabels&quot;: {
		&quot;alertname&quot;: &quot;InstanceDown&quot;,
		&quot;job&quot;: &quot;node&quot;,
		&quot;role&quot;: &quot;api&quot;,
		&quot;service&quot;: &quot;node&quot;
	},
	&quot;commonAnnotations&quot;: {},
	&quot;externalURL&quot;: &quot;http://zy-tw-tianxia-prod-prometheus01:9093&quot;,
	&quot;version&quot;: &quot;4&quot;,
	&quot;groupKey&quot;: &quot;{}:{alertname=\&quot;InstanceDown\&quot;}&quot;
}
</code></pre>
<p><a href="https://www.qikqiak.com/post/prometheus-operator-custom-alert/" target="_blank"
   rel="noopener nofollow noreferrer" >https://www.qikqiak.com/post/prometheus-operator-custom-alert/</a></p>
<h3 id="telegram在文本消息中插入换行符">telegram在文本消息中插入换行符</h3>
<p>尝试&rsquo;％0D&rsquo;或&rsquo;％0A&rsquo;  参考地址：https://stackoverrun.com/cn/q/8787508</p>
<p>telegram api 使用</p>
<p><a href="https://stackoverrun.com/cn/q/8787508" target="_blank"
   rel="noopener nofollow noreferrer" >https://stackoverrun.com/cn/q/8787508</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>prometheus golang_client开发Exporter</title>
      <link>https://www.oomkill.com/2019/06/prometheus-golang_client/</link>
      <pubDate>Sun, 02 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2019/06/prometheus-golang_client/</guid>
      <description></description>
      <content:encoded><![CDATA[<p>exporter是一个独立运行的采集程序，其中的功能需要有这三部分</p>
<ul>
<li>自身是HTTP服务器，可以相应从外部发过来的HTTP GET请求。</li>
<li>自身需要运行在后台，并可以定期触发抓取本地的监控数据。</li>
<li>返回给prometheus_server的内容是要符合prometheus规定的metrics类型的key-Value</li>
</ul>
<p>promethes监控中对于采集过来的数据统一称为metrice数据</p>
<p><strong>Metrics</strong>，为某个系统某个服务做监控、做统计，就需要用到Metrics.</p>
<p>metrics是一种对采样数掘的总称（metrics并不代表某一种具体的数据格式是一种对于度星计算单位的抽象）</p>
<p>metrics的几种主要的类型</p>
<h2 id="metric-types">METRIC TYPES</h2>
<p>prometheus客户端库提供4中metric类型</p>
<ul>
<li>counter 计数器，累加指标</li>
<li>gauge 测量指标</li>
<li>summary 概略</li>
<li>histogram 直方图</li>
</ul>
<h3 id="counter">counter</h3>
<p>Counter计数器，累加的指标数据，随时间逐步增加，如程序运行次数、运行错误发生总数。如网卡流量，代表持续增加的数据包或者传输字节的累加值</p>
<p>比如对用户访问量的采样数据</p>
<p>我们的产品被用户访问一次就是1过了10分钟后积累到100</p>
<p>过一天后累积到20000</p>
<p>一周后积累到100000-150000</p>
<pre><code class="language-go">test = prometheus.NewSummaryVec(
		prometheus.SummaryOpts{
			Name:       &quot;zhangsan&quot;,
			Help:       &quot;username&quot;,
			Objectives: map[float64]float64{0.5: 0.05, 0.9: 0.01, 0.99: 0.001},
		},
		[]string{&quot;service&quot;},
	)
</code></pre>
<pre><code># HELP zhangsan username
# TYPE zhangsan summary
zhangsan{service=&quot;aaa&quot;,quantile=&quot;0.5&quot;} 0.4933459627210085
zhangsan{service=&quot;aaa&quot;,quantile=&quot;0.9&quot;} 0.884503005897664
zhangsan{service=&quot;aaa&quot;,quantile=&quot;0.99&quot;} 0.9939536606026
zhangsan_sum{service=&quot;aaa&quot;} 3145.830341777395
zhangsan_count{service=&quot;aaa&quot;} 6308
</code></pre>
<p>在每次执行后值会累加</p>
<pre><code># HELP zhangsan username
# TYPE zhangsan summary
zhangsan{service=&quot;aaa&quot;,quantile=&quot;0.5&quot;} 0.4933459627210085
zhangsan{service=&quot;aaa&quot;,quantile=&quot;0.9&quot;} 0.884503005897664
zhangsan{service=&quot;aaa&quot;,quantile=&quot;0.99&quot;} 0.9945251964629818
zhangsan_sum{service=&quot;aaa&quot;} 3165.232975252529
zhangsan_count{service=&quot;aaa&quot;} 6347
</code></pre>
<h3 id="gauge">gauge</h3>
<p>最简单的度量指标，只有一个简单的返回值，或者叫瞬时状态，例如，我们想衡量一个特处理队列中任务的个数。</p>
<p>用更简单的方式举个例子</p>
<p>例如：如果我要监控覆盘容量或者内存的使用量，那么就应该使用Gauges的metrics格式来度量，因为硬盘的容量或者内存的使用量是随着时间的推移不断的瞬时，没有规则的变化。这种变化没有规律，当前是多少，采集回来的就是多少，既不能肯定是一直持续增长，也不能肯定是一直降低，是多少就是多少这种就是Gauges使用类型的代表。</p>
<p>如图所示CPU的上下厚动就是采集使用Gauge形式的metrics数据，没有规律是多少就得到多少，然后显示出来。</p>
<p>gauge代表采集的是一个单一的数据，此数据可增可减，如内存使用情况，cpu使用情况等。</p>
<pre><code class="language-go">gaugetest = prometheus.NewGauge(prometheus.GaugeOpts{
		Name: &quot;lisi&quot;,
		Help: &quot;password&quot;,
})
</code></pre>
<pre><code># HELP lisi password
# TYPE lisi gauge
lisi 0.4578056215001356
</code></pre>
<pre><code># HELP lisi password
# TYPE lisi gauge
lisi 0.44668242347036363
</code></pre>
<p><a href="https://github.com/lwhile/workDoc" target="_blank"
   rel="noopener nofollow noreferrer" >https://github.com/lwhile/workDoc</a></p>
<h3 id="summary-概略">summary 概略</h3>
<h3 id="histogram-比例型的估算数值">histogram 比例型的估算数值</h3>
<p>Histogram 统计数据的分布情况。比如最小值，最大值，中间值，还有中位数，75百分位，90百分位，95百分位，98百分位，99百分位，和99.9百分位的值（percentiles）。</p>
<p><strong>这是一种特殊的metrics数据类型，代表的是一种</strong>近似的百分比估算数值</p>
<p>比如我们在企业工作中经常接触这种数据</p>
<p>Http.response_time HTTP响应时间</p>
<p>代表的是一次用户HTTP请求在系统传输和执行过程中总共花费的时间</p>
<p>nginx中的也会记录这一项数值在日志中</p>
<p>那么问题来了</p>
<p>我们做一个假设</p>
<p>如果我们想通过监控的方式抓取当天的nginx accoss.log，并且想监控用户的访问时间我们应该怎么做呢？同学们肯定很容易想到
简单制把日志每行的<code>http_response_time</code> 数值统统采集下来期然后计算一下总的平均值即可。那么假如我们采集到今天一天的访问量是100万次然后把这100万次的<code>http_response_time</code> 全都加一超然后除以100万最后得出来一个值</p>
<p>0.05秒=50毫秒</p>
<p>这个数据的意文大么？</p>
<p>假如今天中午1：00的时候发生了一次线上故障系统整体的访问变得非常缓慢大部分的用户请求时间都达到了0.5~1秒作用但是这一段时间只持续了5分钟，总的一天的平均值并不能表现得出来我们如何在 1:00 ~ 1:05 的时候实现报警呢？</p>
<p>在举个例子：</p>
<p>就算我们一天下来线上没有发生故障大部分用户的响应时间都在0.05秒（通过总时间/总次数得出）但是我们不要忘了任何系统中都一定存在慢请求就是有一少部分的用户请求时间会比总的平均值大很多甚至接近5秒10秒的也有（这种情况很普遍因为各种因素可能是软件本身的bug也可能是系统的原因更有可能是少部分用户的使用途径中出现了问题）</p>
<p>那么我们的监控需要发现和报警这种少部分的特殊状况，用总平均能获得吗？</p>
<p>如果采用总平均的方式，那不管发生什么特殊情况，因为大部分的用户响应都是正常的你永远也发现不了少部分的问题所以Histogram的metrics类型在这种时候就派上用场了通过histogram类型（prometheus中其实提供了一个基于histogram算法的函数可以直接使用）可以分别统计出全部用户的单应时间中
~=0.05秒的量有多少0 ~ 0.05秒的有多少，&gt;2秒的有多少&gt;10秒的有多少</p>
<p>我们就可以很清晰的看到当前我们的系统中必于基本正常状态的有多少百分比的用户（或者是请求）多少处于速度极快的用户，多少处于慢请求或者有问题的请求</p>
<p>metrics的类型其实还有另外的类型</p>
<p>但是在我们大米运维的课程中我们最主要使用的就是counter ganga 和 histogram</p>
<h4 id="kv的数据形式">kv的数据形式</h4>
<p>对于采集回来的数据类型再往细了说必须要以一种具体的数据格式供我们查看和使用那么我们来看一下一个exporter 给我们果集来的服务器上的k/v形式metrics数据当一个exporter被安装和运行在被监控的服务器上后，使用简单的curl命令就可以看到exporer帮我们采集到metrics数据的样子，以k/v的形式展现和保存</p>
<pre><code class="language-bash">curl localhost:9100/metrics
</code></pre>
]]></content:encoded>
    </item>
    
    <item>
      <title>prometheus传统架构安装</title>
      <link>https://www.oomkill.com/2019/04/prometheus-install/</link>
      <pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2019/04/prometheus-install/</guid>
      <description></description>
      <content:encoded><![CDATA[<p>全局配置选项</p>
<pre><code>scrape_interval: 采集生命周期
scrape_timeout: 采集超时时间
evaluation_interval: 告警评估周期
rule_files 监控告警规则
scrape_config: 被监控端

altering 
</code></pre>
<p>检查配置文件语法</p>
<pre><code>$ promtool check config \etc\prometheus.yml 
Checking \etc\prometheus.yml
  SUCCESS: 0 rule files found
</code></pre>
<p>100 - (node_memory_MemFree_bytes+node_memory_Cached_bytes+node_memory_Buffers_bytes) \ node_memory_MemTotal_bytes * 100</p>
<p>计算剩余空间</p>
<p>node_filesystem_free_bytes{mountpoint=&quot;&quot;,fstype=~&ldquo;ext4|xfs&rdquo;} \ node_filesystem_size_bytes{mountpoint=&quot;&quot;,fstype=~&ldquo;ext4|xfs&rdquo;} * 100</p>
<p>查看使用的百分比</p>
<p>100-node_filesystem_free_bytes{mountpoint=&quot;&quot;,fstype=~&ldquo;ext4|xfs&rdquo;} \ node_filesystem_size_bytes{mountpoint=&quot;&quot;,fstype=~&ldquo;ext4|xfs&rdquo;} * 100</p>
<p>prometheus使用influxdb [Prometheus endpoints support in InfluxDB | InfluxData Documentation](https:\docs.influxdata.com\influxdb\v1.7\supported_protocols\prometheus)</p>
<p>[Configuration | Prometheus](https:\prometheus.io\docs\prometheus\latest\configuration\configuration)</p>
<p>配置文件参考</p>
<pre><code class="language-yaml">global:
alerting:
  alertmanagers:
  - static_configs:
    - targets:
rule_files:
scrape_configs:
  - job_name: 'prometheus1'
    file_sd_configs:
    - files: ['\data\sd_config\test.yml']
      refresh_interval: 5s
    relabel_configs:
    - action: replace
      source_labels: ['prometheous1']
      regex: (.*)
      replacement: $1
      target_label: ids
    - action: keep
      source_labels: [&quot;job&quot;]
  - job_name: 'k8s_master'
    file_sd_configs:
    - files: ['\data\sd_config\master.yml']
      refresh_interval: 5s
remote_write:
- url: &quot;http:\\localhost:8086\api\v1\prom\write?db=prometheus&quot;
remote_read:
- url: &quot;http:\\localhost:8086\api\v1\prom\read?db=prometheus&quot;
</code></pre>
<p>influxdb使用</p>
<p><a href="https:%5c%5cwww.linuxdaxue.com%5cinfluxdb-basic-operation.html" target="_blank"
   rel="noopener nofollow noreferrer" >InfluxDB学习之InfluxDB的基本操作 | Linux大学</a></p>
<p>查看所有表</p>
<pre><code class="language-sql">SHOW MEASUREMENTS
</code></pre>
<pre><code class="language-sql">select * from up
</code></pre>
<p>https:\github.com\kubernetes\kubernetes\tree\master\cluster\addons\prometheus</p>
<p>文件主要包括一下几个部分</p>
<ul>
<li>Prometheus的安装 包括 rbac service configmap</li>
<li>Prometheus-metrics 获取资源对象</li>
<li>node-exporter 获取工作节点资源信息</li>
<li>alertmanager 告警</li>
</ul>
<p>安装顺序</p>
<p>prometheus-rbac.yaml Prometheus访问apiserver的授权
prometheus-configmap.yaml 管理Prometheus的配置文件
prometheus-service.yaml 将Prometheus端口暴漏
prometheus-statefulset.yaml</p>
<p>原因为 prometheus-statefulset.yaml中的<code>accessModes</code>不能为<code>ReadWriteOnce</code>
prometheus&quot;is invalid: spec: Forbidden: updates to statefulset spec for fields other than &lsquo;replicas&rsquo;, &rsquo;template&rsquo;, and &lsquo;updateStrategy&rsquo; are forbidden</p>
<p>日志中报错<code>pod has unbound immediate persistentvolumeclaims back-off restarting failed container</code></p>
<p>错误原因：动态绑定至其他sc上，查看<code>kubectl describe pvc prometheus-data-prometheus-0 -n kube-system</code>pvc中报错<code>storageclass.storage.k8s.io &quot;nfs&quot; not found</code></p>
<p>prometheus时间不一致问题</p>
<pre><code class="language-yaml">spec:
  containers:
  - name: myweb
    image: harbor/tomcat:8.5-jre8
    volumeMounts:
    - name: host-time
      mountPath: /etc/localtime
    ports:
    - containerPort: 80
  volumes:
  - name: host-time
    hostPath:
      path: /etc/localtime
</code></pre>
<p>部署应用时，单独读取主机的“/etc/localtime”文件，即创建pod时同步时区，无需修改镜像，但是每个应用都要单独设置。</p>
<p>prometheus server down</p>
<p>编辑prometheus-statusfullset.yaml 修改其配置localhost 改为 127.0.0.1</p>
<pre><code>time=&quot;2020-11-20T18:44:48+08:00&quot; level=error msg=&quot;subset not found for kube-system/prometheus-server&quot; providerName=kubernetescrd ingress=promserver namespace=kube-system
</code></pre>
<p>查找原因kubernetes svc 匹配错误 service endpoint没有匹配到内容</p>
<pre><code>$ kubectl describe svc  prometheus-server  -n kube-system 
Name:              prometheus-server
Namespace:         kube-system
Labels:            &lt;none&gt;
Annotations:       Selector:  monitor=prometheus
Type:              ClusterIP
IP:                10.110.116.203
Port:              &lt;unset&gt;  9090/TCP
TargetPort:        9090/TCP
Endpoints:         &lt;none&gt;
Session Affinity:  None
Events:            &lt;none&gt;
</code></pre>
<p>修改后正常</p>
<p>数学理论基础实现的</p>
<p>配置文件</p>
<pre><code class="language-yaml">- job_name: 'prometheus' 首先定义任务名称
</code></pre>
<p>prometheus的客户端主要有两种方式采集</p>
<ul>
<li>pull 主动输影的形式</li>
<li>push 被动推送的形式</li>
</ul>
<h3 id="put">put</h3>
<p>put指的是客户端（被监控机器）先安装各类已有exporters（由社区组积或企业开发的监控客户端插件）在系统上之后，exporter以守护进程的模式运行并开始采集数据</p>
<p>exporter 本身也是一个htp_server 可以对http请求作出响应返回数据（KV metrics）</p>
<p>prometheua用pull 这种主动拉的方式（HTTP get）去访问每个节点上exporter并采样回需要的数据</p>
<h3 id="push">push：</h3>
<p>push指的是在客户端（或者服务端）安装这个官方提供的pushgateway插件然后，使用我们自行开发的各种脚本把监控数据组织成K/V的形式，metrics形式发送给pushgateway之后 puahgataway会再推送给prometheus</p>
<p>这种是一种被动的数据采集模式</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
