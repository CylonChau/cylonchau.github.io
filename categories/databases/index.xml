<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>databases on Cylon&#39;s Collection</title>
    <link>https://www.oomkill.com/categories/databases/</link>
    <description>Recent content in databases on Cylon&#39;s Collection</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 05 Oct 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://www.oomkill.com/categories/databases/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Docker运行PostgreSQL</title>
      <link>https://www.oomkill.com/2020/10/postgresql-docker-setup/</link>
      <pubDate>Mon, 05 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2020/10/postgresql-docker-setup/</guid>
      <description></description>
      <content:encoded><![CDATA[<p>在本文，尝试使用 Docker 运行 PostgreSQL ，为了适配 goalert 项目，因为从来没有尝试过使用 PostgreSQL</p>
<h2 id="了解postgresql数据库">了解PostgreSQL数据库</h2>
<p>在我们继续运行 PostgreSQL 数据库的 Docker 容器之前，我们先来了解一下 PostgreSQL 数据库。   <strong>PostgreSQL 是一个开源 RDMS，类似于 MySQL。   它是一个面向对象的数据库，但我们可以处理结构化和非结构化数据。</strong></p>
<p>PostgreSQL 数据库可以运行在各种平台上，包括 Windows、Mac OS X 和 Linux。它还提供高级数据类型和性能优化功能来存储和扩展复杂的数据库工作负载。</p>
<h2 id="使用公共镜像运行postgresql">使用公共镜像运行PostgreSQL</h2>
<p>要使用 Docker 运行 PostgreSQL，我们首先需要拉取 <a href="https://hub.docker.com/postgres" target="_blank"
   rel="noopener nofollow noreferrer" >Docker Hub </a> 上可用的 postgres 公共镜像：</p>
<pre><code class="language-bash">docker pull postgres
</code></pre>
<p>在上面的命令中，我们拉取了 <em>postgres</em> 最新的稳定版镜像。 如果要指定版本的 <em>postgres</em> 镜像，可以使用以下命令</p>
<pre><code class="language-bash">docker pull postgres:14.2
</code></pre>
<p>这里将使用 <em>postgres:14.2</em>  版本来运行 Postgres 的容器，这里命令主要为 Linux</p>
<pre><code class="language-bash">docker run -d -e POSTGRES_USER=admin -e POSTGRES_PASSWORD=111111 -p 5432:5432 -v /data:/var/lib/postgresql/data --name postgresql postgres
</code></pre>
<p>如果在 window 或 wsl 上运行，可以执行下面命令</p>
<pre><code class="language-bash">docker run -d -e POSTGRES_USER=admin -e POSTGRES_PASSWORD=111111 -p 5432:5432 -v /data:/var/lib/postgresql/data --name postgresql postgres
</code></pre>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch08 - MySQL存储引擎</title>
      <link>https://www.oomkill.com/2017/05/ch8-mysql-engine/</link>
      <pubDate>Tue, 23 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2017/05/ch8-mysql-engine/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="什么是存储引擎">什么是存储引擎</h2>
<p>在经清楚什么是存储引擎之前，我们先来个比喻，我们都知道录制一个视频文件，可以转换成不同的格式如mp4 avi wmv等，而存在我们电脑的磁盘上也会存在于不同类型的文件系统中如windows里常见的ntfs fat32，存在于linux常见的ext3 ext4 xfs，但是，给我们或者用户看到实际视频内容都是一样的。直观区别是，占用系统的空间大小与清晰程度可能不一样。</p>
<p>那么数据库表里的数据存储在数据库里及磁盘上和上述的视频格式及存储磁盘文件系统格式特征类似，也有很多中存储方式。</p>
<p>但是，对于用户和应用程序来说同样一张表的数据，无论用什么引擎来存储，用户看到的数据都是一样的。不同的引擎存储，引擎功能，占用的空间大小，读取性能等可能有区别。</p>
<p>MySQL最常用的存储引擎为：MyISAM和InnoDB。全文索引：目前MySQL5.5版本，myisam和inondb都已经支持。</p>
<h2 id="mysql存储引擎的架构">MySQL存储引擎的架构</h2>
<p>MySQL的存储引擎是MySQL数据库的重要组成部分，MySQL常用的表的引擎为MyISAM和InnoDB两种。MySQL的每种存储引擎在MySQL里是通过插件的方式使用的，MySQL可以同时支持多种存储引擎。下面是MySQL存储引擎体系结构简图：</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/image-20221214201434104.png" alt="image-20221214201434104" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/image-20221214201452181.png" alt="image-20221214201452181" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h2 id="myisam引擎">MyISAM引擎</h2>
<p>MyISAM引擎是MySQL关系数据库管理系统的默认存储引擎（MySQL 5.5.5以前）。这种MySQL表存储结构从旧的ISAM代码扩展出许多有用的功能。在新版本MySQL中，InnoDB引擎由于其对事务参照完整性，以及更高的并发性等优点开始逐步的取代MyISAM引擎，</p>
<blockquote>
<p>“InnoDB is the default storage engine as of MySQL 5.5.5。MyISAM: The MySQL storage engine that is used the most in Web,data warehousing,and other application environments.MyISAM is supported in all MySQL configurations,an is the default storage engine prior to MySQL 5.5.5。”</p>
</blockquote>
<p>查看MySQL5.1数据库默认引擎</p>
<pre><code class="language-bash">mysql&gt; show create table test1\G
*************************** 1. row ***************************
       Table: test1
Create Table: CREATE TABLE `test1` (
  `name` int(11) DEFAULT NULL
) ENGINE=MyISAM DEFAULT CHARSET=latin1
1 row in set (0.00 sec)
</code></pre>
<p>提示：MySQL 5.1数据库的默认存储引擎为MyISAM。</p>
<p>每一个MyISAM的表都对应于硬盘上的三个文件。这三个文件有一样的文件名，但是有不同的扩展名指示其类型用途：</p>
<hr>
<p>.frm文件保存表的定义，这个文件并不是MyISAM引擎的一部分，而是服务器的一部分</p>
<p>.MYD保存表的数据</p>
<p>.MYI是表的索引文件。</p>
<p># MYD和MYI是MyISAM的关键点</p>
<hr>
<p>范例</p>
<pre><code class="language-bash">$ ll /var/lib/mysql/mysql/
user.frm	# 表的定义
user.MYD	# data
user.MYI	# index
</code></pre>
<p>MySQL系统的表多数属于MyISAM引擎</p>
<pre><code class="language-bash">$ ls /var/lib/mysql/mysql/
columns_priv.frm   help_keyword.frm      proc.frm                   time_zone_leap_second.MYI
columns_priv.MYD   help_keyword.MYD      proc.MYD                   time_zone.MYD
columns_priv.MYI   help_keyword.MYI      proc.MYI                   time_zone.MYI
</code></pre>
<blockquote>
<p>“<strong>为什么MySQL5.5.5以前默认的是MyISAM引擎，而MySQL5.5.5以后默认是innodb</strong>”</p>
<p>答：和互联网发展有关，互联网诞生之初。基本上已读为主，那时机器硬件性能低。设计数据库时需要占用资源少的数据库。5.5之后选择了innodb</p>
<p>“<strong>为什么mysql库里内部表默认是myisam</strong>”</p>
<p>web2.0时代：以用户为中心的时代多数平台都是用户上传其他用户读）在这种时代myisam引擎就胜任不了了，顾mysql5。</p>
</blockquote>
<h3 id="myisam引擎特点">MyISAM引擎特点</h3>
<p><strong><font color="#0215cd" size=3> 至少掌握5点</font></strong></p>
<ol>
<li>
<p><strong>不支持事务</strong> 事务是指逻辑上的一组操作，组成这组操作的各个单元，要么全成功要么全失败</p>
</li>
<li>
<p><strong>表级锁定</strong>  数据更新时锁定整个表：其锁定机制是表级锁定，这虽然可以让锁定的实现成本很小但是也同时降低了其开发性能</p>
<hr>
<p>举例子：上厕所，还有很多小便坑，锁上外面的们，一个人上厕所，谁也去不了厕所了。</p>
<p>表级锁定并发处理降低，但是提升了效率 举例：商场有小偷，不知道在哪，锁住一楼大门，然后逐一摸排</p>
<p>缺点是，别人想出出不去了。但是对于保安来说是最有效的方法。</p>
<hr>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/image-20221214201921894.png" alt="image-20221214201921894" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
</li>
<li>
<p><strong>读写互相阻塞</strong>  不仅会在写入的时候阻塞读取，myisam还会在读取的时候阻塞写入，但读本身并不会阻塞另外的读</p>
</li>
<li>
<p><strong>只会缓存索引</strong>  MyISAM可以通过key_buffer_size（只是myisam）缓存索引，以大大提高访问性能较少磁盘IO，但这个缓存区只会缓存索引，而不会缓存数据</p>
</li>
<li>
<p>读取速度较快。占用资源相对少。</p>
</li>
<li>
<p>不支持外键约束，但支持全文索引。</p>
</li>
<li>
<p>MyISAM引擎是MySQL5.5.5 前默认的存储引擎 ( “is the default storage engine prior to MySQL 5.5.5” )。</p>
</li>
</ol>
<h3 id="myisam引擎适用的生产业务场景">MyISAM引擎适用的生产业务场景</h3>
<ol>
<li>不需要事务支持的业务（例如转账就不行）。</li>
<li>一般为读数据比较多的应用，读写都频繁场景不适合，读多或者写多的都适合。</li>
<li>读写并发相对较低的业务（纯读纯写高并发也可以）（锁机制问题）。</li>
<li>数据修改相对少的业务（阻塞问题）。</li>
<li>已读为主的业务，例如：读数据库系统表、www blog 图片信息数据库 用户数据库 商品库等业务。</li>
<li>对数据一致性要求不是非常高的业务（MySQL 5.6前不支持事务）。</li>
<li>硬件资源比较差的机器都可以用myisam（占用资源少）。</li>
<li>使用读写分离的MySQL从库可以使用myisam（5年前提到较多）</li>
</ol>
<p>小结：单一对数据库的操作都可以使用myisam，所谓单一就是尽量纯读，或纯写（insert update delete）等</p>
<h2 id="innodb引擎">InnoDB引擎</h2>
<p>Innodb引擎是MySQL数据库的另一个重要的存储引擎，正式成为MySQLAB所发行新版的标准，被包含在所有二进制安装包里。和其他的存储引擎相比，InnoDB引擎的优势是支持兼容ACID的事务（类似于PostgreSQL），以及参数完整性（即对外键的支持）。Oracle公司2005年手抽了Innobase。innobase采用双认证授权。它使用GNU发型，也允许其他想将InnoDB结合到商业软件的团体获得授权。</p>
<p>更多参考 reman-5.5-en.html-chapter/storage-engines.html</p>
<hr>
<p>提示：只有test1.frm没有MyISAM对应的数据文件和索引文件了。</p>
<hr>
<pre><code class="language-bash">$ ll test/
ibdata1
ib_logfile0 #
ib_logfile1	# 这里是存放Innodb数据文件
ib_logfile2 #
test1.frm	
test2.frm
</code></pre>
<h3 id="innodb引擎特点">InnoDB引擎特点</h3>
<ol>
<li>支持事务：支持4个事务隔离级别，支持多版本读。</li>
<li>行级锁定（更新时一般是锁定当前行）：通过索引实现，全表扫描仍然会是表锁，注意间隙锁的影响。</li>
<li>读写阻塞与事务隔离级别相关。</li>
<li>具有非常搞笑的缓存特性：能缓存索引，也能缓存数据。</li>
<li>整个表和主键以Cluster方式存储，组成一颗平衡树。</li>
<li>所有Secondary Index都会保存主键信息。</li>
<li>支持分区，表空间，类似oracle数据库</li>
<li>支持外键约束，5.5前不支持全文索引</li>
<li>和MyISAM引擎比，InnoDB对硬件资源要求更高</li>
</ol>
<blockquote>
<p>面试必问</p>
<p>innodb特点：面试必答项：</p>
<ol>
<li>row-level locking</li>
<li>full-text search indexs</li>
<li>data caches</li>
<li>index caches</li>
<li>transactions</li>
<li>占用资源多</li>
<li>读写阻塞与事务隔离级别相关</li>
<li>外键</li>
</ol>
</blockquote>
<h3 id="innodb引擎使用的生产业务场景">innodb引擎使用的生产业务场景</h3>
<ol>
<li>需要事务支持的业务（具有较好的事务特性）。</li>
<li>行级锁定对高并发有很好的适应能力，但需要确保查询是通过索引完成。</li>
<li>数据读写及更新都较为频繁的场景，如:BBS SNS 微博，微信等。</li>
<li>数据一致性要求较高的业务，例如：充值转账，银行卡转账。</li>
<li>硬件设备内存较大，可以利用InnoDB较好的缓存能力来提高内存利用率，尽可能减少磁盘IO</li>
</ol>
<pre><code class="language-conf">innodb_additional_mem_pool_size = 4M
innodb_buffer_pool_size = 32M
innodb_data_file_path = ibdata1:128M:autoextend
innodb_file_io_threads = 4
innodb_thread_concurrency = 8
innodb_flush_log_at_trx_commit = 2
innodb_log_buffer_size = 2M
innodb_log_file_size = 4M
innodb_log_files_in_group = 3
innodb_max_dirty_pages_pct = 90
innodb_lock_wait_timeout = 120
innodb_file_per_table = 0
</code></pre>
<p>共享表空间对应物理数据文件</p>
<pre><code class="language-bash">$ ll test/
ibdata1
ib_logfile0
</code></pre>
<p>独立表空间对应物理数据文件</p>
<pre><code class="language-bash">innodb_file_per_table
innodb_data_home_dir=xxx
</code></pre>
<h3 id="innodb引擎调优精要">innodb引擎调优精要</h3>
<ol>
<li>
<p>主键尽可能小，避免给Secondary index带来过大的空间负担</p>
</li>
<li>
<p>建立有效索引避免全表扫描，因为会使用表锁。</p>
</li>
<li>
<p>尽可能缓存所有的索引和数据，提高相应速度，减少磁盘IO消耗</p>
</li>
<li>
<p>在大批量小插入的时候，尽量自己控制事务而不要使用autocommit自动提交。有开关可以控制提交方式；</p>
</li>
<li>
<p>合理设置innodb_flush_log_at_trx_commit参数值，不要过度追求安全性。</p>
<p>如果innodb_flush_log_at_trx_commit的值为0，log buffer每秒就会被刷写日志文件到磁盘，提交事务时候不做任何操作。</p>
</li>
<li>
<p>避免主键更新。（字段的起名长短都会影响性能）。</p>
</li>
</ol>
<h2 id="mysql引擎特别说明">MySQL引擎特别说明</h2>
<table>
<thead>
<tr>
<th>Feature</th>
<th>MyISAM</th>
<th>Memory</th>
<th>InnoDB</th>
<th>Archive</th>
<th>NDB</th>
</tr>
</thead>
<tbody>
<tr>
<td>Storage limits</td>
<td>256TB</td>
<td>RAM</td>
<td>64TB</td>
<td>None</td>
<td>384EB</td>
</tr>
<tr>
<td>Transactions</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Locking granularity</td>
<td>Table</td>
<td>Table</td>
<td>Row</td>
<td>Row</td>
<td>Row</td>
</tr>
<tr>
<td>MVCC</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>Geospatial data type support</td>
<td>Yes</td>
<td>No</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Geospatial indexing support</td>
<td>Yes</td>
<td>No</td>
<td>Yes[a]</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>B-tree indexes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>T-tree indexes</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Hash indexes</td>
<td>No</td>
<td>Yes</td>
<td>No[b]</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Full-text search indexes</td>
<td>Yes</td>
<td>No</td>
<td>Yes[c]</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>Clustered indexes</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>Data caches</td>
<td>No</td>
<td>N/A</td>
<td>Yes</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Index caches</td>
<td>Yes</td>
<td>N/A</td>
<td>Yes</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Compressed data</td>
<td>Yes[d]</td>
<td>No</td>
<td>Yes[e]</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td>Encrypted data[f]</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Cluster database support</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Replication support[g]</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Foreign key support</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>Backup / point-in-time recovery[h]</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Query cache support</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Update statistics for data dictionary</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>[a] InnoDB support for geospatial indexing is available in MySQL 5.7.5 and higher.</li>
<li>[b] InnoDB utilizes hash indexes internally for its Adaptive Hash Index feature.</li>
<li>[c] InnoDB support for FULLTEXT indexes is available in MySQL 5.6.4 and higher.</li>
<li>[d] Compressed MyISAM tables are supported only when using the compressed row format. Tables using the compressed row format with MyISAM are read only.</li>
<li>[e] Compressed InnoDB tables require the InnoDB Barracuda file format.</li>
<li>[f] Implemented in the server (via encryption functions). Data-at-rest tablespace encryption is available in MySQL 5.7 and higher.</li>
<li>[g] Implemented in the server, rather than in the storage engine.</li>
<li>[h] Implemented in the server, rather than in the storage engine.</li>
</ul>
<p>参考手册：https://dev.mysql.com/doc/refman/5.5/en/storage-engines.html</p>
<p>以上是myisam innodb和NDBCluster三个存储引擎是目前互联网公司应用比较多的存储引擎，特别是前两者，其他如 memory merge csv archive等存储引擎的使用场景都相对较少，初学的同学可以暂时忽略。更多可参考MySQL官方文档。</p>
<h2 id="如何确定mysql服务器有那些引擎可用">如何确定MySQL服务器有那些引擎可用？</h2>
<p>在MySQL中使用显示引擎的命令得到一个可用引擎的列表</p>
<pre><code class="language-bash">show engines\G
...
...
*************************** 5. row ***************************
      Engine: MyISAM
     Support: YES
     Comment: MyISAM storage engine
Transactions: NO
          XA: NO
  Savepoints: NO
*************************** 6. row ***************************
      Engine: InnoDB
     Support: DEFAULT
     Comment: Percona-XtraDB, Supports transactions, row-level locking, and foreign keys
Transactions: YES
          XA: YES
  Savepoints: YES
...
...
10 rows in set (0.01 sec)
</code></pre>
<h2 id="生产场景中批量更改mysql引擎">生产场景中批量更改MySQL引擎</h2>
<p>一般来说这样的需求不多见，但偶尔也会有，在这里我们推荐使用sed对备份内容进行引擎转换的方式，当然，不要忘记修改my.cnf使之支持并能高效的使用对应的引擎</p>
<p><font color="#0215cd" size=3><strong>方法1：MySQL命令语句修改</strong></font></p>
<pre><code class="language-bash">alter table test engine=innodb;
</code></pre>
<p><font color="#0215cd" size=3><strong>方法2：使用sed对备份内容进行引擎转换</strong></font></p>
<pre><code class="language-bash"># 此方法折腾数据不推荐使用
# 主从复制丛库换引擎，正式数据换不要用
sed -e 's#MyISAM#InnoDB#g' b.sql&gt;b1.sql
</code></pre>
<p><font color="#0215cd" size=3><strong>方法3：mysql_convert_table_format命令修改</strong></font></p>
<pre><code class="language-bash">mysql_convert_table_format --host=$HOST --user=$USER --passsword=$PASS --socket=$SOCKET --type=$Engine $DB $TN
</code></pre>
<p>建表语句加上指定引擎：</p>
<pre><code class="language-bash">create table test(
id int not null
) engine=innodb default charset=utf8;
</code></pre>
<p>混合引擎和单独innodb引擎配置差别？</p>
<h2 id="有关mysql引擎常见企业面试题">有关MySQL引擎常见企业面试题</h2>
<ol>
<li>MySQL有那些存储引擎，各自有什么特点和区别？</li>
<li>生产环境中如何选用MySQL的引擎</li>
</ol>
<p>​		在一般的既有读又有写的业务中，建议使用innodb引擎，一句话尽可能多的使用innodb引擎。</p>
<p>​		纯读 纯写可用myisam。例如系统的MySQL库。</p>
<ol start="3">
<li>
<p>不同引擎如何备份？混合引擎如何备份。</p>
<pre><code class="language-bash"># myisam
mysqldump -uroot -p111 -S/data/3306/mysql.sock \
	-A \
	-x \
	-B \
	-F \
	--master-data=2|gzip &gt;back.sql

# innodb
mysqldump -uroot -p111 -S/data/3306/mysql.sock \
	-A \
	-x \
	-B \
	-F \
	--master-data=2 \
	--single-transaction|gzip &gt;back.sql 

</code></pre>
</li>
</ol>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch07 - 实现和MySQL非交互式对话</title>
      <link>https://www.oomkill.com/2017/05/ch7-mysql-non-interact/</link>
      <pubDate>Mon, 22 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2017/05/ch7-mysql-non-interact/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="利用-mysql--e-参数查看-mysql-数据">利用 mysql -e 参数查看 mysql 数据</h2>
<pre><code class="language-bash">$ mysql -uroot -p111 -e 'use test;show tables;'
+------------------------------+
| Tables_in_test               |
+------------------------------+
| 33hao_activity               |
| 33hao_activity_detail        |
| 33hao_address                |
+------------------------------+
</code></pre>
<p>利用 <code>mysql -e</code> 参数查看SQL线程执行状态</p>
<pre><code class="language-bash">$ mysql -uroot -p111 -e 'show processlist;' 
kill 12;
</code></pre>
<p>查看完整的线程状态，此参数才查看慢查询语句是非常有用</p>
<p>解决方法：</p>
<pre><code class="language-bash">root@localhost [test]&gt;show variables like '%_timeout%';
# 设置
set global wait_timeout=60;
set global interactive_timeout=60;
</code></pre>
<ol>
<li>在配置文件里修改</li>
</ol>
<pre><code class="language-conf">set global wait_timeout=60;
set global interactive_timeout=60; # 此参数设置后wait_timeout自动生效
</code></pre>
<ol start="2">
<li>其他方法</li>
</ol>
<ul>
<li>
<p>(1) PHP程序中，不适用持久链接，即 <code>mysql_connect</code> 而不是 <code>pconnect</code>（java调整连接池）</p>
</li>
<li>
<p>(2) PHP程序执行完毕，应该显示调用 <code>mysql_close()</code></p>
</li>
<li>
<p>(3) 逐步分析MySQL的SQL查询及慢查询日志，找到查询过慢的SQL，优化。</p>
</li>
</ul>
<p>利用mysql -e查看mysql变量及性能状态</p>
<pre><code class="language-bash">$ mysql -uroot -p111 -e 'show variables;'|head -5
Variable_name   Value
auto_increment_increment        1
auto_increment_offset   1
autocommit      ON
automatic_sp_privileges ON
</code></pre>
<p>不重启数据库就该数据库参数</p>
<p><strong>要求：重启后还能生效</strong></p>
<pre><code class="language-bash">$ sed -n '122p' /etc/my.cnf                   
key_buffer_size = 16M

$ sed -i 's#key_buffer_size = 16M#key_buffer_size=32M#g' /etc/my.cnf                           
$ sed -n '122p' /etc/my.cnf                             
key_buffer_size=32M
</code></pre>
<p>生产环境常用重要命令小结</p>
<pre><code class="language-bash"># 查看数据库里正在执行的SQL语句，可能无法看完整SQL语句
show processlist;

# 查看正在执行的完整SQL语句，完整显示
show full processlist;

# 不重启数据库调整数据库参数，直接生效，重启后失效
set gloables key_buffer_size=1024*1024*32;

# 查看数据库的配置参数信息，例如：my.cnf里参数的生效情况。
show variables;

# 杀掉SQL线程的命令ID为线程号
kill id

# 查看当前会话的数据库状态信息
show session status;

# 查看整个数据库运行状态信息，很重要，要分析并要做好监控
show global status;

# 显示innodb引擎的性能状态（早期show innodb status）
show engine innodb status;
</code></pre>
<p><strong>计算一天之内：MySQL数据库有多少 insert delect语句，有没有好办法</strong>？</p>
<ol>
<li>
<p>定时任务每天0点，show global status; 按天取出对比。</p>
</li>
<li>
<p>按天分析binlog日志，获取数据库不同语句的频率。</p>
</li>
</ol>
<p>mysqladmin命令</p>
<pre><code class="language-bash"># 修改密码
mysqladmin password 111
mysqladmin -uroot -p111 password 222 

# 查看状态
mysqladmin -uroot -p111 status 
mysqladmin -uroot -p111 extended-status show global status
mysqladmin -uroot -p111 -S /data/3306/mysql.sock -i status

# 刷新日志
mysqladmin -uroot -p111 flush-logs
mysqladmin -uroot -p111 processlist

# 实时跟踪
mysqladmin -uroot -p111 processlist -i 1

# 关闭mysql
mysqladmin -uroot -p111 -S /data/3306/mysql.sock shutdown
mysqladmin -uroot -p111 -S /data/3306/mysql.sock variables show vaiables
</code></pre>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch04 - MySQL数据库服务日志类型</title>
      <link>https://www.oomkill.com/2017/05/ch04-mysql-log/</link>
      <pubDate>Sun, 21 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2017/05/ch04-mysql-log/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="错误日志-error-log">错误日志 error log</h2>
<p>MySQL错误日志记录MySQL服务进程mysqld在启动/关闭或运行过程中遇到的错误信息</p>
<p>错误日志配置</p>
<p><font color="#f8070d" size=3><strong>在配置文件中调整方法，当然可以在启动时加入启动参数</strong></font></p>
<pre><code class="language-bash">[mysqld_safe]
log-error=/data/3306/mysql_3306.err
</code></pre>
<p><font color="#f8070d" size=3><strong>启动MySQL命令里加入</strong></font></p>
<pre><code class="language-bash">/app/mysql/bin/mysqld_safe \
	--defaults-file=/data/3306/my.cnf \
	--log-error=/data/3306/mysql_3306.err

MariaDB&gt; show variables like &quot;%log_error%&quot;;
+-------------------+---------------------------+
| Variable_name 	| Value		                |
+-------------------+---------------------------+
| log_error  	 	| /data/3306/mysql_3306.err |
+-------------------+---------------------------+
</code></pre>
<p><font color="#f8070d" size=3><strong>遇到数据库启动不了</strong></font></p>
<ul>
<li>
<p>先把日志文件备份并清空启动一下mysql服务后再查看日志文件，看报有什么错误</p>
<pre><code class="language-bash">InnoDB: The error means mysqld does not have the access rights to

InnoDB: the directory
</code></pre>
</li>
<li>
<p>然后查看mysql3306目录下文件权限</p>
</li>
</ul>
<h2 id="普通查询日志-general-query-log">普通查询日志 general query log</h2>
<p>普通查询日志 (general query log)：记录客户端链接信息和执行的SQL语句信息。</p>
<p><font color="#f8070d" size=3><strong>普通查询日志配置</strong></font></p>
<pre><code class="language-bash">MariaDB&gt; show variables like &quot;%general_log%&quot;;
+------------------+-----------+
| Variable_name    | Value     |
+------------------+-----------+
| general_log      | OFF       |
| general_log_file | lnmp.log  |
+------------------+-----------+
</code></pre>
<p><strong>临时生效</strong></p>
<pre><code class="language-bash">MariaDB&gt; set global general_log_file = '/data/3306/log/mysql_query.log';
MariaDB&gt; set global general_log='on';

MariaDB&gt; show variables like '%general_log%';                           
+-------------------+----------------------------------+
| Variable_name  	| Value               			   |
+-------------------+----------------------------------+
| general_log    	| ON            	               |
| general_log_file  | /data/3306/log/mysql_query.log   |
+-------------------+----------------------------------+
</code></pre>
<p><strong>永久生效</strong></p>
<pre><code class="language-bash">$ grep general /data/3306/my.cnf  
general_log=on
general_log_file=/data/3306/log/mysql_query.log
</code></pre>
<p>日志示例</p>
<pre><code class="language-bash">cat log/mysql_query.log 
/app/mysql/bin/mysqld, Version: 5.5.54-MariaDB (MariaDB Server). started with:
Tcp port: 3306  Unix socket: /data/3306/mysql.sock
Time                 	Id	 Command    Argument
170130  8:55:03      	1 	 Connect   root@localhost as anonymous on 
 					    1 	 Query     select @@version_comment limit 1
170130  8:55:18      	1 	 Query     show variabales
170130  8:55:44      	2 	 Connect   root@localhost as anonymous on 
                      	2 	 Query     KILL QUERY 1
                      	2 	 Quit
</code></pre>
<h2 id="慢查询日志-slow-query-log">慢查询日志 slow query log</h2>
<p>慢查询日志 (slow query log)：记录执行时间超出指定值 long_query_time的SQL语句</p>
<p><font color="#f8070d" size=3><strong>慢查询日志调整</strong></font></p>
<pre><code class="language-bash">long_query_time=1
log-slow-queries=/data/3306/log/mysql_slow.log
log_queries_not_using_indexes
</code></pre>
<p>慢查询的设置，对于数据库SQL的优化非常重要</p>
<pre><code class="language-bash">$ egrep que ../my.cnf   
long_query_time = 2
log-slow-queries = /data/3306/log/slow.log
log_queries_not_using_indexes
</code></pre>
<h3 id="利用慢查询进行优化解决方案">利用慢查询进行优化解决方案</h3>
<p><font color="#f8070d" size=3><strong>开启慢查询</strong></font></p>
<pre><code class="language-bash">long_query_time = 2
log-slow-queries = /data/3306/log/slow.log
log_queries_not_using_indexes
</code></pre>
<p><font color="#f8070d" size=3><strong>慢查询日志切割</strong></font></p>
<pre><code class="language-bash">#!/bin/sh
cd /data/3306/ &amp;&amp;\
/bin/mv slow.log slow.log.$(date +%F)&amp;&amp;\
mysqladmin -uroot -p111 -S /data/3306/mysql.sock flush-log

00 00 * * * /bin/sh /server/scripts/cut_slow_log.sh &amp;&gt; /dev/null
</code></pre>
<p><font color="#f8070d" size=3><strong>使用mysqlsla分析慢查询，定时发给相关人员信箱</strong></font></p>
<h3 id="使用explain优化sql语句select">使用explain优化SQL语句（select）</h3>
<p><font color="#f8070d" size=3><strong>抓SQL慢查询语句</strong></font></p>
<pre><code class="language-bash">show full processlist;
mysql -uroot -p111 -S /data/3306/mysql.sock -e &quot;show full processlist;&quot;|egrep -vi &quot;sleep&quot;
</code></pre>
<p><font color="#f8070d" size=3><strong>explain语句检查索引执行情况</strong></font></p>
<pre><code class="language-bash">explain select * from test where name='123'\G;
explain select SQL_NO_CACHE * from test where name='123'\G
</code></pre>
<p><font color="#f8070d" size=3><strong>对需要建立索引的条件列建立索引</strong></font></p>
<p>大表不能高峰期建立索引，300w记录</p>
<p><font color="#f8070d" size=3><strong>分析慢查询的工具mysqlsla</strong></font></p>
<h2 id="二进制日志-binary-log">二进制日志 binary log</h2>
<p>二进制日志 (binary log)：用来记录mysql内部增删改等对mysql数据库有更新的内容的记录（对数据库的改动），对数据库查询的语句如：show、select开头的语句，不会被binlog日志记录，用于数据库的增量恢复，以及主从复制</p>
<pre><code class="language-bash">$ ls
mysql-bin.000002  
mysql-bin.000004  
mysql-bin.000001  
mysql-bin.000003  
mysql-bin.index
</code></pre>
<blockquote>
<p>面试题：在MySQL数据库中，关于binlog日志，下列说法正确的是 ___ ?( A )</p>
<p>A. 依靠足够长度的binlog日志和定期的全备，我们可以恢复任何时间点的单表数据。</p>
<p>B. 以mysql主从同步为例，binlog中会记录主数据库进行的所有操作。</p>
<p>C. 以mysql主从同步为例，binlog中会记录主数据库进行的所有查询操作。</p>
<p>D. binlog通过cat和vi无法查看，但可以通过gedit查看</p>
</blockquote>
<p><font color="#f8070d" size=3><strong>开启mysql的binlog功能</strong></font></p>
<pre><code class="language-bash">log-bin=/data/3306/mysql-bin
max_binlog_cache_size = 5M
max_binlog_size = 20M
</code></pre>
<p><font color="#f8070d" size=3><strong>mysqlbinlog工具解析binlog日志</strong></font></p>
<p>默认情况binlog日志是二进制格式的，不能使用查看文本工具的命令查看，例如 cat vi等</p>
<pre><code class="language-bash">$ file mysql-bin.000004
mysql-bin.000004: MySQL replication log

$ cat mysql-bin.000004 
I.5.54-MariaDBlog*ȎX8
      p5ɎXD9std!testB
</code></pre>
<p><font color="#f8070d" size=3><strong>解析指定库的binlog</strong></font></p>
<p>范例：利用 <code>mysqlbinlog -d</code> 参数解析指定库的binlog日志</p>
<pre><code class="language-bash">$ cat -n 10 1.sql 
29  # at 313  # &lt;=对应的位置
# #170130 13:03:49 2017年01月30日 13:03:49秒 对应的时间
# end_log_pos 结束的位置，对应下面开始的位置
    30  #170130 13:03:49 server id 1  end_log_pos 341   Intvar
    31  SET INSERT_ID=3000001/*!*/;
    32  # at 341
    33  #170130 13:03:49 server id 1  end_log_pos 543   Query   thread_id=1     exec_time=0     error_code=0
    34  use `test`/*!*/;
    35  SET TIMESTAMP=1485752629/*!*/;
    36  insert into test1(num1,num2,num3) values( NAME_CONST('rand_num1',3127167), NAME_CONST('rand_num2',3952885), NAME_CONST('rand_num3',382922))
</code></pre>
<p>结论：mysqlbinlog 工具分库导出 binlog，如果使用 <code>-d 参数</code>，那更新数据时，必须有use database，才能分出指定库的binlog，例如：</p>
<pre><code class="language-bash">use test;
insert into test values (1,'test');
</code></pre>
<p>官方资料：<a href="https://dev.mysql.com/doc/refman/5.7/en/mysqlbinlog.html#option_mysqlbinlog_database" target="_blank"
   rel="noopener nofollow noreferrer" >mysqlbinlog — Utility for Processing Binary Log Files</a></p>
<pre><code class="language-bash"> --database=db_name, -d db_name
This option causes mysqlbinlog to output entries from the binary log (local log only) that occur while db_name is been selected as the default database by USE.
</code></pre>
<p><font color="#f8070d" size=3><strong>按照位置截取：精准，时间长</strong></font></p>
<pre><code class="language-bash">mysqlbinlog mysqlbin.000020 --start-position=200 --stop-position=450 -r pos.sql

# 指定开始位置，不指定结束位置。结束位置为文件结尾
mysqlbinlog mysqlbin.000020 --start-position=200  -r pos.sql

# 指定结束位置，不指定开始位置，开始位置为文件开头
mysqlbinlog mysqlbin.000020 --stop-position=450 -r pos.sql
</code></pre>
<p><font color="#f8070d" size=3><strong>按时间截取：模糊、不准，会丢失数据</strong></font></p>
<pre><code class="language-bash">mysqlbinlog mysql-bin.0020 \
	--start-datatime='1912-10-10 10:10:10' \
	--stop-datetime='2015-10-10 10:10:10' \
	-r time.sql
</code></pre>
<h3 id="mysqlbinlog命令">mysqlbinlog命令</h3>
<ul>
<li>把 binlog 解析为sql语句（包含位置和时间点）</li>
<li><code>-d</code> 参数根据指定库拆分binlog（拆分单表binlog可通过SQL关键字过滤）</li>
<li>通过位置参数截取部分binlog：<code>--start-position=111 --stop-position=500</code>，精确定位取部分内容。</li>
<li>通过时间参数截取部分binglog：<code>--start-datetime='2016-10-10 10:10:10'</code></li>
<li><code>-r fileName</code>，相当于重定向 “&gt;”</li>
<li>解析 row 级别 binlog 日志方法 <code>mysqlbinlog --base64-output=decode-rows -v mysql-bin.000004</code></li>
</ul>
<h3 id="binlog三种模式">binlog三种模式</h3>
<p><font color="#f8070d" size=3><strong>Row Level</strong></font></p>
<p>不记录sql语句上下文相关信息，仅保存哪条记录被修改。</p>
<ul>
<li>
<p>优点：binlog中可以不记录执行的sql语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了。所以rowlevel的日志内容会非常清楚的记录下每一行数据修改的细节。而且不会出现某些特定情况下的存储过程，或function，以及trigger的调用和触发无法被正确复制的问题</p>
</li>
<li>
<p>缺点：所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容,比如一条update语句，修改多条记录，则binlog中每一条修改都会有记录，这样造成binlog日志量会很大，特别是当执行alter table之类的语句的时候，由于表结构修改，每条记录都发生改变，那么该表每一条记录都会记录到日志中。</p>
</li>
</ul>
<p><font color="#f8070d" size=3><strong>Statement Level</strong></font></p>
<p>每一条会修改数据的sql都会记录在binlog中。</p>
<ul>
<li>
<p>优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。(相比row能节约多少性能与日志量，这个取决于应用的SQL情况，正常同一条记录修改或者插入row格式所产生的日志量还小于Statement产生的日志量，但是考虑到如果带条件的update操作，以及整表删除，alter表等操作，ROW格式会产生大量日志，因此在考虑是否使用ROW格式日志时应该跟据应用的实际情况，其所产生的日志量会增加多少，以及带来的IO性能问题。)</p>
</li>
<li>
<p>缺点：由于记录的只是执行语句，为了这些语句能在slave上正确运行，因此还必须记录每条语句在执行的时候的一些相关信息，以保证所有语句能在slave得到和在master端执行时候相同 的结果。另外mysql 的复制,像一些特定函数功能，slave可与master上要保持一致会有很多相关问题(如sleep()函数， last_insert_id()，以及user-defined functions(udf)会出现问题).</p>
</li>
</ul>
<p><font color="#f8070d" size=3><strong>Mixed Level</strong></font></p>
<p>是以上两种level的混合使用，一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用 row 格式保存binlog，MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种。新版本的MySQL中队row level模式也被做了优化，并不是所有的修改都会以row level来记录，像遇到表结构变更的时候就会以statement模式来记录。至于update或者delete等修改数据的语句，还是会记录所有行的变更。</p>
<p><font color="#f8070d" size=3><strong>生产环境如何选择binlog的模式</strong></font></p>
<ol>
<li>互联网公司，使用MySQL的功能相对少（存储过程、触发器、函数），选择默认的语句模式。</li>
<li>公司如果用到使用MySQL的特殊功能（存储过程、触发器、函数）。则选择Mixed。</li>
<li>公司如果公道使用MySQL的特殊功能（存储过程、触发器、函数），又希望数据最大化一致，此时最好用row模式</li>
</ol>
<h3 id="设置mysql-binlog的格式">设置MySQL binlog的格式</h3>
<pre><code class="language-bash">MariaDB &gt;show global variables like '%binlog_format%'; 
+---------------+-----------+
| Variable_name | Value 	|
+---------------+-----------+
| binlog_format | STATEMENT |
+---------------+-----------+

MariaDB &gt;set global binlog_format='row';

MariaDB &gt;show global variables like '%binlog_format%';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| binlog_format | ROW   |
+---------------+-------+
</code></pre>
<p><font color="#f8070d" size=3><strong>永久生效</strong></font></p>
<pre><code class="language-bash">log-bin=mysql-bin
binlog_format=STATEMENT
binlog_format=MIXED
binlog_format=ROW
</code></pre>
<p><font color="#f8070d" size=3><strong>测试ROW模式下的binlog记录日志情况</strong></font></p>
<pre><code class="language-bash">  22 # at 366
  23 # at 1377
  24 # at 2392
  25 # at 3410
  26 # at 4420
  27 # at 5428
  28 #170202  6:29:13 server id 1  end_log_pos 366   Table_map: `test`.`test1` mapped to number 35
  25 # at 3410
  26 # at 4420
  27 # at 5428
  28 #170202  6:29:13 server id 1  end_log_pos 366   Table_map: `test`.`test1` mapped to number 35
  29 #170202  6:29:13 server id 1  end_log_pos 1377  Update_rows: table id 35
  30 #170202  6:29:13 server id 1  end_log_pos 2392  Update_rows: table id 35
  31 #170202  6:29:13 server id 1  end_log_pos 3410  Update_rows: table id 35
  32 #170202  6:29:13 server id 1  end_log_pos 4420  Update_rows: table id 35
  33 #170202  6:29:13 server id 1  end_log_pos 5428  Update_rows: table id 35
  34 #170202  6:29:13 server id 1  end_log_pos 6002  Update_rows: table id 35 flags: STMT_END_F
  35 ### UPDATE `test`.`test1`
  36 ### WHERE
  37 ###   @1=1
  38 ###   @2='3941282'
  39 ###   @3='3149717'
  40 ###   @4='3924740'
  41 ### SET
  42 ###   @1=1
  43 ###   @2='3941282'
  44 ###   @3='test'
  45 ###   @4='3924740'
  46 ### UPDATE `test`.`test1`
  47 ### WHERE
  48 ###   @1=2
  49 ###   @2='174549'
  50 ###   @3='9098525'
  51 ###   @4='4968976'
  52 ### SET
  53 ###   @1=2
  54 ###   @2='174549'
  55 ###   @3='test'
  56 ###   @4='4968976'
  57 ### UPDATE `test`.`test1`
  58 ### WHERE
  59 ###   @1=3
  60 ###   @2='7549308'
  61 ###   @3='2839610'
  62 ###   @4='1550126'
  63 ### SET
  64 ###   @1=3
  65 ###   @2='7549308'
  66 ###   @3='test'
  67 ###   @4='1550126' 
</code></pre>
<p><font color="#f8070d" size=3><strong>statement日志记录</strong></font></p>
<pre><code class="language-bash"># at 313
#170202  6:36:27 server id 1  end_log_pos 403 	Query	thread_id=1	exec_time=0	error_code=0
use `test`/*!*/;
SET TIMESTAMP=1485988587/*!*/;
update test1 set num3='aa1'
/*!*/;
# at 403
#170202  6:36:27 server id 1  end_log_pos 430 	Xid = 11
COMMIT/*!*/;
DELIMITER ;
# End of log file
</code></pre>
<p><font color="#f8070d" size=3><strong>1197</strong></font></p>
<pre><code class="language-bash">ERROR 1197 (HY000) at line 4: Multi-statement transaction required more than 'max_binlog_cache_size' bytes of storage; increase this mysqld variable and try again
</code></pre>
<p>原因：row 格式的 binlog 的特点：在 row 模式下，所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容。所以会造成binlog cache因为过小而中断。</p>
<p>解决设置大的cache</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch06 - MySQL主从复制</title>
      <link>https://www.oomkill.com/2017/05/ch6-mysql-replication/</link>
      <pubDate>Sun, 21 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2017/05/ch6-mysql-replication/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="linux文件数据同步方案">Linux文件数据同步方案</h2>
<p>在讲解MySQL主从复制之前，先回忆下，前面将结果的普通文件（磁盘上的文件）的同步方法。</p>
<p><font color="#f8070d" size=3><strong>文件级别的异机同步方案</strong></font></p>
<ul>
<li>scp/sftp/nc命令可以实现远程数据同步。</li>
<li>搭建ftp/http/svn/nfs服务器，然后在客户端上也可以把数据同步到服务器。</li>
<li>搭建samba文件共享服务，然后在客户端上也可以把数据同步到服务器。</li>
<li>利用rsync/csync2/union等均可以实现数据同步。</li>
</ul>
<hr>
<p><font color="#0215cd" size=3> 提示：union可实现双向同步，csync2可实现多机同步。</font></p>
<hr>
<p>​		以上文件同步方式如果结合定时任务或innotify sersync等功能，可以实现定时以及实时的数据同步。</p>
<ul>
<li>
<p>扩展思想：文件级别复制也可以利用mysql,mongodb等软件作为容器实现。</p>
</li>
<li>
<p>扩展思想：程序向两个服务器同时写数据，双写就是一个同步机制。</p>
</li>
</ul>
<p>​		特点：简单、方便、效率和文件系统级别要差一些，但是被同步的节点可以提供访问。</p>
<ul>
<li>软件的自身同步机制（mysql、oracle、mongdb、ttserver、redis&hellip;..），文件放到数据库，听不到从库，再把文件拿出来。</li>
</ul>
<p><font color="#f8070d" size=3><strong>文件系统级别的异机同步方案</strong></font></p>
<p><strong>drbd基于文件系统同步，相当于网络RAID1，可以同步几乎任何业务数据。</strong></p>
<p>mysql数据的官方推荐drbd同步数据，所有单点服务例如：NFS，MFS(DRBD)，MySQL等度可以用drbd做复制，效率很高，缺点：备机服务不可用。</p>
<p><font color="#f8070d" size=3><strong>数据库同步方案</strong></font></p>
<ul>
<li>自身同步机制：mysql relication，（逻辑的SQL重写）物理复制方法drbd（丛库不提供读写）。</li>
<li>第三方drbd</li>
</ul>
<h2 id="mysql主从复制概述">MySQL主从复制概述</h2>
<p>MySQL的主从复制方案，和上述文件及文件系统级别同步是类似的，都是数据的传输。只不过MySQL无需借助第三方工具，而是其自带的同步复制功能，另外一点，MySQL的主从复制并不是磁盘上文件直接同步，而是逻辑的binlog日志绒布到本地在应用执行的过程</p>
<p>MySQL主从复制是一个异步的复制过程（虽然一般情况下感觉是实时的），数据将从一个MySQL数据库（Master）复制到另一个数据库（Slave），在 mater 与 Slave之 间实现整个主从复制的过程是由三个线程参与完成的。其中有两个线程( SQL和IO )在Slave端，另外一个线程（I/O）在Master端。</p>
<p>要实现MySQL的主从复制，首先必须打开 Master 端的 <code>binlog</code> 记录功能，否则就无法实现。因为整个复制过程实际上就是Slave从Master端获取Binlog日志，然后在Slave上以相同顺序逐自获取 <code>binlog</code> 日志中所记录的各种SQL操作。</p>
<p>要打开MySQL的binlog记录功能，可能通过在MySQL的配置文件 <code>my.cnf</code> 中的 <code>mysqld</code> 模块( [mysqld] )标识后的参数部分增加 “log-bin” 参数选项来实现，具体信息如下：</p>
<pre><code class="language-bash">[mysqld]
log-bin = /data/3307/mysql-bin
</code></pre>
<hr>
<p>提示：log-bin需放置在[mysqld]标识后，否则会导致配置复制不成功。</p>
<hr>
<p>MySQL数据可支持单向、双向、链式级联等不同场景的复制。在复制过程中，一台服务器充当主服务器（Master），而一个或多个其他的服务器充当从服务器（Slave）。</p>
<p>复制可以使单向：M==&gt;S，也可以是双向 M&lt;==&gt;M，当然也可以多M环装同步等。</p>
<p>如果设置了链式级联复制，那么，从（slave）服务器本身除了充当从服务器外，也会同时充当其下面从服务器的主服务器。链式级联复制类似 A==&gt;B==&gt;C==&gt;D 的复制形式。</p>
<p>下面是MySQL各种同步架构的逻辑图。</p>
<p><font style="background:#ffc104;" size=3>单向主从复制逻辑图</font>，次架构只能在Master端进行数据写入。官方给出Slave最多9，工作中不要超过5</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/image-20221213174920924.png" alt="image-20221213174920924" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><font style="background:#ffc104;" size=3>双向主主同步逻辑图</font>，次架构可以再Master1端或Master2端进行数据写入</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/image-20221213175252660.png" alt="image-20221213175252660" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><font style="background:#ffc104;" size=3>线性级联单向双主同步逻辑图</font>，此架构只能在Master1端进行数据写入</p>
<p>缺陷：1 ==&gt;3 之间会存在延迟</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/image-20221213175658442.png" alt="image-20221213175658442" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><font style="background:#ffc104;" size=3>环装级联单向多主同步逻辑图</font>，任意一个点都可以写入数据。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/image-20221213175758789.png" alt="image-20221213175758789" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><font style="background:#ffc104;" size=3>环装级联单向多主多从同步逻辑图</font>，次架构只能在任意一个Master端进行数据写入。</p>
<p>应对读比较多的情况，将所有的从做成负载均衡，三个主做负载均衡。如果其中一个主断掉，其从节点就成了旧数据</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/image-20221213180018027.png" alt="image-20221213180018027" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><font style="background:#ffc104;" size=3>MySQL官方同步架构图</font></p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/image-20221213180057034.png" alt="image-20221213180057034" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="mysql主从复制过程原理">MySQL主从复制过程原理</h3>
<p>下面简单描述下MySQL Replication的复制原理过程</p>
<ol>
<li>在 Slave 服务器上执行 <code>start slave</code> 命令开启主从复制开关，主从复制开始进行。</li>
<li>此时，Slave服务器的 <strong>I/O线程</strong> 会通过在Master上已经授权的复制用户权限请求连接 Master 服务器，并请求从指定 <strong>binlog</strong> 日志文件的指定位置（日志文件名和位置就是在配置主从复制服务时执行change master命令指定的）之后开始发送binlog日志内容。</li>
<li>Master服务器接受到来自 Slave服务器 <strong>I/O线程</strong> 的请求后，其上负责复制的I/O线程会根据Slave服务器I/O线程请求的信息分批读取指定 Binlog 日志文件指定位置之后的 <strong>Binlog</strong> 日志信息，然后返回给 <strong>Slave</strong> 端的 <strong>I/O线程</strong>。返回的信息中除了 Binlog 日志内容外，还有在Master服务器端记录的新的Binlog文件以及在新的Binlog中的下一个指定更新位置。</li>
<li>当Slave服务器的 <strong>I/O线程</strong> 发送的日志内容及日志文件及位置后，会将 Binlog日志 内容依次写入到 Slave 端自身的 <strong>Relay Log</strong>（即<strong>中继日志</strong>）(mysql-relay-bin_xxxxx）端新binlog日志时，能告诉master端服务器需要从新Binlog日志的指定文件及位置开始请求新的binlog日志内容</li>
<li>Slave服务器端的SQL线程会实时地检测本地 <strong>Relay Log</strong> 中 <strong>I/O线程</strong> 新增加的日志内容，然后及时地把 <strong>Relay Log</strong> 文件中的内容解析成SQL语句，并在自身 Slave服务器 上按解析SQL语句的位置顺序执行应用这些SQL语句，并记录当前应用中继日志的文件名及位置点在 **<code>relay-log.info</code>**中。</li>
</ol>
<p>经过了上面的过程，就可以确保在Master端和Slave端执行了同样的SQL语句。当复制状态正常的情况下，Master端和Slave端的数据是完全一样的。当然，MySQL的复制机制也有一些特殊情况，具体请参考官方的说明。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/image-20221213180405932.png" alt="image-20221213180405932" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：MySQL主从复制基本原理</center><br>
<p><font color="#f8070d" size=3><strong>MySQL主从复制原理小结</strong>：</font></p>
<ul>
<li>主从复制是异步的逻辑SQL语句级的复制。</li>
<li>复制时，主库有一个I/O线程，从库有两个线程I/O和SQL线程。</li>
<li>实现主从复制的必要条件是主库要开启记录binlog功能。</li>
<li>作为复制的所有MySQL节点的server-id都不能相同</li>
<li>binlog文件只记录对数据库有关的SQL（来自主数据库内容的变更），不记录任何查询（select show）语句。</li>
</ul>
<h2 id="mysql主从复制配置">MySQL主从复制配置</h2>
<h3 id="环境准备">环境准备</h3>
<p>MySQL主从复制实践对环境的要求比较简单，可以是单机单数据库多实例的环境，也可以是两台服务器，每个机器上独立数据库的环境。</p>
<pre><code class="language-bash">$ ss -lnt
State  Recv-Q Send-Q      Local Address:Port          Peer Address:Port 
LISTEN     0   128         \*:3306                             	\*:\*     
LISTEN     0      128      \*:3307                             	\*:\* 
</code></pre>
<p>提示：这里把3306实例作为主库，3307实例作为从库，如果根据前面的内容配置了mysql多实例环境，直接开启多实例环境使用即可。</p>
<p><font color="#f8070d" size=3><strong>定义主从复制需要的服务器角色</strong></font></p>
<p>主库及从库IP、端口信息：</p>
<ul>
<li>master:	192.168.2.110:3306</li>
<li>slave:	192.168.2.110:3307</li>
</ul>
<p>这里的主从复制技术是针对前面的内容以单机数据库多实例环境来讲的。一般情况下，小企业在做常规的主从复制时，主从服务器多数在不同的机器上，并且监听的端口均为默认的3306。虽然不在同一个机器上，但是步骤和过程却是一样的。</p>
<h3 id="主库部分配置">主库部分配置</h3>
<p><font color="#f8070d" size=3><strong>设置server-id值并开启binlog功能参数</strong></font></p>
<p>根据前文介绍的MySQL主从复制原理我们知道，要实现主从复制，关键是要开启binlog日志功能，所以，首先来打开主库的binlog参数。</p>
<pre><code class="language-bash">[mysqld]
server-id=1	# &lt;=用于同步的每台机器或实例server-id都不能相同			
log-bin=/data/3306/mysql-bin	#&lt;=该部分可省略
</code></pre>
<p>提示：</p>
<ol>
<li>
<p>上面的两个参数要放在my.cnf中的 <code>[mysqld]</code> 模块下，否则会出错。</p>
</li>
<li>
<p><code>server-id</code> 的值使用服务器ip地址最后一个小数点后面数字如：19，目的是避免不同机器或实例ID重复（不适合多实例） 0 &lt; server-id &lt; 232-1的自然数</p>
</li>
<li>
<p>要先在 <code>my.cnf</code> 配置文件中查找相关参数，并按要求修改。若不存在再添加参数。切记参数不能重复</p>
</li>
<li>
<p>修改my.cnf配置后需要重启数据库，命令为: <code>/data/3306/mysql restart</code>，要确认真正重启了</p>
</li>
</ol>
<p><font color="#f8070d" size=3><strong>检查配置参数后的结果</strong></font></p>
<pre><code class="language-bash">$ grep -E 'log-bin|server-id' my.cnf  
log-bin = /data/3306/mysql-bin
server-id = 1
</code></pre>
<p><font color="#f8070d" size=3><strong>登陆数据库检查参数的更改情况（需重启）</strong></font></p>
<pre><code class="language-bash">mysql&gt; show variables like 'server_id';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| server_id	    | 1     |
+---------------+-------+

mysql&gt; show variables like 'log_bin';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| log_bin       | ON    |
+---------------+-------+
</code></pre>
<p><font color="#f8070d" size=3><strong>在主库上建立用于主从复制的账号</strong></font></p>
<p>根据主从复制的原理，从库要想和主库同步，必须有一个可以连接主库的账号，并且这个账号是主库上创建的，权限是允许主库的从库连接并同步数据。</p>
<p><strong>登陆3306实例猪数据库</strong></p>
<pre><code class="language-bash">mysql -uroot -p111 -S /data/3306/mysql.sock
</code></pre>
<p><strong>建立用于从库复制的账号rep</strong>：</p>
<pre><code class="language-bash">grant replication slave on *.* to 'rep'@'192.168.2.%' identified by '1234';
# relication slave为mysql同步的必须权限，此处不要授权all
# *.*表示所有库所有表，也可以指定具体的库和表进行复制，例如shop.test
# rep@'192.168.2.%'为同步账号。192.168.2.%为授权网段，使用%表示192.168.2.0网段以rep用户访问
# identified by '1234' 为密码。生产环境要使用复杂密码
mysql&gt; flush privileges;
</code></pre>
<p><strong>检查主库复制账号权限</strong></p>
<pre><code class="language-bash">mysql&gt; show grants for rep@'192.168.2.%'\G
*************************** 1. row ***************************
Grants for rep@192.168.2.%: GRANT REPLICATION SLAVE ON *.* TO 'rep'@'192.168.2.%' IDENTIFIED BY PASSWORD '*A4B6157319038724E3560894F7F932C8886EBFCF'
</code></pre>
<p><font color="#f8070d" size=3><strong>实现对数据库锁表只读</strong></font></p>
<p><strong>1. 对主数据库锁表只读（当钱窗口不要关闭）的命令</strong>：</p>
<pre><code class="language-bash">flush table with read lock;
# 锁表后新建窗口查看mysql此时是不能插入数据的
</code></pre>
<hr>
<p>提示：在引擎不同的情况，这个锁表命令的时间会受下面参数的控制。锁表时，如果草果设置时间不操作会自动解锁。</p>
<hr>
<p>默认情况下自动解锁的市场参数值如下：</p>
<pre><code class="language-bash">mysql&gt; show variables like '%timeout%';
+----------------------------+----------+
| Variable_name              | Value    |
+----------------------------+----------+
| interactive_timeout        | 28800    |
| wait_timeout               | 28800    |
+----------------------------+----------+
</code></pre>
<p><strong>2. 锁表后查看主库状态。可通过当前binlog日志文件名和二进制binlog日志偏移量来查看</strong></p>
<p>注意，show master status;命令显示的信息要记录在案，后面的从库导入全备后，继续和主库复制时就是要从这个位置开始。</p>
<pre><code class="language-bash">mysql&gt; show master status;
+------------------+----------+--------------+------------------+
| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB |
+------------------+----------+--------------+------------------+
| mysql-bin.000319 |      331 |              |                  |
+------------------+----------+--------------+------------------+

mysql -uroot -p111 -S /data/3306/mysql.sock -e 'show master status;'
</code></pre>
<p><strong>3. 锁表后，一定要单开一个新的SSH窗口，导出数据库的所有数据，如果数据量很大( 50GB+ )，并且允许停机，可以停库直接打包数据文件迁移，那样还快些</strong></p>
<pre><code class="language-bash">mysqldump -uroot -p111 \
	-S /data/3306/mysql.sock \
	--events -A -B|gzip &gt;bak.`date +%F.sql.gz`
</code></pre>
<p>为了确保导出数据期间，数据库没有数据插入，导库完毕可以再检查下主库状态信息。</p>
<pre><code class="language-bash">$ mysql -uroot -p111 -S /data/3306/mysql.sock -e 'show master status;'                      
+------------------+----------+--------------+------------------+
| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB |
+------------------+----------+--------------+------------------+
| mysql-bin.000319 |      331 |              |                  |
+------------------+----------+--------------+------------------+
# 若无特殊情况，binlog文件及位置点和锁表后导出数据前是一致的，即没有变化的。
</code></pre>
<p>导出数据后，解锁主库，恢复可写，因为主库还要对外提供服务，不能一直锁定不让用户访问。</p>
<pre><code class="language-bash">unlock tables;
# 此时新窗口的写入语句会立刻写入数据
</code></pre>
<p>实际上做从库前，无论主库更新多少数据库，最后从库都可以从上面show master status的位置很快赶上主库的进度的。</p>
<p><font color="#f8070d" size=3><strong>将导出数据迁移到从库</strong></font></p>
<p>常用scp rsync等，将备份的数据往异地拷贝。</p>
<p>这里是多实例的主从配置，mysqldum p备份的3306实例的数据和要恢复的3307实例在一台机器上，因此无需异地复制拷贝了，</p>
<p><strong>1. 设置server-id并关闭binlog功能</strong></p>
<p>数据库的server-id一般在一套主从复制体系内是唯一的，这里从库的server-id要和主库及其他的从库不同，并且要注释掉从库的binlog参数，如果从库不做级联复制，并且不做备份用，就不要开启binlog，开启了反而会增加从库磁盘I/O等压力。</p>
<p>如下两种情况需要打开 <code>binlog</code> 功能，记录数据更新的SQL语句</p>
<p>级联同步 A=&gt;B=&gt;C中间的B时，就要开启binlog</p>
<p>在从库做数据库备份，数据库备份必须要有全备和binlog日志，才是完整的备份。</p>
<pre><code class="language-bash">$ grep -E 'server-id|log-bin' my.cnf       
#log-bin = /data/3307/mysql-bin
server-id = 3
</code></pre>
<p>提示：</p>
<ul>
<li>
<p>参数要放在 my.cnf 中的 <code>[mysqld]</code> 模块下，否则会出错。</p>
</li>
<li>
<p>server-id的值可使用服务器ip地址最后一个数字。</p>
</li>
<li>
<p>要先在文件中查找相关参数按要求修改。若发现不存在，再添加参数，切记参数不能同步。</p>
</li>
<li>
<p>修改完配置后需重启数据库。</p>
</li>
</ul>
<p><strong>2. 登陆数据库查看参数改变情况</strong></p>
<pre><code class="language-bash">$ mysql -uroot  -S /data/3307/mysql.sock -e 'show variables like &quot;log_bin&quot;;';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| log_bin       | OFF   |
+---------------+-------+
</code></pre>
<p><strong>3. 将全备恢复到从库</strong></p>
<pre><code class="language-bash">mysql -uroot -p111 -S /data/3307/mysql.sock &lt; bac.sql
</code></pre>
<hr>
<p><font style="background:#659bfd;" size=3>提示：如果备份时使用了-A参数，则在还原数据到3307实例时，登陆3307实例的密码也回合3306主库一致，因为3307的授权表mysql也被覆盖了</font></p>
<hr>
<p><strong>4. 登陆3307从库，配置复制参数</strong></p>
<pre><code class="language-conf">CHANGE MASTER TO
MASTER_HOST='192.168.2.110',
MASTER_PORT=3306,
MASTER_USER='rep',
MASTER_PASSWORD='1234',
MASTER_LOG_FILE='mysql-bin.000322',
MASTER_LOG_POS=188;

CHANGE MASTER TO
MASTER_LOG_FILE='mysql-bin.000322',
MASTER_LOG_POS=107;
</code></pre>
<hr>
<p><font style="background:#659bfd;" size=3>提示：字符串用单引号括起来，数值不用引号，密码需要。内容前后不能用空格</font></p>
<hr>
<p>主从复制是不是成功，其中最关键的为下面三项状态参数：</p>
<pre><code class="language-bash">$ mysql -uroot -S /data/3307/mysql.sock -e 'show slave status\G
'|grep -E 'IO_Running|SQL_Running|Seconds_Behind'
        Slave_IO_Running: Yes
       	Slave_SQL_Running: Yes
        Seconds_Behind_Master: 0
</code></pre>
<ul>
<li><font style="background:#ffc104;" size=3><strong><code>Slave_IO_Running: Yes</code></strong></font>，这个是I/O线程状态，I/O线程负责从从库去主库读取binlog日志，并写入从库的中继日志中，状态为Yes表示I/O线程工作正常。</li>
<li><font style="background:#ffc104;" size=3><strong><code>Slave_SQL_Running: Yes</code></strong></font>，这个是SQL线程状态，SQL线程负责读取中继日志(relay-log)中的数据并转换为SQL语句应用到丛库数据库中，状态为Yes表示I/O线程工作正常。</li>
<li><font style="background:#ffc104;" size=3><strong><code>Seconds_Behind_Master: 0</code></strong></font>，这个是在复制过程中，丛库比主库延迟的秒数，这个参数很重要，但企业里更准确的判断主从延迟的方法为：在主库写时间戳，然后从库读取时间戳和当前数据库时间的进行比较，从而认定是都延迟。</li>
</ul>
<p>有关show slave status结果的说明。请参考MySQL手册。</p>
<h3 id="mysql主从复制配置步骤小结">MySQL主从复制配置步骤小结</h3>
<p>MySQL主从复制配置完整步骤如下：</p>
<ol>
<li>准备两台数据库环境或者单台多实例环境，确定能正常启动和登陆。</li>
<li>配置my.cnf文件：主库配置 <code>log-bin</code> 和 <code>server-id</code> 参数，从库配置 <code>server-id</code> ，该值不能和主库及其他从库一样，一般不开启从库log-bin功能。注意，配置参数后要重启才能生效。</li>
<li>登陆主库增加从库连接主库同步的账户，例如：rep，并授权replication slave同步的权限。</li>
<li>登陆主库，整库锁表 <code>flush table with read lock</code>（关闭窗口后失效，超时时间到了锁表也失效），然后<code>show master status</code> 查看 <code>binlog</code> 的位置状态。</li>
<li>新开窗口，在Linux命令行备份导出原有的数据库数据，并拷贝到丛库所在的服务器目录。如果数据库数据量很大，并且允许停机，可以停机打包，而不用mysqldump。</li>
<li>导出主库数据后，执行 <code>unlock tablesl;</code> 解锁主库。</li>
<li>把主库导出的数据库恢复到从库。</li>
<li>根据主库的<code>show master status</code> 查看到 <code>binlog</code> 的位置状态，在从库执行 <code>change master to</code> 语句</li>
<li>从库开启复制开关即执行 <code>start slave</code>。</li>
<li>从库 <code>show slave status\G</code></li>
</ol>
<p><font color="#f8070d" size=3><strong>快速配置MySQL主从复制</strong></font></p>
<p>步骤</p>
<ol>
<li>安装好要配置从库的数据库，配置好 <code>log-bin</code> 和 <code>server-id</code> 参数</li>
<li>无需配置主从库 <code>my.cnf</code> 文件，主库 <code>log-bin</code> 和 <code>server-id</code> 参数默认就是配置好的。</li>
<li>登陆主库，增加从库链接主库同步的账户，例如：rep，并授权 <code>replication slave</code> 同步的权限。</li>
<li>使用在半夜通过定时任务备份 <code>mysqldump</code> 带 <code>-x</code> 和 <code>--master-date=1</code> 的命令及参数的全备数据，恢复到从库</li>
<li>在从库执行 <code>change master to..</code> 语句，无需 <code>binlog</code> 文件及对应位置点。</li>
<li>从库开启同步开关，<code>start slave</code></li>
<li>从库 <code>show slave status\G</code>，检查同步状态，并在主库进行更新测试。</li>
</ol>
<h2 id="mysql主从复制线程状态说明及用途">MySQL主从复制线程状态说明及用途</h2>
<h3 id="mysql主从复制主库io线程状态说明">MySQL主从复制主库I/O线程状态说明</h3>
<p>登陆主数据库查看MySQL线程的同步状态。</p>
<pre><code class="language-bash">mysql&gt; show processlist\G;
*************************** 1. row ***************************
     Id: 7
   User: rep
   Host: 192.168.2.110:39610
     db: NULL
Command: Binlog Dump
   Time: 57983
  State: Master has sent all binlog to slave; waiting for binlog to be updated
   Info: NULL
*************************** 2. row ***************************
     Id: 11
   User: rep
   Host: 192.168.2.110:39614
     db: NULL
Command: Binlog Dump
   Time: 21942
  State: Master has sent all binlog to slave; waiting for binlog to be updated
   Info: NULL
*************************** 3. row ***************************
     Id: 16
   User: root
   Host: localhost
     db: information_schema
Command: Query
   Time: 0
  State: NULL
   Info: show processlist
3 rows in set (0.00 sec)

ERROR: 
No query specified
# 上述两个从库，每个从库对应一个I/O线程
</code></pre>
<hr>
<p><font color="#0215cd" size=3> 提示：上述状态的意思是线程已经从binlog日志读取所有更新，并已经发送到了从数据库服务器，线程现在为空闲状态，等待由主服务器上二进制日志中的新事件更新</font></p>
<hr>
<p>下表列出主服务器的 binlog Dump线程中State列的最常见状态。如果没有在主服务器上看见任何Binlog Dump线程，则说明复制没有在运行，二进制binlog日志由各种事件组成，一个事件会通常为一个更新加一些其他信息。</p>
<table>
<thead>
<tr>
<th>状态</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sending binlog event to slave</td>
<td>线程已经从二进制binlog读取了一个事件并且正将它发送到从服务器</td>
</tr>
<tr>
<td>Finished reading on binlog switching to next binlog</td>
<td>线程已经读完二进制binlog日志文件，并且正在打开下一个要发送到从服务器的binlog日志文件</td>
</tr>
<tr>
<td>Has sent all binlog to slave;waiting for binlof to be update</td>
<td>线程已经从binlog日志读取所有的更新并已经发送到了从数据库服务器。线程现在为空闲状态，等待由主服务器上二进制binlog日志中的新事件更新。</td>
</tr>
<tr>
<td>Waiting to finalize termination</td>
<td>线程停止时发生了一个简单的状态</td>
</tr>
</tbody>
</table>
<p>登陆从数据库查看mysql线程工作状态，从库有两个线程，即I/O和SQL线程。</p>
<p>下面是从I/O线程的状态。</p>
<pre><code class="language-bash">mysql&gt; show processlist\G
*************************** 1. row ***************************
     Id: 7
   User: system user
   Host: 
     db: NULL
Command: Connect
   Time: 33004
  State: Waiting for master to send event
   Info: NULL
*************************** 2. row ***************************
     Id: 8
   User: system user
   Host: 
     db: NULL
Command: Connect
   Time: 3510
  State: Slave has read all relay log; waiting for the slave I/O thread to update it
   Info: NULL
*************************** 3. row ***************************
</code></pre>
<p>下表列出了从库服务器的I/O线程的state列的最常见的状态。该状态也出现在Slave_IO_State列，有show slave status;显示</p>
<table>
<thead>
<tr>
<th>从库I/O线程工作状态</th>
<th>解释说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Connecting to master</td>
<td>线程正试图连接主服务器</td>
</tr>
<tr>
<td>Checking master version</td>
<td>同主服务器之间建立连接后临时出现的状态</td>
</tr>
<tr>
<td>Registering slave on master</td>
<td></td>
</tr>
<tr>
<td>Requesting binlog dump</td>
<td>建立同主服务器之间的连接后立即临时出现的状态。线程向主服务器发送一条请求，索取从请求的二进制binlog日志文件名和位置开始的二进制binlog日志的内容。</td>
</tr>
<tr>
<td>Waiting to reconnect after a failed binlogdump request</td>
<td>如果二进制binlog日志转储请求失败，线程进入睡眠状态，然后定期尝试重新连接。可以使用&ndash;master-connect-retry选项指定重试之间的间隔。</td>
</tr>
<tr>
<td>Reconnect after a failed binlog dump request</td>
<td>线程正尝试重新连接主服务器。</td>
</tr>
<tr>
<td>Waiting for master to sent event</td>
<td>线程已经连接上主服务器，正等待二进制binlog日志事件到达。</td>
</tr>
<tr>
<td>Queueing master event to the relay log</td>
<td>线程已经读取一个事件，正将它复制到中继日志供SQL线程来处理</td>
</tr>
<tr>
<td>Reconnecting after failed master event read</td>
<td>线程正尝试重新连接主服务器。当连接重新建立后，状态变为 Waiting for master to send event</td>
</tr>
</tbody>
</table>
<p>下面是从库SQL线程的状态</p>
<pre><code class="language-bash">*************************** 2. row ***************************
     Id: 8
   User: system user
   Host: 
     db: NULL
Command: Connect
   Time: 5460
  State: Slave has read all relay log; waiting for the slave I/O thread to update it
   Info: NULL
</code></pre>
<table>
<thead>
<tr>
<th>从库SQL线程状态</th>
<th>解释说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Reading event from the relay log</td>
<td>线程已经从中继日志读取一个事件，可以对事件进行处理了。</td>
</tr>
<tr>
<td>Has read all relay log;waiting for the slave I/O thread to update it</td>
<td>线程已经处理了中继日志文件中的所有事件，现在正等待I/O线程将新事件写入中级日志。</td>
</tr>
<tr>
<td>Waiting for slave mutex on exit</td>
<td>线程停止时发生的一个很简单的状态。</td>
</tr>
</tbody>
</table>
<p>更多状态在mysql手册6.3章节</p>
<h3 id="查看mysql线程同步状态的用途">查看MySQL线程同步状态的用途</h3>
<p><font color="#f8070d" size=3><strong>故障1：主库show master status;没返回状态结果</strong></font></p>
<pre><code class="language-bash">mysql&gt; show master status;
Empty set (0.00 sec)
</code></pre>
<p>解答：上述问题原因是主库binlog功能没有开启或没生效</p>
<p><font color="#f8070d" size=3><strong>故障2：出现Last_IO_Error:Got fatal error 1236 from master when reading date from binary log:&rsquo;&rsquo;</strong></font></p>
<pre><code class="language-bash">Last_IO_Error: Got fatal error 1236 from master when reading data from binary log: 'Could not find first log file name in binary log index file'
</code></pre>
<p>原因：</p>
<ol>
<li>主库停机导致binlog错误</li>
<li>从库执行change master命令时某一个参数的值多了空格，因而产生错误</li>
</ol>
<p>解决方法</p>
<pre><code class="language-bash">flush logs;
show master status;
slave start;
show slave status \G
</code></pre>
<p><font color="#f8070d" size=3><strong>故障3：Fatal error: The slave I/O thread stops because master and slave have equal MySQL server ids;</strong> </font></p>
<pre><code class="language-bash">Last_IO_Error: Fatal error: The slave I/O thread stops because master and slave have equal MySQL server ids; these ids must be different for replication to work (or the --replicate-same-server-id option must be used on slave but this does not always make sense; please check the manual before using it).
</code></pre>
<p>原因sever-id与主一致，更改后重启服务器恢复。</p>
<h3 id="工作中mysql从库停止复制故障案例">工作中MySQL从库停止复制故障案例</h3>
<p>模拟重现故障的能力是运维人员最重要的能力。先从从库创建一个库，然后去主库创建同名的库来模拟数据冲突。</p>
<pre><code class="language-bash">mysql&gt; show slave status\G;
....
....
               Last_IO_Errno: 0
               Last_IO_Error: 
               Last_SQL_Errno: 1007
               Last_SQL_Error: Error 'Can't create database 'test123'; database exists' on query. Default database: 'test123'. Query: 'create database test123 default character set utf8'
  Replicate_Ignore_Server_Ids: 
             Master_Server_Id: 1
</code></pre>
<p><font color="#f8070d" size=3><strong>对于该冲突，解决方法1</strong>：</font></p>
<pre><code class="language-bash">stop slave; # 临时停止同步开关
set global sql_slave_skip_counter=1;# 将同步指针想下移动一个，如果多次不同步，可以重复操作
start slave;

mysql&gt; show slave status\G
....
....
               Last_IO_Errno: 0
               Last_IO_Error: 
               Last_SQL_Errno: 0
               Last_SQL_Error: 
  Replicate_Ignore_Server_Ids: 
             Master_Server_Id: 1
</code></pre>
<p>对于普通的互联网业务，上述的移动指针的命令操作带来的问题不是很大。当然要确认不影响公司业务的前提下。</p>
<p>若是在企业场景下，对当前业务来说，解决主从同步比主从不一致更重要，如果主从数据一致也是很重要的，那就再找个时间恢复下这个从库。</p>
<p>主从数据不一致更重要还是保持主从同步持续状态更重要，则要根据业务选择。</p>
<p>这样Slave就会和Master同步了，其关键点为：</p>
<pre><code class="language-bash">Slave_IO_Running:Yes
Slave_SQL_Running:Yes
Senconds_Behind_Master # 是否为0 0表示已经同步状态
</code></pre>
<hr>
<p>提示：``set global sql_slave_skip_counter=n`  n取值&gt;0，忽略执行N个更新。</p>
<hr>
<p><font color="#f8070d" size=3><strong>解决方法2：根据可以忽略的错误号事先在配置文件中配置，跳过指定的不同映像业务数据的错误，例如</strong>：</font></p>
<pre><code class="language-bash">slave-skip-errors=1032,1062,1007
</code></pre>
<hr>
<p>提示：类似由于入库重复导致的失败可以忽略，其他情况是不是可以忽略需要根据不同送死的具体业务来评估</p>
<hr>
<pre><code class="language-bash">mysql&gt; show slave status\G      
*************************** 1. row ***************************
               Slave_IO_State: Waiting for master to send event
                 ....
             ....
             Slave_IO_Running: Yes
            Slave_SQL_Running: No
              Replicate_Do_DB: 
         		....
            ....
          Last_SQL_Errno: 1007
          Last_SQL_Error: Error 'Can't create database 'zhangsan'; database exists' on query. Default database: 'zhangsan'. Query: 'create database zhangsan'
</code></pre>
<p>其他可能引起复制故障的问题：</p>
<p>MySQL自身的原因及认为重复插入数据。</p>
<p>不同的数据库版本会引起不同步，低版本到高版本可以，但是高版本不能往低版本同步。</p>
<p>MySQL的运行错误或者程序BUG。</p>
<p>binlog记录模式，例如：row level模式就比默认的语句模式要好。</p>
<h2 id="让mysql从库记录binlog日志方法">让MySQL从库记录binlog日志方法</h2>
<p>从库需要记录binlog的应用场景为：当前的从库还要作为其他从库的主库，例如：级联复制或双主互为主从场景的情况下。从库记录binlog日志的方法：</p>
<p>在从库的 <code>my.cnf</code> 中加入如下参数，然后重启服务生效即可。</p>
<pre><code class="language-conf">log-slave-updaes # 必须要有这个参数
log-bin=/data/3306/mysql-bin
expire_logs_days=7 # binlog日志过期参数，过期自动删除
</code></pre>
<h2 id="mysql主从复制集群架构的数据备份策略">MySQL主从复制集群架构的数据备份策略</h2>
<p>有了主从复制了，还需要做定时全量加增量备份么？答案是肯定的</p>
<p>因为，如果主库有语句级误操作（例如：<code>drop database test;</code> ），从库也会这行 <code>drop database test;</code> ，这样MySQL主从库就都删除了该数据。</p>
<p>把从库作为数据库备份服务器时，备份策略如下：</p>
<ul>
<li>高并发业务场景备份时，可以选择在一台数据库上备份（Slave5），把从库作为数据库备份服务器时需要在从库开启 <code>binlog</code> 功能，如图所示</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/image-20221214195010930.png" alt="image-20221214195010930" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><font color="#f8070d" size=3><strong>步骤如下</strong></font></p>
<ol>
<li>选择一个不对外提供服务器的从库，这样可以确保和主库更新最接近，专门做数据备份用。</li>
<li>开启从库binlog功能。</li>
</ol>
<p>备份时可以选择只停止 <strong>SQL</strong> 线程，停止应用SQL语句到数据库，I/O线程保留工作状态，执行命令为 <code>stop slave sql_thread;</code> ，备份方式可以采取 <strong>mysqldump</strong> 逻辑备份或者直接物理备份，例如：<code>cp tar</code>（打包目录）工具，或 <strong>xtrabackup</strong>（第三方的物理备份软件）进行备份，逻辑备份和物理备份的选择，一般是根据总的本分数据了多少进行选择，数据量低于20G，建议选择 mysqldump 逻辑备份方法，安全稳定，最后把全备和 binlog 数据发总到备份服务器上留存</p>
<h2 id="mysql主从复制延迟问题原因及解决方案">MySQL主从复制延迟问题原因及解决方案</h2>
<p><strong><font color="#0215cd" size=3>问题一：一个主库的从库太多，导致复制延迟</font></strong></p>
<p>建议从库数量3-5个为宜，要复制的节点数量过多，会导致复制延迟。</p>
<p><strong><font color="#0215cd" size=3>问题二：从库硬件比主库差，导致复制延迟</font></strong></p>
<p>查看master和slave的系统配置，可能会因为机器配置的问题，包括磁盘IO、CPU内存等各方面因素曹成复制的延迟，一般发生在高并发大数据量写入场景。</p>
<p><strong><font color="#0215cd" size=3>问题三：慢查询SQL语句过多</font></strong></p>
<p>假如一条SQL语句，执行时间是20秒，那么从执行完毕，到从库上能查到数据也至少是20秒，这样就延迟了20秒</p>
<p>SQL语句的优化一般要作为常规工作不断的监控和优化，如果是单个SQL的写入时间长，可以修改后分多次写入，通过查看慢查询日志或 <code>show full processlist</code> 命令找出执行时间长的查询语句或者大的事务。</p>
<p><strong><font color="#0215cd" size=3>问题四：主从复制的设计问题</font></strong></p>
<p>例如，主从复制单线程，如果主库写并发太大，来不及传送到从库就会导致延迟，更高版本的MySQL可以支持多线程复制(MySQL5.6 Mariadb10.0)，门户网站则会自己开发多线程同步功能。</p>
<p><strong><font color="#0215cd" size=3>问题五：主从之间的网络延迟</font></strong></p>
<p>主从库的网卡，网线，链接的交换机等网络设备都可能成为复制的瓶颈，导致复制延迟。另外，跨公网主从复制很容易导致主从复制延迟。</p>
<p><strong><font color="#0215cd" size=3>问题六：主库读写压力大，导致复制延迟</font></strong></p>
<p>主库的硬件要搞好一些，架构的前端要加buffer以及缓存层。</p>
<h2 id="通过read-only让主库只读访问">通过read-only让主库只读访问</h2>
<p>read-only参数选项可以让出服务器只允许来自从服务器线程或具有SUPER权限的数据库用户进行更新。可以确保从服务器不接受来自用户端的非法用户更新。</p>
<p>read-only参数允许数据库更新的条件为：</p>
<ol>
<li>具有SUPER权限的用户可以更新，不收read-only参数影响。例如：管理员root（<strong>注：工作中用户连接的账号授权不要给all，这样可以防止用户写数据</strong>）</li>
<li>来自从服务器线程可以更新，不收read-only参数影响，例如，前文的rep用户，在生产环境中，可以再从库Slave中使用read-only参数，确保从库数据不被非法更新。</li>
</ol>
<h3 id="read-only参数配置方法如下">read-only参数配置方法如下</h3>
<p><font color="#f8070d" size=3><strong>方法一：启动数据库时直接带&ndash;read-only参数启动或重启使用</strong></font></p>
<pre><code class="language-bash">killall mysqld
mysqladmin -uroot -p111 -S /data/3307/mysql.sock shutdown 
mysqld_safe --defaults-file=/data/3307/my.cnf --read-only &amp;
</code></pre>
<p><font color="#f8070d" size=3><strong>方法二：在my.cnf中[mysqld]模块下加read-only参数，然后重启数据库，配置如下</strong></font></p>
<pre><code class="language-conf">[mysqld]
read-only
</code></pre>
<h3 id="web用户专业设置方案mysql主从复制读写分离集群">Web用户专业设置方案：MySQL主从复制读写分离集群</h3>
<p>专业的运维人员提供给开发人员的读写分离账户设置方法如下：</p>
<ol>
<li>访问主库和从库使用一套用户密码，例如：用户为web，密码为111</li>
<li>即使访问IP不同，端口也尽量相同（3306）。例如：写库VIP为10.0.0.7，读库VIP10.0.0.8。</li>
</ol>
<p>除了IP没办法修改之外，要尽量为开发人员提供方便，如果是数据库前段有DAL层（dbproxy），还可以只给开发人员一套用户、密码、IP、端口，这样就更专业了，剩下的都由鱼尾人员搞定。</p>
<p>下面是授权web连接用户访问的方案：MySQL主从复制读写分离集群。</p>
<p><font color="#f8070d" size=3><strong>方法1：从库和主库使用不同的用户，授权不同的权限</strong></font></p>
<p>主库上对web_m用户授权</p>
<ul>
<li>
<p>用户：web_m，密码：111 端口：3306 主库VIP：10.0.0.7</p>
</li>
<li>
<p>权限：select insert update delete</p>
</li>
<li>
<p>命令：<code>grant select,insert,update,delete on web.* to web_m@10.0.0.% identified by '111'</code></p>
</li>
</ul>
<p>主库上对web_s用户授权</p>
<ul>
<li>
<p>用户：web_s，密码：111 端口：3306 主库VIP：10.0.0.8</p>
</li>
<li>
<p>权限：select</p>
</li>
<li>
<p>命令：<code>grant select on web.* to web_m@10.0.0.% identified by '111'</code></p>
</li>
</ul>
<p>提示：此方法不够专业，但是可以满足开发需求</p>
<p><font color="#f8070d" size=3><strong>方法2：主库和从库使用相同的用户，但授予不同的权限</strong></font></p>
<p>主库上对web用户授权</p>
<ul>
<li>用户：web密码：111 端口：3306 主库VIP：10.0.0.7</li>
<li>权限：select insert update delete</li>
<li>命令：<code>grant select,insert,update,delete on web.* to web_m@10.0.0.% identified by '111'</code></li>
</ul>
<p>从库上对web用户授权</p>
<ul>
<li>用户：web_m，密码：111 端口：3306 主库VIP：10.0.0.7</li>
<li>权限：select</li>
<li>命令：<code>grant select on web.* to web_m@10.0.0.% identified by '111'</code></li>
</ul>
<p>提示：由于主库和从库是同步复制的，所以从库上的web用户会自动和主库一致，即无法实现只读select权限</p>
<p><font color="#f8070d" size=3><strong>要实现方法2中的授权方案，有两个方法</strong></font></p>
<ol>
<li>在主库上创建完用户和权限，从库上revoke收回对应更新权限（insert,update,delete）。</li>
</ol>
<pre><code class="language-bash">revoke insert,update,delete on `web`.* from web@10.0.0.%;
</code></pre>
<ol start="2">
<li>忽略授权库mysql同步，主库的配置参数如下：</li>
</ol>
<pre><code class="language-conf">binlog-ignore-db = mysql
replicate-ignore-db = mysql
# 参数两旁必须有空格
</code></pre>
<p><font color="#f8070d" size=3><strong>方法3：在从库上设置read-only参数，让从库只读</strong></font></p>
<p>从库主库：主库和从库使用相同的用户，授予相同的权限（非ALL权限）</p>
<ul>
<li>用户：web密码：111 端口：3306 主库VIP：10.0.0.7</li>
<li>权限：select insert update delete</li>
<li>命令：<code>grant select,insert,update,delete on web.* to web_m@10.0.0.% identified by '111'</code></li>
</ul>
<p>由于主库设置了read-only，非super权限是无法写入的，因此，通过read-only参数就可以很好的控制用户非法将数据写入从库。</p>
<p><font color="#f8070d" size=3><strong>生产工作场景的设置方案如下</strong>：</font></p>
<ol>
<li>忽略主库mysql同步</li>
<li>主库和从库使用相同的用户，但授权不同的权限</li>
<li>在从库上设置read-only参数，让从库只读。</li>
</ol>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch02 - MySQL安全相关配置</title>
      <link>https://www.oomkill.com/2017/05/ch2-mysql-security/</link>
      <pubDate>Tue, 16 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2017/05/ch2-mysql-security/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="设置mysql管理员账号密码">设置MySQL管理员账号密码</h2>
<p>在安装MySQL数据库后，MySQL管理员的账号root密码默认为空，极不安全</p>
<p><strong>启动修改丢失的MySQL单实例root密码方法</strong></p>
<p>停止MySQL</p>
<pre><code class="language-bash">/etc/init.d/mysqld stop
</code></pre>
<p><strong>使用 &ndash;skip-grant-tables启动mysql，忽略授权登陆验证</strong></p>
<pre><code class="language-bash"># 单实例
/app/mysql/bin/mysqld_safe --skip-grant-tables --user=mysql
# 多实例
/app/mysql/bin/mysqld_safe --defaults-file=/data/3306/my.cnf --user=mysql --skip-grant-tables &amp;
# 登录时空密码

$ mysql -S /data/3306/mysql.sock
...
...
Welcome to the MySQL monitor.  Commands end with ; or \g.
# 在启动时加 --skip-grant-tables参数，表示忽略授权
</code></pre>
<p><strong>修改root密码为新密码</strong></p>
<pre><code class="language-bash">mysql&gt; set password=password('123');
ERROR 1290 (HY000): The MySQL server is running with the --skip-grant-tables option so it cannot execute this statement
mysql&gt; update mysql.user set password=password('123') where user='root';      
Query OK, 4 rows affected (0.00 sec)
Rows matched: 4  Changed: 4  Warnings: 0
mysql&gt; flush privileges;
</code></pre>
<p><strong>重启服务再登陆</strong></p>
<pre><code class="language-bash"># 此时发现用原密码不能登陆mysql了
$ mysql -uroot -S /data/3306/mysql.sock
ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: NO)

$ mysql -uroot -S /data/3306/mysql.sock -p111
ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: YES)

$ mysql -uroot -S /data/3306/mysql.sock -p123
Welcome to the MySQL monitor.  Commands end with ; or \g.
</code></pre>
<p><strong>提示</strong>：<font color="#659bfd;" size=3>启动时加 <code>--skip-grant-tables</code> 参数启动登陆修改完密码后一定要重启再对外提供服务，skip一定要放到后面</font></p>
<h2 id="清理无用的mysql用户与库">清理无用的MySQL用户与库</h2>
<p>清理无用的库</p>
<pre><code class="language-bash">mysql&gt; show databases;
+---------------------+
| Database            |
+---------------------+
| information_schema  |
| mysql               |  # 这个是mysql系统信息
| performance_schema  |
| test                |  # 这个相当于linux的/tmp，不用保留，直接删掉
+---------------------+
</code></pre>
<p>语法：dorp user &lsquo;<strong>user</strong>&rsquo;@&rsquo;<strong>host/ip</strong>&rsquo;  &lt;= 注意引号，可以使单或双引号</p>
<pre><code class="language-bash">mysql&gt; DROP USER 'root'@'::1';
mysql&gt; FLUSH PRIVILEGES;
</code></pre>
<p>注意：如果drop删除不了（一般为特殊字符或大写），可以用下面方式删除（以root用户，oldboy主机为例）：</p>
<pre><code class="language-bash">DELETE FROM mysql.user WHERE user= 'root' AND host='oldboy';
flush privileges;
</code></pre>
<p>处理完用户必须执行 <code>flush privileges</code></p>
<h2 id="创建mysql用户及赋予用户权限">创建MySQL用户及赋予用户权限</h2>
<p>通过help查看grant命令帮助</p>
<pre><code class="language-bash">mysql&gt; help grant
Name: 'GRANT'
Description:
Syntax:
GRANT
    priv_type [(column_list)]
      [, priv_type [(column_list)]] ...
    ON [object_type] priv_level
    TO user [auth_option] [, user [auth_option]] ...
    [REQUIRE {NONE | tls_option [[AND] tls_option] ...}]
    [WITH {GRANT OPTION | resource_option} ...]

GRANT PROXY ON user
    TO user [, user] ...
    [WITH GRANT OPTION]
....
....

CREATE USER 'jeffrey'@'localhost' IDENTIFIED BY 'mypass';
GRANT ALL ON db1.* TO 'jeffrey'@'localhost';
GRANT SELECT ON db2.invoice TO 'jeffrey'@'localhost';
GRANT USAGE ON *.* TO 'jeffrey'@'localhost' WITH MAX_QUERIES_PER_HOUR 90;
</code></pre>
<p>通过查看grant的命令帮助，可以很容易的找到创建用户并授权的例子。</p>
<p><strong><font color="#f8070d" size=3>比较常见的创建用户的方法是，使用grant命令在创建用户的通同时进行授权。具体例子：</font></strong></p>
<pre><code class="language-bash">GRANT ALL ON db1.* TO 'lc'@'localhost' IDENTIFIED BY '111';
</code></pre>
<p><strong><font color="#f8070d" size=3>上述grant命令帮助里还提供了一个先用create命令创建用户，然后再用grant授权的方法，即创建用户和授权分开进行</font></strong></p>
<pre><code class="language-bash">CREATE USER 'jeffrey'@'localhost' IDENTIFIED BY 'mypass';	 # 创建用户

useradd Jeffrey|passwd --stdin jeffrey

GRANT ALL ON db1.* TO 'jeffrey'@'localhost'; 	# 对用户授权
</code></pre>
<p><strong><font color="#f8070d" size=3>通过grant命令创建用户并授权</font></strong></p>
<pre><code class="language-bash">grant all privileges on dbname.* to username@'localhost' identified by 'passwd'
</code></pre>
<p>列表说明如下</p>
<table>
<thead>
<tr>
<th>grant</th>
<th>all privileges</th>
<th>on dbname.*</th>
<th>to username@localhost</th>
<th>identified by &lsquo;passwd&rsquo;</th>
</tr>
</thead>
<tbody>
<tr>
<td>授权命令</td>
<td>对应权限</td>
<td>目标：表和库</td>
<td>用户名和客户端主机</td>
<td>用户密码</td>
</tr>
</tbody>
</table>
<p>说明：上述命令是授权localhost主机上通过用户username管理dbname数据库的所有权限，密码为passwd。其中username，dbname，passwd可根据业务的情况修改。</p>
<p><strong><font color="#f8070d" size=3>create和grant配合法</font></strong></p>
<p>创建用户名username及密码passwd，授权主机localhost。</p>
<pre><code class="language-bash">create user 'username'@'localhost' identified by 'passwd';
</code></pre>
<p>然后授权localhost主机上通过用户名username管理dbname数据库的所有权限，无需密码。</p>
<pre><code class="language-bash">grant all on dbname.* to 'username'@'localhost';
</code></pre>
<h2 id="操作示例">操作示例</h2>
<p>案例1：创建oldboy用户，对zhangsan库具备所有权限，允许localhost主机登陆管理数据库，密码是oldboy123</p>
<p>实现具体命令：</p>
<pre><code class="language-bash">GRANT ALL PRIVILEGES ON oldboy.* TO zhangsan@'localhost' IDENTIFIED BY '123';
</code></pre>
<p><strong>演示</strong>：</p>
<pre><code class="language-bash"># 查看当前数据库情况，然后执行对应命令授权如下：
select user,host from mysql.user;

# 查看zhangsan具体权限
show grants for zhangsan@'localhost';
</code></pre>
<p><strong>案例2：创建oldgirl用户，对test库具备所有权限，允许localhost主机登陆管理数据库的所有权限，无需密码</strong></p>
<p><font color="#0215cd" size=3> 查看当前数据库用户情况，然后执行命令创建用户</font></p>
<pre><code class="language-bash">mysql&gt; select user,host from mysql.user;
+----------+--------------+
| user     	| host        |
+----------+--------------+
| root   	| 127.0.0.1   |
| zhangsan	| 172.168.1.% |
| root     	| localhost   |
| zhangsan	| localhost   |
+----------+--------------+
</code></pre>
<p><font color="#0215cd" size=3>创建用户，指定密码，提示：仅仅是创建用户并未授权</font></p>
<pre><code class="language-bash">create user 'oldgirl'@'localhost';
grant all on test.* to 'oldgirl'@'localhost';
</code></pre>
<p><font color="#0215cd" size=3> 查看授权后的MySQL用户列表情况</font></p>
<pre><code class="language-bash">mysql&gt; show grants for 'oldgirl'@'localhost';
+-----------------------------------------------------------+
| Grants for oldgirl@localhost                              |
+-----------------------------------------------------------+
| GRANT USAGE ON *.* TO 'oldgirl'@'localhost'			    |
| GRANT ALL PRIVILEGES ON `test`.* TO 'oldgirl'@'localhost' |
+-----------------------------------------------------------+
# 默认权限是usage，即连接的权限，因为此时还没有权限。
# 第二个表示对test库有所有权限
</code></pre>
<h2 id="授权局域网内主机远程链接数据库">授权局域网内主机远程链接数据库</h2>
<p>根据grant命令语法，知道test@&rsquo;localhsot&rsquo;位置为授权方位数据库的主机，localhost可以用域名，IP或IP段来代替，因此，要授权局域网内主机可以通过如下方法实现</p>
<p><strong>一条命令，“百分号” 匹配法</strong></p>
<pre><code class="language-bash">grant all on *.* to test@'10.0.0.%' identified by '111';
</code></pre>
<p><strong>一条命令，“子网掩码” 配置法</strong></p>
<pre><code class="language-bash">grant all on *.* to test@'10.0.0.0/255.255.255.0' identified by '111'
# 子网掩码部分不要用24
</code></pre>
<p><strong>两条命令实现</strong></p>
<pre><code class="language-bash">create user test@'10.0.0.%' identified by '111'
grant all on *.* to test@'10.0.0.%'
</code></pre>
<p><strong><font color="#f8070d" size=3>最后记得上述每条grant命令都要刷新权限</font></strong></p>
<pre><code class="language-bash">flush privileges
</code></pre>
<hr>
<p><font color="#0215cd" size=3> 提示：如果是web链接数据库的用户，尽量不要授权all，而是select,insert,update,delete&hellip;.</font></p>
<hr>
<h2 id="通过mysql客户端链接异地数据库服务">通过MySQL客户端链接异地数据库服务</h2>
<p>本地 <code>mysql -uroot -p111</code> 连接相当于 <code>mysql -uroot -p111 -hlocalhost</code></p>
<p>要远程链接10.0.0.7的数据库，命令为 <code>mysql -utest -p111 -h10.0.0.7</code>，如果要能链接成功，还需要在10.0.0.7 的数据库服务器上通过如下命令授权：</p>
<pre><code class="language-bash">grant all on *.*  to test@'10.0.0.%'identified by '111'
</code></pre>
<h2 id="用户可以授权的权限都有那些">用户可以授权的权限都有那些?</h2>
<p>通过实验获得all privileges包括那些权限，</p>
<p><strong>先看看前面授权过的oldgirl的权限</strong></p>
<pre><code class="language-bash">mysql&gt; show grants for oldgirl@'localhost';
+-----------------------------------------------------------+
| Grants for oldgirl@localhost                              |
+-----------------------------------------------------------+
| GRANT USAGE ON *.* TO 'oldgirl'@'localhost'			 	|
| GRANT ALL PRIVILEGES ON `test`.* TO 'oldgirl'@'localhost' |
+-----------------------------------------------------------+
# 此时查看，还是all privileges权限，但并未细分
</code></pre>
<p>取消 oldgirl 的只读权限（SELECT）看看结果</p>
<pre><code class="language-bash">mysql&gt; help revoke
Name: 'REVOKE'
Description:
Syntax:
REVOKE
    priv_type [(column_list)]
      [, priv_type [(column_list)]] ...
    ON [object_type] priv_level
    FROM user [, user] ...

REVOKE ALL PRIVILEGES, GRANT OPTION
    FROM user [, user] ...

REVOKE PROXY ON user
    FROM user [, user] ...
....
....
REVOKE INSERT ON *.* FROM 'jeffrey'@'localhost';
....
....
# 通过help revoke可以看出删除一个权限的方法
</code></pre>
<p>使用revoke移除授权</p>
<pre><code class="language-bash">mysql&gt; revoke SELECT on test.* from oldgirl@'localhost';
Query OK, 0 rows affected (0.00 sec)

mysql&gt; show grants for oldgirl@'localhost';
| Grants for oldgirl@localhost                                                         ---------------| GRANT USAGE ON *.* TO 'oldgirl'@'localhost'--------------------------                         
| GRANT INSERT, UPDATE, DELETE, CREATE, DROP, REFERENCES, INDEX, ALTER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, EVENT, TRIGGER ON `test`.* TO 'oldgirl'@'localhost' |
--------------------------------2 rows in set (0.01 sec)------------------------------
</code></pre>
<p>此时我们再查看oldgirl用户权限，ALL PRIVILEGES权限已经被细分了，但是没有SELECT权限了。</p>
<p>因此我们就可以得出结论：ALL PRIVILEGES包括</p>
<pre><code class="language-bash"> SELECT
 INSERT
 UPDATE
 DELETE
 CREATE
 DROP
 REFERENCES
 INDEX
 ALTER
 CREATE TEMPORARY TABLES
 LOCK TABLES
 EXECUTE
 CREATE VIEW
 SHOW VIEW
 CREATE ROUTINE
 ALTER ROUTINE
 EVENT
 TRIGGER
</code></pre>
<p>在授权时，可以授权用户最小的满足业务需求的权限，而不是一味的授权“ALL PRIVILEGES”</p>
<h2 id="生产环境如何授权用户权限">生产环境如何授权用户权限</h2>
<p><font color="#f8070d" size=3><strong>博客 CMS等产品的数据库授权</strong>：</font></p>
<p>对于web链接用户授权尽量采用最小化原则，很多开源软件都是web界面安装，因此，在安装期间处理select, insert, update, delete4个权限外，还需要 create drop 等比较危险的权限。</p>
<p>常规情况下授权 select, insert, update, delete4个权限即可，有的开源软件，如 discuz cms还需要create drop等比较危险的权限。</p>
<p><strong>生成数据库表后，要收回create、drop权限</strong></p>
<p><strong>生产环境针对主库（写为主读为辅）用户授权</strong></p>
<p><strong><font color="#f8070d" size=3>普通的环境：</font></strong></p>
<p><strong>本机：lnmp，lamp环境数据库授权</strong></p>
<pre><code class="language-bash">grant all privileges on `blog`.* to blog@'localhost' identified by '111';
</code></pre>
<p><strong>应用服务器和数据库服务器不在一个主机上的授权</strong>：</p>
<pre><code class="language-bash">grant all privileges on `blog`.* to blog@'10.0.0.1' identified by '111';
</code></pre>
<p><strong>严格的授权：重视安全，忽略了方便</strong></p>
<pre><code class="language-bash">grant SELECT,INSERT,UPDATE,DELETE privileges on `blog`.* to blog@'10.0.0.1' identified by '111';
</code></pre>
<p><strong>生产环境从库（只读）用户的授权</strong>：</p>
<pre><code class="language-bash">grant SELECT privileges on `blog`.* to blog@'10.0.0.1' identified by '111';
</code></pre>
<p><font color="#0215cd" size=3> 说明：这里表示给10.0.0.0/24的用户blog管理blog数据库的所有表（ * 表示所有表）只读权限（select），密码为111。</font></p>
<h2 id="生产场景授权具体命令为">生产场景授权具体命令为</h2>
<p><strong>主库授权的命令</strong></p>
<pre><code class="language-bash">grant select,insert,update,delete on `blog`.* to blog@'10.0.0.%' identified by '111';
</code></pre>
<p><strong>从库授权用户命令</strong></p>
<pre><code class="language-bash">grant SELECT on `blog`.* to blog@'localhost' identified by '111'
</code></pre>
<p>当然从库除了做SELECT授权外，还可以加read-only等只读参数，严格控制web用户写从库。</p>
<p>重要问题：就是主从库的MySQL库和表是同步的，无法针对同一个用户授权不同的权限。应为，主库授权后会自动同步到从库上，导致从库的授权只读失败。</p>
<p>解决方法：</p>
<ol>
<li>
<p>取消mysql库的同步。</p>
</li>
<li>
<p>授权主库权限后，从库执行收回增删改权限。</p>
</li>
<li>
<p>不在授权上控制增删改，而是用read-only参数，控制普通用户更新从库，注意，read-only参数对超级用户无效。</p>
</li>
</ol>
<p><strong>查看MySQL数据库中的用户和主机信息</strong></p>
<p>查询授权用户oldboy的具体的授权权限</p>
<pre><code class="language-bash\">mysql&gt; show grants for root@'localhost';    
+--------------------------------------------------------------------------+
| Grants for root@localhost                                                |           
+--------------------------------------------------------------------------+
| GRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' IDENTIFIED BY PASSWORD '*23AE809DDACAF96AF0FD78ED04B6A265E05AA257' WITH GRANT OPTION 			  |
| GRANT PROXY ON ''@'' TO 'root'@'localhost' WITH GRANT OPTION   		   |           
+--------------------------------------------------------------------------+
</code></pre>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch05 - MySQL字符集相关配置</title>
      <link>https://www.oomkill.com/2017/05/ch5-mysql-charset/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2017/05/ch5-mysql-charset/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="mysql数据库字符集介绍">MySQL数据库字符集介绍</h2>
<p>简单来说，字符集就是一套文字符号及其编码、比较规则的集合，第一个计算机字符集ASCII！</p>
<p>MySQL数据库字符集包括字符集<code>(character)</code>和校对规则<code>(collation)</code>两个概念。其中，字符集是用来定义MySQL数据字符串的存储方式。而校对规则则是定义比较字符串的方式。</p>
<p>上面命令查看已建立的test数据库语句中 CHARACTER SET latin1即为数据库字符集，而COLLATE latin1_swedish_ci为校对规则，更多内容 见mysql手册第10章。</p>
<p>编译MySQL时，指定字符集了，这样以后建库的时候就直接create database test;</p>
<p><font style="background:#ffff00;" size=2>二进制安装MySQL，并没有指定字符集，这时字符集默认latin1，此时，需要建立UTF8字符集的库，就需要指定UTF8字符集建库。</font></p>
<pre><code class="language-sql">create database test1 default character set utf8 default collate=utf8_general_ci; 
</code></pre>
<h3 id="mysql常见字符集介绍">MySQL常见字符集介绍</h3>
<p>在互联网环境中，使用MySQL时常用的字符集有：</p>
<table>
<thead>
<tr>
<th>常用字符集</th>
<th>一个汉字长度（字节）</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>GBK</td>
<td>2</td>
<td>不是国际标准，对中文环境支持很好。</td>
</tr>
<tr>
<td>UTF8</td>
<td>3</td>
<td>中英文混合环境，建议使用此字符集，用的比较多的。</td>
</tr>
<tr>
<td>latin1</td>
<td>1</td>
<td>MySQL的默认字符集</td>
</tr>
<tr>
<td>utf8mb4</td>
<td>4</td>
<td>UTF8 Unicode，移动互联网</td>
</tr>
</tbody>
</table>
<h3 id="mysql如何选择合适的字符集">MySQL如何选择合适的字符集？</h3>
<ol>
<li>
<p>如果处理各种各样的文字，发布到不同语言的国家地区，应选Unicode字符集，对MySQL来说就是utf-8（每个汉字三个字节），如果应用需处理英文，仅有少量汉字的utf-8更好。</p>
</li>
<li>
<p>如果只需支持中文，并且数据两很大，性能要求也高，可选GBK（定长 每个汉字占双字节，英文也占双字节），如果需大量运算，比较排序等，定长字符集更快，性能</p>
</li>
<li>
<p>处理移动互联网业务，可能需要使用utf8mb4字符集。</p>
</li>
</ol>
<p><strong>如无特别需求，选择UTF8</strong></p>
<h3 id="查看mysql字符集">查看MySQL字符集</h3>
<blockquote>
<p><strong>查看当前MySQL系统支持的字符集</strong></p>
</blockquote>
<p>MySQL可支持多种字符集，同一台机器，库或表的不同字段都可以指定不同的字符集。</p>
<pre><code class="language-sql">mysql&gt; show character set;
+----------+-------------------------+---------------------+--------+
| Charset  | Description             | Default collation   | Maxlen |
+----------+-------------------------+---------------------+--------+
| latin1   | cp1252 West European    | latin1_swedish_ci   |      1 |
| gbk      | GBK Simplified Chinese  | gbk_chinese_ci      |      2 |
| utf8     | UTF-8 Unicode           | utf8_general_ci     |      3 |
| utf8mb4  | UTF-8 Unicode           | utf8mb4_general_ci  |      4 |
+----------+-------------------------+---------------------+--------+
</code></pre>
<blockquote>
<p><strong>查看MySQL当前的字符集设置情况</strong></p>
</blockquote>
<pre><code class="language-sql">mysql&gt; show global variables like '%character_set%';
+---------------------------+-----------------------------------+
| Variable_name             | Value                             |
+---------------------------+-----------------------------------+
| character_set_client      | utf8                              |
| character_set_connection  | utf8                              |
| character_set_database    | utf8                              |
| character_set_filesystem  | binary                            |
| character_set_results     | utf8                              |
| character_set_server      | utf8                              |
| character_set_system      | utf8                              |
| character_sets_dir        | /app/mysql-5.5.54/share/charsets/ |
+---------------------------+-----------------------------------+
</code></pre>
<p>提示：默认情况下<font color="#f8070d" size=3><code>character_set_client</code></font><font color="#f8070d" size=3><code>character_set_connection</code></font><font color="#f8070d" size=3><code>character_set_results</code></font>三者字符集和系统的字符集一致。即为</p>
<pre><code class="language-bash"># CentOS 6
$ cat /etc/sysconfig/i18n 
LANG=&quot;zh_CN.UTF-8&quot;
SYSFONT=&quot;latarcyrheb-sun16&quot;
$ echo $LANG
zh_CN.UTF-8
# CentOS 7
$ echo $LANG
en_US.UTF-8
$ cat /etc/locale.conf 
LANG=&quot;en_US.UTF-8&quot;
</code></pre>
<h2 id="mysql插入中文数据乱码深度剖析">MySQL插入中文数据乱码深度剖析</h2>
<h3 id="mysql数据库默认设置的字符集是什么">MySQL数据库默认设置的字符集是什么？</h3>
<blockquote>
<p><strong>1.查看MySQL默认情况下设置的字符集</strong></p>
</blockquote>
<pre><code class="language-sql">mysql&gt; show global variables like '%character_set%';
+-----------------------------+---------+
| Variable_name               | Value   |
+-----------------------------+---------+
| character_set_client        | utf8    |   客户端字符集
| character_set_connection    | utf8    |   客户端连接字符集
| character_set_database      | utf8    |   数据库字符集，配置文件指定或建库建表指定
| character_set_filesystem    | binary  |   文件系统字符集
| character_set_results       | utf8    |   返回结果字符集
| character_set_server        | utf8    |   服务器字符集，配置文件指定或建库建表指定
| character_set_system        | utf8    |   系统字符集
+-----------------------------+---------+
</code></pre>
<h3 id="执行set-names-gbk到底做了什么">执行set names gbk到底做了什么</h3>
<p>无论Linux系统的字符集是gb2312还是utf8，默认情况插入的数据都是乱码</p>
<pre><code class="language-sql">mysql&gt; show global variables like '%character_set%';
+---------------------------+--------+
| Variable_name             | Value  |
+---------------------------+--------+
| character_set_client      | gbk    |  
| character_set_connection  | gbk    |  
| character_set_database    | utf8   |  
| character_set_filesystem  | binary |  
| character_set_results     | gbk    |  
| character_set_server      | utf8   |  
| character_set_system      | utf8   |  
+---------------------------+--------+

|  5 |  2 |    3 | 0000-00-00 00:00:00 | 小中僠（国） | 大中僠（国）  
</code></pre>
<p>执行完set对应的字符集操作，再次插入数据乱码就不乱了<font color="#f8070d" size=2>（注：原有乱码数据不可恢复）</font></p>
<pre><code class="language-sql">mysql&gt; select id,title,content from documents;
+----+----------+--------------------------------------------------------+
| id | title    | content                                                |
+----+----------+--------------------------------------------------------+
|  5 | 灏忎腑鍏	| 澶т腑鍏                                                |
|  6 | 小中共	|                                                        |
|  7 | 巨龙中国 | 大気汚染　超大国の苦闘                                 |
|  8 | 巨龙中国 | 大気汚染　超大国の苦闘 ～ＰＭ２.５　沈黙を破る人々～   |  &lt;=字符集不对查询也乱码
+----+----------+--------------------------------------------------------+
</code></pre>
<h3 id="set-names-改变了如下字符串">set names 改变了如下字符串</h3>
<pre><code class="language-bash">character_set_client  
character_set_connection
character_set_results
</code></pre>
<hr>
<p><strong><font color="#0215cd" size=2>提示：<font color="#f8070d"  size=2><code>set names gbk</code></font> 就是把上面3个桉树改成了 <font color="#f8070d"  size=2><code>latin1</code></font> 。也就是说 <font color="#f8070d"  size=2><code>character_set_client</code></font> <font color="#f8070d"  size=2><code>character_set_connection</code></font>  <font color="#f8070d"  size=2><code>character_set_results</code></font> 三者的字符集和默认会和linux系统的字符集一致，但是当在mysql中执行 <font color="#f8070d"  size=2><code>set names charset</code></font> 操作后，这三者都会改变为设置的字符集，但是<font style="background:#ffff00;" size=2>命令修改是临时生效的</font></font></strong></p>
<hr>
<p>set names gbk也可以用下面三个命令替代</p>
<pre><code class="language-sql">set character_set_client=gbk;
set character_set_results=gbk;
set character_set_connection=gbk;
</code></pre>
<p>此文下回看到要了解下：http://blog.sina.com.cn/s/blog_7c35df9b010122ir.html</p>
<h2 id="mysql命令参数---default-character-setlatin1-在做什么">MySQL命令参数 <code>--default-character-set=latin1</code> 在做什么？</h2>
<h3 id="先查看mysql的字符集">先查看MySQL的字符集</h3>
<pre><code class="language-sql">mysql -uroot -p111 -S /data/3306/mysql.sock -e 'show variables like &quot;character_set%&quot;'
+---------------------------+---------+
| Variable_name             | Value   |
+---------------------------+---------+
| character_set_client      | utf8    | 
| character_set_connection  | utf8    | 
| character_set_database    | utf8    | 
| character_set_filesystem  | binary  | 
| character_set_results     | utf8    | 
| character_set_server      | utf8    | 
| character_set_system      | utf8    | 
+---------------------------+---------+
</code></pre>
<h3 id="带参数--default-character-setlatin1登录到mysql中查看字符集">带参数&ndash;default-character-set=latin1登录到MySQL中查看字符集</h3>
<pre><code class="language-sql">$ mysql -uroot -p111 -S /data/3306/mysql.sock --default-character=latin1

mysql&gt; show variables like '%character_set%';
+---------------------------+---------+
| Variable_name             | Value   |
+---------------------------+---------+
| character_set_client      | latin1  | 
| character_set_connection  | latin1  | 
| character_set_database    | utf8    | 
| character_set_filesystem  | binary  | 
| character_set_results     | latin1  | 
| character_set_server      | utf8    | 
| character_set_system      | utf8    | 
+---------------------------+---------+
</code></pre>
<hr>
<p><strong><font color="#0215cd" size=2>提示：和 <font color="#f8070d" size=3><code>set names latin1</code></font> 作用一样，MySQL命令后面加字符集也是把上面3个参数改成了 <font color="#f8070d" size=3><code>latin1</code></font> 。即 <font color="#f8070d" size=3><code>character_set_client</code></font> ，<font color="#f8070d" size=3><code>character_set_connection</code></font>，<font color="#f8070d" size=3><code>character_set_results</code></font> 三者字符集，但是这个登录命令修改字符集也是<font style="background:#ffff00;" size=2>临时生效的</font>。</font></strong></p>
<hr>
<h2 id="确保mysql数据库插入数据不乱码解决方案">确保MySQL数据库插入数据不乱码解决方案</h2>
<h3 id="统一mysql数据库客户及服务端字符集">统一MySQL数据库客户及服务端字符集</h3>
<p>通常MySQL数据库下面几个字符集（客户端和服务端）统一成一个字符集，才能确保插入的中文数据可以正确输出。即 <font color="#f8070d" size=2><code>show variables like 'character_set%';</code></font> 结果中的字符集设置尽量统一。当然，linux系统的字符集也要尽可能和数据库字符集统一。</p>
<blockquote>
<p><strong>show variables like &lsquo;character_set%&rsquo;;</strong></p>
</blockquote>
<p>其中 <font color="#f8070d" size=2><code>character_set_client</code></font>，<font color="#f8070d" size=2><code>character_set_connection</code></font>，<font color="#f8070d" size=2><code>character_set_results</code></font> 默认情况下采用Linux系统字符集设置，人工登录数据库执行 <font color="#f8070d" size=2><code>set names latin1;</code></font> 以及MySQL指定字符集登录操作，都是改变了MySQL客户端的<font color="#f8070d" size=2><code>client connection results</code></font> 三个参数的字符集为 <font color="#f8070d" size=2><code>latin</code></font>，从而解决了插入中文乱码的问题，这个操作可以通过改变my.cnf配置文件客户端模块的参数来改变，并且永久生效。</p>
<blockquote>
<p><strong>通过修改my.cnf实现修改MySQL客户端的字符集，配置方法如下</strong></p>
</blockquote>
<pre><code class="language-bash">[client]
default-character-set=latin1
# 提示无需重启服务，退出重新登录生效，此参数相当于，登录后执行 set names latin1;
# 特别注意：多实例的MySQL客户端默认读/etc/my.cnf，所以指定客户端字符集就在/etc/my.cnf
</code></pre>
<h2 id="更改mysql服务端字符集参数">更改MySQL服务端字符集参数</h2>
<h3 id="按如下要求更改mycnf">按如下要求更改my.cnf</h3>
<pre><code class="language-bash">[mysqld]
default-character-set=latin1  # 5.1
character-set-server=latin1   # 5.5
</code></pre>
<p>强调：以上在[mysqld]下设置的参数会更改下面两个参数的字符集设置</p>
<pre><code class="language-bash">character_set_database 
character_set_server
</code></pre>
<h3 id="编译时指定服务端字符集">编译时指定服务端字符集</h3>
<pre><code class="language-bash">-DDEFAULT_CHARSET=utf8 \
-DDEFAULT_COLLATION=utf*_general_ci \
-DEXTRA_CHARSETS=gbk,gb2312,utf8,ascii \
</code></pre>
<h2 id="统一mysql数据库客户服务端字符集总结">统一MySQL数据库客户服务端字符集总结</h2>
<ul>
<li>
<p><strong>客户端字符集设置为 <font color="#f8070d" size=2><code>&quot;set names utf8;&quot;</code></font>，这样可以确保插入后的中文，不会出现乱码，但是对执行 <font color="#f8070d" size=2><code>set names utf8;</code></font> 前插入的中文无效，此命令临时生效。</strong></p>
</li>
<li>
<p><strong>和设置客户端字符集 <font color="#f8070d" size=2><code>&quot;set names utf8&quot;</code></font> 命令有相同作用的方法还有，MySQL命令指定utf8字符集参数登录，以及在my.cnf里更改参数实现。</strong></p>
</li>
<li>
<p><strong>在MySQL的 <font color="#f8070d" size=2><code>my.cnf</code></font> 配置文件里 <font color="#f8070d" size=2><code>[client]</code></font> 模块下添加字符集配置，生效后，相当于命令行 <font color="#f8070d" size=2><code>&quot;set names utf8;&quot;</code> </font>的效果，由于更改的是客户端、连接和返回结果3个字符集，因此无需重启服务就生效。</strong></p>
</li>
<li>
<p><strong>在MySQL的 <font color="#f8070d" size=2><code>my.cnf</code></font> 配置文件里 <font color="#f8070d" size=2><code>[mysqld]</code></font> 模块下添加字符集配置，生效后，创建数据库和表默认都是这个设置的字符集MySQL5.5和5.1的服务端字符集参数有变化，具体为 <font color="#f8070d" size=2><code>character-set-server=utf8</code></font> 参数适合5.5，<font color="#f8070d" size=2><code>default-character-set=utf8</code></font> 参数适合5.1及以前版本。</strong></p>
</li>
</ul>
<h2 id="彻底解决mysql数据库插入中文乱码方案">彻底解决MySQL数据库插入中文乱码方案</h2>
<p><font style="background:#ffff00;" size=3>切记：字符集的不一致是数据库乱码的罪魁祸首。</font></p>
<ol>
<li>
<p>确保以下（客户端和服务端）字符集是一致的，当然，字符集的选择可以有多种。</p>
</li>
<li>
<p>修改字客户端字符集</p>
</li>
</ol>
<pre><code class="language-bash">set names gbk;

[mysql]
/app/mysql/bin/mysqlsafe --default-character
</code></pre>
<ol start="3">
<li>建库建表的时候要指定和上述设置的字符集相同的字符集，以GBK字符集为例：</li>
</ol>
<pre><code class="language-bash">create database test default character set gbk collate gbk_chinese_ci;
</code></pre>
<ol start="4">
<li>在数据库中执行sql语句方法</li>
</ol>
<ul>
<li>尽量不在MySQL命令行直接插入数据。</li>
<li>可在MySQL中source执行sql文件。</li>
<li>sql文件用utf8没有签名。</li>
</ul>
<ol start="5">
<li>开发程序的字符集</li>
</ol>
<h2 id="生产中如何更改mysql数据库库表的字符集">生产中如何更改MySQL数据库库表的字符集</h2>
<h3 id="数据库字符集修改步骤">数据库字符集修改步骤</h3>
<p>对于已有的数据库想修改字符集不能直接通过 <strong><font color="#f8070d" size=2><code>&quot;alter database character set *&quot;</code></font></strong> 或 <strong><font color="#f8070d" size=2><code>&quot;alter TableName character set *&quot;</code></font></strong>，这两个命令都没有更新已有数据的字符集，而只是对新创建的表或者数据生效。</p>
<p>已有数据的字符集调整，必须先将数据导出，经过修改字符集后重新导入后才可完成。</p>
<p>步骤如下：</p>
<blockquote>
<p><strong>1. 导出表结构</strong></p>
</blockquote>
<pre><code class="language-sql">mysqldump -uroot -p --default-character-set=latin1 -d dbname&gt;table.sql
</code></pre>
<blockquote>
<p><strong>2. 编辑表结构语句alltable.sql将所有latin1字符串改成utf8;</strong></p>
</blockquote>
<pre><code class="language-sql">mysqldump -uroot -p111 -S /data/3306/mysql.sock --default-character-set=utf8 --compact -d test&gt;table.sql
sed -i 's#utf8#gbk#g' table.sql
</code></pre>
<blockquote>
<p><strong>3.确保数据不在更新，导出所有数据（不带表结构）</strong></p>
</blockquote>
<pre><code class="language-bash">mysqldump -uroot -p111 \
--S/data/3306/mysql.sock \
--quick --no-create-info \
--extended-insert \
--default-character-set=utf8 
</code></pre>
<p>参数说明</p>
<p><strong><code>--quick</code></strong>：用于转储大的表，强制mysqldump从服务器一次一行的检索数据而不是检索所有的行，并输出前cache到内存中。</p>
<p><strong><code>--no-create-info</code></strong>：不创建create table语句</p>
<p><strong><code>--extended-insert</code></strong>：使用包括几个values列表的多行insert语句，这样文件更小,IO也小，导入数据时会非常快。</p>
<p><strong><code>--default-character-set=latin1</code></strong> ：按照原有字符集导出数据，这样导出的文件中，所有中文都是可见的，不会保存成乱码</p>
<blockquote>
<p><strong>4. 修改my.cnf配置调整客户端及服务端字符集，重启生效</strong></p>
</blockquote>
<pre><code class="language-bash">[client]
default-character-set=latin1
# 提示无需重启服务，退出重新登录生效，此参数相当于，登录后执行 set names latin1;
# 特别注意：多实例的MySQL客户端默认读/etc/my.cnf，所以指定客户端字符集就在/etc/my.cnf
[mysqld]
default-character-set=latin1  # 5.1
character-set-server=latin1   # 5.5
</code></pre>
<blockquote>
<p><strong>5. 通过utf8建库</strong></p>
</blockquote>
<pre><code class="language-sql">create database test default character set utf8;
</code></pre>
<blockquote>
<p><strong>6.导入表结构（更改过字符集的表结构）</strong></p>
</blockquote>
<pre><code class="language-sql">mysql -uroot -p111 -S /data/3306/mysql.sock dbname&lt;table.sql
</code></pre>
<blockquote>
<p><strong>7.导入数据</strong></p>
</blockquote>
<pre><code class="language-sql">mysql -uroot -p -S /data/3306/mysql.sock db&lt;data.sql
</code></pre>
<p>更改字符集思想</p>
<ol>
<li>数据库不要更新，导出所有数据。</li>
<li>把导出的数据进行字符集更换（替换表和库）。</li>
<li>修改my.cnf，更改MySQL客户端服务端字符集，重启生效</li>
<li>导入更改过字符集的数据，包括表结构语句，提供服务。</li>
<li>SSH客户端，以及程序更改为对应字符集</li>
</ol>
<h2 id="校对集collate">校对集collate</h2>
<p>collate指的是 字符之间的比较关系！</p>
<p>校对集，依赖于字符集！</p>
<p>校对集，指的是，在某个字符集下，字符的排序关系应该是什么，称之为校对集！</p>
<p><strong><font color="#f8070d" size=3>a B c or B a c</font></strong></p>
<p>此时，使用 order by对结果排序，看结果：顺序为 a-B-c 忽略了大小写！</p>
<pre><code class="language-sql">MariaDB [t_t]&gt; select * from test order by name;
+-----------+
|name       |
+-----------+
| a         |
| B         |
| c         |
+-----------+
</code></pre>
<p>可以被 校对集改变：</p>
<p>利用 show collation; 查看到所有的校对集！</p>
<pre><code class="language-sql">mysql&gt; show collation;
+---------------------+-----------+------+----------+-----------+---------+
| Collation           | Charset   | Id   | Default  | Compiled  | Sortlen |
+---------------------+-----------+------+----------+-----------+---------+
| latin1_bin          | latin1    |  47  |          | Yes       |      1  |
| latin1_general_ci   | latin1    |  48  |          | Yes       |      1  |
| gbk_chinese_ci      | gbk       |  28  | Yes      | Yes       |      1  |
| utf8_general_ci     | utf8      |  33  | Yes      | Yes       |      1  |
+---------------------+-----------+------+----------+-----------+---------+
</code></pre>
<p>ci大小写不敏感的</p>
<p>一个字符集下可以存在多个校对集，且有一个是默认的。</p>
<p>再创建一个 utt8_bin的校对集表，在排序：</p>
<pre><code class="language-sql">create table t( name varchar(2) )engine innodb default charset=utf8 collate=utf8_bin;
insert into t values ('a'),('B'),('c');

MariaDB [t_t]&gt; select * from t order by name;
+------+
| name |
+------+
| B    |
| a    |
| c    |
+------+
</code></pre>
<p>我们典型的选择：utf8_genreal_ci utf8_unicode_ci</p>
<h3 id="校验规则后缀说明">校验规则后缀说明：</h3>
<p><strong><font color="#f8070d" size=2>_bin 二进制编码层面直接比较</font></strong></p>
<p><strong><font color="#f8070d" size=2>_ci 忽略大小写（大小写不敏感）比较</font></strong></p>
<p><strong><font color="#f8070d" size=2>_cs 大小写敏感比较</font></strong></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch03 - MySQL的备份与恢复</title>
      <link>https://www.oomkill.com/2017/05/ch3-mysql-backup-and-restore/</link>
      <pubDate>Sun, 14 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2017/05/ch3-mysql-backup-and-restore/</guid>
      <description></description>
      <content:encoded><![CDATA[<h3 id="备份数据库的意义">备份数据库的意义</h3>
<p>运维工作到底是什么工作，到底是做什么？</p>
<p>运维工作简单的概括就两件事：</p>
<p>一是保护公司的数据；二是网站7*24小时提供服务。</p>
<p>那么对数据丢失一部分和网站7*24小时提供服务那个更重要呢？</p>
<p>都很重要，只是说相比哪个更为重要？这个具体要看业务个公司。例如：银行、金融行业，数据是最重要的，一条都不能丢，可能宕机停机影响就没那么大。百度搜索，腾讯qq聊天记录丢失了几万条数据，都不算啥。</p>
<p>对于数据来讲，数据最核心的就是数据库数据。</p>
<h3 id="备份单个数据库练习多种参数的使用">备份单个数据库练习多种参数的使用</h3>
<p>MySQL数据库自带了一个很好用的备份命令，就是mysqldump，它的基本使用如下：</p>
<pre><code class="language-sql">mysqldump -u UserName -p PassWord dbName &gt; backName.sql
</code></pre>
<h4 id="备份库">备份库</h4>
<pre><code class="language-sql">mysqldump -S /data/3306/mysql.sock -uroot -p test&gt;mysql.sql   
</code></pre>
<p>检查备份结果</p>
<pre><code class="language-sql">$ egrep -v  &quot;#|\*|--|^$&quot; ./mysql.sql
DROP TABLE IF EXISTS `test1`;
CREATE TABLE `test1` (
  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,
  `num1` varchar(20) NOT NULL,
  `num2` varchar(20) NOT NULL,
  `num3` varchar(20) NOT NULL,
  `num4` int(11) NOT NULL DEFAULT '0' COMMENT 'test1',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2000001 DEFAULT CHARSET=utf8;
LOCK TABLES `test1` WRITE;
INSERT INTO `test1` VALUES (1,'1455577','9779520','4530868',0),
</code></pre>
<hr>
<p><font color="#0215cd" size=2> 注：因为导出时的格式没有加字符集，一般恢复到数据库里会正常，只是系统外查看不正常而已。另外，insert是批量插入的方式，这样在恢复时效率很高。</font></p>
<hr>
<p>根据查看的结果，我们看到了已备份的表结构语句及插入的数据整合的sql语句，但是中文数据乱码了。</p>
<h4 id="设置字符集参数备份解决乱码问题">设置字符集参数备份解决乱码问题</h4>
<p>查看备份前数据库客户端及服务器端的字符集设置</p>
<pre><code class="language-sql">mysql&gt; show variables like &quot;character%&quot;
+---------------------------+-----------------------------------+
| Variable_name             | Value                     		|
+---------------------------+-----------------------------------+
| character_set_client   	| utf8                              |
| character_set_connection	| utf8                            	|
| character_set_database   	| utf8                            	|
| character_set_filesystem	| binary                          	|
| character_set_results    	| utf8                            	|
| character_set_server     	| utf8                            	|
| character_set_system     	| utf8                            	|
| character_sets_dir       	| /app/mysql-5.5.54/share/charsets/ |
+---------------------------+-----------------------------------+
</code></pre>
<p>指定对应的字符集备份，这里为<font color="#f8070d" size=3><code>--default-character-set=utf8</code></font></p>
<pre><code>mysqldump -uroot -p111 --default-character-set=utf8 t1 &gt; t.sql -S /data/3306/mysql.sock
</code></pre>
<h4 id="备份时加-b参数增加创建库与选择库">备份时加<code>-B</code>参数，增加创建库与选择库</h4>
<pre><code class="language-sql"> -- Current Database: `t1`
 CREATE DATABASE /*!32312 IF NOT EXISTS*/ `t1` /*!40100|  
 USE `t1`;
</code></pre>
<h4 id="优化配置文件大小减少输出注释debug调试">优化配置文件大小减少输出注释（debug调试）</h4>
<p>利用<font color="#f8070d" size=3><code>mysqldump</code></font>的<font color="#f8070d" size=3><code>--compact</code></font>参数优化下备份结果</p>
<pre><code class="language-bash">$ mysqldump -uroot -p111 --default-character-set=utf8 --compact -B t1 &gt; t_b.sql
$ cat t_b.sql 
</code></pre>
<pre><code class="language-sql">CREATE DATABASE /*!32312 IF NOT EXISTS*/ `t1` /*!40100 DEFAULT CHARACTER SET utf8 */;

USE `t1`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `test1` (
  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,
  `num1` varchar(20) NOT NULL,
  `num2` varchar(20) NOT NULL,
  `num3` varchar(20) NOT NULL,
  `num4` int(11) NOT NULL DEFAULT '0' COMMENT 'test1',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2000031 DEFAULT CHARSET=utf8;

/*!40101 SET character_set_client = @saved_cs_client */;
INSERT INTO `test1` VALUES (2000001,'690938','794482','1899596',0),(2000002,'7114536','9873892','8025852',0),(2000003,'507584','8460367','779079',0),(2000004,'8514298','234250','5628359',0),(2000005,'7439042','310137','9233557',0),(2000006,'5237373','8486196','6718861',0),(2000007,'8135719','522012','8202901',0),(2000008,'9448472','2633656','4822864',0),(2000009,'6213355','6598180','4350835',0),(2000010,'1959635','6745673','7849459',0),(2000011,'9010275','1503001','484179',0),(2000012,'7911894','8106930','6798971',0),(2000013,'9674065','7973412','844865',0),(2000014,'304088','8985848','4016974',0),(2000015,'3127327','3585711','8546578',0),(2000016,'1975754','4239037','5267926',0),(2000017,'3622517','2308806','676480',0),(2000018,'6455983','250474','1884422',0),(2000019,'8670686','7700168','2488781',0),(2000020,'9343400','9250657','8223086',0),(2000021,'3363461','2148048','649856',0),(2000022,'6805137','2076115','9965166',0),(2000023,'3597485','8091927','9667180',0),(2000024,'4060121','1299065','4314962',0),(2000025,'7677614','5443186','4183087',0),(2000026,'4585879','380131','8143022',0),(2000027,'9574716','3444513','8498418',0),(2000028,'2158552','5297508','11882',0),(2000029,'4166888','798795','1493311',0),(2000030,'5070170','870919','9144083',0);
</code></pre>
<blockquote>
<p><strong>&ndash;compact参数说明</strong>：</p>
</blockquote>
<p>（测试时用的比较多）可以优化输出内容的大小，让容量更少，适合调试。</p>
<pre><code class="language-sql">--compact		Give less verbose output (useful for debugging).		Disables
 			structure comments and header/footer contructs. 	Enables
options  --skip-add-drop-table --no-set-names
 	 --skip-disable-keys --skip-add-locks
</code></pre>
<p>参数说明：该选项使得输出内容更简介，不包括默认选项中各种注释。有如下几个参数的功能。</p>
<p><font color="#f8070d" size=3><code>--skip-add-drop-table</code></font></p>
<p><font color="#f8070d" size=3><code>--no-set-names</code></font></p>
<p><font color="#f8070d" size=3><code>--skip-disable-keys</code></font></p>
<p><font color="#f8070d" size=3><code>--skip-add-locks</code></font></p>
<h4 id="压缩备份的数据">压缩备份的数据</h4>
<pre><code class="language-sql">--- 输出时用管道进行备份，压缩效率将近3倍
--- 这个保存为一个压缩文件

mysqldump -S /data/3306/mysql.sock -uroot -p111 -B t1|gzip &gt;t1.sql.gz
1360  t1.sql.g
3365  t2.sql
</code></pre>
<p>小结：</p>
<ol>
<li>备份数据使用-B参数，会在备份数据中增加建库及use库的语句</li>
<li>备份数据使用-B参数，后面可以直接接多个库名。</li>
<li>共gzip对备份的数据亚索</li>
<li>debug时可以用&ndash;compact减少输出，但不用于生产</li>
<li>指定字符集备份用&ndash;default-character-set=utf8（一般不用）</li>
</ol>
<h3 id="mysqldump的工作原理">mysqldump的工作原理</h3>
<p>利用mysqldump命令备份数据的过程，实际上就是把数据从mysql库里以逻辑的sql语句的形式直接输出或者生成备份的文件的过程。</p>
<p>提示：使用mysqldump是把数据库的数据导出通过sql语句的形式存储，这种备份方式称之为逻辑备份，效率不是很高，一般50G以内的数据。</p>
<p>其他备份方式：物理备份：cp tar（停库），xtrabackup物理热备份。
备份多个库及多个参数</p>
<pre><code class="language-sql">mysqldump -uroot -p111 -S /data/3306/mysql.sock --compact \
-B test t1|gzip&gt;/data/test1.sql
</code></pre>
<p><strong>-B参数说明</strong></p>
<pre><code class="language-bash">-B，参数是关键，表示接多个库并且增加use db和create database db的信息
-B, --databases     Dump several databases. Note the difference in usage; in
                      this case no tables are given. All name arguments are
                      regarded as database names. 'USE db_name;' will be
                      included in the output.
                      
# 用于导出多个数据库，注意这种情况系没有表。所有的名称参数都被认作为是数据库。
# 每个数据库名以空格隔开，将使用的数据库名称包含到输出里
# 当-B后的数据库列全时，同-A参数。
</code></pre>
<h3 id="分库备份">分库备份</h3>
<p>分库备份实际上就是执行一个备份语句备份一个库，如果数据库里有多个库，就执行多条相同的备份单个库的备份语句就可以备份多个库了，注意每个库都可以用对应备份的库作为库名，结尾加.sql。备份多个库的命令如下：</p>
<p>mysqldump -uroot -p111 -B oldboy;</p>
<p>mysqldump -uroot -p111 -B test;</p>
<p>&hellip;.</p>
<p>&hellip;.</p>
<blockquote>
<p><strong>分库备份法1</strong>：</p>
</blockquote>
<pre><code class="language-sql">mysql -uroot -p111 -S /data/3306/mysql.sock \
-e 'show databases;'|\
egrep -v &quot;Database|_schema|mysql&quot;|\
sed -r 's#^(.*)#mysqldump -uroot -p111 -S /data/3306/mysql.sock \1#g'

mysql -uroot -p111 -S /data/3306/mysql.sock bingbing
mysql -uroot -p111 -S /data/3306/mysql.sock t1
mysql -uroot -p111 -S /data/3306/mysql.sock test

-- 将结果交给bash
mysql -uroot -p111 -S /data/3306/mysql.sock \
-e 'show databases;'|egrep -v &quot;Database|_schema|mysql&quot;|\
sed -r 's#^(.*)#mysqldump -uroot -p111 -S /data/3306/mysql.sock -B \1|gzip&gt;\1.sql.gz#g' \
|bash
</code></pre>
<blockquote>
<p>法2：</p>
</blockquote>
<p>见分库分表备份视频：http://edu.51cto.com/course/course_id-808.html</p>
<blockquote>
<p><strong>分库备份的意义何在？</strong></p>
</blockquote>
<p>有时一个企业的数据库里会有多个库，例如（www.bbs，blog），但是出问题的时候很可能是某一个库，如果在备份时把所有的库都备份成了一个数据文件的话，回复某一个库的数据是就比较麻烦了。</p>
<h3 id="备份单个表">备份单个表</h3>
<p>语法：</p>
<pre><code class="language-bash">mysqldump -uuserName -ppassWord dbName tableName &gt;/data.sql
mysqldump -uuserName -ppassWord dbName tableName1 tableName2.. &gt;/data.sql
</code></pre>
<hr>
<p><strong><font color="#0215cd" size=2>提示：不能加<font color="#f8070d" size=3><code>-B</code></font>参数了，因为库后面就是表了。</font></strong></p>
<hr>
<p>企业需求：一个库里有大表有小标，有时可能需要只回复某一个小表，上述的多表备份很难拆开，就想没有分库那样导致恢复某一个小表很麻烦。</p>
<p>那么又如何进行分表备份呢？如下，和分库的思想一样，每执行一条语句备份一个表，生成不同的数据文件即可。如下：</p>
<pre><code class="language-bash">mysql -uroot -p111 -e 'use test; show tables;' \
|egrep -v 'Tables_in_test' \
|sed -r 's#^(.*)#mysqldump -uroot -p111 --compact test \1&gt;\1.sq$g'|bash
</code></pre>
<p><font color="#f8070d" size=2>分表备份缺点：文件多，很碎</font></p>
<pre><code>  备一个完整全备，在做一个分库分表备份
  脚本批量备份恢复多个SQL文件
</code></pre>
<blockquote>
<p><strong>面试题：多个库或者多个表备份到一块了，如何恢复单个库或者表？</strong></p>
</blockquote>
<p>解答：</p>
<ol>
<li>第三方测试库，导入到库里，然后把需要的备份出来，恢复到正式库里。</li>
<li>单表：grep表名 bak.sql&gt;tab_name。</li>
<li>实现分库分表备份</li>
</ol>
<h3 id="备份数据表结构">备份数据表结构</h3>
<p>利用<font color="#f8070d" size=2><code>mysqldump -d</code></font>参数只备份表的结构，例：备份oldboy库的所有表的结构</p>
<pre><code class="language-sql">mysqldump -uroot -p111 -d --compact -B test &gt; t.sql
</code></pre>
<p>如果只导出数据则用<font color="#f8070d" size=2><code>-t</code></font></p>
<pre><code class="language-sql">mysqldump -uroot -p111 -S /data/3306/mysql.sock -t --compact -B test &gt; 1t.sql 
</code></pre>
<p><font color="#f8070d" size=2><code>-T --tab=path</code></font>：语句与数据分离，数据为文本。</p>
<pre><code class="language-sql">mysqldump -uroot -p111 -S /data/3306/mysql.sock t1 test1 -T /data
</code></pre>
<p>注意只能对表进行分离，对数据库进行分离提示如下：</p>
<pre><code class="language-bash">$ mysqldump -uroot -p111 -S /data/3306/mysql.sock -B t1 -T /data         
mysqldump: --databases or --all-databases can't be used with --tab.
</code></pre>
<p>小结：</p>
<ul>
<li><font color="#f8070d" size=3><code>-B</code></font>备份多个库（并添加create和use语句）</li>
<li><font color="#f8070d" size=3><code>-d</code></font>只备份库表结构</li>
<li><font color="#f8070d" size=3><code>-t</code></font>只备份数据（sql语句形式）</li>
<li><font color="#f8070d" size=3><code>-T</code></font>分离表和数据成不同的文件，数据是文本，非SQL语句</li>
</ul>
<h3 id="刷新binlog参数">刷新binlog参数</h3>
<p>mysqldump用于定时对某一时刻的数据的全备份，例如：00点进行备份bak.sql.gz</p>
<p>增量备份：当有数据写入到数据库时，还会同时把更新的SQL语句写入到对应的文件里，这个文件就叫做binlog。</p>
<p>比如说晚上0点做备份， 10点宕机了，0-10点的数据就丢失了</p>
<p><strong>10点前丢失数据需要恢复的数据</strong>：</p>
<ol>
<li>00点时刻备份的bak.sql.gz数据还原到数据库，这个时候数据恢复到了00点</li>
<li>00-10点数据，就要从binlog里恢复。</li>
</ol>
<h4 id="binlog作用">binlog作用</h4>
<p>记录数据库更新的sql语句，不记录show select等，只是记录对数据库记录变更的二进制文件。</p>
<p>在mysql数据库当中，当你做一个全备之后到出问题的时刻，要想恢复，就是全备+全备之后的所有binlog。</p>
<h4 id="定界binlog">定界binlog</h4>
<p><strong>问题：怎么界定备份之后和binlog文件之间连接的很紧密不多也不少。</strong></p>
<p>通过文件的日志点。可以通过<font color="#f8070d" size=3><code>-F</code></font>做一个区分。</p>
<p>只要我们做了备份，然后就刷新binlog，将来恢复的就是130以下的。130以上的包里面就包含了
binlog日志切割：确定全备和增量的结界点-F刷新binlog日志，生成新日志文件，将来增量恢复从这个新日志文件开始。</p>
<p>binglog文件生效需要一个参数：<font color="#f8070d" size=3><code>log-bin log-bin=/data/3306/mysql-bin</code></font></p>
<pre><code class="language-bash">$ ll # ←备份前，查看目录binlog文件
mysql-bin.000316
mysql-bin.000317
mysql-bin.index

mysqldump -uroot -p111 -S /data/3306/mysql.sock --compact -B t1 &gt; t1.sql -F

$ ll #←在刷新之后可以看到binlog文件增加了
mysql-bin.000316
mysql-bin.000317
mysql-bin.000318
mysql-bin.index
</code></pre>
<p><font color="#f8070d" size=2><code>--master-data</code></font> 在备份语句里添加 <font color="#f8070d" size=3><code>CHANGE MASTER</code></font> 语句及 <font color="#f8070d" size=3><code>binlog</code></font> 文件及位置点信息</p>
<p>  值1，为可执行的CHANGE MASTER语句</p>
<p>  值2，为注释的<code>--CHANGE MASTER</code>语句</p>
<hr>
<p><font color="#0215cd" size=3> 注：--master-data除了增量恢复确定临界点外，做主从复制时作用更大</font></p>
<hr>
<pre><code class="language-bash"># 不加--master-data语句
mysqldump -uroot -p111 --compact -B t1 &gt; t1.sql
cat t1.sql 

CREATE DATABASE /*!32312 IF NOT EXISTS*/ `t1` /*!40100 DEFAULT CHARACTER SET utf8 */;
</code></pre>
<pre><code class="language-sql">-- 加上master-data语句后
mysqldump -uroot -p111 --compact -B t1 &gt; t1.sql --master-data=1
cat t1.sql 

CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000318', MASTER_LOG_POS=107;

CREATE DATABASE /*!32312 IF NOT EXISTS*/ `t1` /*!40100 DEFAULT CHARACTER SET utf8 */;
</code></pre>
<pre><code class="language-bash">$ mysqldump -uroot -p111 --compact -B t1 &gt; t1.sql --master-data=2
$ cat t1.sql 
</code></pre>
<pre><code class="language-sql">-- CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000318', MASTER_LOG_POS=107;
</code></pre>
<h3 id="mysqldump关键参数说明">mysqldump关键参数说明</h3>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>-B</td>
<td>指定多个库，增加建库语句和use语句。</td>
</tr>
<tr>
<td>&ndash;compact</td>
<td>去掉注释，适合调试输出，生产不适用</td>
</tr>
<tr>
<td>-A</td>
<td>备份所有库</td>
</tr>
<tr>
<td>-F</td>
<td>刷新binlog日志，生成新文件，将来增量恢复从这个文件开始。</td>
</tr>
<tr>
<td>&ndash;master-data</td>
<td>增加binlog日志文件名及对应的位置点（即CHANGE MASTER语句）。&ndash;mater-data=1不注释 2注释</td>
</tr>
<tr>
<td>-x &ndash;lock-all-tables</td>
<td></td>
</tr>
<tr>
<td>-l &ndash;lock-tables</td>
<td>lock all tables for read</td>
</tr>
<tr>
<td>-d</td>
<td>只备份数据，无表结构，SQL语句形式。</td>
</tr>
<tr>
<td>-t</td>
<td>只备份数据，无库表结构，SQL语句形式。</td>
</tr>
<tr>
<td>-T</td>
<td>库表和数据分离不同文件，数据是文本形式。</td>
</tr>
<tr>
<td>&ndash;single-transaction</td>
<td>适合innodb事务数据库备份</td>
</tr>
<tr>
<td>-q --quick don&rsquo;t bufferquery</td>
<td>dump directly to stdout (Defaults to on; use &ndash;skip-quick to disable)</td>
</tr>
</tbody>
</table>
<hr>
<p><strong><font color="#0215cd" size=2> 说明：innodb表在备份时，通常启用选线&ndash;single-transaction来保证备份的一致性，实际上它的工作原理是设定本次会话的隔离级别为REPEATABLE READ，确保本次会话（dump）时，不会看到其他会话已经提交了的数据。</font></strong></p>
<hr>
<h3 id="生产场景不同引擎mysqldump备份命令">生产场景不同引擎mysqldump备份命令</h3>
<h4 id="myisam引擎企业生产备份命令适合所有引擎或混合引擎">myisam引擎企业生产备份，命令（适合所有引擎或混合引擎）：</h4>
<pre><code class="language-sh">mysqldump -uroot -p111 -A -B -F -R --master-data=2 -x --events|gzip &gt; /data/all.sql.gz
</code></pre>
<p>提示：-F也可以不用，与&ndash;，master-data有写重复</p>
<h4 id="innodb引擎企业生产备份命令推荐使用">innodb引擎企业生产备份命令：推荐使用</h4>
<pre><code class="language-sh">mysqldump -uroot -p111 -A -B -F -R --master-data=2 --events --single-transaction|gzip &gt;/data/all.sql.gz
</code></pre>
<h4 id="--master-data作用">&ndash;master-data作用：</h4>
<ol>
<li>使用&ndash;master-data=2进行备份文件会增加如下内容：适合普通备份增量恢复</li>
</ol>
<pre><code class="language-sh">--CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.00020', MASTER_LOGZ_POS=1191
</code></pre>
<ol start="2">
<li>使用&ndash;maste-data=1进行备份文件会增加如下内容：更适合主从复制</li>
</ol>
<pre><code class="language-sh">CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.00020', MASTER_LOGZ_POS=1191
</code></pre>
<p>锁表的原理：
<img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed@latest/img/wps1.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>innodb有acid的特性</p>
<p>dump命令是看不到后面生成的数据，只能看到执行这个命令时所有数据之前的这个数据</p>
<p>事务引擎不锁表备份原理：&ndash;single-transaction 会话隔离</p>
<p>额外补充：</p>
<ol>
<li>mysqldump逻辑备份说明</li>
</ol>
<p>缺点：效率不是特别高</p>
<p>优点：简单、方便、可靠、迁移。</p>
<ol start="2">
<li>超过50G可选方案</li>
</ol>
<p>恢复数据到数据库的时候，认为通过SQL语句将数据删除的时候，做主从复制的时候</p>
<h3 id="恢复数据库实战">恢复数据库实战</h3>
<p>数据库恢复事项</p>
<ol>
<li>数据恢复和字符集关联很大，如果字符集不正确会导致恢复的数据乱码。</li>
</ol>
<p>mysql命令以及source命令恢复数据可的原理就是把文件的SQL语句，在数据库里重新执行过程。</p>
<ol start="2">
<li>利用source命令恢复数据库。</li>
</ol>
<p>进入mysql数据库控制台，mysql -uroot -p登陆后</p>
<p>use database;</p>
<p>然后使用source xx.sql，后面参数为脚本文件（如这里用到的sql）</p>
<p>source 2.sql 这个文件是系统路径，默认是登陆mysql前的系统路径</p>
<p>提示：</p>
<pre><code>  source数据恢复和字符集关联很大，如果字符集不正确会导致恢复的数据乱码。
  utf8数据库，那么恢复的文件格式需要为utf8无bom头。
</code></pre>
<blockquote>
<p><strong>利用mysql命令恢复（标准）</strong></p>
</blockquote>
<pre><code class="language-sh">mysql -uroot -p111 -e 'use test;drop tables test1;show tables;'
mysql -uroot -p111 test &lt; /2.sql
</code></pre>
<p>假设开发人员让我们插入数据到数据库（可能是邮件发给我们的，内容可能是字符串或是文件）sql文件里没有use db这样的字符，在导入时就要指定数据库名了。</p>
<pre><code class="language-sql">$ mysql -uroot -p111 &lt; /data/3306/2.sql
ERROR 1046 (3D000) at line 22: No database selected

$ mysql -uroot -p111 -e'use test';
ERROR 1049 (42000) at line 1: Unknown database 'test'

$ mysql -uroot -p111 test&lt;/data/3306/2.sql
</code></pre>
<p>如果在导出时指定-B参数，恢复时无需指定库恢复，为什么？</p>
<p>因为-B参数带了<font color="#f8070d" size=3><code>use test;</code></font>还会有<font color="#f8070d" size=3><code>create database test;</code></font>，而恢复时指定库就类似与<font color="#f8070d" size=3><code>use test</code></font>。</p>
<p>如果mysqldump备份时指定了-B，则恢复可以用如下方法：</p>
<pre><code class="language-sh">mysql -uroot -p111 &lt; back.sql
mysql -uroot -p111 DbName &lt; back.sql$ 条件是dbname库必须存在
</code></pre>
<hr>
<p><font color="#0215cd" size=3>提示：此处DbName相当于use Dbname</font></p>
<hr>
<blockquote>
<p><strong>问题：分库分表备份的数据如何快速恢复呢？</strong></p>
</blockquote>
<p>还是通过脚本读指定的库和表，调用mysql命令恢复</p>
<pre><code class="language-sh">for name in `ls /back/*.sql|sed -r 's#.back.sq$#g'`;do mysql -uroot -p111 test&lt;${name}.back.sql; done;
</code></pre>
<blockquote>
<p><strong>针对压缩的备份数据恢复</strong></p>
</blockquote>
<p><strong>方法1</strong>：</p>
<pre><code class="language-sh">gzip -d /back/mysql_back.sql.gz
mysql -uroot -p111 dbname &lt; /back/mysql_back.sql

gzip -cd mysql_back.sql.gz &gt; mysql.sql$←不删除源备份文件
</code></pre>
<p><strong>方法2</strong>：</p>
<pre><code class="language-sh">gunzip &lt; b.sql.gz &gt; /opt/mysql.sql
mysql -uroot -p111 &lt; /opt/mysql.sql
</code></pre>
<p>或者</p>
<pre><code class="language-sh">gunzip -c back.sql.gz|mysql -uroot -p111 test
</code></pre>
<pre><code class="language-sh">mysql -uroot -p111 -e \
'SELECT CONCAT(&quot;drop table &quot;,table_name,&quot;;&quot;) FROM information_schema.`TABLES` WHERE table_schema=&quot;test&quot;;' \
|grep -Ev 'CONCAT(&quot;drop table &quot;,table_name,&quot;;&quot;)'|sed -r &quot;s#^(.*)#mysql -uroot -p111 -e 'use test;\1'#g&quot; \
|bash
</code></pre>
<blockquote>
<p><strong>分表分库备份脚本</strong></p>
</blockquote>
<pre><code class="language-sh">#!/bin/sh
. /etc/init.d/functions
# define variable
BackDir=~/back
User=root
PassWD=111
Socket=/data/3306/mysql.sock
# define comment
Login=&quot;mysql -u${User} -p${PassWD} -S ${Socket}&quot;
Dump=&quot;mysqldump -u${User} -p${PassWD} -S${Socket} -x --master-data=2 --compact&quot;
DataBase=`$Login -e 'show databases;'|egrep -v  '*chema|mysql'|sed '1d'`

[ ! -d $BackDir ] &amp;&amp; mkdir -p $BackDir
for list in $DataBase
do
	ST=`$Login -e &quot;use $list;show tables;&quot;|sed '1d'`
	[ ! -d $BackDir/$list ] &amp;&amp; mkdir -p $BackDir/$list
	for table in $ST
	do
		$Dump $list $table|gzip&gt;$BackDir/$list/$table.`date +%F`.sql.gz
		[ $? -eq 0 ] &amp;&amp; action &quot;$list &gt; $table is ok&quot; /bin/true || &quot;$list &gt; $table dump is fail&quot;
	done
done
</code></pre>
]]></content:encoded>
    </item>
    
    <item>
      <title>ch01 - Linux下安装Mysql</title>
      <link>https://www.oomkill.com/2017/05/ch1-mysql-deployment/</link>
      <pubDate>Fri, 12 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2017/05/ch1-mysql-deployment/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="mysql数据库简介">MySQL数据库简介</h2>
<p>编程语言排名：http://www.tiobe.com/tiobe-index</p>
<p>数据库排名：http://db-engines.com/en/ranking</p>
<h3 id="mysql数据库分类与版本升级">MySQL数据库分类与版本升级</h3>
<p>MySQL数据库官网为http://www.mysql.com，其发布的MySQL版本采用双授权政策，和大多数开源产品的路线一样，分别为社区版和商业版，而这两个版本又各自分四个版本依次发布，这四个版本为Alpha版、Beta版、RC版和GA版（GA正式发布版）</p>
<h3 id="mysql数据库商业版和社区版的区别">MySQL数据库商业版和社区版的区别</h3>
<p>在前面的内容已经阐述过了，MySQL的版本发布采用双授权政策，即分为社区版和商业版，而这两个版本又各自分四个版本依次发布：Alpha版、Beta版、RC版和GA版（GA正式发布版）</p>
<h3 id="alpha版">Alpha版</h3>
<p>Alpha版一般只在开发的公司内部运行，不对外公开。主要死开发者自己对产品进行测试，检查产品是否存在缺陷、错误，验证产品功能与说明书、用户手册是否一致。MySQL是属于开放源代码的开源产品，因此需要世界各地开发者、爱好者和用户参与软件的开发测试和手册编写等工作。所以会对外公布此版本的源码和产品，方便任何人可以参与开发测试工作，甚至编写与修改用户手册。</p>
<h3 id="beta版">Beta版</h3>
<p>Beta版一般是完成功能的开发和所有的测试工作时候的产品，不会存在较大的功能或性能BUG，并且邀请或提供给公户体验与测试，以便更全面地测试软件的不足之处或存在的问题。</p>
<h3 id="rc版">RC版</h3>
<p>RC版属于生产环境发布之前的一个小版本或称候选版，是根据Beta测试结果，收集到的BUG或缺陷之处等收集到信息，进行修复和完善之后的新一版本</p>
<h3 id="ga版">GA版</h3>
<p>GA版是软件产品正式发布的版本，也称生产版本的产品。一般情况下，企业生产环境都会选择GA版本的MySQL软件，用于真实的生产环境中。偶尔有个别的大型企业会追求新功能驱动而牺牲稳定性使用其他版本，但这个是个例。</p>
<h3 id="mysql四中发布版本选择说明">MySQL四中发布版本选择说明</h3>
<p>MySQL AB官方网站会把五种数据库版本都提供下载，主要是MySQL数据库属于开发源代码的数据库产品，鼓励全球的技术爱好者参与研发、测试、文档编写和经验分享，甚至包过产品发展规划，对于Development版本、Alpha版本和Beta版本是绝对不允许使用在任何生产环境，毕竟这是一个GA版本之前，也即生产版本发布之前的一个小版本。另外，对MySQL数据库GA版本，也是需要慎重选择，开源社区产品毕竟不是经过严格的测试工序完成的产品，是全球开源技术人员的资源完成的，会存在比商业产品稳定性弱的缺陷。更严格的选择见后文。</p>
<h3 id="mysql产品路线">MySQL产品路线</h3>
<h4 id="mysql产品路线变更历史背景">MySQL产品路线变更历史背景</h4>
<p>早起MySQL也是遵循版本号逐渐增加的方式发展的，格式例如：mysql-x.xx.xx.tar.gz，例如DBA都非常熟悉的生产场景版本：4.1.7、5.0.56等。</p>
<p>近几年，为了提高MySQL产品的竞争优势、以及提高性能、降低开发维护成本等原因，同时，更方便企业用户更精准的选择适合的版本产品用于自己的企业生产环境中。
MySQL在发展到5.1系列版本之后，重新规划为3条产品线</p>
<h4 id="50xx到51xx产品线介绍">5.0.xx到5.1.xx产品线介绍</h4>
<p>第一条产品线：5.0.xx及升级到5.1.xx的产品系列，这条产品线继续完善与改进其用户体验和性能，同时增加新功能，这条路线可以说是MySQL早起产品的延续系列，这一系列的产品发布情况及历史版本如下：
MySQL 5.1是当前稳定（产品质量）发布系列。只针对漏洞修复重新发布；没有增加会影响稳定性的新功能。</p>
<ul>
<li>MySQL 5.1:Previous stable(production-quality) release
MySQL 5.0是前一稳定（产品质量）发布系列。只针对严重漏洞修复和安全修复重新发布；没有增加会影响该系列的重要功能。</li>
<li>MySQL 5.0:Old stable release nearing the end of the product lifecycle
MySQL 4.0和3.23是旧的稳定(产品质量)发布系列。该版本不再使用，新的发布只用来修复特别严重的漏洞(以前的安全问题)。</li>
</ul>
<h4 id="54xx开始到57xx产品线系列介绍">5.4.xx开始到5.7.xx产品线系列介绍</h4>
<p>为了更好的整合MySQL AB公司社区和第三方公司开发的新存储引擎，以及吸收新的实现算法等，从而更好的支持SMP架构，提高性能而做了大量的代码重构。版本号为从5.4.xx开始，目前发展到了5.6.x
主流：互联网公司用mysql5.5，逐步过渡到5.6。</p>
<h4 id="60xx-71xx产品线系列介绍">6.0.xx-7.1.xx产品线系列介绍</h4>
<p>第三条产品线：为了更好的推广MySQL Cluster版本，以及提高MySQL Cluster的性能和稳定性，以及功能改进和增加，以及改动mysql基础功能，使其对Cluster存储引擎提供更有效地支持与优化。版本号为6.0.xx开发，目前发展到7.1.xx</p>
<h3 id="mysql数据库软件命名介绍">MySQL数据库软件命名介绍</h3>
<p>MySQL数据库软件的名字是由3个数字和一个后缀组成的版本号。例如，像 <code>mysql-5.0.56.tar.gz</code> 的版本号这样解释：</p>
<ul>
<li>第一个数字（5）为主版本号，描述了文件格式。所有版本5发行都有相同文件格式。</li>
<li>第二个数字（0）为发行级别，主版本号和发行级别组合到一起便构成了发行序列号。</li>
<li>第三个数字（56 为在此发行系列的版本号，随每个新分发版本递增。通常你需要已经选择的发行(release)的最新版本。</li>
</ul>
<p>每次更新后，版本字符串的最后一个数字递增。如果相对于前一个版本增加了新功能或有微小的不兼容性，字符串的第二个数字递增。如果文件格式改变，第一个数字递增。
后缀显示发现的稳定性级别。通过一系列后缀显示如何改进稳定性。可能的后缀有：</p>
<p><em><strong>alpha</strong></em> 表明发行包含大量未被彻底测试的新代码。已知的缺陷应该在新闻小节被记录。请参见附录D：MySQL变更史。在大多数alpha版本中也有新的命令和扩展。alpha版本也可能有主要代码更改等开发。但我们在发布前一定对其进行测试。</p>
<p><em><strong>beta</strong></em> 意味着该版本功能是完整的，并且所有的新代码被测试了，没有增加重要的新特征，应该没有已知的缺陷。当alpha版本至少一个月没有出现报导的致命漏洞，并且没有计划增加导致已经实施的功能不稳定的新功能时，版本则从alpha版变为beta版。在以后的beta版、发布版或产品发布中，所有API、外部可视结构和SQL命令列均不再更改。</p>
<p><em><strong>rc</strong></em> 是发布代表；是一个发行了一段时间的beta版本，看起来应该运行正常。只增加了很小的修复。(发布代表即以前所称的gamma 版)
如果没有后缀，这意味着该版本已经在很多地方运行一段时间了，而且没有非平台特定的缺陷报告。只增加了关键漏洞修复修复。这就是我们称为一个产品（稳定）或“通用”版本的东西。</p>
<p>MySQL的命名机制于其它产品稍有不同。一般情况，我们可以很放心地使用已经投放市场两周而没有被相同发布系列的新版本所代替的版本。</p>
<h4 id="mysql产品版本最终选择建议">MySQL产品版本最终选择建议</h4>
<ul>
<li>稳定版：选择开源的社区版的稳定GA版本。</li>
<li>产品线：可以选择5.1或5.5，互联网公司主流5.5，其次是5.1和5.6</li>
<li>选择MySQL数据库GA版本发布后6个月以上的GA版本</li>
<li>选择前后几个月没有打的BUG修复的版本，二不是大量修复BUG的集中版本</li>
<li>最好向后较长时间没有更新发布的版本</li>
<li>考虑开发人员开发程序使用的版本是否兼容你选择的版本</li>
<li>作为内部开发测试数据库环境，跑大概3-6个月的时间</li>
<li>优先企业非核心业务采用新版本的数据库GA版本软件</li>
<li>向DBA高手请教，使用真正的高手们使用过得好用的GA版本产品</li>
<li>经过上述工序后，若是没有重要功能BUG或性能瓶颈，则可以开始开率作为任何业务数据服务的后端数据库软件。</li>
</ul>
<h2 id="安装mysql">安装MySQL</h2>
<p>最正宗的产品线5.1及以前：常规的编译方式安装MySQL</p>
<p>所谓常规方式编译安装MySQL就是延续早起MySQL的3部曲安装方式，即 <code>./configure; make; make install</code></p>
<p>此种方式适合所有 MySQL 5.0.xx ~ 5.1.xx产品系列，是最常规的编译方式。</p>
<h3 id="采用cmake方式编译安装mysql">采用cmake方式编译安装MySQL</h3>
<p>由于MySQL 5.5.xx ~ 5.6.xx 产品系列特殊性，所以编译方式也和早期的产品安装方式不同，采用cmake或gmake方式编译安装。即 <code>./cmake;make;make install</code>，生产场景具体命令及参数为</p>
<h4 id="采用二进制方式免编译安装mysql">采用二进制方式免编译安装MySQL</h4>
<p>采用二进制方式免编译安装MySQL，这种方式和yum/rpm包安装方式类似，适合类MySQL产品系列，不需要负载的编译设置及编译时间等待，直接解压下载的软件包，初始化可完成mysql的安装启动。</p>
<h4 id="如何正确选择mysql的安装方式">如何正确选择MySQL的安装方式</h4>
<p>yum/rpm安装适合对数据库要求不太高的场合，例如并发不大，公司内部，企业内部的一些应用场景。二进制免安装比较简单方便，适合5.0-5.1和5.5-5.6系列，是很多专业DBA的选择，普通linux运维人员多采用编译的方式，5.0-5.1采用的常规方式，5.5-5.6采用cmake方式。</p>
<p>建议，安装机器较少，推荐cmake方式，数量多了就用二进制免安装。</p>
<h3 id="mysql下载">MySQL下载</h3>
<p><a href="http://www.mysql.com" target="_blank"
   rel="noopener nofollow noreferrer" >http://www.mysql.com</a></p>
<ul>
<li>enterprise：企业版 商业版</li>
<li>community：社区版</li>
<li>yum repository：yum仓库（centos redhat fedora）</li>
<li>apt repository：apt-get仓库（debian Ubuntu）</li>
<li>SUSE repository：suse仓库</li>
<li>window：windows版</li>
</ul>
<h4 id="企业场景mysql安装方式">企业场景MySQL安装方式</h4>
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th>安装方式</th>
<th>特点说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1   </td>
<td>yum/rpm包安装</td>
<td>简单、速度快，但是不能定制安装，入门新手常用这种方式</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td>二进制安装</td>
<td><font style="background:#fee904;" size=2> 解压软件</font>，简单配置后就能使用，<font style="background:#fee904;" size=2>不用安装</font>，速度较快，专业DBA喜欢这种方式。软件名如：<br><font style="background:#fee904;" size=2>linux-5.5.32-linux2.6-x86_64.tar.gz</font><br><font style="background:#fee904;" size=2>mysql-5.6.33-linux-glibc2.5-x86_64.tar</font></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td>源码编译安装</td>
<td>可以定制安装，但是安装时间长，例如：字符集安装路径等，软件名：<font style="background:#fee904;" size=2>linux-5.5.32.tar.gz</font>。<br>针对mysql5.1；<br>mysql5.5以上 <code>./cmake</code> ; <code>gmake;gmake instal</code> ;</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td>源码软件结合yum/rpm安装</td>
<td>把源码软件制作成符合要求的rpm，放到yum仓库里，然后通过yum来安装，结合上面1和3的优点，即安装快速，可任意定制参数，但是安装者需要具备更深能力。</td>
</tr>
</tbody>
</table>
<p>默认路径 usr/local/mysql</p>
<p>大型门户把源码根据企业的需求制作成rpm，搭建yum仓库，yum install xxx -y</p>
<h3 id="二进制包安装">二进制包安装</h3>
<h4 id="创建mysql用的账号">创建MySQL用的账号</h4>
<pre><code class="language-bash">useradd -s /sbin/nologin -M mysql
</code></pre>
<h4 id="二进制方式安装mysql">二进制方式安装mysql</h4>
<p>解压软件包</p>
<pre><code class="language-bash">tar -zxf mysql-5.5.32-linux2.6-x86_64.tar.gz
</code></pre>
<p>移动目录</p>
<pre><code class="language-bash">mv mysql-5.5.32-linux2.6-x86_64 /app/mysql-5.5.32
</code></pre>
<p>创建软连接，生成去掉版本号的路径方便访问</p>
<pre><code class="language-bash">ln -s /app/mysql-5.5.32/ /app/mysql
</code></pre>
<hr>
<p><font color="#0215cd" size=2>提示：操作到此部，相当于编译安装make install之后</font></p>
<hr>
<h4 id="初始化mysql">初始化MySQL</h4>
<pre><code class="language-bash">$ /app/mysql/scripts/mysql_install_db \
--basedir=/app/mysql/ \
--datadir=/app/mysql/data \
--user=mysql
WARNING: The host 'centos' could not be looked up with resolveip.
This probably means that your libc libraries are not 100 % compatible
with this binary MySQL version. The MySQL daemon, mysqld, should work
normally with the exception that host name resolving will not work.
This means that you should use IP addresses instead of hostnames
when specifying MySQL privileges !
Installing MySQL system tables...
OK
Filling help tables...
OK
 
To start mysqld at boot time you have to copy
support-files/mysql.server to the right place for your system

.....
.....

You can start the MySQL daemon with:
cd /app/mysql/ ; /app/mysql//bin/mysqld_safe &amp;
 
You can test the MySQL daemon with mysql-test-run.pl
cd /app/mysql//mysql-test ; perl mysql-test-run.pl
 
Please report any problems with the /app/mysql//scripts/mysqlbug script!
</code></pre>
<h4 id="初始化mysql配置文件">初始化MySQL配置文件</h4>
<pre><code class="language-bash">$ ls /app/mysql/support-files/*.cnf
my-huge.cnf
my-innodb-heavy-4G.cnf
my-large.cnf
my-medium.cnf
my-small.cnf
 # my-medium.cnf &lt; my-small.cnf &lt; my-small.cnf &lt; my-huge.cnf &lt; my-innodb-heavy-4G.cnf
</code></pre>
<p>虚拟机测试环境下选择my-small.cnf配置模板。如果是生产环境可以根据硬件配置选择高级的配置文件</p>
<pre><code class="language-bash">cp /app/mysql/support-files/my-small.cnf /etc/my.cnf
</code></pre>
<h4 id="配置启动mysql数据库">配置启动MySql数据库</h4>
<p>设置启动脚本
二进制默认安装路径是/usr/local/mysql，启动脚本里是/usr/local/mysql都需要替换</p>
<pre><code class="language-bash"># 启动脚本
/app/mysql/bin/mysqld_safe

# 替换命令
sed -i 's#/usr/local/mysql#/app/mysql#g' /app/mysql/bin/mysqld_safe
</code></pre>
<blockquote>
<p><strong>启动数据库</strong></p>
</blockquote>
<ol>
<li>传统方式</li>
</ol>
<pre><code class="language-bash">cp mysql.server /etc/init.d/mysqld
sed -i 's#/usr/local/mysql#/app/mysql#g' /etc/init.d/mysqld
chmod +x /etc/init.d/mysqld
killall mysqld

$ /etc/init.d/mysqld start
Starting MySQL.. SUCCESS!

$ /etc/init.d/mysqld stop
Shutting down MySQL. SUCCESS!
 
$ /app/mysql/bin/mysqld_safe &amp; #&lt;==“&amp;”作用是在后台执行MySQL服务
</code></pre>
<blockquote>
<p><strong>mysql启动错误</strong></p>
</blockquote>
<pre><code class="language-bash">$ ./mysql start
Starting MySQL...
$ 170521 22:59:38 mysqld_safe error: log-error set to '/data/3306/logs/mysql_3306.err', however file don't exists. Create writable for user 'mysql'.
</code></pre>
<p>mysqlbug <a href="https://bugs.mysql.com/bug.php?id=84427" target="_blank"
   rel="noopener nofollow noreferrer" >https://bugs.mysql.com/bug.php?id=84427</a></p>
<blockquote>
<p><strong>检查MySQL数据库是否启动</strong></p>
</blockquote>
<pre><code class="language-bash">$ lsof -i :3306
COMMAND   PID    USER    FD   TYPE  DEVICE  SIZE/OFF  NODE  NAME
mysqld    38313  mysql   10u  IPv4  73384   0t0       TCP   *:mysql (LISTEN)
</code></pre>
<h4 id="配置mysql命令全局使用">配置mysql命令全局使用</h4>
<blockquote>
<p><strong>配置全局路径的意义</strong></p>
</blockquote>
<p>如果不为MySQL的命令配置全局路径，就无法直接在命令行输入mysql这样的命令，只能用全局命令</p>
<p>方法1：</p>
<pre><code class="language-bash">vi /etc/profile
PATH=&quot;/app/mysql/bin:$PATH&quot;
source /etc/profile
echo 'PATH=&quot;/app/mysql/bin:$PATH&quot;' &gt;&gt;/etc/profile &amp;&amp; . /etc/profile
</code></pre>
<p>方法2：</p>
<pre><code class="language-bash"># 尽量往前面拷，要不会和系统yum安装的mysql冲突
cp /app/mysql/bin/* /usr/local/sbin 

$ which mysql
# 如果找到的是 /usr/bin是系统yum安装的，不要让我们安装的和yum安装的冲突
/app/mysql/bin/mysql  
</code></pre>
<p>方法3：</p>
<pre><code class="language-bash">ln -s /app/mysql/bin/* /usr/local/sbin/
</code></pre>
<hr>
<p><strong><font color="#0215cd" size=2>特别强调：必须把MySQL命令路径放在PATH路径中的前面，否则可能会导使用了mysql等命令和编译安装的不是一个，进而产生错误。</font></strong></p>
<hr>
<p>yum安装MySQL命令访问编译安装的服务器而出来问题：http://oldboy.blog.51cto/25614110/011</p>
<h4 id="mysql-56-二进制包安装">MySQL-5.6 二进制包安装</h4>
<p>安装成功提示：与MySQL 5.5.x一样看到两个OK即安装完毕</p>
<pre><code class="language-bash">$ /app/mysql/scripts/mysql_install_db \
--basedir=/app/mysql/ \
--datadir=/app/mysql/data \
--user=mysql

WARNING: The host 'lamp_server' could not be looked up with /app/mysql//bin/resolveip.
This probably means that your libc libraries are not 100 % compatible
with this binary MySQL version. The MySQL daemon, mysqld, should work
normally with the exception that host name resolving will not work.
This means that you should use IP addresses instead of hostnames
when specifying MySQL privileges !
 
Installing MySQL system tables...2016-09-28 17:45:23 0 [Warning] TIMESTAMP with implicit DEFAULT
....
....
OK
 
Filling help tables...2016-09-28 17:45:28 0 
[Warning] TIMESTAMP with implicit DEFAULT value is deprecated. 
Please use --explicit_defaults_for_timestamp server option (see documentation for more details).
....

</code></pre>
<p>将启动脚本复制到/etc/ini.d下</p>
<pre><code class="language-bash">cp support-files/mysql.server /etc/init.d/mysqld
cp my.cnf /etc/my.cnf #←修改配置文件
vi /etc/my.cnf
</code></pre>
<p>[mysqld] 中添加：</p>
<pre><code class="language-bash">basedir = /usr/local/mysql
datadir = /usr/local/mysql/data
port = 3306
server_id = 1
</code></pre>
<p>将全局启动命令做个链接</p>
<pre><code class="language-bash">ln -s /app/mysql/bin/mysql /usr/bin
echo &quot;PATH=/app/mysql/bin:$PATH&quot; &gt;&gt;/etc/profile
</code></pre>
<p>mysql5.6二进制后登陆</p>
<pre><code class="language-bash">$  mysql -uroot -p
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 2
Server version: 5.6.33 MySQL Community Server (GPL)
 
Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.
 
Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.
 
Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
 
mysql&gt;
</code></pre>
<h2 id="mysql多实例">MySQL多实例</h2>
<h3 id="什么是mysql多实例">什么是MySQL多实例？</h3>
<p>简单的说，MySQL多实例就是一台服务器上同时开启多个不同的服务器端口（如3306、3307），同时运行多个MySQL服务器进程，这些服务进程通过不同socket监听不同的服务端口来提供服务。</p>
<p>这些MySQL多实例共用一套MySQL安装程序，使用不同的my.cnf（也可相同）配置文件、启动程序（也可以相同）的数据文件。在提供服务时，多实例MySQL在逻辑上看来是各自独立的，他们根据配置文件的对应设定值，获得服务器相应数量的硬件资源。</p>
<p>MySQL多实例就相当于房子的多个我是，每个实例可以看做一件我是，整个服务器就是一套房子，服务器的硬件资源（cpu,mem,disk）、软件资源（centos）可以看做房子的卫生间、厨房、客厅，是房子的公用资源。</p>
<p>nginx apache Haproxy memcached redis等都可配置多实例。</p>
<h3 id="mysql多实例的作用与问题">MySQL多实例的作用与问题</h3>
<h4 id="有效利用服务器资源">有效利用服务器资源</h4>
<p>当单个服务器资源有剩余时，可以充分利用剩余的资源提供更多的服务，实现资源的逻辑隔离。</p>
<h4 id="节约服务器资源">节约服务器资源</h4>
<p>当公司自己紧张，但是数据库又需要各自尽量独立地提供服务，而且需要主从复制等技术，多实例就再好不过了。</p>
<p>当某个数据库实例并发很高或者有SQL慢查询时，整个实例会消耗大量的系统CPU、磁盘IO等资源，导致服务器上的其他数据库实例提供服务的质量一起下降。会存在资源互抢占问题。不同实例获取的资源是相对立的，无法像虚拟化一样完全隔离。</p>
<h3 id="mysql多实例的生产应用场景">MySQL多实例的生产应用场景</h3>
<h4 id="资金紧张型公司的选择">资金紧张型公司的选择</h4>
<p>若公司资金紧张，公司业务访问量又不太大，但又希望不同业务的数据库服务各自尽量独立的提供服务而互相不收影响，同时，还需要主从复制等技术提供备份或读写分离服务，那么，多实例就再好不过了。比如：可以通过3台服务器部署9-15个实例，交叉做主从复制、数据备份及读写分离，这样就可达到9-15太服务器每个只装一个数据库才有的效果。这里要强调的是，所谓的尽量独立是相对的。</p>
<h4 id="并发不是特别大的业务">并发不是特别大的业务</h4>
<p>当公司业务访问量不太大的时候，服务器的资源基本都是浪费的，这时就很适合多实例的应用，如果对SQL语句的优化做的比较好，MySQL多实例会是一个很值得使用的技术，及时并发很大，合理分配好系统资源以及搭配好系统服务，也不会有太大问题</p>
<h4 id="门户网站应用mysql多实例场景">门户网站应用MySQL多实例场景</h4>
<p>门户网站通常都会使用多实例，因为配置硬件好的服务器，可节省IDC机柜空间，同时，跑多实例也会减少硬件资源跑不满的浪费。一般是丛库多实例，例如某部门中使用的IBM服务器为48核，96GB内存，一台服务器跑3-4个实例。(高配多实例，节省机柜空间，虚拟化也是这样)</p>
<h3 id="mysql多实例常见的配置方案">MySQL多实例常见的配置方案</h3>
<h4 id="单一配置文件单一启动程序多实例部署方案">单一配置文件、单一启动程序多实例部署方案</h4>
<p>下面是MySQL官方文档提到的单一配置文件、单一启动程序多实例部署方案，不推荐此方案，这里仅作为知识点提及，不在涉及此方案说明。</p>
<pre><code class="language-bash">[mysqld_multi]
mysqld=/usr/bin/mysqld_safe
mysqladmin=/usr/bin/mysqladmin
user=mysql
[mysql1]
socket=/var/lib/mysql/mysql.sock
port=3306
pid-file=/var/lib/mysql/mysql.pid
datadir=/var/lib/mysql
user=mysql
[mysql1]
socket=/var/lib/mysql/mysql.sock
port=3306
pid-file=/var/lib/mysql/mysql.pid
datadir=/var/lib/mysql
user=mysql
skip-name-resolve
server-id=10
</code></pre>
<pre><code class="language-bash">mysql_multi --config-file=/data/mysql/my_multi.cnf start 1,2 #&lt;==启动命令
</code></pre>
<p>对于该方案，缺点是耦合度太高，一个配置文件，不好管理。工作开发和运维的统一。原则：降低耦合度。</p>
<h4 id="多配置文件多启动程序部署方案">多配置文件多启动程序部署方案</h4>
<p>以下是已经部署好的MySQL-5.5双实例的目录信息及文件注释说明</p>
<pre><code class="language-bash">data
├── 3306
│   ├── my.cnf   #&lt;==配置文件
│ ├── data     #&lt;==数据文件
│   └── mysql #&lt;==多实例启动脚本
└── 3307
    ├── my.cnf
└── mysql
</code></pre>
<h3 id="安装mysql多实例">安装MySQL多实例</h3>
<h4 id="安装mysql需要的依赖包和编译软件">安装MySQL需要的依赖包和编译软件</h4>
<p>安装MySQL之前需要安装MySQL依赖包</p>
<pre><code class="language-bash">yum install -y libaio-devel ncurses-devel
</code></pre>
<blockquote>
<p><strong>安装编译MySQL需要的软件</strong></p>
</blockquote>
<p>因MySQL5.5系列采用的cmake编译，需要先下载安装cmake</p>
<pre><code class="language-bash">yum install cmake -y
</code></pre>
<h4 id="采用编译方式安装mysql">采用编译方式安装MySQL</h4>
<pre><code class="language-bash">tar zxf mysql-5.5.52.tar.gz
cd mysql-5.5.52
</code></pre>
<p>编译参数</p>
<pre><code class="language-bash">cmake . -DCMAKE_INSTALL_PREFIX=/app/mysql-5.5.54 \
-DMSQL_DATADIR=/app/mysql-5.5.54/data \
-DMYSQL_UNIX_ADDR=/app/mysql-5.5.54/tmp/mysql.sock \
-DDEFAULT_CHARSET=utf8 \
-DDEFAULT_COLLATION=utf8_general_ci \
-DEXTRA_CHARSETS=gbk,gb2312,utf8,ascii \
-DENABLED_LOCAL_INFILE=ON \
-DWITH_INNOBASE_STORAGE_ENGINE=1 \
-DWITH_FEDERATED_STORAGE_ENGINE=1 \
-DWITH_BLACKHOLE_STORAGE_ENGINE=1 \
-DWITH_EXAMPLE_STORAGE_ENGINE=1 \
-DWITHOUT_PARTITION_STORAGE_ENGINE=1 \
-DWITH_FAST_MUTEXES=1 \
-DWITH_ZLIB=bundled \
-DENABLED_LOCAL_INFILE=1 \
-DWITH_READLINE=1 \
-DWITH_EMBEDDED_SERVER=1 \
-DWITH_DEBUG=0
</code></pre>
<p>创建软连接</p>
<pre><code class="language-bash">ln -s /app/mysql-5.5.54/ /app/mysql
</code></pre>
<h4 id="创建mysql多实例的数据文件目录">创建MySQL多实例的数据文件目录</h4>
<p>在企业中，通常以 <code>/data</code> 目录作为MySQL多实例总的根目录，然后规划不同的数字（即MySQL实例端口号）作为/data下面的二级目录，不同的二级目录对应的数字就作为MySQL实例的端口号，以区别不同的实例，数字对应的二级目录下包含MySQL的数据文件、配置文件及启动文件等。
创建数据目录</p>
<pre><code class="language-bash">mkdir -p /data/{3306,3307}/data 
# 多个可以依次累加，生产环境中一般3-4个实例为最佳。
</code></pre>
<h4 id="创建mysql多实例的配置文件">创建MySQL多实例的配置文件</h4>
<p>MySQL数据库默认为用户提供了多个配置文件模板，用户可以根据服务器硬件配置的大小来选择。</p>
<pre><code class="language-bash">$  ls /app/mysql/support-files/my*.cnf
my-huge.cnf             
my-medium.cnf
my-innodb-heavy-4G.cnf  
my-small.cnf
my-large.cnf
</code></pre>
<p>上面是单实例的默认配置文件模板，如果配置多实例，和单实例会有不同。为了让MySQL多实例之间彼此独立，因此要为每一个实例建立一个my.cnf配置文件和一个启动文件mysql，让他们分别对应自己的数据文件目录data
创建配置文件及目录略，一般都是用配置好的配置文件与脚本</p>
<h4 id="配置权限">配置权限</h4>
<pre><code class="language-bash">$  find /data -type f -name 'mysql' #&lt;==启动脚本中存在mysql密码要注意权限
/data/3306/mysql
/data/3307/mysql
find /data -type f -name 'mysql'|xargs chmod 700
</code></pre>
<h4 id="mysql相关命令加入全局路径的配置">MySQL相关命令加入全局路径的配置</h4>
<pre><code class="language-bash">echo &quot;PATH=/app/mysql/bin:$PATH&quot;
ln -s /app/mysql/bin/* /usr/sbin/ 
</code></pre>
<h3 id="初始化多实例数据库文件">初始化多实例数据库文件</h3>
<p>上述步骤全部配置完毕后，就可以初始化数据库文件了，这个步骤其实也可以在编译安装MySQL之后就操作，只不过放到这里更合理，</p>
<h4 id="初始化mysql数据库">初始化MySQL数据库</h4>
<p>初始化数据库会有很多提示，如果没有error级别的错误，有两个ok字样表示初始化成功，否则就解决初始化问题</p>
<pre><code class="language-bash">cd /app/mysql/script/
./mysql_install_db \
--basedir=/app/mysql/ \
--datedir=/data/3306/data \
--user=mysql
 
./mysql_install_db \
--basedir=/app/mysql/ \
--datadir=/data/3306/data \
--user=mysql \
--defaults-file=/data/3306/my.cnf
</code></pre>
<h4 id="初始化数据可的原理及结果说明">初始化数据可的原理及结果说明</h4>
<p>初始化数据库的实质就是创建基础的数据库系统的库文件，例如：生成MySQL库表等。
初始化数据可偶查看对应实例的数据目录，可以看到多了一些文件
启动MySQL多实例数据库</p>
<pre><code class="language-bash">/data/3306/mysql start
/data/3307/mysql start
 
$ netstat -nltup       
tcp      0      0 0.0.0.0:3306    0.0.0.0:*    LISTEN     38980/mysqld        
tcp      0      0 0.0.0.0:3307    0.0.0.0:*    LISTEN     22942/mysqld        
tcp      0      0 :::52113             :::*    LISTEN     1123/sshd  
</code></pre>
<h3 id="mysql多实例启动故障排错说明">MySQL多实例启动故障排错说明</h3>
<p>如果MySQL多实例有服务没有被启动，排查办法如下：</p>
<p>如果发现没有显示MySQL对应实例的端口，请稍微等待几秒再检查，MySQL服务的启动比web服务慢一些</p>
<p>如果还是不行，请查看MySQL服务对应实例的错误日志，错误日志路径在my.cnf配置的最下面定义。</p>
<p>例如3306的错误日志为：</p>
<pre><code class="language-bash">[mysqld_safe]
log-error=/data/3306/mysql_3306.err
pid-file=/data/3306/mysqld.pid
</code></pre>
<ol>
<li>细看所有执行命令返回屏幕输出，不要忽略关键的输出内容。</li>
<li>辅助查看系统日志/var/log/message</li>
<li>如果是MySQL关联了其他服务。要同时查看相关服务的日志</li>
</ol>
<h3 id="配置及管理mysql多实例数据库">配置及管理MySQL多实例数据库</h3>
<h4 id="配置mysql多实例数据库开机自启动">配置MySQL多实例数据库开机自启动</h4>
<p>服务的开机自启动很关键，MySQL多实例的启动也不例外。</p>
<blockquote>
<p><strong>登陆MySQL测试</strong></p>
</blockquote>
<pre><code>$ mysql -S /data/3306/mysql.sock  #←socket用于区别不同的实例
Welcome to the MySQL monitor.  Commands end with ; or \g.
.....
Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
</code></pre>
<h4 id="mysql多实例数据库的管理方法">MySQL多实例数据库的管理方法</h4>
<p>MySQL安装完成后，默认root账户是没有密码的，登陆不同的实例需要指定不同实例的socket路径及文件，在my.cnf中指定的。注意：不同的socket虽然名字相同，但是路径是不同的，因此是不同的文件。</p>
<pre><code class="language-bash">mysql -S /data/3306/mysql.sock
mysql -S /data/3307/mysql.sock
</code></pre>
<h4 id="重启多实例">重启多实例</h4>
<p>若要重启多实例数据库也需要进行相应的配置。在重启数据库前，需要调整不同实例启动文件里对应的数据库密码：</p>
<pre><code class="language-bash">sed -n '13p' mysql
sed -i 's#mysql_pwd=&quot;oldboy&quot;#mysql_pwd=&quot;111&quot;#g' mysql ../3307/mysql
sed -i 's#mysql_pwd=&quot;oldboy&quot;#mysql_pwd=&quot;111&quot;#g' mysql ../3307/mysql
sed -n '13p' mysql
</code></pre>
<p>由于选择了<code>mysqladmin shutdown</code>的停止方式，所以停止数据库时，需要在启动文件里配置数据库的密码。上面由于密码不对，顾提示密码不对的错误</p>
<pre><code class="language-bash">$ /data/3306/mysql stop
Stoping MySQL...
/app/mysql/bin/mysqladmin: connect to server at 'localhost' failed
error: 'Access denied for user 'root'@'localhost' (using password: YES)'
$ /data/3306/mysql stop -S /data/3306/mysql.sock   
Stoping MySQL...
</code></pre>
<hr>
<p>提示：禁止使用pkill、kill -9 killall -9等命令强制杀死数据库，这回引起数据库无法启动等故障发生。</p>
<hr>
<h3 id="多实例mysql登陆问题">多实例MySQL登陆问题</h3>
<h3 id="多实例本地登陆mysql">多实例本地登陆MySQL</h3>
<p>多实例本地登陆一般是通过socket文件来指定具体登陆到那个实例的，此文件的具体位置是在mysql编译过程或my.cnf文件里指定的。在本地登陆数据库时，登陆程序会通过socket文件来判断登陆的是哪个数据库实例。</p>
<p>例如：通过mysql -uroot -p111 -S /data/3307/mysql.sock可知，登陆的是3307实例。mysql.sock是MySQL服务器端与本地MySQL客户端进行通信的Unix套接字文件。</p>
<h4 id="远程连接登陆mysql">远程连接登陆mysql</h4>
<p>远程登陆MySQL多实例中的一个实例时，通过TCP端口(port)来指定所要登陆的MySQL实例，此端口的配置是在MySQL配置文件my.cnf指定的</p>
<p>例如：在<code>mysql -uroot -p111 -h192.16-P3307 -P</code>为端口参数，后面接具体的实例端口，端口是一种 “逻辑连接位置” ，是客户端程序被分派到计算机上特殊服务程序的一种方式，强调提前在192.168.1.2上对该用户做授权。</p>
<pre><code class="language-sql">DROP USER 'monitor'@'%';

mysql&gt; select user,host from mysql.user;
+----------+------------+
| user     | host    |
+----------+------------+
| root     | 127. |
| root     | localhost  |
+----------+------------+

--MySQL的用户加主机名组成一个用户

mysql&gt; select user();
+----------------+
| user()         |
+----------------+
| root@localhost |
+----------------+
</code></pre>
<h2 id="常见错误">常见错误</h2>
<h3 id="安装报错解决">安装报错解决</h3>
<h4 id="access-denied-for-user-rootlocalhost-using-password-no"><code>Access denied for user 'root'@'localhost' (using password: NO)</code></h4>
<pre><code class="language-sql">ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: NO)
</code></pre>
<p>问题原因：密码不对哦</p>
<h4 id="error-cant-createwrite-to-file"><code>Error: Can't create/write to file</code></h4>
<pre><code class="language-sql">Error: Can't create/write to file '/tmp/#sql_4f4_0.MYD' (Errcode: 17)
</code></pre>
<p>问题原因： 权限问题</p>
<p>解决方法：<code>chmod -R 1777 /tmp</code></p>
<h4 id="error-2002-hy000-cant-connect-to-local"><code>ERROR 2002 (HY000): Can't connect to local</code></h4>
<pre><code class="language-sql">ERROR 2002 (HY000): 
Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)
</code></pre>
<p>问题原因：⑴ 服务没启动 ⑵ 配置文件中socket文件与编译时指定路径不一致</p>
<p>解决方法：⑴ 启动服务 ⑵ 多实例启动指定socket文件</p>
<h4 id="error-while-loading-shared-libraries"><code>error while loading shared libraries:</code></h4>
<pre><code class="language-bash">$ /app/mysql/scripts/mysql_install_db \
--basedir=/app/mysql/ \
--datadir=/app/mysql/data \
--user=mysql
Installing MySQL system tables...
/app/mysql//bin/mysqld:error while loading shared libraries: libaio.so.1: cannot open shared object file: No such file or directory
</code></pre>
<p>问题原因：缺少libaio包支持</p>
<p>解决方法：安装后重新初始化即可</p>
<pre><code class="language-bash">yum -install libaio* -y
</code></pre>
<h4 id="warning-the-host-xxx"><code>WARNING: The host 'xxx'</code></h4>
<pre><code class="language-bash">WARNING: The host 'centos' could not be looked up with resolveip.
</code></pre>
<p>问题原因：需要修改主机名的解析，使其和uname -n一样</p>
<h4 id="error-1004-cant-create-file"><code>ERROR: 1004 Can’t create file</code></h4>
<pre><code class="language-bash">ERROR: 1004 Can’t create file '/tmp/#sql300e_1_0.frm' (error: 13)
</code></pre>
<p>解决：原因是/tmp权限有问题(不解决，后面可能无法登陆数据库)</p>
<h3 id="使用错误解决">使用错误解决</h3>
<h4 id="error-2006">ERROR 2006</h4>
<p>在大批量导入数据库时，出现如下错误</p>
<pre><code class="language-bash">ERROR 2006 (HY000): MySQL server has gone away
No connection. Trying to reconnect...
</code></pre>
<p>排查思路：后来检查了没有导入成功的几篇文章，其大小都在8MB以上，会不会是单条记录太大了导致出现<code>ERROR 2006 (HY000): MySQL server has gone away</code>的呢？</p>
<p><strong>查看允许的最大值</strong></p>
<p>登陆MySQL后，使用如下命令查询：</p>
<pre><code class="language-sql">mysql&gt; show global variables like 'max_allowed_packet';   
+--------------------+---------+
| Variable_name      | Value   |
+--------------------+---------+
| max_allowed_packet | 8388608 |
+--------------------+---------+
</code></pre>
<p>上限是刚好8MB，怪不得报错。</p>
<blockquote>
<p>即时生效方法</p>
</blockquote>
<pre><code class="language-sql">set global max_allowed_packet=1024*1024*16;
</code></pre>
<p>可在不重启MySQL的情况下立即生效，但是重启后就会恢复原样。</p>
<blockquote>
<p>永久生效方法</p>
</blockquote>
<p>编辑 <code>/etc/my.cnf</code> ，将</p>
<pre><code class="language-sql">max_allowed_packet = 1M
</code></pre>
<p>修改为</p>
<pre><code class="language-sql">max_allowed_packet = 16M
</code></pre>
<p>之后重新导入，就不会产生ERROR 2006 (HY000): MySQL server has gone away错误了。
Unknown/unsupported storage engine: Innodb
Plugin &lsquo;InnoDB&rsquo; init function returned error.</p>
<pre><code class="language-sql">mysql&gt; show warnings;
+---------+------+----------------------------------------+
| Level   | Code | Message                                |
+---------+------+----------------------------------------+
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
| Warning | 1292 | Truncated incorrect DOUBLE value: 'Y ' |
+---------+------+----------------------------------------+
64 rows in set (0.00 sec)
</code></pre>
]]></content:encoded>
    </item>
    
    <item>
      <title>redis安全相关配置</title>
      <link>https://www.oomkill.com/2016/11/redis-security/</link>
      <pubDate>Wed, 23 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2016/11/redis-security/</guid>
      <description></description>
      <content:encoded><![CDATA[<h3 id="为redis客户端外部设置连接密码">为Redis客户端外部设置连接密码</h3>
<p>因为redis速度相当快，所以在一台比较好的服务器下，一个外部的用户可在一秒钟进行上万次的密码尝试，这意味着你需要指定非常非常强大的密码来防止暴力破解。</p>
<h4 id="修改配置文件">修改配置文件</h4>
<pre><code class="language-bash">requirepass 123@1
</code></pre>
<p><strong>重启服务后登录客户端提示没有验证</strong></p>
<pre><code class="language-bash">$ redis-cli
127.0.0.1:6379&gt; keys *
(error) NOAUTH Authentication required.
</code></pre>
<p><strong>验证成功后，可以正常操作</strong></p>
<pre><code class="language-bash">127.0.0.1:6379&gt; auth 123@1
OK
127.0.0.1:6379&gt; keys *
1) &quot;test-durable-1&quot;
2) &quot;test-durable&quot;
</code></pre>
<h4 id="命令行临时生效">命令行临时生效</h4>
<p><em><strong>在命令行设置后，redis在下次重启前，每次登录都需要验证密码</strong></em></p>
<pre><code class="language-bash">127.0.0.1:6379&gt; CONFIG set requirepass 123@1
OK
127.0.0.1:6379&gt; quit
$ redis-cli
127.0.0.1:6379&gt; keys *
(error) NOAUTH Authentication required.
</code></pre>
<hr>
<p><font color=#360c9f size=2><strong>注意：配置Redis复制的时候如果主数据库设置了密码，需要在从数据库的配置文件中通过masterauth参数设置主数据库的密码，以使从数据库连接主数据库时自动使用AUTH命令认证。</strong></font></p>
<hr>
<p><strong>通过mysql命令行指定密码方式登录Redis客户端</strong></p>
<pre><code class="language-bash">$ redis-cli -a 123@1
127.0.0.1:6379&gt; keys *
1) &quot;test-durable-1&quot;
2) &quot;test-durable&quot;
</code></pre>
<h3 id="危险命令重命名">危险命令重命名</h3>
<pre><code class="language-bash">rename-command flushall abc
rename-command get eee
rename-command FLUSHALL &quot;&quot;  #←禁用FLUSHALL命令
</code></pre>
<pre><code class="language-bash">127.0.0.1:6379&gt; get test-durable
(error) ERR unknown command 'get'
127.0.0.1:6379&gt; eee test-durable
&quot;test1&quot;
</code></pre>
<h3 id="绑定只能本机连接">绑定只能本机连接</h3>
<p>Redis的默认配置会接受来自任何地址发送来的请求，即在任何一个拥有公网IP的服务器上启动Redis服务器，都可以被外界直接访问到。要更改这一设置，在配置文件中修改bind参数，如只允许本机应用连接Redis.</p>
<pre><code class="language-sh">bind 127.0.0.1
</code></pre>
]]></content:encoded>
    </item>
    
    <item>
      <title>Redis安装</title>
      <link>https://www.oomkill.com/2016/11/redis-install/</link>
      <pubDate>Wed, 23 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2016/11/redis-install/</guid>
      <description></description>
      <content:encoded><![CDATA[<p>Remote Dictonary Server(Redis)是一个基于key-value键值对的持久化数据库存储系统。redis和大名鼎鼎的Memcached缓存服务很像,但是redis支持的数据存储类型更丰富,包括<font style="background:#bafe01;" size=2>string(字符串)、list(链表)、set(集合)和zset(有序集合)、Hash等</font>。</p>
<p>这些数据类型都支持push/pop,add/remove及取交集、并集和差集及更丰富的操作,而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。与memcached缓存服务一样，为了保证效率数据都是缓存在内存中提供服务。和memcached不同的是，<font style="background:#bafe01;" size=2>redis持久化缓存服务</font>还会周期性的把更新的数据写入到磁盘以及把修改的操作记录追加到文件里记录下来，比memcached更有优势的是，<font style="background:#bafe01;" size=2>redis还支持master-slave(主从)同步</font>,这点很类似关系型数据库MySQL。</p>
<p>Redis是一个开源的、使用C语言编写、３万多行代码、支持网络、可基于内存亦可久化的日志型、Key-Value数据库，并提供多种语言的API从2010年3月15日起，Redis开发工作由VMware主持。</p>
<p>Redis的出现，再一定程度上弥补了memcached这类key-value内存缓存服务的不足,在部分场合可以对关系数据库起到很好的补充作用.redis提供了Python, Ruby, Erlang, PHP客户端，使用很方便。redis官方文档如下：http://www.redis.io/documentation</p>
<h3 id="redis的优点">Redis的优点</h3>
<ul>
<li>与memcached不用，redis可以持久化存储数据。</li>
<li>性能很高：Redis能支持超过10w/秒的读写频率。</li>
<li>丰富的数据类型：redis支持二进制的Strings, Lists, Hashes, Sets及sorted sets等数据类型操作。</li>
<li>原子：Redis的所有操作都是原子性的,同时Redis还支持对几个操作全并后的原子性执行。</li>
<li>丰富的特性：Redis还支持publish/subscribe(发布/订阅)，通知，key过期等等特性。</li>
<li>redis支持异步主从复制。</li>
</ul>
<h3 id="redis的应用场景">Redis的应用场景</h3>
<p><strong>传统的MySQL+Memcached的网站架构遇到的问题</strong>：</p>
<p>MySQL数据库实际上是适合进行海量数据存储的,加上通过Memcached将热点数据  存放到到内存cache里,达到加速数据访问的目的,绝大部分公司都曾经使用过这样的架构,但随着业务数据量的不断增加,和访问量的增长,很多问题就会暴漏出来：</p>
<ol>
<li>需要不断的对MySQL进行拆库拆表Memcached也需不断跟着扩容,扩容和维护工作占据大量开发运维时间。</li>
<li>Memcached与MySQL数据库数据一致性问题是个老大难。</li>
<li>Memcached数据命中率低或down机,会导致大量访问直接穿透到数据库,导致MySQL无法支撑访问。</li>
<li>跨机房cache同步一致性问题。</li>
</ol>
<h4 id="redis在微博中的应用">redis在微博中的应用</h4>
<ol>
<li>计数器：微博（评论、转发、阅读、赞等）</li>
<li>用户（粉丝、关注、收藏、双向关注等）</li>
</ol>
<h4 id="redis在短信中的应用">redis在短信中的应用</h4>
<p>发送短信后存入redis中60秒过期。</p>
<h3 id="redis的最佳应用场景">redis的最佳应用场景</h3>
<ol>
<li>Redis最佳试用场景是全部数据in-memory。</li>
<li>Redis更多场景是作为Memcached的替代品来使用。</li>
<li>当需要除key/value之外的更多数据类型支持时,使用Redis更合适。</li>
<li>数据比较重要，对数据一致性有一定要求的业务。</li>
<li>当存储的数据不能被剔除时,使用Redis更合适。</li>
<li>更多</li>
</ol>
<ul>
<li><font color=#2b01fe size=2>Redis作者谈Redis应用场景</font>
<a href="http://blog.nosglfan.com/html/2235.html" target="_blank"
   rel="noopener nofollow noreferrer" >http://blog.nosglfan.com/html/2235.html</a></li>
<li><font color=#2b01fe size=2>使用redis bitmap进行活跃用户统计</font>
<a href="http://blog.nosqlfun.com/html/3501.html" target="_blank"
   rel="noopener nofollow noreferrer" >http://blog.nosqlfun.com/html/3501.html</a></li>
</ul>
<p>计数、cache服务、展示最近、最热、点击率最高、活跃度最高等等条件的top list、用户最近访问记录表、relation list/Message Queue、粉丝列表</p>
<p>Key-Value Store更加注重对海量数据存取的性能、分布式、扩展性支持上，并不需要传统关系数据库的一些特征。例如：Schema事务、完整SQL查询支持等等，因此在布式环境下的性能相对于传统的关系数据库有较大的提升。</p>
<h3 id="redis的生产经验教训">redis的生产经验教训</h3>
<ol>
<li>要进行Master-slave主从同步配置，在出现服务故障时可以切换。</li>
<li>在master禁用数据据持久化只需在slave上配置数据持久化。</li>
<li>物理内存+虚拟内存不足，这个时候dump一直死着，时间久了机器挂掉。这个情就是灾难。</li>
<li>当Redis物理内存使用超过内存总容量的3/5时就会开始比较危险了，就开始做swap，内存碎片大！</li>
<li>当达到最大内存时，会清空带有过期时间的如</li>
<li>redis与DB同步写的问题，先写DB，后写redis，因为写内存基本上没有问题。</li>
</ol>
<h3 id="业务场景">业务场景</h3>
<ol>
<li>提高了DB的可扩展性,只需要将新加的数据放到新加的服务器上就可以了。</li>
<li>提高了DB的可用性,只影响到需要访问的shard服务器上的数据的用户。</li>
<li>提高了DB的可维护性,对系统的升级和配里可以按shard一个个来搞,对服务产生的影响小。</li>
<li>小的数据库存的查询压力小,查询更快,性能更好。</li>
</ol>
<blockquote>
<p><strong>使用过程中的一些经验与教训,做个小结</strong>：</p>
</blockquote>
<ol>
<li>要进行Master-slave配置,出现服务故障时可以支持切换。</li>
<li>在master侧禁用数据持久化,只需在slave上配置数据持久化。</li>
<li>物理内存+虚拟内存不足时,这个时候dump已知死着,时间久了机器挂掉。这个情况就是灾难。</li>
<li>当Redis物理内存使用超过内存总容量的3/5时就会开始比较危险了,就开始做swap,内存碎片大。</li>
<li>当达到最大内存时,会清空带有过期时间的key,即使key未到过期时间。</li>
<li>redis与DB同步写的问题,先写DB,后写redis,因为写内存基本上没有问题。</li>
</ol>
<h2 id="安装配置redis">安装配置Redis</h2>
<h3 id="下载安装redis">下载安装Redis</h3>
<p>redis官方网站：www.redis.io</p>
<pre><code class="language-bash">make
make PREFIX=/app/redis-3.2.8 install 
</code></pre>
<p>命令执行完成后,会在/app/redis-3.2.8/bin/目录下生成5个可执行文件</p>
<pre><code class="language-bash">/app/redis-3.2.8/
└── bin
   ├── redis-benchmark #← redis性能测试工具,测试redis在你的系统及你的配置下读写性能
   ├── redis-check-aof #← 更新日志检查
   ├── redis-check-rdb 
   ├── redis-cli      #← redis命令行操作工具。当然也可用telnet根据其纯文本协议来操作
   └── redis-server   #←redis服务器的daemon启动服务
</code></pre>
<h3 id="配置并启动redis服务">配置并启动Redis服务</h3>
<h4 id="文件头部分">文件头部分</h4>
<p>操作命令：</p>
<pre><code class="language-bash">echo 'PATH=&quot;/app/redis/bin:$PATH&quot;' &gt;&gt;/etc/profile
. /etc/profile
</code></pre>
<h4 id="查看命令帮助">查看命令帮助</h4>
<pre><code class="language-bash">Usage: ./redis-server [/path/to/redis.conf] [options]
       ./redis-server - (read config from stdin)
       ./redis-server -v or --version
       ./redis-server -h or --help
       ./redis-server --test-memory &lt;megabytes&gt; 

Examples:
       ./redis-server (run the server with default conf)
       ./redis-server /etc/redis/6379.conf
       ./redis-server --port 7777 #&lt;==指定端口
       ./redis-server --port 7777 --slaveof 127.0.0.1 8888 
       ./redis-server /etc/myredis.conf --loglevel verbose #&lt;==指定配置文件

Sentinel mode:
       ./redis-server /etc/sentinel.conf --sentinel
</code></pre>
<h3 id="启动redis服务">启动redis服务</h3>
<p>创建配置文件,redis的配置文件在二进制安装包解压目录下的 redis.conf</p>
<pre><code class="language-bash">mkdir /app/redis-3.2.8/conf
cp /root/tools/redis-3.2.8/redis.conf /app/redis-3.2.8/conf/
</code></pre>
<p>启动命令</p>
<pre><code class="language-bash">redis-server /app/redis-3.2.8/conf/redis.conf &amp;
</code></pre>
<h3 id="启动错误">启动错误</h3>
<pre><code class="language-bash">WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.
</code></pre>
<p>原因：此参数确定了TCP连接中已完成队列(完成三次握手之后)的长度, 当然此值必须不大于Linux系统定义的/proc/sys/net/core/somaxconn值,默认是511,而Linux的默认参数值是128。当系统并发量大并且客户端速度缓慢的时候,可以将这二个参数一起参考设定。</p>
<p>暂时解决：redis.conf中 tcp backlog=128</p>
<pre><code class="language-bash">WARNING overcommit_memory is set to 0! Background save may fail under low memory condition.To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
</code></pre>
<p>原因：</p>
<p><strong>overcommit_memory参数说明</strong>：</p>
<p>设置内存分配策略（可选,根据服务器的实际情况进行设置）/proc/sys/vm/overcommit_memory可选值：0、1、2。</p>
<p>0：当用户空间请求更多的内存时，内核尝试估算出剩余可用的内存。</p>
<p>1：设这个参数值为1时，内核允许超量舒勇内存直到用完为止,主要用于科学计算。(最大限度的使用内存)</p>
<p>2：当设这个参数值为2时，内核会使用一个决不过量使用内存的算法，即系统整个内存地址空间不能超过swap+50%的RAM值，50%参数的设定是在overcommit_ratio中设定。</p>
<p><strong>解决：sysctl vm.overcommit_memory=1</strong>*</p>
<pre><code class="language-bash">WARNING you have Transparent Huge Pages (THP) support enabled in your kernel.
This will create latency and memory usage issues with Redis. 
To fix this issue run the command 
'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' 
as root, 
and add it to your /etc/rc.local in order to retain the setting after a reboot.
Redis must be restarted after THP is disabled.
</code></pre>
<p>原因</p>
<p>临时解决方法：</p>
<pre><code class="language-bash">echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled
</code></pre>
<p>参考文档：http://blog.csdn.net/a491857321/article/details/52006376</p>
<h3 id="客户端测试redis服务">客户端测试redis服务</h3>
<h4 id="redis-cli客户端帮助">redis-cli客户端帮助</h4>
<pre><code class="language-bash">redis-cli -help
</code></pre>
<h4 id="使用redis-cli客户端连接redis">使用redis-cli客户端连接redis</h4>
<p><strong>指定密码 ip 端口登陆</strong></p>
<pre><code class="language-bash">redis-cli -h 10.0.0.10 -p 3307 -a '111'
Usage: redis-cli [OPTIONS] [cmd [arg [arg ...]]]
  -h &lt;hostname&gt;      Server hostname (default: 127.0.0.1).
  -p &lt;port&gt;          Server port (default: 6379).
  -s &lt;socket&gt;        Server socket (overrides hostname and port).
</code></pre>
<p><strong>在Linux命令行操作redis</strong></p>
<pre><code class="language-bash">$ redis-cli set zhangsan 10-10
OK
$ redis-cli get zhangsan
&quot;10-10&quot;
</code></pre>
<h4 id="使用telnet连接redis">使用telnet连接redis</h4>
<pre><code class="language-bash">$ telnet 127.0.0.1 6379
Trying 127.0.0.1...
Connected to 127.0.0.1.
Escape character is '^]'.
get name
$2
45
</code></pre>
<h4 id="通过nc连接redis">通过NC连接redis</h4>
<pre><code class="language-bash">$ echo &quot;set three-world 刘备&quot;|nc 127.0.0.1 6379
+OK
$ echo &quot;get three-world&quot;|nc 127.0.0.1 6379
$6
刘备
</code></pre>
<h3 id="关闭redis服务">关闭redis服务</h3>
<pre><code class="language-bash">redis-cli shutdown
</code></pre>
<p>通过客户端测试redis服务</p>
<h3 id="php安装redis扩展">PHP安装Redis扩展</h3>
<p><strong>源码地址</strong>：</p>
<p><a href="https://github.com/phpredis/phpredis" target="_blank"
   rel="noopener nofollow noreferrer" >https://github.com/phpredis/phpredis</a></p>
<p><a href="http://pecl.php.net/package/redis" target="_blank"
   rel="noopener nofollow noreferrer" >http://pecl.php.net/package/redis</a></p>
<p><strong>安装</strong></p>
<pre><code class="language-bash">/app/php/bin/phpize
./configure --with-php-config=/app/php/bin/php-config
</code></pre>
<p><strong>修改php.ini设置</strong></p>
<pre><code class="language-bash">extension=redis.so
</code></pre>
<p><strong>查看结果</strong></p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/image-20221214204900666.png" alt="image-20221214204900666" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h2 id="redis配置文件注解">Redis配置文件注解</h2>
<pre><code class="language-bash"># 是否在后台执行,yes：后台运行；no：不是后台运行（老版本默认）
daemonize yes

# 此参数确定了TCP连接中已完成队列(完成三次握手之后)的长度, 当然此值必须不大于Linux系统定义的/proc/sys/net/core/somaxconn值,默认是511,而Linux的默认参数值是128。当系统并发量大并且客户端速度缓慢的时候,可以将这二个参数一起参考设定。该内核参数默认值一般是128,对于负载很大的服务程序来说大大的不够。一般会将它修改为2048或者更大。在/etc/sysctl.conf中添加:net.core.somaxconn = 2048,然后在终端中执行sysctl -p。
tcp-backlog 511

# 指定 redis 只接收来自于该 IP 地址的请求,如果不进行设置,那么将处理所有请求
bind 127.0.0.1

# 此参数为设置客户端空闲超过timeout,服务端会断开连接,为0则服务端不会主动断开连接,不能小于0。
timeout 0

# 指定了服务端日志的级别。级别包括：debug（很多信息,方便开发、测试）,verbose（许多有用的信息,但是没有debug级别信息多）,notice（适当的日志级别,适合生产环境）,warn（只有非常重要的信息）	
loglevel notice
# 指定了记录日志的文件。空字符串的话,日志会打印到标准输出设备。后台运行的redis标准输出是/dev/null。
logfile /var/log/redis/redis-server.log

# 注释掉&quot;save&quot;这一行配置项就可以让保存数据库功能失效
# 设置sedis进行数据库镜像的频率。
# 900秒（15分钟）内至少1个key值改变（则进行数据库保存--持久化） 
# 300秒（5分钟）内至少10个key值改变（则进行数据库保存--持久化） 
# 60秒（1分钟）内至少10000个key值改变（则进行数据库保存--持久化）
save 900 1
save 300 10
save 60 10000
</code></pre>
<p>更多配置详情：http://www.cnblogs.com/zhang-ke/p/5981108.html</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>redis事务与发布订阅</title>
      <link>https://www.oomkill.com/2016/11/redis-subscribe-and-transaction/</link>
      <pubDate>Wed, 23 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2016/11/redis-subscribe-and-transaction/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="发布与订阅">发布与订阅</h2>
<h3 id="publishsubscribe">Publish/Subscribe</h3>
<p>发布订阅(pub/sub)是一种消息通信模式，主要的目的是解耦消息发布者和消息订阅者之间的藕合，这点和设计模式中的观察者模式比较相似。pub/sub不仅仅解决发布者和订阅者直接代码级别耦合也解决两者在物理部署上的耦合。Redis作为一个pub/sub的server,在订阅者和发布者之间起到了消息路由的功能。订阅者可以通过subscribe和psubscribe命令向Redis server订阅自己感兴趣的消息类型，Redis将消息类型称为通道(channel)。当发布者通过publish命令向Redis server发送特定类型的消息时。订阅该消息类型的全部client</p>
<p>都会收到此消息。这里消息的传递是多对多的。一个client可以订阅多个channel,也可以向多个channel发送消息。</p>
<p>Redis支持这样一种特性，你可以将数据推到某个信息管道中，然后其它人可以通过订阅这些管道来获取推送过来的信息。</p>
<h3 id="用一个客户端订阅频道">用一个客户端订阅频道</h3>
<pre><code class="language-bash">psubscribe new
#### 1.批量订阅
127.0.0.1:6379&gt; publish news news-test
(integer) 1
127.0.0.1:6379&gt; publish video video-test
(integer) 1
</code></pre>
<p><strong>此时可以见到接受的信息</strong></p>
<pre><code class="language-bash">127.0.0.1:6379&gt; psubscribe news video
Reading messages... (press Ctrl-C to quit)
1) &quot;psubscribe&quot;
2) &quot;news&quot;
3) (integer) 1
1) &quot;psubscribe&quot;
2) &quot;video&quot;
3) (integer) 2
1) &quot;pmessage&quot;
2) &quot;news&quot;
3) &quot;news&quot;
4) &quot;news-test&quot;
1) &quot;pmessage&quot;
2) &quot;video&quot;
3) &quot;video&quot;
4) &quot;video-test&quot;
</code></pre>
<h2 id="数据过期设置及机制">数据过期设置及机制</h2>
<h3 id="redis-key的过期机制">Redis key的过期机制</h3>
<p>Redis对过期键采用了lazy expiration：在访间key的时候判定key是否过期，如果过期，则进行过期处理<font style="background:#bafe01;" size=2>（过期的key没有被访间可能不会被删除）</font>。其次，每秒对volatile keys进行抽样测试，如果有过期键，那么对所有过期key进行处理。</p>
<h3 id="expire设置key的生命周期">expire设置key的生命周期</h3>
<p><strong>使用ttl命令可以获得某个key的过期时间</strong></p>
<pre><code class="language-bash">127.0.0.1:6379&gt; ttl test 
(integer) -1  #&lt;== -1代表永久
127.0.0.1:6379&gt; ttl test1
(integer) -2  #&lt;==redis2.8后不存在的key返回-2
</code></pre>
<p><strong>expire：设置一个key的生命周期，单位秒</strong></p>
<pre><code class="language-bash">127.0.0.1:6379&gt; expire site 10240000  #&lt;==设置key多长时间后过期,单位秒
(integer) 1
127.0.0.1:6379&gt; ttl site
(integer) 10239996
</code></pre>
<p><strong>pexpire：以毫秒数设置key的生命周期</strong></p>
<pre><code class="language-bash">127.0.0.1:6379&gt; pexpire a 10000
(integer) 1
127.0.0.1:6379&gt; ttl a
(integer) 8
</code></pre>
<p><strong>pttl：以毫秒返回生命周期</strong></p>
<pre><code class="language-bash">127.0.0.1:6379&gt; pttl a
(integer) 5432
</code></pre>
<p><strong>persist：将key设置为永久有效</strong></p>
<pre><code class="language-bash">127.0.0.1:6379&gt; pexpire a 10000
(integer) 1
127.0.0.1:6379&gt; persist a
(integer) 1
127.0.0.1:6379&gt; ttl a
(integer) -1
</code></pre>
<h3 id="设置指定时间过期">设置指定时间过期</h3>
<p>unix时间戳转换：http://tool.chinaz.com/Tools/unixtime.aspx</p>
<p>linux下获得unix时间戳</p>
<pre><code class="language-bash">$ date +%s  #&lt;==获得当前时间的时间戳
1492845155  
$ date +%s -d '2017-4-27 18:10' #&lt;==获得指定时间的时间戳
1493287800
</code></pre>
<h3 id="创建key时设置生命周期">创建key时设置生命周期</h3>
<pre><code class="language-bash">127.0.0.1:6379&gt; set test-expire test-tmp ex 10  #&lt;==ex/px 秒/毫秒
OK
127.0.0.1:6379&gt; ttl test-expire
(integer) 4 
</code></pre>
<h2 id="事务">事务</h2>
<p>redis对事务的支持目前还比较简单。redis只能保证一个client发起的事务中的命令可以连续的执行，而中间不会插入其他client的命令。 由于redis是单线程来处理所有client的请求的，所以做到这点是很容易的。一般情况下redis在接受到一个client发来的命令后会立即处理并返回处理结果，但是当一个client在一个连接中发出multi命令有，这个连接会进入一个事务上下文，该连接后续的命令并不是立即执行，而是先放到一个队列中。当从此连接受到exec命令后，redis会顺序的执行队列中的所有命令。并将所有命令的运行结果打包到一起返回给client，然后此连接就结束事务上下文。</p>
<h3 id="用法">用法</h3>
<p><em><strong>选项详解</strong></em></p>
<table>
<thead>
<tr>
<th>命令</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>MULTI</td>
<td>于开启一个事务，它总是返回 OK</td>
</tr>
<tr>
<td>DISCARD</td>
<td>清空事务队列， 并放弃执行事务。</td>
</tr>
<tr>
<td>EXEC</td>
<td>负责触发并执行事务中的所有命令</td>
</tr>
<tr>
<td>WATCH</td>
<td>为Redis 事务提供 check-and-set （CAS）行为；<br>被WATCH的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监执行之前被修改了， 那么整个事务都会被取消。</td>
</tr>
</tbody>
</table>
<pre><code class="language-bash">127.0.0.1:6379&gt; set num 1000
OK
127.0.0.1:6379&gt; set num2 2000
OK
127.0.0.1:6379&gt; multi  #&lt;==开启队列
OK
127.0.0.1:6379&gt; decrby num2 1000 #&lt;==将num2的值减少1000
QUEUED #&lt;==当客户端处于事务状态时,所有传入的命令都会返回一个内容为QUEUED的状态回复
127.0.0.1:6379&gt; get num2
&quot;1000&quot; #&lt;==这时在当前查看num2的值，发现已经被更改了
127.0.0.1:6379&gt; get num2 
&quot;2000&quot; #&lt;==此时在其他客户端查看num2的值
127.0.0.1:6379&gt; exec #&lt;==执行队列中的语句
1)(integer) 1000 
127.0.0.1:6379&gt; get num2 #&lt;==这时在其他客户端查看num2
&quot;1000&quot;
</code></pre>
<hr>
<p>注：即使事务中有某条/某些命令执行失败了， 事务队列中的其他命令仍然会继续执行，Redis 不会停止执行事务中的命令。</p>
<hr>
<pre><code class="language-bash">127.0.0.1:6379&gt; decrby num1 5
QUEUED
127.0.0.1:6379&gt; decrby num2 aaa
QUEUED
127.0.0.1:6379&gt; exec
1) (integer) -5
2) (error) ERR value is not an integer or out of range
</code></pre>
<h3 id="放弃事务">放弃事务</h3>
<p>执行 DISCARD 命令，事务会被放弃，事务队列会被清空，并且客户端会从事务状态中退出</p>
<pre><code class="language-bash">127.0.0.1:6379&gt; multi
OK
127.0.0.1:6379&gt; keys *
QUEUED
127.0.0.1:6379&gt; discard
OK
127.0.0.1:6379&gt; keys *
1) &quot;num1&quot;
2) &quot;num2&quot;
</code></pre>
<blockquote>
<p><em><strong>使用 check-and-set 操作实现乐观锁</strong></em></p>
</blockquote>
<p>被 WATCH 的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在 EXEC 执行之前被修改了， 那么整个事务都会被取消， EXEC 返回空多条批量回复（null multi-bulk reply）来表示事务已经失败。</p>
<pre><code class="language-bash">127.0.0.1:6379&gt; watch num1
OK
127.0.0.1:6379&gt; multi
OK
127.0.0.1:6379&gt; incr num1 #&lt;==在其它客户端修改num1
(integer) 101
127.0.0.1:6379&gt; incr num1
QUEUED
127.0.0.1:6379&gt; exec
(nil)
</code></pre>
<p>参考资料 <a href="http://doc.redisfans.com/topic/transaction.html" target="_blank"
   rel="noopener nofollow noreferrer" >http://doc.redisfans.com/topic/transaction.html</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>redis数据持久化</title>
      <link>https://www.oomkill.com/2016/11/redis-persist/</link>
      <pubDate>Wed, 23 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2016/11/redis-persist/</guid>
      <description></description>
      <content:encoded><![CDATA[<p>Redis的所有数据都存储在内存中，但是他也提供对这些数据的持久化。</p>
<p>Redis是一个支持持久化的内存数据库，Redis需要经常将内存中的数据同步到磁盘来保证持久化。Redis支持四种持久化方式，一种是 <font style="background:#bafe01;" size=2><code>Snapshotting</code>(快照)也是默认方式</font> ，另一种是 <font style="background:#bafe01;" size=2><code>Append-only file</code>(aof)的方式</font> 。</p>
<h2 id="rdb持久化方式">RDB持久化方式</h2>
<p>Snapshotting方式是将内存中数据以快照的方式写入到二进制文件中，默认的文件名为dump.rdb。可以通过配置设置自动做快照持久化。例如可以配置redis在n秒内如果超过m个key被修改就自动做快照。</p>
<h3 id="实现机制">实现机制</h3>
<ol>
<li>
<p>Redis调用fork子进程。</p>
</li>
<li>
<p>父进程继续处理client请求，子进程负责将内存内容写入到临时文件。由于os的实时复制机制(copy on write)父子进程会共享相同的物理页面，当父进程处理写请求时os会为父进程要修改的页面创建副本，而不是写共享的页面。所以子进程地址空间内的数据是fork时刻整个数据库的一个快照。</p>
</li>
<li>
<p>当子进程将快照写入临时文件完毕后，用临时文件替换原来的快照文件，然后子进程退出。client也可以使用save或者bgsave命令通知redis做一次快照持久化。save操作是在主线程中保存快照的，由于redis是用一个主线程来处理所有client的请求，这种方式会阻塞所有clien:请求。所以不推荐使用。另一点需要注意的是，每次快照持久化都是完整写入到磁盘一次并不是增量的只同步变更数据。如果数据量大的话，而且写操作比较多，必然会引起大量的磁盘IO操作，可能会严重影响性能。</p>
</li>
</ol>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/image-20221214204240265.png" alt="image-20221214204240265" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><strong>缺点</strong>：</p>
<p>快照方式是在一定间隔时间做一次的，所以如果<font style="background:#bafe01;" size=2>redis意外down掉的话，就会丢失最后一次快照后的所有修改</font>。如果应用要求不能丢失任何修改的话，可以采用aof持久化方式。</p>
<h3 id="相关配置">相关配置</h3>
<pre><code class="language-bash">save 900 1 	#←900秒内至少有1个key被改变
save 300 10 	#←300秒内至少有10个key被改变
save 60 10000 	#←60秒内至少有10000个key被改变
stop-writes-on-bgsave-error yes #←后台存储错误后停止写。如：磁盘空间不足
rdbcompression yes #←使用LZF压缩rdb文件
rdbchecksum yes 	  #←存储和加载rdb文件时校验
dbfilename dump.rdb #←存储rdb文件名
dir /app/redis/db/  #←rdb文件路径
</code></pre>
<h3 id="持久化测试">持久化测试</h3>
<pre><code class="language-bash">11512:M 22 Apr 01:04:47.028 * 5 changes in 60 seconds. Saving...
11512:M 22 Apr 01:04:47.029 * Backgroundsaving started by pid 11520
11520:C 22 Apr 01:04:47.032 * DB saved on disk
11520:C 22 Apr 01:04:47.033 * RDB: 0 MB of memory used by copy-on-write
11512:M 22 Apr 01:04:47.129 * Background saving terminated with success
</code></pre>
<p><strong>生成dump.rdb文件</strong></p>
<pre><code class="language-bash">$ ll /app/redis/db
dump.rdb
</code></pre>
<p><strong>关闭服务删除dump.rdb文件重新启动redis服务</strong></p>
<pre><code class="language-bash">127.0.0.1:6379&gt; keys *
(empty list or set)
</code></pre>
<p><strong>将dump.rdb.bk文件恢复成dump.rdb。再启动服务器。</strong></p>
<pre><code class="language-bash">127.0.0.1:6379&gt; keys *
1) &quot;test-durable&quot;
2) &quot;test-durable-1&quot;
</code></pre>
<h3 id="手工强制刷新">手工强制刷新</h3>
<pre><code class="language-bash">127.0.0.1:6379&gt; save
OK
127.0.0.1:6379&gt; bgsave
Background saving started
</code></pre>
<p><strong>此时服务器端消息</strong></p>
<pre><code class="language-bash">4330:M 30 Mar 02:42:14.496 * DB saved on disk
$ 4330:M 30 Mar 02:42:28.700 * Background saving started by pid 18345
18345:C 30 Mar 02:42:28.718 * DB saved on disk
18345:C 30 Mar 02:42:28.718 * RDB: 0 MB of memory used by copy-on-write
4330:M 30 Mar 02:42:28.796 * Background saving terminated with success
</code></pre>
<h2 id="aof存储介绍">AOF存储介绍</h2>
<p>Append-Only-File(追加式的操作日志记录)</p>
<p>由于快照方式是在一定间隔时间做一次的，所以如果<font style="background:#bafe01;" size=2>redis意外down掉的话，就会丢失最后一次快照后的所有修改</font>。如果应用要求不能丢失任何修改的话，可以采用aof持久化方式。</p>
<p>aof比快照方式有更好的持久化性，是由于在使用aof持久化方式时,redis会将每一个收到的写命令都通过write函数追加到文件中(默认是appendonly.aof)。当redis重启时会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。当然由于os会在内核中缓存write做的修改，所以可能不是立即写到磁盘上。这样aof方式的持久化也还是有可能会丢失部分修改.不过我们可以通过配置文件告诉redis我们想要通过fsync函数强制os写入到磁盘的时机。</p>
<h3 id="实现机制-1">实现机制</h3>
<p>以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来<font style="background:#bafe01;" size=2>(不记录读操作)</font>，只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据。<font style="background:#bafe01;" size=2>当 Redis 重启时，它会优先使用AOF文件来还原数据</font>，因为AOF文件保存的数据集通常比RDB文件所保存的数据集更完整。你甚至可以关闭持久化功能，让数据只在服务器运行时存在。在redis中这种存储方式默认是关闭的，需要在redis.conf文件中开启。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/image-20221214204404144.png" alt="image-20221214204404144" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>Redis AOF重写原理图</center>
<h3 id="相关配置-1">相关配置</h3>
<pre><code class="language-bash">appendonly no/yes 		#←是否打开 aof日志功能
appendfsync always  #←每次收到写命令就立即强制写入磁盘，最慢,保证完全的持久化，不推荐
appendfsync everysec #←每秒钟强制写入磁盘一次，在性能和持久化方面折中，推荐
appendfsync no #←完全依赖os，性能最好,持久化没保证
no-appendfsync-on-rewrite  yes: #←导出rdb快照的过程中,是否停止同步aof
auto-aof-rewrite-percentage 100#←aof文件大小比起上次重写时的大小,增长率100%时,重写
auto-aof-rewrite-min-size 64mb #←aof文件,至少超过64M时,重写
</code></pre>
<h3 id="测试">测试</h3>
<blockquote>
<p><strong>使用for循环批量更改一个key的值</strong></p>
</blockquote>
<pre><code class="language-bash">for n in {1..8888};do redis-cli set name $n;done
</code></pre>
<blockquote>
<p><strong>此时redis服务端的信息</strong></p>
</blockquote>
<pre><code class="language-bash">4330:M 30 Mar 02:15:23.581 * Starting automatic rewriting of AOF on 101% growth
4330:M 30 Mar 02:15:23.581 * Background append only file rewriting started by pid 11921
4330:M 30 Mar 02:15:24.598 * AOF rewrite child asks to stop sending diffs.
11921:C 30 Mar 02:15:24.598 * Parent agreed to stop sending diffs. Finalizing AOF...
11921:C 30 Mar 02:15:24.598 * Concatenating 0.02 MB of AOF diff received from parent.
11921:C 30 Mar 02:15:24.606 * SYNC append only file rewrite performed
11921:C 30 Mar 02:15:24.606 * AOF rewrite: 0 MB of memory used by copy-on-write
4330:M 30 Mar 02:15:24.685 * Background AOF rewrite terminated with success
4330:M 30 Mar 02:15:24.685 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)
</code></pre>
<blockquote>
<p><strong>此时日志文件大小</strong></p>
</blockquote>
<pre><code class="language-bash">$ ll -h
total 132K
-rw-r--r--. 1 root root  59K Mar 30 02:15 appendonly.aof
-rw-r--r--. 1 root root   56 Mar 30 02:15 temp-rewriteaof-17659.aof
$ ll -h
-rw-r--r--. 1 root root  22K Mar 30 02:15 appendonly.aof
</code></pre>
<h3 id="手动生成新的aof文件">手动生成新的AOF文件</h3>
<pre><code class="language-bash">bgrewriteaof
</code></pre>
<h2 id="日志重写">日志重写</h2>
<p>aof的方式也同时带来了另一个问题。持久化文件会变的越来越大。例如我们调用<font style="background:#bafe01;" size=2>incr test命令100次</font>，文保中必须保存全部的100条命令，<font style="background:#bafe01;" size=2>其实有99条都是多余的</font>。因为要恢复数据库的状态其实文件中保存一条set test 100就够了。为了压缩aof的持久化文件，Redis提供了bgrewriteaof命令.收到此命令Redis将使用与快照类似的方式将内存中的数据以命令的方式保存到临时文件中，最后替换原来的文件。</p>
<p>自动bgrewriteaof参数设置</p>
<pre><code class="language-sh">auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64m
</code></pre>
<h2 id="如何选择rdb和aof-">如何选择RDB和AOF ？</h2>
<p>一般来说,如果想达到足以媲美 PostgreSQL 的数据安全性，你应该同时使用两种持久化功能。如果你非常关心你的数据,但仍然可以承受数分钟以内的数据丢失，那么你可以只使用 RDB 持久化。有很多用户都只使用 AOF 持久化，并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且RDB恢复数据集的速度也要比AOF恢复的速度要快， 除此之外， 使用RDB还可以避免之前提到的AOF程序的bug 。因为以上提到的种种原因， <font style="background:#bafe01;" size=2>未来Redis可能会将AOF和RDB整合成单个持久化模型。（这是一个长期计划）</font>。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>redis数据类型</title>
      <link>https://www.oomkill.com/2016/11/redis-datatype/</link>
      <pubDate>Wed, 23 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2016/11/redis-datatype/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="keyvalue介绍">key/value介绍</h2>
<p>Redis key值是二进制安全的，这意味着可以用任何二进制序列作为key值，从形如“0foo”的简单字符串到一个JPG文件的内容都可以。空字符串也是有效key值。</p>
<p><em><strong>关于key的几条规则</strong></em>：</p>
<p>太长的键值，例如1024字节的键值，不仅因为消耗内存，而且在数据中查找这类键值的计算成本很高。</p>
<p>太短的键值，如果你要用 <font color="#f8070d" size=3><code>u:1000:pwd</code></font>来代替<font color="#f8070d" size=3><code>user:1000:password</code></font>，这没有什么问题，但后者更易阅读，并且由此增加的空间消耗相对于key object和value object本身来说很小.当然，没人阻止您一定要用更短的键值节省一丁点空间。</p>
<p><font style="background:#bafe01;" size=2>最好坚持一种模式;</font>。例如：<font color="#f8070d" size=2><code>object-type🆔field</code></font>就是个不错的注意，像这样<font color="#f8070d" size=2><code>user:1000:password</code></font>。我喜欢对多单词的字段名中加上一个点，就像这样：<font color="#f8070d" size=2><code>comment.1234.renlv_to</code></font></p>
<p>key建议：<font color="#f8070d" size=3><code>object-type🆔field</code></font> <font style="background:#bafe01;" size=2>长度10-20</font></p>
<p>value建议：<font style="background:#bafe01;" size=2>string不要超过2K set sortedset元素不要超过5000</font></p>
<pre><code class="language-bash">$ redis-cli set user_list:user_id:5 zhangsan
OK
$ redis-cli get user_list:user_id:5
&quot;zhangsan&quot;
</code></pre>
<h2 id="通用操作">通用操作</h2>
<h3 id="找到全部给定模式的匹配到的key">找到全部给定模式的匹配到的key</h3>
<pre><code class="language-bash">127.0.0.1:6379&gt; keys * #&lt;==打印全部key
1) &quot;name&quot;
2) &quot;site&quot;
127.0.0.1:6379&gt; keys na[ma]e #&lt;==返回正则匹配到的key
1) &quot;name&quot;
127.0.0.1:6379&gt; keys nam?
1) &quot;name&quot;
</code></pre>
<h3 id="randomkey返回随机key">randomkey返回随机key</h3>
<pre><code class="language-bash">127.0.0.1:6379&gt; randomkey
&quot;name&quot;
127.0.0.1:6379&gt; randomkey
&quot;site&quot;
</code></pre>
<h3 id="exists检查key是否存在">exists检查key是否存在</h3>
<pre><code class="language-bash">127.0.0.1:6379&gt; exists site
(integer) 1
127.0.0.1:6379&gt; exists sites
(integer) 0
</code></pre>
<h3 id="type-查看key类型">type 查看key类型</h3>
<pre><code class="language-bash">127.0.0.1:6379&gt; type set
set
127.0.0.1:6379&gt; type site
string
</code></pre>
<h3 id="修改key名称">修改key名称</h3>
<pre><code class="language-bash">127.0.0.1:6379&gt; rename site web 
OK
127.0.0.1:6379&gt; keys *
1) &quot;set&quot;
2) &quot;web&quot;
3) &quot;name&quot;
4) &quot;test&quot;
</code></pre>
<blockquote>
<p><strong>renamnx rename not exists,当要修改的新名称存在,会用改名后的覆盖存在的那个key</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; set rename_test test
OK
127.0.0.1:6379&gt; set rename_test1 test1
OK
127.0.0.1:6379&gt; set tmp tmp
OK
127.0.0.1:6379&gt; rename rename_test tmp
OK
127.0.0.1:6379&gt; keys *
1) &quot;tmp&quot;
2) &quot;rename_test1&quot;
127.0.0.1:6379&gt; get tmp
&quot;test&quot; #&lt;==可以看到tmp把rename_test给覆盖了
</code></pre>
<h3 id="将当前数据库的-key-移动到给定的数据库db当中">将当前数据库的 key 移动到给定的数据库db当中</h3>
<pre><code class="language-bash">127.0.0.1:6379&gt; select 2
OK
127.0.0.1:6379[2]&gt; keys *
(empty list or set)
127.0.0.1:6379[2]&gt; select 0
OK
127.0.0.1:6379&gt; move web 2
(integer) 1
127.0.0.1:6379&gt; select 2
OK
127.0.0.1:6379[2]&gt; keys *
1)&quot;web&quot;
</code></pre>
<h3 id="dbsize返回当前选择的数据库的key数量">dbsize返回当前选择的数据库的key数量</h3>
<pre><code class="language-bash">127.0.0.1:6379&gt; dbsize
(integer) 1
</code></pre>
<h3 id="shutdown-同步保存数据到磁盘并结束redis进程">shutdown 同步保存数据到磁盘，并结束Redis进程</h3>
<p>语法：shutdown [NOSAVE|SAVE]</p>
<pre><code class="language-bash">redis-cli shutdown save
12632:M 22 Apr 16:42:23.492 * Saving the final RDB snapshot before exiting.
12632:M 22 Apr 16:42:23.528 * DB saved on disk
12632:M 22 Apr 16:42:23.528 * Removing the pid file.
12632:M 22 Apr 16:42:23.529 # Redis is now ready to exit, bye bye...
</code></pre>
<h3 id="异步操作redis">异步操作Redis</h3>
<p>bgrewriteaof (异步重写aof日志文件)
作用减少aof文件大小
BGSAVE(异步保存数据到磁盘)</p>
<h2 id="string字符串类型">String字符串类型</h2>
<p>这是最简单的Redis类型。如果你只用这种类型,Redis就是一个可以持久化的memcached服务器(注:memcache的数据仅保存在内存中,服务器重启后,数据将丢失)。</p>
<h3 id="常规字符串操作">常规字符串操作</h3>
<p>在Redis中，常用set设置一对key/value键值，然后用get来获取字符串的值。value值可以是任何类型的字符串(包括二进制数据)，例如你可以在一个键下保存一个jpg图片。但值的长度不能超过1GB。</p>
<blockquote>
<p><strong>set：设置一个建的字符串值</strong></p>
</blockquote>
<p>语法：set key value [EX seconds] [PX milliseconds] [NX|XX]</p>
<pre><code class="language-bash">127.0.0.1:6379&gt; set k1 test🔑123
OK  
127.0.0.1:6379&gt; ttl k1
(integer) -1 #&lt;==set默认生命周期为永久有效
127.0.0.1:6379&gt; set k1 test_key NX #&lt;==设置一个key,如果不存在就创建。
(nil) #&lt;==因k1存在故没有创建
127.0.0.1:6379&gt; set k2 test_key NX
OK	#&lt;==名为k2的key不存在成功创建
127.0.0.1:6379&gt; set k2 test EX 100 #&lt;==设置key的生命周期 px毫秒 ex秒
OK 
127.0.0.1:6379&gt; ttl k2
(integer) 97
</code></pre>
<blockquote>
<p><strong>mset：设置多个key value</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; mset key zhangsan ex 100 key1 lisi 
OK
127.0.0.1:6379&gt; keys *
1) &quot;key1&quot;
2) &quot;ex&quot;
3) &quot;key&quot; #&lt;==通过结果可得知 mset不支持判断是否存在与设置生命周期
</code></pre>
<blockquote>
<p><strong>setrange：从指定偏移量开始重写字符串的一部分</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; set key test:123
OK
127.0.0.1:6379&gt; setrange key 5 abc
(integer) 8
127.0.0.1:6379&gt; get key
&quot;test:abc&quot;  #&lt;==不存在的偏移量用\x00填充
</code></pre>
<blockquote>
<p><strong>append：将值附加到key中</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; set test a
OK
127.0.0.1:6379&gt; APPEND test bc
(integer) 3
127.0.0.1:6379&gt; get test
&quot;abc&quot;
</code></pre>
<blockquote>
<p><strong>getrange：Get a substring of the string stored at a key</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; set k test:getrange
OK
127.0.0.1:6379&gt; getrange k 0 3
&quot;test&quot;
127.0.0.1:6379&gt; getrange k 0 100
&quot;test:getrange&quot; #&lt;==如果指定值大于字符串长度返回到字符串结尾处
127.0.0.1:6379&gt; getrange k 100 1000
&quot;&quot; #&lt;==如果开始位置大于字符串总长度,返回空字符串
</code></pre>
<h3 id="string类型可以用来存储数字">String类型可以用来存储数字</h3>
<p>虽然字符串是Redis的基本值类型,但你仍然能通过它完成一些有趣的操作。例如：原子递增。</p>
<p>INCR命令将字符串值解析成整型,将其加1,最后将结果保存为新的字符串值,类似的命令有INCRBY, DECR and DECRBYC实际上他们在内部就是同一个命令,只是看上去有点儿不同。</p>
<p>incr是原子操作意味着什么呢?就是说即使多个客户端对同一个key发出INCR命令,也决不会导致竟争的情况.例如如下情况永远不可能发生:「客户端1和客户端2同时读出“10&quot;,他们俩都对其加到11,然后将新值设置为11。最终的值一定是12,read-increment-set操作完成时,其他客户端不会在同一时间执行任何命令。</p>
<blockquote>
<p><strong>incr:将键的整数值递增1</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; set num 1
OK
127.0.0.1:6379&gt; incr num
(integer) 2
</code></pre>
<blockquote>
<p><strong>decr:将键的整数值递减1</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; decr num
(integer) 0
127.0.0.1:6379&gt; decr num
(integer) -1 #&lt;==与memcached不同的是,redis会被减少为负数
</code></pre>
<blockquote>
<p><strong>incrby:将键增加一个指定定量</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; incrby num 10
(integer) 9
</code></pre>
<blockquote>
<p><strong>incrbyfloat: 将键增加一个指定定量的浮点值</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; incrbyfloat num 
&quot;9.1&quot; #&lt;==操作后值变为浮点型
127.0.0.1:6379&gt; incrby num 11 
(error) ERR value is not an integer or out of range #&lt;==不可以在进行整型原子递增
</code></pre>
<h3 id="为key设置新值并且返回原值">为key设置新值并且返回原值</h3>
<p>对字符串,另一个操作是GETSET命令,行如其名:他为key设置新值并且返回原值。这有什么用处呢?例如:你的系统每当有新用户访问时就用INCR命令操作一个Redis key。你希望每小时对这个信息收集一次。你就可以GETSET这个key并给其赋值0并读取原值。</p>
<blockquote>
<p><strong>getset：设置key的字符串值，并返回旧值</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; getset k1 test:getset:demo
&quot;test&quot;
127.0.0.1:6379&gt; get k1
&quot;test:getset:demo&quot;
</code></pre>
<h3 id="setbit-getbit-bitcount-binop">setbit getbit bitcount binop</h3>
<blockquote>
<p><strong>这是偏移位上的二进制值</strong></p>
</blockquote>
<pre><code class="language-bash">(error) ERR bit offset is not an integer or out of range
127.0.0.1:6379&gt; setbit s 4294967296 1
(error) ERR bit offset is not an integer or out of range
127.0.0.1:6379&gt; setbit s 4294967295 1 #&lt;==最大范围为232-1 512M key的最大值
(integer) 0
(1.46s)
</code></pre>
<h2 id="list类型">List类型</h2>
<p>要说清楚列表数据类型,最好先讲一点儿理论背景,在信息技术界List这个词常常被使用不当.例如&quot;Python Lists&quot;就名不副实(名为Linked Lists),<font style="background:#bafe01;" size=2>但他们实际上是数组</font>(同样的数据类型在Ruby中叫数组)。</p>
<p>列表就是有<font style="background:#bafe01;" size=2>序元素的序列</font>:10,20,1,2,3就是一个列表。但用数组实现的List和用Linked List实现的List,在属性方面大不相同。</p>
<p>Redis lists基于Linked Lists实现。这意味着即使在一个list中有数百万个元素,在头部或尾部添加一个元素的操作,其时间复杂度也是常数级别的。用LPUSH命令在十个元素的list头部添加新元素,和在千万元素list头部添加新元素的速度相同。</p>
<p>那么,坏消息是什么?在数组实现的list中利用索引访问元素的速度极快,而同样的操作在linked list实现的list上没有那么快。</p>
<p>Redis Lists用linked list实现的原因是:对于数据库系统来说,至关重要的特性是:能非常快的在很大的列表上添加元素.另一个重要因素是,正如你将要看到的:Redis lists能在常数时何取得常数长度。</p>
<h3 id="创建list并插入数据">创建list并插入数据</h3>
<p>LPUSH命令可向list的左边(头部)添加一个新元素,而RPUSH命令可向list的右边(尾部)添加一个新元素。最后LRANGE命令可从list中取出一定范围的元素。</p>
<blockquote>
<p><strong>lpush:向list头部插入数据，如果list不存在则自动创建</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; lpush list lisi #&lt;== 头部插入一个数据
(integer) 1
127.0.0.1:6379&gt; lpush list zhangsan
(integer) 2
</code></pre>
<blockquote>
<p><strong>llen:查看list列表元素个数</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; llen list	#&lt;==获得列表元素个数
(integer) 2
</code></pre>
<blockquote>
<p><strong>lrange:查看列表所有元素</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; lrange list 0 3 #&lt;== 打印列表的1,3元素
 1) &quot;zhangsan&quot;
 2) &quot;lisi&quot;
 3) &quot;test1&quot;
127.0.0.1:6379&gt; lrange list 0 -1#&lt;== 打印列表的所有元素
</code></pre>
<hr>
<p><strong><font color="#0215cd" size=2> <font color="#f8070d" size=2>⚠</font> 注意：RANGE带有两个索引,范围内第一个和最后一个元素。这两个索引都可以负来告知redis从尾部开始计数,因此-1表示最后一个元素,-2表示list中的倒数第二个元素,以此类推。
</font></strong></p>
<hr>
<blockquote>
<p><strong>lindex:返回指定元素在列表中的下标</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; rpush a 1 2 3 4 5
(integer) 5
127.0.0.1:6379&gt; lindex a 1
&quot;2&quot;
127.0.0.1:6379&gt; lindex a 1
</code></pre>
<blockquote>
<p><strong>linsert在指定元素前后插入数据</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; rpush arr 1 2 3
(integer) 3
127.0.0.1:6379&gt; linsert arr after 2 5
(integer) 4
127.0.0.1:6379&gt; lrange arr 0 -1
1) &quot;1&quot;
2) &quot;2&quot;
3) &quot;5&quot;
4) &quot;3&quot;
</code></pre>
<h3 id="list应用场景">list应用场景</h3>
<p>正如你可以从上面的例子中猜到的,list可被用来实现聊天系统。还可以作为不同进程间传递消息的队列。关键是,你可以每次都以原先添加的顺序访问数据。这不需要任何SQL ORDER BY操作,将会非常快,也会很容易扩展到百万级别元素的规模。</p>
<p>例如在评级系统中,比如社会化新闻网站reddit.com,你可以把每个新提交的链接添加到一个list,用LRANGE可简单的对结果分页。</p>
<p>在博客引擎实现中,你可为每篇日志设置一个list,在该list中推入进博客评论,等等。</p>
<p>向Redis list压入ID而不是实际的数据,</p>
<p>在上面的例子里,我们将“对象”(此例中是简单消息)直接压入Redis list,但通常不应这么做,由于对象可能被多次引4:例如在一个lis:中维护其时间顺序,在一个集合中保存它的类别,只要有必要,它还会出现在其他list中,等等。</p>
<p>让我们回到reddit.com的例子,将用户提交的链接(新闻)添加到list中,有更可靠的方法如下所示</p>
<pre><code class="language-bash">127.0.0.1:6379&gt; incr next.news.id
(integer) 1
127.0.0.1:6379&gt; set new:1:title &quot;redis is simple&quot;
OK
127.0.0.1:6379&gt; set news:1:url &quot;http://www.baidu.com&quot;
OK
127.0.0.1:6379&gt; lpush submitted.news 1
(integer) 1
</code></pre>
<p>OK我们自增一个key,很容易得到一个独一无二的自增ID,然后通过此ID创建对象入为对象的每个字段设置一个key。最后将新对象的submitted.news lists。</p>
<blockquote>
<blockquote>
<p>rpop 从尾部删除一个元素
rpush 向尾部插入一个数据
lpop 从头部删除一个元素</p>
</blockquote>
</blockquote>
<h3 id="删除list内元素">删除list内元素</h3>
<blockquote>
<p><strong>lrem:删除count的绝对值个value后结束<font style="background:#bafe01;" size=2> count &gt; 0从头开始删,&lt;0从尾部开始删</font></strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; rpush aa a a b c a a
(integer) 6
127.0.0.1:6379&gt; lrem aa 1 a
(integer) 1
127.0.0.1:6379&gt; LRANGE aa 0 -1
1) &quot;a&quot;
2) &quot;b&quot;
3) &quot;c&quot;
4) &quot;a&quot;
5) &quot;a&quot;
127.0.0.1:6379&gt; lrem aa -2 a
(integer) 2
127.0.0.1:6379&gt; LRANGE aa 0 -1
1) &quot;a&quot;
2) &quot;b&quot;
3) &quot;c&quot;
</code></pre>
<blockquote>
<p><strong>ltrim:剪切key对应的链接,切[start,stop]一段,并把该段重新赋给key</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; rpush a 1 2 3 4 5
(integer) 5
127.0.0.1:6379&gt; ltrim a 2 3
OK
127.0.0.1:6379&gt; lrange a 0 -1
1) &quot;3&quot;
2) &quot;4&quot;
</code></pre>
<blockquote>
<p><strong>rpoplpush:将arr尾部的元素弹出到tmp头部</strong></p>
</blockquote>
<p>作用：接收返回值,并做业务处理。如果成功,rpop tmp清除任务；如不成功,下次从tmp表里取任务</p>
<pre><code class="language-bash">127.0.0.1:6379&gt; rpoplpush arr tmp
&quot;3&quot;
127.0.0.1:6379&gt; lrange arr 0 -1
1) &quot;1&quot;
2) &quot;2&quot;
3) &quot;5&quot;
127.0.0.1:6379&gt; lrange tmp 0 -1
1) &quot;3&quot;
</code></pre>
<h2 id="set集合">set集合</h2>
<p>Redis集合是未排序的集合,其元素是二进制安全的字符串。sadd命令可以向集合添加一个新元素。和sets相关的操作也有许多,比如检测某个元素是否存在,以及实现交集,并集,差集等等。</p>
<h3 id="创建并向集合插入新元素">创建并向集合插入新元素</h3>
<blockquote>
<p><strong>sadd：向集合内添加一个或多个元素</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; sadd set a b c d #&lt;==向集合key中增加元素
(integer) 4 
</code></pre>
<blockquote>
<p><strong>smembers：查看集合内所有元素</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; smembers set #&lt;==返回集合中的所有元素
1) &quot;d&quot;
2) &quot;c&quot;
3) &quot;b&quot;
4) &quot;a&quot;
</code></pre>
<h3 id="删除集合中元素">删除集合中元素</h3>
<blockquote>
<p><strong>sadd：从集合内删除一个或多个指定元素</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; srem set a #&lt;==删除集合中名为a的元素
(integer) 1
127.0.0.1:6379&gt; smembers set
1) &quot;d&quot;
2) &quot;c&quot;
3) &quot;b&quot;
</code></pre>
<h3 id="查看集合内元素">查看集合内元素</h3>
<blockquote>
<p><strong>sismember：检查集合中是否存在某个元素</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; sismember set a
(integer) 0
127.0.0.1:6379&gt; sismember set b
(integer) 1
</code></pre>
<blockquote>
<p><strong>srandmember：返回元素中指定个数的随机元素</strong></p>
</blockquote>
<p>语法 srandmember key [count]</p>
<pre><code class="language-bash">127.0.0.1:6379&gt; srandmember set  2
1) &quot;d&quot;
2) &quot;b&quot;
</code></pre>
<blockquote>
<p><strong>scard返回元素中的个数</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; scard set
(integer) 3
</code></pre>
<h3 id="移动集合内元素">移动集合内元素</h3>
<blockquote>
<p><strong>smove：将source里的member移动到destination集合中</strong></p>
</blockquote>
<p>语法：SMOVE source destination member</p>
<pre><code class="language-bash">127.0.0.1:6379&gt; keys *
(empty list or set)
127.0.0.1:6379&gt; sadd set a b c d e
(integer) 5
127.0.0.1:6379&gt; smove set tmp e
(integer) 1
127.0.0.1:6379&gt; keys *
1) &quot;set&quot;
2) &quot;tmp&quot;
127.0.0.1:6379&gt; smembers tmp
1) &quot;e&quot;
127.0.0.1:6379&gt; smembers set
1) &quot;c&quot;
2) &quot;b&quot;
3) &quot;a&quot;
4) &quot;d&quot;
</code></pre>
<p>“b”是这个集合的成员,而“b”不是。集合特别适合表现对象之间的关系。例如<font style="background:#bafe01;" size=2>用Redis集合可以很容易实现标签功能</font>。</p>
<p>下面是一个简单的方案:对每个想加标签的对象,用一个标签ID集合与之关联,并且对每个已有的标签,一组对象ID与之关联。</p>
<p>例如假设我们的新闻ID=1000被加了三个tag 1,2,5就可以设置下面两个集合</p>
<pre><code class="language-bash">127.0.0.1:6379&gt; sadd news:1000:tags 1
(integer) 1
127.0.0.1:6379&gt; sadd news:1000:tags 2
(integer) 1
127.0.0.1:6379&gt; sadd news:1000:tags 5
(integer) 1
127.0.0.1:6379&gt; smembers news:1000:tags
1) &quot;1&quot;
2) &quot;2&quot;
3) &quot;5&quot;
</code></pre>
<p>而有些看上去并不简单的操作仍然能使用相应的redis命令轻松实现。例如我们也许想获得一份同时拥有标签1,2,10和27的对象列表。这可以用SINTER命令来做,他可以在不同集合之间取出交集。</p>
<p>tags:1:obj tags:2:obj tags:5:obj tags:27:obj</p>
<pre><code class="language-bash">127.0.0.1:6379&gt; smembers test1
1) &quot;1&quot;
2) &quot;2&quot;
3) &quot;3&quot;
127.0.0.1:6379&gt; smembers test4
1) &quot;1&quot;
2) &quot;2&quot;
3) &quot;9&quot;
127.0.0.1:6379&gt; sinter test1 test4
1) &quot;1&quot;
2) &quot;2&quot;
</code></pre>
<h3 id="集合计算">集合计算</h3>
<p><em><strong>创建一个集合</strong></em></p>
<pre><code class="language-bash">127.0.0.1:6379&gt; sadd A 1 2 3 4 5
(integer) 5
127.0.0.1:6379&gt; sadd B 1 3 4 5
(integer) 4
127.0.0.1:6379&gt; sadd C 1 2 6 7 8 9
(integer) 6
</code></pre>
<blockquote>
<p><strong>sinter：取出指定集合内的交集</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; sinter A B  #&lt;==取出A B两个集合中的交集
1) &quot;1&quot; 
2) &quot;3&quot;
3) &quot;4&quot;
4) &quot;5&quot;
127.0.0.1:6379&gt; sinter A B C
1)&quot;1&quot;
</code></pre>
<blockquote>
<p><strong>sinterstore：将多个集合的交集放入另一个集合内</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; sinterstore tmp A B  #&lt;== 将A B集合中的交集放置在tmp集合中
2)(integer) 4
3)127.0.0.1:6379&gt; smembers tmp
4)1) &quot;1&quot;
5)2) &quot;3&quot;
6)3) &quot;4&quot;
7)4) &quot;5&quot;
</code></pre>
<blockquote>
<p><strong>sunion获得多个集合的并集</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; sunion A B
1) &quot;1&quot;
2) &quot;2&quot;
3) &quot;3&quot;
4) &quot;4&quot;
5) &quot;5&quot;
</code></pre>
<blockquote>
<p><strong>sdiff获得多个集合的差</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; sdiff A B
1) &quot;2&quot;
</code></pre>
<h2 id="有序集合">有序集合</h2>
<p>集合是使用频率很高的数据类型,但是…对许多问题来说他们也有点儿太不讲顺序了；因此Redis1.2引入了有序集合。他和集合非常相似,也是二进制安全的字符串集合,但是这次带有关联的score,以及一个类似lrange的操作可以返回有序元素,此操作只能作用于有序集合,它就是,zrange命令。</p>
<p>基本上有序集合从某种程度上说是SQL世界的索引在Redis中的等价物。例如在上面提到的reddit.com例子中,并祥有提到如何根据用户投票和时间因素将新闻组合生成首页。我们将看到有序集合如何解决这个问题,但最好先从更简单的事情开始,阐明这个高级数据类型是如何工作的.让我们添加几个黑客,并将他们的生日作为&quot;score&quot;。</p>
<h3 id="添加并查看有序集合">添加并查看有序集合</h3>
<blockquote>
<p><strong>添加一个或多个成员到一个集合,如果这个成员存在,则更新其排序分数</strong></p>
</blockquote>
<p>语法：ZADD key [NX|XX] [CH] [INCR] score member [score member &hellip;]</p>
<p><em><strong>选项详解</strong></em></p>
<table>
<thead>
<tr>
<th style="text-align:center">参数</th>
<th style="text-align:left">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">XX</td>
<td style="text-align:left">仅更新已经存在的元素。不要添加元素。</td>
</tr>
<tr>
<td style="text-align:center">NX</td>
<td style="text-align:left">不要更新现有的元素。始终添加新元素。</td>
</tr>
<tr>
<td style="text-align:center">CH</td>
<td style="text-align:left">从添加的新元素的数量修改返回值,改变元素的总数（CH是更改的缩写）。已更改的元素是添加的新元素,已经存在的元素已更新。所以在命令行中指定的具有与过去相同的分数的元素不计算在内。注意：通常,ZADD的返回值仅计算添加的新元素的数量。</td>
</tr>
<tr>
<td style="text-align:center">INCR</td>
<td style="text-align:left">当指定此选项时,ZADD的行为就像ZINCRBY。在此模式下只能指定一个记分元素对。</td>
</tr>
</tbody>
</table>
<p><strong>创建一个集合</strong></p>
<pre><code class="language-bash">127.0.0.1:6379&gt; zadd hacker 1953 zhangfei 1963 zhaoyun 1989 wangping 1992 zhugeliang 1945 liubei
(integer) 5
127.0.0.1:6379&gt; zadd hacker 100 zhugeliang
(integer) 0
127.0.0.1:6379&gt; zrange hacker 0 -1
1) &quot;zhugeliang&quot;
2) &quot;liubei&quot;
3) &quot;zhangfei&quot;
4) &quot;zhaoyun&quot;
5) &quot;wangping&quot;
</code></pre>
<blockquote>
<p><strong>查看某个元素在集合内的位置</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; zscore code_lag py
&quot;4&quot;
</code></pre>
<p>对有序集合采说,按生日排序返回这些数据易如反掌,因为他们已经是有序的。有序集合是通过一个dual-ported数据结构实现的,它包含一个精简的有序列表和一个hash table,因此添加一个元素的时间复杂度是O(log(N))。这还行,但当我们需要访问有序的元素时,Redis不必再做任何事情,它已经是有序的了。</p>
<h3 id="对集合的值排序">对集合的值排序</h3>
<blockquote>
<p><strong>通过索引查看一个有序集合的范围</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; zrange hacker 0 -1 withscores  #&lt;==打印score
 1) &quot;liubei&quot;
 2) &quot;1945&quot;
 3) &quot;zhangfei&quot;
 4) &quot;1953&quot;
 5) &quot;zhaoyun&quot;
 6) &quot;1988&quot;
 7) &quot;wangping&quot;
 8) &quot;1989&quot;
 9) &quot;zhugeliang&quot;
10) &quot;1992&quot;
</code></pre>
<blockquote>
<p><strong>通过指定索引范围查看有序集合列表（倒序）</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; zrevrange hacker 0 -1 withscores
 1) &quot;zhugeliang&quot;
 2) &quot;1992&quot;
 3) &quot;wangping&quot;
 4) &quot;1989&quot;
 5) &quot;zhaoyun&quot;
 6) &quot;1988&quot;
 7) &quot;zhangfei&quot;
 8) &quot;1953&quot;
 9) &quot;liubei&quot;
10)&quot;1945&quot;
</code></pre>
<h3 id="查看集合中的元素个数">查看集合中的元素个数</h3>
<blockquote>
<p><strong>返回有序集合中元素的个数</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; zcard hacker   
(integer) 8
</code></pre>
<blockquote>
<p><strong>返回min,max包括极值</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; zcount hacker 1950 2000
(integer) 7
127.0.0.1:6379&gt; zcount hacker (1950 (2000 #&lt;==不包括极值的用法
(integer) 4
</code></pre>
<h3 id="查找集合区间的元素">查找集合区间的元素</h3>
<p>zrangebysocre：返回有序集合key的分数min与max之间的所有元素（等于min或max）。这些元素被认为是从低到高的顺序排列。min和max可以是-inf(无穷)和+inf(正无穷)，可以不需要知道的有序集合最高或最低score来获得元素。</p>
<blockquote>
<p><strong>获取1950年之前（两个极值也包含）出生的人</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; zrangebyscore hacker -inf 1950 withscores
1) &quot;liubei&quot;
2) &quot;1945&quot;
3) &quot;jiangwie&quot;
4) &quot;1950&quot;
</code></pre>
<blockquote>
<p><strong>返回1950,1970区间内的值</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; zrangebyscore hacker 1950 1970 withscores
1) &quot;jiangwie&quot;
2) &quot;1950&quot; 
3) &quot;zhangfei&quot;
4) &quot;1953&quot; 
</code></pre>
<blockquote>
<p><strong>使用)返回 1950,2000区间内的值</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; zrangebyscore hacker (1950 (2000 withscores
1) &quot;zhangfei&quot;
2) &quot;1953&quot;
3) &quot;zhaoyun&quot;
4) &quot;1988&quot;
5) &quot;wangping&quot;
6) &quot;1989&quot;
7) &quot;zhugeliang&quot;
8) &quot;1992&quot;
</code></pre>
<blockquote>
<p><strong>使用limit返回指定区间内的值</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; zrangebyscore hacker -inf +inf withscores limit 0 3
1) &quot;liubei&quot;
2) &quot;1945&quot;
3) &quot;jiangwie&quot;
4) &quot;1950&quot;
5) &quot;zhangfei&quot;
6) &quot;1953&quot;
</code></pre>
<p>zremrangebyscore这个名字虽然不算好,但他却非常有用,还会返回已删除的元素数量。</p>
<p>回到Reddit的例子，现在我们有个基于有序集合的像样方案来生成首页。用一个有序集合来包含最近几天的新闻(用zremrangebyscore不时的删除旧新闻).用一个后台任务从有序集合中获取所有元素,根据用户投票和新闻时间计算score,然后用新闻ID和scores关联生成reddit.home.page有序集合.要显示首页,我们只需闪电般的调用ZRANGE不时的从reddit.home.page有序集合中删除过旧的新闻也是为了让我们的系统总是工作在有限的新闻集合之上。
更新有序集合的scores.</p>
<p>结束这篇指南之前还有最后一个小贴士.有序集合scores可以在任何时候更新。只要用ZADD对有序集合内的元素操作就会更新它的score(和位置),时间复杂度是O(log(N)),因此即使大量更新,有序集合也是合适的。<font style="background:#bafe01;" size=2>其中N是排序集合中的元素数，M是返回元素的数量。如果M是常数（例如，总是用LIMIT来询问前10个元素)，可以考虑O(log=(N))。</font></p>
<h3 id="计算交并集">计算交并集</h3>
<blockquote>
<p><strong>计算由numkeys指定个数的key的的交集，并将结果存储在其中destination</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; zadd k1 1 a 2 b 3 c
(integer) 3  #&lt;==a b c相当于数组的key 1 2 3相当于数组的值

127.0.0.1:6379&gt; zadd k2 10 a 20 b 30 c
(integer) 3 

127.0.0.1:6379&gt; zinterstore tmp 1 k1 k2
(error) ERR syntax error #&lt;==指定numkeys的数量和传参数量不一致会提示语法错误
127.0.0.1:6379&gt; zinterstore tmp 2 k1 k2
(integer) 3

127.0.0.1:6379&gt; zrange tmp 0 -1 withscores
1) &quot;a&quot; #&lt;==可以看出默认的聚合方法是sum
2) &quot;11&quot;
3) &quot;b&quot;
4) &quot;22&quot;
5) &quot;c&quot;
6) &quot;33&quot;

127.0.0.1:6379&gt; zinterstore tmp 2 k1 k2 weights 2 1 aggregate sum
(integer) 3  #&lt;==指定权重计算两个之间key之间的交集

127.0.0.1:6379&gt; zrange tmp 0 -1 withscores
1) &quot;a&quot; 
2) &quot;12&quot; #&lt;==k1 a=1权重为2 就等于2x1+10=12 
3) &quot;b&quot;
4) &quot;24&quot;
5) &quot;c&quot;
6) &quot;36&quot;
</code></pre>
<h2 id="hash">hash</h2>
<p>hash能够<font style="background:#bafe01;" size=2>存储一个key对多个属性的数据</font> 如：<font color="#f8070d" size=3><code>user.username user.password</code></font></p>
<h3 id="设置key中的域与值">设置key中的域与值</h3>
<blockquote>
<p><strong>hset：将key中的field域设置为value，如果field域存在则覆盖原value，不存在则添加</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; hset user1 name zhangsan
(integer) 1
127.0.0.1:6379&gt; hset user1 age 12
(integer) 1
127.0.0.1:6379&gt; hset user1 gender male
(integer) 1
</code></pre>
<blockquote>
<p><strong>hmset：给key设置多个field域与值</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; hmset user2 name lisi age 11 gender female
OK
</code></pre>
<h3 id="获得key中的域和值">获得key中的域和值</h3>
<blockquote>
<p><strong>hget：返回key中一个域的值</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; hget user1 name
&quot;zhangsan&quot;
</code></pre>
<blockquote>
<p><strong>hgetall：返回key中所有域和值</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; hgetall user1
1) &quot;name&quot;
2) &quot;zhangsan&quot;
3) &quot;age&quot;
4) &quot;12&quot;
5) &quot;gender&quot;
6) &quot;male&quot;
</code></pre>
<blockquote>
<p><strong>hmget：返回key中多个值</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; hmget user1 name age
1) &quot;zhangsan&quot;
2) &quot;12&quot;
</code></pre>
<blockquote>
<p><strong>hkeys：返回key中的所有域</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; hkeys user1
1) &quot;age&quot;
2) &quot;gender&quot;
3) 
</code></pre>
<blockquote>
<p><strong>hvals：返回key中的所有域的值</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; hvals user1
1) &quot;12&quot;
2) &quot;male&quot;
</code></pre>
<h3 id="删除key">删除key</h3>
<blockquote>
<p><strong>hdel：删除key中一个或多个域</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; hdel user1 name
(integer) 1
127.0.0.1:6379&gt; hgetall user1
1) &quot;age&quot;
2) &quot;12&quot;
3) &quot;gender&quot;
4) &quot;male&quot;

</code></pre>
<h3 id="查看域信息">查看域信息</h3>
<blockquote>
<p><strong>hlen：返回key中域的个数</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; hlen user1
(integer) 2
</code></pre>
<blockquote>
<p><strong>hexists：查看key中是否存在某个域</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; hexists user1 name
(integer) 0
127.0.0.1:6379&gt; hexists user1 age
(integer) 1
</code></pre>
<blockquote>
<p><strong>hstrlen：返回key中域的值的长度</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; HSTRLEN user2 gender
(integer) 6
</code></pre>
<h3 id="hash的原子操作">hash的原子操作</h3>
<blockquote>
<p><strong>hincrby：对域中的值增长value个(单位整型)</strong></p>
<blockquote>
<p>语法：hincrby key field increment</p>
</blockquote>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; hget user1 age
&quot;14&quot;
127.0.0.1:6379&gt; hincrby user1 age 2
(integer) 16
127.0.0.1:6379&gt; hget user1 age
&quot;16&quot;
</code></pre>
<blockquote>
<p><strong>hincrbyfloat：对域中的值增长value(单位浮点型)</strong></p>
</blockquote>
<pre><code class="language-bash">127.0.0.1:6379&gt; hincrbyfloat user1 age 0.3
&quot;16.3&quot;
127.0.0.1:6379&gt; hget user1 age
&quot;16.3&quot;
127.0.0.1:6379&gt; hincrbyfloat user1 age -2 #&lt;==减少用负数即可
&quot;14.3&quot;
</code></pre>
<p>bitMap 可实现用很小的内存实现高效的存储。</p>
<p>HyperLogLog 超小内存唯一值计数。 12k来实现唯一值得计数</p>
<p>GEO 基于地理信息位置定位</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>redis主从复制工作原理</title>
      <link>https://www.oomkill.com/2016/11/redis-replication/</link>
      <pubDate>Wed, 23 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2016/11/redis-replication/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="replication的工作原理">Replication的工作原理</h2>
<p>设置一个Slave，无论是第一次还是重连到Master，它都会发出一个sync命令。当Master收到sync命令之后，会做两件事：</p>
<ol>
<li>Master执行BGSAVE，即在后台保存数据到磁盘（rdb快照文件）。</li>
<li>Master同时将新收到的写入和修改数据集的命令存入缓冲区（非查询类）。</li>
</ol>
<p>当Master在后台把数据保存到快照文件完成之后，把这个快照传送给Slave，而Slave则把内存清空后，加载该文件到内存中。而Master也会把此前收集到缓冲区中的命令，通过Reids命令协议形式转发给Slave，Slave执行这些命令，实现和Master的同步。Master/Slave此后会不断通过<font style="background:#edfb05;" size=2>异步方式进行命令的同步</font>。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed//img/image-20221214204055170.png" alt="image-20221214204055170" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<hr>
<p><font color=#360c9f size=2><strong>注：在redis2.8之前，主从之间一旦发生重连都会引发全量同步操作。但在2.8之后版本，也可能是部分同步操作。</strong></font></p>
<hr>
<h3 id="部分复制">部分复制</h3>
<p>2.8后，当主从之间的连接断开之后，他们之间可以采用持续复制处理方式代替采用全量同步。Master端为复制流维护一个内存缓冲区（in-memory backlog），记录最近发送的复制流命令；同时，Master和Slave之间都维护一个复制偏移量(replication offset)和当前Master服务器ID（Master run id）。当网络断开，Slave尝试重连时：</p>
<ol>
<li>
<p>如果MasterID相同（即仍是断网前的Master服务器），并且从断开时到当前时刻的历史命令依然在Master的内存缓冲区中存在，则Master会将缺失的这段时间的所有命令发送给Slave执行，然后复制工作就可以继续执行了</p>
</li>
<li>
<p>否则，依然需要全量复制操作。</p>
</li>
</ol>
<p>Redis 2.8 的这个部分重同步特性会用到一个新增的PSYNC内部命令， 而 Redis 2.8以前的旧版本只有SYNC命令，不过，只要从服务器是Redis 2.8或以上的版本，它就会根据主服务器的版本来决定到底是使用 PSYNC还是SYNC。
如果主服务器是 Redis 2.8 或以上版本，那么从服务器使用 PSYNC 命令来进行同步。
如果主服务器是 Redis 2.8 之前的版本，那么从服务器使用 SYNC 命令来进行同步。</p>
<h2 id="redis主从同步特点">redis主从同步特点</h2>
<ol>
<li>一个Master可以有多个Slave。</li>
<li>Redis使用异步复制。从2.8开始，Slave会周期性（每秒一次）发起一个ack确认复制流（replication stream）被处理进度；</li>
<li>不仅主服务器可以有从服务器， 从服务器也可以有自己的从服务器， 多个从服务器之间可以构成一个图状结构；</li>
<li>复制在Master端是非阻塞模式的，这意味着即便是多个Slave执行首次同步时，Master依然可以提供查询服务；</li>
<li>复制在Slave端也是非阻塞模式的：如果你在redis.conf做了设置，Slave在执行首次同步的时候仍可以使用旧数据集提供查询；你也可以配置为当Master与Slave失去联系时，让Slave返回客户端一个错误提示；</li>
<li>当Slave要删掉旧的数据集，并重新加载新版数据时，Slave会阻塞连接请求（一般发生在与Master断开重连后的恢复阶段）；</li>
<li>复制功能可以单纯地用于数据冗余（data redundancy），也可以通过让多个从服务器处理只读命令请求来提升扩展性（scalability）： 比如说， 繁重的 SORT 命令可以交给附属节点去运行。</li>
<li>可以通过修改Master端的redis.config来避免在Master端执行持久化操作（Save），由Slave端来执行持久化。</li>
</ol>
<h2 id="redis-replication配置文件详解">redis replication配置文件详解</h2>
<pre><code class="language-bash">slaveof [masterip] [masterport] #←该redis为slave ip和port是master的ip和port

masterauth &lt;master-password&gt; #←如果master设置了安全密码，此处为master的安全密码

slave-serve-stale-data yes#←当slave丢失master或同步正在进行时，如果发生对slave的服务请求：
slave-serve-stale-data no #←slave返回client错误:&quot;SYNC with master in progress&quot;
slave-serve-stale-data yes #←slave依然正常提供服务

slave-read-only yes #←设置slave不可以写数据，只能用于同步

repl-ping-slave-period 10 #←发送ping到master的时间间隔
repl-timeout 60 #←IO超时时间
repl-backlog-size 1mb #←backlog的大小，当从库连接不到主库时，backlog的队列能放多少
repl-backlog-ttl 3600 #←backlog的生命周期
min-slaves-max-lag 10 #←延迟小于min-slaves-max-lag秒的slave才认为是健康的slave
# 当master不可用,Sentinel会根据slave的优先级选举一个master。
# 最低的优先级的slave,当选master.而配置成0,永远不会被选举
slave-priority 100 
</code></pre>
<h2 id="配置replication">配置Replication</h2>
<p><em><strong>当前生效：在命令行输入以下命令</strong></em></p>
<pre><code class="language-bash">redis-cli slaveof 127.0.0.1 6379
</code></pre>
<p><em><strong>永久生效：修改配置文件&quot;slaveof&quot;选项</strong></em></p>
<pre><code class="language-bash">slaveof [masterip] [masterport]
slaveof 127.0.0.1 6379
</code></pre>
<p>这样就可以保证Redis_6380服务程序在每次启动后都会主动建立与Redis_6379的Replication连接了。</p>
<p><em><strong>查看从库的同步情况</strong></em></p>
<pre><code class="language-bash">127.0.0.1:6380&gt; MONITOR   #←监听服务器实时收到的所有请求
OK
1492710733.401532 [0 127.0.0.1:6379] &quot;PING&quot; #← 从库会ping主库
1492710743.510808 [0 127.0.0.1:6379] &quot;PING&quot;
1492711152.901232 [0 127.0.0.1:6379] &quot;sadd&quot; &quot;web_site&quot; &quot;www.baidu.com&quot; &quot;www.google.com&quot; &quot;www.qq.com&quot;
</code></pre>
<p><em><strong>获取有关服务器的信息和统计信息</strong></em></p>
<pre><code class="language-bash">127.0.0.1:6380&gt; info Replication
Replication
role:slave
master_host:127.0.0.1
master_port:6379
master_link_status:up
master_last_io_seconds_ago:9
master_sync_in_progress:0
slave_repl_offset:8999
slave_priority:100
slave_read_only:1
connected_slaves:0
master_repl_offset:0
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0
</code></pre>
<p><em><strong>当前主从同步存在的问题</strong></em>
由于master和slave服务器不是Redis自动选举产生，需要人工参与，因此主从倒换无法自动完成。这样就存在一个问题，什么时候以及由谁来触发倒换。redis2.8的master和slave服务器是Redis自动选举产生了。</p>
<p>redis高可用 <a href="http://www.cnblogs.com/Xrinehart/p/3501372.html" target="_blank"
   rel="noopener nofollow noreferrer" >http://www.cnblogs.com/Xrinehart/p/3501372.html</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>memcached从入门到精通</title>
      <link>https://www.oomkill.com/2016/09/memcached/</link>
      <pubDate>Wed, 28 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2016/09/memcached/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="1-memcached介绍及常见同类软件对比">1 Memcached介绍及常见同类软件对比</h2>
<h3 id="11-memcached是什么">1.1 Memcached是什么？</h3>
<p>Memcached是一个开源的、支持高性能、高并发的分布式缓存系统，由C语言编写，总共2000多行代码。从软件名称上看，前3个字符的单词Mem就是内存的意思，接下来的后面5个字符的单词Cache就是缓存的意思，最后一个字符d是daemon的意思，代表是服务端守护进程模式服务。</p>
<p>Memcached服务分为服务端和客户端两部分，其中，<font style="background:#ffc104;" size=2>服务端</font>软件的名字形如 <code>Memcached-1.4.24.tat.gz</code>，<font style="background:#ffc104;" size=2>客户端</font>软件的名字形如 <code>Memcache-2.25.tar.gz</code></p>
<p>Memcached软件诞生于2003年，最初由LiveJournal的BradFitzpatrick开发完成。Memcached是整个项目的名称，而Memcached是服务器端的主程序名，因其协议简单，使用部署方便、且支持高并发而被互联网企业广泛使用，知道现在仍然被广泛应用。官方网址：http://memcached.org</p>
<h3 id="12-memcached的作用">1.2 Memcached的作用</h3>
<p>传统场景，多数Web应用都将数据保存到关系型数据库中（例如MySQL），Web服务器从中读取数据并在浏览器中显示。但随着数据量的增大、访问的集中，关系型数据库的负担就会加重、响应缓慢、导致网站打开延迟等问题，影响用户体验。</p>
<p>这时就需要Memcached软件出马了。使用Memcached的主要目的是，通过在自身内存中缓存关系型数据库的查询结果，减少数据库自身被访问的次数，以提高动态web应用的速度、提高网站架构的并发能力和可扩展性。</p>
<p>Memcached服务的运行原理是通过在实现规划好的系统内存空间中临时缓存数据库的各类数据，以达到减少前端业务服务对数据库的直接高并发访问，从而达到提升大规模网站急群众动态服务的并发访问能力。</p>
<p>生产场景的Memcached服务一般被用来保存网站中经常被读取的对象或数据，就像我们的客户端浏览器也会把经常访问的网页缓存起来一样，通过内存缓存来存取对象或数据要比磁盘存取快很多，因为磁盘是机械的，因此，在当今的IT企业中，Memcached的应用范围很广泛</p>
<h3 id="13-互联网常见内存服务软件">1.3 互联网常见内存服务软件</h3>
<p>下表为互联网企业场景常见内存缓存服务软件相关对比信息：</p>
<table>
<thead>
<tr>
<th>软件</th>
<th>类型</th>
<th>主要作用</th>
<th>缓存的数据</th>
</tr>
</thead>
<tbody>
<tr>
<td>Memcached</td>
<td>纯内存型</td>
<td>常用于缓存网站后端的各类数据，例如数据库中的数据</td>
<td>主要缓存用户重复请求的动态内容，</br>blog的博文</br>BBS的帖子等内容</br>用户的Session会话信息</td>
</tr>
<tr>
<td>Redis/Mongodb/memcachedb</td>
<td>可持久化存储，即使用内存也会使用磁盘存储</td>
<td>1. 缓存后端数据库的查询数据<br>2.作为关系数据库的重要补充</td>
<td>1.作为缓存：主要缓存用户重复请求的动态内容：例如BLOG的博文、BBS的帖子等内容。</br>2.作为数据库的有效补充：例如：好友关注、粉丝统计、业务统计等功能可以用持久化存储。</td>
</tr>
<tr>
<td>Squid/Nginx</td>
<td>内存或内存加磁盘缓存</td>
<td>主要用于缓存web前端的服务内容</td>
<td>主要用于静态数据缓存，例如：图片，附件（压缩包），js,css,html等，</br>此部分功能大多数企业会选择专业的CDN公司如：蓝讯、网宿。</td>
</tr>
</tbody>
</table>
<h2 id="2-memcached常见用途工作流程">2 Memcached常见用途工作流程</h2>
<p>Memcached是一种内存缓存软件，在工作中经常用来缓存数据库的查询数据，数据被缓存在事先预分配的Memcached管理的内存中，可以通过API或命令的方式存取内存中缓存的这些数据，Memcached服务内存中缓存的数据就像一张巨大的HASH表，每条数据都是以key-value对的形式存在。</p>
<h3 id="21-网站读取memcached数据时的工作流程">2.1 网站读取Memcached数据时的工作流程</h3>
<p>Memcached用来缓存查询到的数据库中的数据，逻辑上，当程序访问后端数据库获取数据时会先优先访问Memcached缓存，如果缓存中有数据就直接返回给客户端用户，如果没有数据（没有命中）程序再去读取后端的数据库的数据，读取到需要的数据后，把数据返回给客户端，同时还会把读取到的数据库缓存到Memcached内存中，这样客户端用户再请求相同数据就会直接读取Memcached缓存的数据，这样就大大减轻了后端数据库的压力，并提高了整个网站的响应速断，提升了用户体验。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221025002621702.png" alt="image-20221025002621702" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图2-1展示了Memcached缓存系统和后端数据库系统的协作流程</center>
<blockquote>
<p><strong>上图，使用Memcached缓存查询数据来减少数据库压力的具体工作流程如下</strong>：</p>
</blockquote>
<ol>
<li>
<p>web程序首先检查客户端请求的数据是否在Memcached缓存中存在，如果存在，直接把请求的数据返回给客户端，此时不在请求后端数据库。</p>
</li>
<li>
<p>如果请求的数据在Memcached缓存中不存在，则程序会请求数据库服务，把数据库中取到的数据返回给客户端，此时不再请求后端数据库。</p>
</li>
</ol>
<h3 id="22-网站更新memcached数据时工作流程">2.2 网站更新Memcached数据时工作流程</h3>
<ol>
<li>当程序更新或者删除数据时，会首先处理后端数据库中的数据。</li>
<li>程序处理后端数据库中的数据的同时，也会通知Memcached中的对应旧数据失效，从而保证Memcached中缓存的数据始终和数据库中的户数一直，这个数据一致性非常重要，也是大型网站分布式缓存集群的最头痛的问题所在。</li>
<li>如果是在高并发读写场合，除了要程序通知Memcached过期的缓存失效外，还可能会通过相关机制，例如在数据库上部署相关程序（例如：在数据库中设置触发器使用UDFs），实现当数据库有更新就会把数据更新到Memcached服务中，使得客户端在访问新数据前，预先把更新过的数据库数据复制到Memcached中缓存起来，这样可以减少第一次查询数据库带来的访问压力，提升Memcached中缓存的命中率，甚至sina门户还会把持久化存储redis做成MySQL数据库的从库，实现真正的主从复制。</li>
</ol>
<center>Memcached网站作为缓存应用更新数据流程图见下图1-2</center>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024234831970.png" alt="image-20221024234831970" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>Memcached服务作为缓存应用通过相关软件更新数据见图2-2</center>
<h2 id="3-memcached在企业中的应用场景">3 Memcached在企业中的应用场景</h2>
<h3 id="31-作为数据库查询数据缓存">3.1 作为数据库查询数据缓存</h3>
<h4 id="311-完整数据缓存">3.1.1 完整数据缓存</h4>
<p>例如电商的商品分类功能不会经常变动，就可以实现放到Memcached里，然后再对外提供数据访问。这个过程被称之为“数据预热”。</p>
<p>此时秩序读取缓存无需读取数据库就能读到Memcached缓存里的所有商品分类数据了，所以数据库的访问压力就会大大降低了。</p>
<blockquote>
<p><strong>为什么商品分类数据可以实现放在缓存里呢？</strong></p>
</blockquote>
<p>因为，商品分类几乎都是由内部人员管理的，如果需要更新数据，更新数据库后，就可以把数据同时更新到Memcached里。</p>
<p>如果把商品分类数据做成静态化文件，然后通过在前段WEB缓存或者使用CDN加速效果更好。</p>
<h4 id="312-热点数据缓存">3.1.2 热点数据缓存</h4>
<p>热点数据缓存一般是用于由用户更新的商品，例如淘宝的卖家，当卖家新增商品后，网站程序就会把商品写入后端数据库，同时把这部分数据，放入Memcached内存中，下一次访问这个商品的请求就直接从Memcached内存中取走了。这种方法用来缓存网站热点的数据，即利用Memcached缓存经常被访问的数据。</p>
<p>特别提示：这个过程可以通过程序实现，也可以在数据库上安装软件进行设置，直接由数据库把内容更新到Memcached中，相当于Memcached是MySQL的丛库一样。</p>
<blockquote>
<p><strong>淘宝、京东、小米等电商双11秒杀抢购场景</strong>：</p>
</blockquote>
<p>如果碰到电商双11秒杀高并发的业务场景，必须要实现预热各种缓存，包括前端的web缓存和后端的数据缓存。</p>
<p>先把数据放入内存预热，然后在逐步动态更新。先读取缓存，如果缓存里没有对应的数据，再去读取数据库，然后把读到的数据放入缓存。如果数据库里的数据更细，需要同时触发缓存更细，防止给用户过期的数据，当然对于百万级别并发还有很多其它的工作要做。</p>
<hr>
<p><strong><font color="#0215cd" size=2> <font color="#f8070d" size=2>⚠</font> 提示：这个过程可以通过程序实现，也可以在数据库上安装相关软件进行设置，直接由数据库把内容更新到Memcached中，就相当于Memcached是MySQL的从库一样</font></strong></p>
<hr>
<p>如果碰到双十一、秒杀高并发的业务场景，必须要事先预热各种缓存，包括前段的Web缓存和后端的数据缓存。</p>
<p>也就是说事先把数据放入内存预热，然后逐步动态更新。此时，会先读取缓存，如果缓存里没有对应的数据，再去读取数据库，然后把读到的数据放入缓存。如果数据库里的数据更新，需要同时触发缓存更新，防止给用户过期的数据，当然对于百万级别并发还有很多其他的工作要做。</p>
<p>绝大多数的网站动态数据都是保存在数据库当中的，每次频繁地存取数据库，会导致数据库性能急剧下降，无法同时服务更多的用户（比如MySQL特别频繁的表锁就会存在此问题），那么，就可以让Memcached来分担数据库的压力。增加Memcached服务的好处除了可以分担数据库的压力以外，还包括无须改动整个网站架构，只需简单修改下程序逻辑，让程序先读取Memcached缓存查询数据即可。更新数据时也要更新Memcached缓存。</p>
<blockquote>
<p><strong>【分布式应用1】</strong></p>
</blockquote>
<p>Memcached支持分布式，我们在应用服务程序上改造，就可以更好的支持。例如：可以根据key适当进行有规律的封装，比如以用户位置的网站来说，每个用户都有UID。那么可以按照固定的ID来进行提取和存取，比如1开头的用户保存在第一台Memcached服务器上，以2开头的用户的数据保存在第二天Memcached服务器上，存取数据都先按照UID来进行的转换和存取。</p>
<blockquote>
<p><strong>【分布式应用2】</strong></p>
</blockquote>
<p>在应用服务器上通过程序及URL_HASH，抑制性哈希算法区访问Memcache服务，所有Memcached服务器的地址池可以简单的配在程序的配置文件里。</p>
<blockquote>
<p><strong>【分布式应用3】</strong></p>
</blockquote>
<p>门户网站如百度，会通过一个中间件代理负责请求后端的Cache服务。</p>
<blockquote>
<p><strong>【分布式应用4】</strong></p>
</blockquote>
<p>可以用常见的LVS haproxy做Cache的负载均衡，和普通应用服务相比，这里的重点是轮训算法，一般会选择url_hash，及consistent hash算法。</p>
<p>算法重要性图解</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024234919688.png" alt="image-20221024234919688" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="32-作为集群节点的session会话存储">3.2 作为集群节点的session会话存储</h3>
<p>即把客户端用户请求多个前端应用服务集群产生的session会话信息，统一存储到一个Memcached缓存中。由于session会话数据是存储在内存中的，所以速度很快。</p>
<p>图3-2为Memcached服务在企业集群架构中常见的工作位置。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024234934265.png" alt="image-20221024234934265" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="33-memcached服务在企业集群架构中的位置">3.3 Memcached服务在企业集群架构中的位置</h3>
<p>下图为Memcached服务在企业集群架构中常见的工作位置。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235014658.png" alt="image-20221024235014658" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="34-缓存雪崩效应">3.4 缓存雪崩效应</h3>
<p>一般是由于某个节点生效，导致其他节点的缓存命中率下降，缓存中缺失的数据去数据可查询。短时间内造成数据库服务器崩溃。或，由于缓存周期性的输小，如：6小时失效一次，那么每6小时，将有一个请求&quot;峰值&quot;，严重情况下会导致数据库宕机。</p>
<h2 id="4-memcached的特点与工作机制">4 Memcached的特点与工作机制</h2>
<h3 id="41-memcache的特征">4.1 Memcache的特征</h3>
<p>Memcached作为高并发、高性能的缓存服务，具有如下特征：</p>
<h4 id="411-协议简单">4.1.1 协议简单</h4>
<p>Memcached的协议实现简单，采用基于文本行的协议，能通过telnet/nc等命令直接操作Memcached服务读取数据。</p>
<h4 id="412-支持epollkqueue异步io模型使用libevent作为事件处理通知机制">4.1.2 支持epoll/kqueue异步I/O模型，使用libevent作为事件处理通知机制。</h4>
<p>简单的说libevent是一套利用C开发的程序库，他将BSD系统的kqueue，Linux系统的epoll等事件处理功能封装成一个接口，确保即使服务器端的连接数量增加也能发挥很好的性能。Memcached就是利用这个libevent库进行异步事件处理。</p>
<h4 id="413-keyvalue键值数据类型">4.1.3 key/value键值数据类型</h4>
<p>被缓存的数据以key/value键形式存在的，例如：</p>
<pre><code>zhangsan=&gt;23 key=zhangsan value=23
通过zhangsan key可以获取到23
</code></pre>
<h4 id="414-全内存缓存效率高">4.1.4 全内存缓存，效率高</h4>
<p>Memcached管理内存的方式非常搞笑，即全部的数据都存放于Memcached服务实现分配好的内存中，无持久化存储的设计，和系统的物理内存一样，当重启系统或Memcached服务时，Memcached内存中的数据即会丢失。</p>
<p>如果希望重启后，数据依然能保存，那么就可以采用redis这样的持久性内存缓存系统的缓存数据。也可以在存放数据时，对存储的数据设置过期时间，这样过期后数据就自动被清除，Memcached服务本身不会监控数据过期，而是在访问的时候查看key的时间戳判断是否过期。</p>
<h4 id="415-可支持分布式集群">4.1.5 可支持分布式集群</h4>
<p>Memcached没有像MySQL那样的主从复制方式，分布式Memcached集群的不同服务器之间是互不通讯的，每一个节点都独立存取数据，并且数据内容也不一样。通过对Web应用端的程序设计或者通过支持hash算法的负载均衡软件，可以让Memcached支持大规模海量分布式缓存集群应用。</p>
<h3 id="42-memcached工作原理与机制">4.2 Memcached工作原理与机制</h3>
<h4 id="421-memcached工作原理">4.2.1 Memcached工作原理</h4>
<p>Memcached是一套类似C/S模式的架构软件，在服务器端启动Memcached服务守护进程，可以指定监听本地的IP地址、端口号、并发访问连接数，以及分配了多少内存来处理客户端请求。</p>
<h4 id="422-socket时间处理机制">4.2.2 Socket时间处理机制</h4>
<p>Memcached软件是由C语言来实现的，全部代码仅有2000多行，采用的是异步epoll/kqueue非阻塞I/O网络模型，其实现方式是基于异步的libevent时间单进程、单线程模式。使用libevent作为事件通知机制，应用程序端通过指定服务器的IP地址及端口，就可以连接Memcached服务进程通讯。</p>
<h4 id="423-数据存储机制">4.2.3 数据存储机制</h4>
<p>需要被缓存的数据以key/value键值对的形式保存在服务器端预分配的内存区中，每个被缓存的数据都有唯一的标识key，操作Memcached中的数据就是通过这个唯一标识的key进行的。缓存到Memcached中的数据仅放置在Memcached服务预分配的内存中，而非存储在Memcached服务器所在的磁盘上，因此存取速度非常快。</p>
<p>由于Memcached服务自身没有对缓存的数据进行持久化存储的设计，因此，在服务端的Memcached服务进程重启之后，存储在内存中的这些数据都会丢失。且当内存中缓存的数据容量达到启动时设定的内存值时，也会自动使用LRU算法删除过期的数据。</p>
<p>开发Memcached的初衷仅是通过内存缓存提示访问效率，并没有过多考虑数据的永久存储问题。因此，如果使用Memcached作为缓存数据服务，要考虑数据丢失后带来的问题，例如：是否可以重新生成数据，还有，在高并发场合下缓存宕机或重启会不会导致大量请求直接到数据库，导致数据库无法承受，最终导致网站架构雪崩等。</p>
<h4 id="424-内存管理机制">4.2.4 内存管理机制</h4>
<ul>
<li>Memcached采用了如下机制：</li>
<li>采用slab内存分配机制。</li>
<li>采用LRU对象清除机制。</li>
<li>采用hash机制快速检索item。</li>
</ul>
<h4 id="425-多线程处理机制">4.2.5 多线程处理机制</h4>
<ul>
<li>多线程处理时采用的是pthread（POSIX）线程模式。</li>
<li>若要激活多线程，可在编译时指定：<font color="#f8070d" size=2><code>./configure --enable-threads</code></font> 。</li>
<li>锁机制不够完善。</li>
<li>负载过重时，可以开启多线程（-t线程数为CPU核数）。</li>
</ul>
<h3 id="43-memcached预热理念及集群节点的正确重启方法">4.3 Memcached预热理念及集群节点的正确重启方法</h3>
<h4 id="431-memcached预热理念">4.3.1 Memcached预热理念</h4>
<p>当需要大面积重启Memcached时，首先要在前端控制网站入口的访问流量，然后重启Memcached集群并进行数据预热，所有数据都预热完毕之后，在逐步开放前端网站入口的流量。</p>
<p>为了满足Memcached服务可以持久化存储的需求，在较早时期，新浪网基于Memcached服务开发了一款NoSQL软件，名字为MemcacheDB，实现了在缓存的基础上增加了之久存储的特性，不过目前逐步被更优秀的redis mongodb取代了。</p>
<h4 id="432-如何正确开启网站集群服务器">4.3.2 如何正确开启网站集群服务器</h4>
<p>如果由于机房断电或者搬迁服务器集群到新机房，那么启动集群服务器时，一定要从网站集群的后端**==依次往前端开启==**，特别是开启Memcached缓存服务器时要提前预热。</p>
<h2 id="5-memcached内存管理">5 Memcached内存管理</h2>
<h3 id="51-memcached内存管理机制深入剖析">5.1 Memcached内存管理机制深入剖析</h3>
<h4 id="511-malloc内存管理机制">5.1.1 Malloc内存管理机制</h4>
<p>在讲解Memcached内存管理机制前，先来了解malloc。</p>
<p>malloc的全称是memory allocation，中文名称动态内存分配，当无法知道内存具体位置的时候，想要绑定真正的内存空间，就需要用到动态分配内存。</p>
<p>早期的Memcached内存管理是通过malloc分配的内存实现的，使用完后通过free来回收内存。这种方式容易产生内存碎片并降低操作系统对内存的管理效率。因此，也会加重操作系统内存管理器的负担，最坏的情况下，会导致操作系统比Memcached进程本身还慢，为了解决上述问题，Slab Allocator内存分配机制就诞生了。</p>
<h4 id="512-slab内存管理机制">5.1.2 Slab内存管理机制</h4>
<p>现在的Memcached是利用Slab Allocation机制来分配和管理内存的，过程如下。</p>
<ol>
<li>提前将大内存分配大小为1MB的若干个slab，然后针对每个slab在进行小对象填充，这个小对象成为chunk，避免大量重复的初始化和清理，减轻了内存管理器的负担。</li>
<li>Slab Allocation内存分配的原理是按照预先规定的大小，将分配给Memcached服务的内存预先分割成特定长度的内存块(chunk)分成组(chunks slab class)，这些内存块不会释放，可以重复利用。</li>
</ol>
<p>新增数据对象存储时。因Memcached服务器中保存这slab内空闲chunk的列表，他会根据该列表选择chunk，然后将数据缓存于其中。当有数据存入时，Memcached根据接收到的数据大小，选择最适合数据大小的slab分配一个能存下这个数据的最小内存块(chunk)。例如：有100字节的一个数据，就会分配存入下面112字节的内存块中，会有这样12字节被浪费，这部分空间就不能被使用了，这也是SlabAllocator机制的一个缺点。</p>
<p>Slab Allocator还可以重复使用已分配的内存，即分配道德内存不书房，而是重复利用。</p>
<blockquote>
<p><strong>Slab Allocation的主要术语</strong></p>
</blockquote>
<table>
<thead>
<tr>
<th>Slab Allocation主要术语</th>
<th>注解说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>slab class</td>
<td>内存区类别（48bytes-1MB）</td>
</tr>
<tr>
<td>slab</td>
<td>动态创建的实际内存区，即分配给Slab的内存空间，默认是1MB。分配给Slab之后根据slab的大小切分成chunk。slab默认大小为1048576byte(1MB)，大于1MB的数据会忽略。</td>
</tr>
<tr>
<td>slab classid</td>
<td>slab class的ID</td>
</tr>
<tr>
<td>chunk</td>
<td>数据区块，固定大小，chunk初始大小，1.4版本中是48bytes</td>
</tr>
<tr>
<td>item</td>
<td>实际存储在chunk中的数据项。</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>Slab内存管理机制特点</strong></p>
</blockquote>
<ul>
<li>提前分配大量内存Slab 1Mb，再进行小对象填充chunk。</li>
<li>避免大量重复的初始化和清理，减轻内存管理器的负担。</li>
<li>避免频繁malloc/free内存分配导致的碎片。</li>
</ul>
<blockquote>
<p><strong>下面对Mc内存管理机制进行一个小结</strong></p>
</blockquote>
<ul>
<li>mc的早期内存管理机制为malloc（动态分配内存）。</li>
<li>malloc（动态内存分配）产生内存碎片，导致操作系统性能急剧下降。</li>
<li>Slab内存分配机制可以解决内存碎片的问题</li>
<li>Memcached服务的内存预先分割成特定长度的内存块，成为chunk，用于缓存数据的内存空间或内存块，相当于磁盘的block，只不过磁盘的每一个block都是相等的，而chunk只有在同一个Slab Class内才是相等的。</li>
<li>Slab Class指特定大小（1MB）的包含多个chunk的集合或组，一个Memcached包含多个Slab Class，每个Slab Class包含多个相同大小的chunk。</li>
<li>Slab机制也有缺点，例如，Chunk的空间会有浪费等。</li>
</ul>
<h3 id="52-memcached-slab-allocator内存管理机制的缺点">5.2 Memcached Slab Allocator内存管理机制的缺点</h3>
<p>chunk存储item浪费空间</p>
<p>Slab Allocator解决了当初的内存碎片问题，但新的机制也给Memcached带来了新的问题。这个问题就是，由于分配的是特定长度的内存，因此无法有效利用分配的内存。例如：将100字节的数据缓存到128字节的chunk中，剩余的28字节就浪费了</p>
<p>避免浪费内存的方法是，预先计算出应用存入的数据大小，或把同一业务类型的数据存入一个Memcached服务器中，确保存入的数据大小相对均匀，这样就可以较少内存的浪费。</p>
<p>还有一种方法是，在启动时，指定-f参数，能在某种程度上控制内存组之间的大小差异。在应用中使用Memcached时，通常可以不重新设置这个参数，即默认值1.25进行部署即可。如果想优化Memcached对内存的使用，可以考虑重新计算数据的预期品均长度，调整这个参数来获得合适的设置值。</p>
<h3 id="53-memcached的检测过期与删除机制">5.3 Memcached的检测过期与删除机制</h3>
<h4 id="531-memcached懒惰检测对象的过期机制">5.3.1 Memcached懒惰检测对象的过期机制</h4>
<p>首先要知道，Memcached不会主动检测item对象是否过期，而是在进行get操作时检查item对象是否过期自己是否应该删除！</p>
<p>因为不会主动检测item对象是否过期，自然也就不会释放已分配给对象的内存空间了，除非为添加的数据设定过期时间或内存缓存满了，在数据过期后，客户端不能通过key取他的值，起存储空前被重新利用。</p>
<p>Memcached使用的这种策略为懒惰检测对象过期策略，即自己不监控存入的key/value对是否过期，而是在获取key值时查看记录时间戳(set key flag exptime bytes)，从而检查key/value对空间是否过期。这种策略不会在过期检测上浪费CPU资源</p>
<h4 id="532-memcached惰性删除对象机制">5.3.2 Memcached惰性删除对象机制</h4>
<p>当删除item对象时，一般不会释放内存空间，而是做删除标记，将指针放入slot回收插槽，下次分配的时候直接使用。</p>
<p>Memcached在分配空间时，会优先使用已经过期的key/value对空间；若分配的内存空间占满，Memcached就会使用LRU算法来分配空间，删除最近最少使用的key/value对，从而将其空间分配给新的key/value对。在某些情况下（完整缓存），如果不想使用LRU算法，那么可以通过“-M”参数来启动Memcached，这样Memcached在内存耗尽时，会返回一本报错信息，如下：</p>
<pre><code class="language-sh">-M   return error on memory exhausted (rather than removing items)
</code></pre>
<blockquote>
<p><strong>Memcache删除机制小结</strong>：</p>
</blockquote>
<p>不主动检测item对象是否过期，而是在get时才会检查item对象是否过期以及是否应该删除。</p>
<p>当删除item对象时，一般不释放内存空间，而是做删除标记，将指针放入slot回收插槽，下次分配的时候直接使用。</p>
<p>当内存空间满的时候，将会根据LRU算法把最近最少使用的item对象删除。</p>
<p>数据存入可以设定过期时间，但是数据过期后不会被立即删除，而是在get时检查item对象是否过期以及是否应该删除。</p>
<p>如果不希望系统使用LRU算法清楚数据，可以使用-M参数。</p>
<pre><code class="language-sh">stats 
STAT curr_items 3
STAT total_items 10	#←删除前的item对象
STAT evictions 0
END
flush_all
OK
stats
STAT pid 1532
...
STAT curr_items 3		#←由于memcached删除机制的原理，数据并未释放而是做了标记
STAT total_items 10	#←在下次访问过
STAT evictions 0
END
flush_all 
OK
STAT curr_items 2
STAT total_items 6
STAT evictions 0
END
get a
END
stats
...
STAT bytes 67
STAT curr_items 1
STAT total_items 6
STAT evictions 0
END
# 数据过期与上述基本相同
set key 0 10 2
23
STORED
stats
..
STAT curr_items 1
STAT total_items 2
STAT evictions 0
END
get ket   
END
stats
...
STAT curr_items 1
STAT total_items 2
STAT evictions 0
END
get key
END
stats
...
STAT curr_items 0
STAT total_items 2
STAT evictions 0
END
</code></pre>
<p><a href="http://www.cnblogs.com/UnGeek/p/5136410.html" target="_blank"
   rel="noopener nofollow noreferrer" >memcached-slab内存管理</a></p>
<h2 id="6-memcache服务安装">6 Memcache服务安装</h2>
<h3 id="61-memcached-安装">6.1 Memcached 安装</h3>
<p>Memcached的安装比较简单，支持Memcached的平台常见的有Linux、FreeBSD、Solaris、windows。这里以CentOS 7为例进行讲解。</p>
<h4 id="611-安装libevent及连接memcached工具nc">6.1.1 安装libevent及连接Memcached工具nc</h4>
<p>系统安装环境如下</p>
<pre><code class="language-sh">$ cat /etc/redhat-release 
CentOS Linux release 7.1.1503 (Core) 
$ uname -r
3.10.0-229.el7.x86_64
$ uname -m
x86_64
</code></pre>
<p>安装Memcached前，需要先安装libevent，此处用yum安装libevent。</p>
<pre><code class="language-sh">yum install libevent libevent-devel nc -y
# centos7 nc变更为nmap-ncat
</code></pre>
<h4 id="612-编译安装memcached">6.1.2 编译安装Memcached</h4>
<pre><code class="language-sh">./configure --prefix=/app/memcached
make &amp;&amp; make install
</code></pre>
<p>yum安装的Memcached版本略低，但是不影响使用。</p>
<pre><code class="language-sh"># CentOS 6
$ yum list nc memcached
Loaded plugins: fastestmirror, security
Loading mirror speeds from cached hostfile
Available Packages
memcached.x86_64                	1.4.4-3.el6_8.1                 		 updates
nc.x86_64                        	1.84-24.el6                          base   

# CentOS 7
$ yum list memcached|grep memcached
memcached.x86_64                  1.4.15-10.el7_3.1                    updates
</code></pre>
<h3 id="62-安装memcached客户端">6.2 安装Memcached客户端</h3>
<blockquote>
<p><strong>LAMP PHP环境准备</strong></p>
</blockquote>
<p>这里以PHP虚拟机程序为例，首先要在LAMP环境下能出来phpinfo信息页面，只有这样才能继续操作。具体如图：</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235122992.png" alt="image-20221024235122992" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="621-php扩展插件memcache与memcached">6.2.1 PHP扩展插件Memcache与Memcached</h3>
<p>PHP的Memcached扩展分为两个版本：</p>
<ol>
<li>
<p>memcache 是 pecl 扩展库版本，原生支持php，出现于2004年。</p>
</li>
<li>
<p>memcached 是 libmemcached 版本，出现较后，是新一代，因此也更加完善，推荐使用。</p>
</li>
</ol>
<p>在安装memcache扩展的时候并不要求安装其他依赖，但是在安装memcached的时候会要求你安装libmemcached，问题来了，libmemcached是memcache的C客户端，它具有的优点是低内存，线程安全等特点。比如新浪微博之前就全面将php的memcache替换成php的memcached，在高并发下，稳定性果断提高。差别比较大的一点是，memcached 支持 Binary Protocol，而 memcache 不支持，意味着 memcached 会有更高的性能。不过，还需要注意的是，memcached 目前还不支持长连接。</p>
<p>参考网址：http://blog.wpjam.com/m/memcache-vs-memcached/</p>
<h3 id="622-php-memcache扩展安装">6.2.2 PHP Memcache扩展安装</h3>
<p>php的Memcache的扩展插件下载地址为：http://pecl.php.net/package/memcache</p>
<p>PHP的Memcache客户端扩展插件安装命令如下：</p>
<pre><code class="language-bash">/app/php/bin/phpize
./configure --enable-memcache --with-php-config=/app/php/bin/php-config
make &amp;&amp; make install
</code></pre>
<p>配置Memcache客户端，使其生效</p>
<p>修改PHP的配置文件php.ini，加入Memcache客户端的配置</p>
<pre><code class="language-sh">extension=/app/php-5.5/lib/php/extensions/no-debug-non-zts-20121212/memcache.so
</code></pre>
<p>重启php fpm服务使php的配置修改生效</p>
<pre><code class="language-sh">/app/php/sbin/php-fpm -t
</code></pre>
<p>打开浏览器访问phpinfo页面，出现下图表示Memcache客户端安装成功。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235143724.png" alt="image-20221024235143724" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="622-部署memcached">6.2.2 部署memcached</h4>
<p>PHP Memcached 扩展基于 libmemcached 开发的，使用 libmemcached 库提供的 API 与 Memcached 服务进行交互。顾安装php memcached扩展需要先安装libmemcached</p>
<p>libmemcached下载地址:https://launchpad.net/libmemcached</p>
<blockquote>
<p><strong>安装libmemcached依赖包</strong></p>
</blockquote>
<pre><code class="language-sh">yum install cyrus-sasl-devel -y
</code></pre>
<p>遇到如下错误：</p>
<pre><code class="language-sh">configure: error: no, sasl.h is not available. Run configure with 
--disable-memcached-sasl to disable this check
</code></pre>
<p>解决：需先安装后在编译libmemcached</p>
<pre><code class="language-sh">yum install cyrus-sasl-devel -y
</code></pre>
<p>编译libmemcached：</p>
<pre><code class="language-sh">./configure \
--with-memcached=/usr/local/memcached \
--prefix=/usr/local/libmemcached
</code></pre>
<blockquote>
<p><strong>安装PHP Memcached组件</strong></p>
</blockquote>
<p>下载和解压这步，我们要区分是PHP7还是之前的版本：</p>
<p>下载网址：http://pecl.php.net/package，这里写名3.0版本之后，支持PHP版本为7.0或以上</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235218253.png" alt="image-20221024235218253" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>编译参数</p>
<pre><code class="language-sh">/app/php/bin/phpize
./configure \
--enable-memcached \
--with-php-config=/app/php-5.5/bin/php-config \
--with-libmemcached-dir=/app/libmem-1.0.18/
</code></pre>
<p>配置Memcache客户端，使其生效</p>
<p>修改PHP的配置文件php.ini，加入Memcache客户端的配置</p>
<pre><code class="language-conf">extension=/app/php-5.5/lib/php/extensions/no-debug-non-zts-20121212/memcached.so
</code></pre>
<p>打开浏览器访问phpinfo页面，出现下图表示Memcached组件安装成功。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235234830.png" alt="image-20221024235234830" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<blockquote>
<p><strong>测试Memcache扩展与Memcached扩展</strong></p>
</blockquote>
<ol>
<li><strong>测试Memcache扩展是否成功</strong></li>
</ol>
<pre><code class="language-php">$m = new Memcache();
$m-&gt;connect('127.0.0.1',11211) or die('Could not connect');
$m-&gt;set('key2321','zhangsan');
echo $m-&gt;get('key2321');
</code></pre>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235252036.png" alt="image-20221024235252036" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<ol start="2">
<li><strong>测试Memcached扩展是否成功</strong></li>
</ol>
<pre><code class="language-php">$m = new Memcached();
$m-&gt;addServer('127.0.0.1',11211,40);
$m-&gt;set('ke1','zhangsan2');
echo $m-&gt;get('ke1');
</code></pre>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235304685.png" alt="image-20221024235304685" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<blockquote>
<p><strong>用telnet查询</strong></p>
</blockquote>
<pre><code class="language-sh">$ telnet 127.0.0.1 11211
Trying 127.0.0.1...
Connected to 127.0.0.1.
Escape character is '^]'.
get key2321
VALUE key2321 0 8
zhangsan
END

get ke1
VALUE ke1 0 9
zhangsan2
END
</code></pre>
<p>参考网址：http://www.bcty365.com/content-103-3516-1.html</p>
<h2 id="7-memcached服务的基本管理">7 Memcached服务的基本管理</h2>
<h3 id="71-启动memcached">7.1 启动Memcached</h3>
<p>启动Memcached的命令如下：</p>
<pre><code class="language-sh">$ /home/memcached/bin/memcached -m 16m -p 11211 -d -u root -c 8192
</code></pre>
<p>查看启动状态</p>
<pre><code class="language-sh">$ lsof -i:11211
COMMAND     PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
memcached 16729 root   26u  IPv4 139948      0t0  TCP *:memcache (LISTEN)
memcached 16729 root   27u  IPv6 139949      0t0  TCP *:memcache (LISTEN)
memcached 16729 root   28u  IPv4 139952      0t0  UDP *:memcache 
memcached 16729 root   29u  IPv4 139952      0t0  UDP *:memcache 
memcached 16729 root   30u  IPv4 139952      0t0  UDP *:memcache 
memcached 16729 root   31u  IPv4 139952      0t0  UDP *:memcache 
memcached 16729 root   32u  IPv6 139953      0t0  UDP *:memcache 
memcached 16729 root   33u  IPv6 139953      0t0  UDP *:memcache 
memcached 16729 root   34u  IPv6 139953      0t0  UDP *:memcache 
memcached 16729 root   35u  IPv6 139953      0t0  UDP *:memcache    
</code></pre>
<p>配置ld.so.conf路径防止启动Memcached时报错</p>
<pre><code class="language-sh">echo '/usr/local/lib' &gt;&gt;/etc/ld.so.conf
ldconfig
</code></pre>
<p>启动多个实例</p>
<pre><code class="language-sh">memcached -m 16m -p 11212 -d -uroot -c 8192
</code></pre>
<p>查看结构</p>
<pre><code class="language-sh">$ netstat -lntup
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address    Foreign Address     State       PID/Program name    
tcp        0      0  0.0.0.0:11211     0.0.0.0:*         LISTEN      16729/memcached           
tcp        0      0 0.0.0.0:11212      0.0.0.0:*         LISTEN      16741/memcached                
tcp6       0      0 :::11211           :::*              LISTEN      16729/memcached     
tcp6       0      0 :::11212           :::*              LISTEN      16741/memcached              
udp        0      0 0.0.0.0:11211      0.0.0.0:*                     16729/memcached     
udp        0      0 0.0.0.0:11212      0.0.0.0:*                     16741/memcached     
udp6       0      0 :::11211           :::*                          16729/memcached     
udp6       0      0 :::11212           :::*                          16741/memcached 
</code></pre>
<h3 id="72-memcached启动相关参数说明">7.2 Memcached启动相关参数说明</h3>
<p>表7-1为Memcached启动命令相关参数说明</p>
<table>
<thead>
<tr>
<th style="text-align:center">命令参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
<td><strong>进程与连接参数</strong></td>
</tr>
<tr>
<td style="text-align:center">-d</td>
<td>以守护进程（daemon）方式运行服务</td>
</tr>
<tr>
<td style="text-align:center">-u</td>
<td>指定运行Memcached的用户，如果当前用户为root，需要使用此参数指定用户</td>
</tr>
<tr>
<td style="text-align:center">-l</td>
<td>指定Memcached进程监听的服务器IP地址，可以不设置此参数。</td>
</tr>
<tr>
<td style="text-align:center">-p</td>
<td>指定Memcached服务监听TCP端口号。默认为11211</td>
</tr>
<tr>
<td style="text-align:center">-P</td>
<td>设置Memcached的PID文件（$$），保存PID到指定文件</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td><strong>内存相关设置</strong></td>
</tr>
<tr>
<td style="text-align:center">-m</td>
<td>指定Memcached服务可以缓存数据的最大内存，默认为64M</td>
</tr>
<tr>
<td style="text-align:center">-M</td>
<td>Memcached服务内存不够时禁止LRU，如果内存满了会报错</td>
</tr>
<tr>
<td style="text-align:center">-n</td>
<td>为key+value+flags分配的最小内存空间，默认为48节</td>
</tr>
<tr>
<td style="text-align:center">-f</td>
<td>chunk size增长因子，默认为1.25</td>
</tr>
<tr>
<td style="text-align:center">-L</td>
<td>启用大内存页，可以降低内存浪费，改进性能。</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td><strong>并发连接设置</strong></td>
</tr>
<tr>
<td style="text-align:center">-c</td>
<td>最大的并发连接数，默认是1024</td>
</tr>
<tr>
<td style="text-align:center">-t</td>
<td>线程数，默认4,。由于Memcached采用的是NIO，所以太多线程作用不大</td>
</tr>
<tr>
<td style="text-align:center">-R</td>
<td>每个event的最大请求，默认是20</td>
</tr>
<tr>
<td style="text-align:center">-C</td>
<td>禁用CAS（可以禁止版本计数，减少开销）</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td><strong>调试参数</strong></td>
</tr>
<tr>
<td style="text-align:center">-v</td>
<td>打印较少的errors/warings</td>
</tr>
<tr>
<td style="text-align:center">-vv</td>
<td>打印非常多调试信息和错误输出到控制台，也打印客户端命令及相应</td>
</tr>
<tr>
<td style="text-align:center">-vvv</td>
<td>打印极多的调试信息和错误输出，也打印内部状态转变</td>
</tr>
</tbody>
</table>
<p>更多参数 <strong><code>memcached -h</code></strong></p>
<h3 id="73-向memcached中写入数据并检查">7.3 向Memcached中写入数据。并检查</h3>
<h4 id="731-memcached中的数据形式及与mysql相关语句对比">7.3.1 Memcached中的数据形式及与MySQL相关语句对比</h4>
<p>向Memcached中添加数据时，注意添加的数据一般为键值对的形式，例如：<font color="#f8070d" size=3><code>key1-value1 key2-value2</code></font></p>
<p>这里把Memcached添加、查询、删除等的命令和MySQL数据库做了一个基本类比。见表7-2</p>
<table>
<thead>
<tr>
<th>MySQL数据库管理</th>
<th>Memcached管理</th>
</tr>
</thead>
<tbody>
<tr>
<td>MySQL的insert语句</td>
<td>Memcached的set命令</td>
</tr>
<tr>
<td>MySQL的select语句</td>
<td>Memcached的get命令</td>
</tr>
<tr>
<td>MySQL的delete语句</td>
<td>Memcached的delete命令</td>
</tr>
</tbody>
</table>
<p>管理MySQL和Memcached的常见命令类比</p>
<h4 id="732-向memcached中写入数据实践">7.3.2 向Memcached中写入数据实践</h4>
<p>通过printf配合nc想Memcached中写入数据</p>
<pre><code class="language-bash">$ printf &quot;set key1 0 0 6\r\nzhang\r\n&quot;|nc 127.0.0.1 11211 
$ 
</code></pre>
<p>如果set命令的字节是6就要6个字符（字节）。否则插入数据就不会成功</p>
<pre><code class="language-bash">$ printf &quot;set key1 0 0 6\r\nzhangs\r\n&quot;|nc 127.0.0.1 11211
STORED
</code></pre>
<p>通过printf配合nc从Memcached中读取数据，命令如下：</p>
<pre><code class="language-sh">$ printf &quot;get key1\r\n&quot;|nc 127.0.0.1 11211
VALUE key1 0 6
zhangs # 这就是读到的key1对应额值
END
</code></pre>
<p>通过printf配合nc从Memcached中删除数据</p>
<pre><code class="language-sh">$ printf &quot;delete key1\r\n&quot;|nc 127.0.0.1 11211  
DELETED   #←出现DELETED表示成功删除key1及对应的数据
$ printf &quot;get key1\r\n&quot;|nc 127.0.0.1 11211   
END
</code></pre>
<hr>
<p><strong><font color="#0215cd" size=2> <font color="#f8070d" size=2>⚠</font> 提示：推荐使用上述方法测试操作Memcached
</font></strong></p>
<hr>
<p>通过telnet命令写入数据时，具体步骤如下。</p>
<blockquote>
<p><strong>通过telnet向Memcached写入数据</strong></p>
</blockquote>
<pre><code class="language-sh">$ telnet 127.0.0.1 11211
Trying 127.0.0.1...
Connected to 127.0.0.1.
Escape character is '^]'.
add id 0 0 5	
12345		#← 写入数据
STORED
add id 0 0 3	
123
NOT_STORED	#← 若key存在则报如下错误
set name 0 0 6 	#← 写入数据，如果key不存在则创建key，如果存在则更改key的value值
张三	#← 中文，每个字占3个bytes
STORED
get name
VALUE name 0 6
张三
END
get id
VALUE id 0 5
12345
END
set id 0 0 1	#← 写入数据，如果key不存在则创建key，如果存在则更改key的value值
2
STORED
get id
VALUE id 0 1
2
END
</code></pre>
<blockquote>
<p><strong>incr/decr</strong></p>
</blockquote>
<pre><code class="language-sh">set key 0 0 1
9
STORED
get key
VALUE key 0 1
9
END
incr key 1
10		
get key   
VALUE key 0 2	  #← 对整型增加后对应的bytes也增加
10		
END
get key
VALUE key 0 1
1
END
decr key 1
0
decr key 1
0
</code></pre>
<hr>
<p><strong><font color="#0215cd" size=2> <font color="#f8070d" size=2>⚠</font> 提示：telnet连接后如果输入字符错了，可以通过Ctrl+Backspace删除
</font></strong></p>
<hr>
<h4 id="733-操作memcached相关命令的语法">7.3.3 操作Memcached相关命令的语法</h4>
<p>以下为操作Memcached的相关命令基础语法</p>
<pre><code class="language-sh">set			   key1	  0 	   0		 6
[command name]  [key]  [flags]  [exptime]  [bytes]
[datablock]\r\n
[status]\r\n
</code></pre>
<p>表7-3 Memcached相关命令详细说明</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>command name</td>
<td>set：无论如何都进行写入数据，会覆盖老数据<br>add：只有对应数据不存在时才添加数据<br>repalce：只有数据存在时进行替换数据<br>delete [second] 加秒数之后，被删除的key N秒内不能再用，作用：让网站的页面也代谢完毕<br>append往后追加：prepend[key]datablock[status]?<br>prepend往前追加：prepend[key]datablock[status]<br>cas按版本号更换<br>incr key num  增加一个值的大小。<br>decr key num  减少一个值的大小。<br>incr decr操作将值进行32位无符号计算  0-232-1范围内<br>应用场景，限时秒杀中库存量，先给抢中者分发订单号，数据低谷期将数据写入数据库</td>
</tr>
<tr>
<td>key</td>
<td>普通字符串，要求小于250个字符，不包含空格和控制字符</td>
</tr>
<tr>
<td>flags</td>
<td>客户端用来标识数据格式和数值，如json、xml、压缩、数组等</td>
</tr>
<tr>
<td>exptime</td>
<td>存活时间s，<br/>0为永久有效：编译时默认为30天。<br/>小于30天，60x60x24x30为秒数，<br/>大于30天为unix timestamp 如：团购网站，某团到中午12:00失效。</td>
</tr>
<tr>
<td>bytes</td>
<td>byte字节数，不包含\r\n，根据长度截取存/取的字符串，可以是0，即存空串</td>
</tr>
<tr>
<td>datablock</td>
<td>文本行，以\r\n结尾，当然可以包含\r或\n</td>
</tr>
<tr>
<td>status</td>
<td>STORED/NOT_STORED/EXISTS/NOT_FOUND<br/>ERROR/CLIENT_ERROR/SERVER_ERROR服务器端会关闭连接以修复。</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>事例1：向memcached中插入数据</strong></p>
</blockquote>
<pre><code class="language-sh">add id 0 0 5
12345
STORED
set name 0 0 6
张三
STORED
get name
VALUE name 0 6
张三
END
get id
VALUE id 0 5
12345
END
set id 0 0 1
2
STORED
get id
VALUE id 0 1
2
END
</code></pre>
<h4 id="734-关闭memcached">7.3.4 关闭Memcached</h4>
<blockquote>
<p><strong>单实例关闭Memcached的方法如下</strong>：</p>
</blockquote>
<pre><code class="language-sh">killall memcached 或 pkill
</code></pre>
<p>若启动了多个实例Memcached，使用killall或pkill方式就会同时关闭这些实例！因此最好在启动时增加-P参数指定固定的pid文件，这样便于管理不同的实例。实例如下</p>
<pre><code class="language-sh">memcached -m 16m -p 11211 -d -u root -c 8192 -P /var/run/memcached/11211.pid
memcached -m 16m -p 11211 -d -u root -c 8192 -P /var/run/memcached/11212.pid
</code></pre>
<p>此时，即可以通过kill命令关闭Memcached</p>
<pre><code class="language-sh">kill `cat /var/run/memcached/11211.pid`
</code></pre>
<blockquote>
<p><strong>关闭Memcached的方法小结如下</strong>：</p>
</blockquote>
<pre><code class="language-sh">ps -ef|grep memcached|grep -v grep|awk '{print $2}'|xargs kill
kill `cat /var/run/memcached/11211.pid`
pkill memcached
killall memcached
</code></pre>
<h4 id="735-企业工作场景中如何配置memcached">7.3.5 企业工作场景中如何配置Memcached</h4>
<p>在企业实际工作中，一般是开发人员提出需求，说要不熟一个Memcached数据缓存。运维人员在接到这个不确定的需求后，需要和开发人员深入沟通，进而确定要将内存指定为多大，或者和开发人员商量如何根据具体业务来指定内存缓存的大小。此外，还要确定业务的重要性，进而决定是否采取负载均衡、分布式缓存集群等架构，最后确定使用多大的并发连接数等。</p>
<p>对于运维人员，部署Memcached一般就是安装Memcached服务端，把服务启动起来，最好监控，配好开机自启动，基本上就OK了，客户端的PHP程序环境一般在安装LNMP环境时都会提前安装Memcached客户端插件，Java程序环境下，开发人员会用第三方的JAR包直接连接Memcached服务。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>一致性hash在memcache中的应用</title>
      <link>https://www.oomkill.com/2016/09/consistent-hash/</link>
      <pubDate>Wed, 28 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2016/09/consistent-hash/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="memcache应用场景">Memcache应用场景</h2>
<h3 id="基本场景">基本场景</h3>
<p>比如有 N 台 cache 服务器（后面简称 cache），那么如何将一个对象 object 映射到 N 个 cache 上呢，你很可能会采用类似下面的通用方法计算 object 的 hash 值，然后均匀的映射到到N个cache; <font color="#f8070d" size=3><code>hash(object)%N</code></font></p>
<p>如下图：</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235352996.png" alt="image-20221024235352996" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<blockquote>
<p><strong>这时，一切都运行正常，再考虑如下的两种情况</strong>：</p>
</blockquote>
<p>一个 cache服务器m down掉了（在实际应用中必须要考虑这种情况），这样所有映射到cache m的对象都会失效，怎么办，需要把cache m从cache 中移除，这时候 cache 是 $N-1$ 台，映射公式变成了 <font color="#f8070d" size=3><code>hash(object)%(N-1)</code></font> 。此时数据 $3%3-1=3%2=1$ 此时，3应该在S3上，但是由于S3down机导致到S1去取，这时会未命中。如下图</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235406831.png" alt="image-20221024235406831" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>由于访问加重，需要添加 cache ，这时候 cache 是 $N+1$ 台，映射公式变成了 <font color="#f8070d" size=3><code>hash(object)%(N+1)</code></font> 。1和2意味着突然之间几乎所有的 cache 都失效了。对于服务器而言，这是一场灾难，洪水般的访问都会直接冲向后台服务器。$\frac{N-1} { N\times (N-1)}$</p>
<p><strong>即</strong>：</p>
<p>有N台服务器，变为 $N-1$ 台，即每 $N \times (N-1)$个数中，求余相同的只有 <font color="#f8070d" size=3><code>N-1</code></font> 个。命中率为：$\frac{1}{3}$</p>
<p>再来考虑第三个问题，由于硬件能力越来越强，你可能想让后面添加的节点多做点活，显然上面的 hash 算法也做不到。</p>
<p>有什么方法可以改变这个状况呢，这就是 <font color="#f8070d" size=3>consistent hashing</font>&hellip;</p>
<p>但现在一致性hash算法在分布式系统中也得到了广泛应用，研究过memcached缓存数据库的人都知道，memcached服务器端本身不提供分布式cache的一致性，而是由客户端来提供，具体在计算一致性hash时采用如下步骤：</p>
<ol>
<li>
<p>首先求出memcached服务器（节点）的哈希值，并将其配置到 0～2<sup>32 </sup>的圆（continuum）上。</p>
</li>
<li>
<p>然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。</p>
</li>
<li>
<p>然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过2<sup>32</sup>仍然找不到服务器，就会保存到第一台memcached服务器上。</p>
</li>
</ol>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235424248.png" alt="image-20221024235424248" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>从上图的状态中添加一台memcached服务器。余数分布式算法由于保存键的服务器会发生巨大变化而影响缓存的命中率，但Consistent Hashing中，只有在圆（continuum）上增加服务器的地点逆时针方向的第一台服务器上的键会受到影响，如下图所示：</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235424248.png" alt="image-20221024235424248" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。</p>
<h2 id="consistent-hash原理">consistent hash原理</h2>
<h3 id="基本概念">基本概念</h3>
<p>一致性哈希算法（Consistent Hashing）最早在论文《Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web》中被提出。简单来说，一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为 <font color="#f8070d" size=3>0-2<sup>32</sup>-1</font>（即哈希值是一个32位无符号整形），整个哈希空间环如下：</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235550927.png" alt="image-20221024235550927" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>整个空间按顺时针方向组织。0和2<sup>32</sup>-1在零点中方向重合。</p>
<p>下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中四台服务器使用ip地址哈希后在环空间的位置如下：</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235605237.png" alt="image-20221024235605237" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。</p>
<p>例如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下：</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235630275.png" alt="image-20221024235630275" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>根据一致性哈希算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。</p>
<p>下面分析一致性哈希算法的容错性和可扩展性。现假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。如下图所示：</p>
<p>下面考虑另外一种情况，如果在系统中增加一台服务器Node X，如下图所示：</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235642951.png" alt="image-20221024235642951" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X 。一般的，在一致性哈希算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。</p>
<p>综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。</p>
<p>另外，一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。例如系统中只有两台服务器，其环分布如下：</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235702564.png" alt="image-20221024235702564" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性哈希算法引入了<font style="background:#ffc104;" size=2>虚拟节点机制</font>，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器ip或主机名的后面增加编号来实现。例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 <font color="#f8070d" size=3><code>Node A#1</code></font>  <font color="#f8070d" size=3><code>Node A#2</code></font>  <font color="#f8070d" size=3><code>Node A#3</code></font>  <font color="#f8070d" size=3><code>Node B#1</code></font>  <font color="#f8070d" size=3><code>Node B#2</code></font>  <font color="#f8070d" size=3><code>Node B#3</code></font> 的哈希值，于是形成六个虚拟节点：</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235718095.png" alt="image-20221024235718095" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到<font color="#f8070d" size=3><code>Node A#1</code></font>  <font color="#f8070d" size=3><code>Node A#2</code></font>  <font color="#f8070d" size=3><code>Node A#3</code></font> 三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为**==32==**甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。</p>
<p>参考: <a href="http://www.cnblogs.com/haippy/archive/2011/12/10/2282943.html" target="_blank"
   rel="noopener nofollow noreferrer" >http://www.cnblogs.com/haippy/archive/2011/12/10/2282943.html</a></p>
<h2 id="一致性hashconsistent-hash在php中使用">一致性hash（consistent hash）在PHP中使用</h2>
<pre><code class="language-php">&lt;?php 
	class ConsistentHash
	{
		public $nodes = array();
		
		public function __construct(){
			
		}
  
		public function generateHash($str){
			return sprintf('%u',crc32($str));
		}
		
		public function findNode(){
			
		}
  
		public function lookup($key){
			$tmp = $this-&gt;generateHash($key);
			$node = current($this-&gt;nodes);
			foreach($this-&gt;nodes as $key=&gt;$val){
				if( $tmp &lt;= $key ){
					$node = $val;
					break;
				}
			}
			return $node;
		}
		
		public function getNode(){
			var_dump($this-&gt;nodes);
		}
		
		public function addNode($node){
			$this-&gt;nodes[$this-&gt;generateHash($node)] = $node;
			ksort($this-&gt;nodes);
		}	
	}
	
	$hash = new ConsistentHash;
	$hash-&gt;addNode('192.168.2.80:11211');
	$hash-&gt;addNode('192.168.2.80:11212');
	$hash-&gt;addNode('192.168.2.80:11213');
	echo '&lt;hr&gt;&lt;br&gt;';
	$hash-&gt;getNode();
	echo '&lt;br&gt;';
	echo $hash-&gt;generateHash('zhangsan'),'&lt;br&gt;';
	echo $hash-&gt;lookup('zhangsan'),'&lt;br&gt;';
?&gt;
</code></pre>
<p>执行结果</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235759078.png" alt="image-20221024235759078" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235812368.png" alt="image-20221024235812368" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>这时可以看出，数据倾斜问题。</p>
<p>创建虚拟节点，解决数据倾斜问题</p>
<pre><code class="language-php">&lt;?php 
	class ConsistentHash{
		public $nodes = array();
		protected $num = 0;
		protected $priNode = array();
		
		public function __construct($nodeNum){
			$this-&gt;num = $nodeNum;
		}
		
    public function generateHash($str){
			return sprintf('%u',crc32($str));
		}
		
		public function selectNode($key){
			$tmp = $this-&gt;generateHash($key);
			$node = current($this-&gt;nodes);  # 选择最小的节点作为默认值
			foreach($this-&gt;priNode as $key=&gt;$val){
				if( $tmp &lt;= $key ){
					$node = $val;
					break;
				}
			}
			return $node;
		}
		
		public function getNode(){
			var_dump($this-&gt;nodes);
			var_dump($this-&gt;priNode);
		}
		
		public function addNode($node){	
			for($n=0;$n&lt;$this-&gt;num;$n++){
				$this-&gt;priNode[$this-&gt;generateHash($node.'_'.$n)] = $node;
			}
			$this-&gt;nodes[$this-&gt;generateHash($node)] = $node;
			ksort($this-&gt;priNode);
		}	
	}
	
	$hash = new ConsistentHash(32);
	$hash-&gt;addNode('192.168.2.80:11211');
	$hash-&gt;addNode('192.168.2.80:11212');
	$hash-&gt;addNode('192.168.2.80:11213');
	$hash-&gt;getNode();
	echo '&lt;br&gt;';
	echo $hash-&gt;generateHash('zhangsan'),'&lt;br&gt;';
	echo $hash-&gt;generateHash('lisi'),'&lt;br&gt;';
	echo $hash-&gt;lookup('zhangsan'),'&lt;br&gt;';
	echo $hash-&gt;lookup('lisi'),'&lt;br&gt;';
	echo $hash-&gt;generateHash('wangwu'),'&lt;br&gt;';
	echo $hash-&gt;lookup('wangwu'),'&lt;br&gt;';
?&gt;
</code></pre>
<p>此时自动分配的节点为</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235829164.png" alt="image-20221024235829164" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>可看出6E-8E存在11211上，大于。35.7E-35.9E存在11212上</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235847363.png" alt="image-20221024235847363" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235855512.png" alt="image-20221024235855512" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h2 id="一致性hash与取模命中率的对比实验">一致性hash与取模命中率的对比实验</h2>
<p><a href="../../../images%5cdring.rar">dring.rar</a></p>
<h3 id="实验目的">实验目的</h3>
<p>测试Memcached缓存服务器有N台变为N-台时，取模和consistent hasing算法的命中率</p>
<h3 id="实验原理">实验原理</h3>
<p>相同的硬件环境、操作系统、数据缓存环境，5个memcached节点，用两种分布式算法建立缓存，缓存命中率稳定后，减少1个节点，观察命中率的变化，知道命中率在次稳定。</p>
<h3 id="前端软件架构">前端软件架构</h3>
<pre><code class="language-sh">config.php 		#←配置memcached节点信息
hash.php 	 	#←分布式算法
init.php 		#←初始化数据
exec.php 		#←减少节点后请求数据
stat.php		#←统计平均命中率
index.html 		#←生成动态图表
</code></pre>
<h3 id="取模算法的实验">取模算法的实验</h3>
<p>当5台缓存服务器全部正常的情况下，此时的命中率统计图如下：</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235917083.png" alt="image-20221024235917083" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<blockquote>
<p><strong>这是查看5台缓存服务器的查询与命中次数如下</strong>：</p>
</blockquote>
<pre><code class="language-sh">$ for n in {1..5};do printf &quot;stats\r\n&quot;|nc 127.0.0.1 1121$n|egrep 'get_hits|cmd_get'; done
STAT cmd_get 0
STAT get_hits 0
STAT cmd_get 0
STAT get_hits 0
STAT cmd_get 0
STAT get_hits 0
STAT cmd_get 0
STAT get_hits 0
STAT cmd_get 0
STAT get_hits 0
$ for n in {1..5};do printf &quot;stats\r\n&quot;|nc 127.0.0.1 1121$n|grep item; done
STAT curr_items 2044
STAT total_items 2044
STAT curr_items 1983
STAT total_items 1983
STAT curr_items 1993
STAT total_items 1993
STAT curr_items 2001
STAT total_items 2001
STAT curr_items 1979
STAT total_items 1979
</code></pre>
<p>这时断掉一台缓存服务器，此时的命中率从100%瞬间降至8%。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235932558.png" alt="image-20221024235932558" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>运行一段时间后，可见命中率保持20%左右，在预热完毕后，逐步上升。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221024235950143.png" alt="image-20221024235950143" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>此时查看5台缓存服务器的查询次数与命中次数，发现已经很均匀了。</p>
<pre><code class="language-sh">$ for n in {1..5};do printf &quot;stats\r\n&quot;|nc 127.0.0.1 1121$n|egrep 'get_hits|cmd_get'; done
STAT cmd_get 0
STAT get_hits 0
STAT cmd_get 8481
STAT get_hits 6465
STAT cmd_get 8482
STAT get_hits 6476
STAT cmd_get 8482
STAT get_hits 6504
STAT cmd_get 8483
STAT get_hits 6478
</code></pre>
<p>经过较长时间后，可以看到命中率已经很平稳了</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221025000013472.png" alt="image-20221025000013472" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="一致性hash算法命中率实验">一致性hash算法命中率实验</h3>
<p>模拟出正常情况下，5台缓存服务器的命中率</p>
<pre><code class="language-sh">$ for n in {1..5};do printf &quot;stats\r\n&quot;|nc 127.0.0.1 1121$n|egrep 'get_hits|cmd_get'; done
STAT cmd_get 0
STAT get_hits 0
STAT cmd_get 0
STAT get_hits 0
STAT cmd_get 0
STAT get_hits 0
STAT cmd_get 0
STAT get_hits 0
STAT cmd_get 0
STAT get_hits 0

$ for n in {1..5};do printf &quot;stats\r\n&quot;|nc 127.0.0.1 1121$n|grep item; done
STAT curr_items 999
STAT total_items 999
STAT curr_items 1005
STAT total_items 1005
STAT curr_items 6005
STAT total_items 6005
STAT curr_items 998
STAT total_items 998
STAT curr_items 993
STAT total_items 993
</code></pre>
<p>此时断开1台服务器，可以见到命中率下降到73%就稳定了。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221025000031883.png" alt="image-20221025000031883" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>观察一段时间后命中率逐步上升到95%</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221025000050675.png" alt="image-20221025000050675" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h2 id="在实战中会存在的问题">在实战中会存在的问题</h2>
<p>缓存雪崩的现象</p>
<p>一般是由于某个节点生效，导致其他节点的缓存命中率下降，缓存中缺失的数据去数据可查询。短时间内造成数据库服务器崩溃。或，由于缓存周期性的输小，如：6小时失效一次，那么每6小时，将有一个请求““峰值”，严重情况下会导致数据库宕机。</p>
<p>建议解决方案：</p>
<ul>
<li>将缓存的生命周期设置为随机的时间短（如4-10）小时，这样缓存不同时失效，把工作分担到各个时间点上。</li>
<li>可在夜间缓慢建立一部分缓存</li>
<li>可建立多个缓存交叉使用，做好镜像，将多个缓存失效时间错开。</li>
</ul>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
