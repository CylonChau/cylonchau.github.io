<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Cicd on Cylon&#39;s Collection</title>
    <link>http://localhost:1313/tags/cicd/</link>
    <description>Recent content in Cicd on Cylon&#39;s Collection</description>
    <generator>Hugo -- 0.125.7</generator>
    <language>zh</language>
    <lastBuildDate>Sun, 05 Nov 2023 23:00:36 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/cicd/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Spinnaker 基于判断的条件分支流水线</title>
      <link>http://localhost:1313/2024/07/spinnaker-branching-judgment/</link>
      <pubDate>Sat, 27 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2024/07/spinnaker-branching-judgment/</guid>
      <description>Manual Judgment Stage “Manual Judgment Stage” 是 Spinnaker Pipeline 中的一种阶段 (&amp;ldquo;Stage&amp;rdquo;) 类型，该类型可以作为流水线的门户，作为带外 (Out-of-Bound) 流水线检查，等待手动检查，并且判断结果会终止或继续流水线的执行。
创建一个基于Manual Judgment的流水线 创建一个流水线，添加一个新的 Stage，选择 “Manual Judgment”
图：Manual Judgment创建页面 Jugement Inputs 部分添加对应的选项，选项可以带入变量 $judgment 中
图：Manual Judgment 在执行时 Jugement Inputs Option 的展示 或者是不添加任何选项，那么这个时候就会只有 Stop 和 Continue 两个按钮
图：当 Manual Judgment 没有配置Jugement Inputs Option 的展示 如果添加了选项，可以根据 “选项” 来判断执行的分支
判断可以使用每个阶段内的条件表达式 ”Conditional on Expression“，或者 Check Precondition 类型的阶段
图：根据 “Stage Conditional on Expression” 来定义的选项 “Check Precondition” 是 Spinnaker 流水线中的一个阶段，它可以先前条件并且判断是否继续，这里主要检查该流水线之前所有的流水线你定义要检查的内容，并继续执行接下分支或者阶段
图：“Check Precondition” 的三种类型 图：“Check Precondition” 选择添加表达式的页面 这里选择使用 表达式 (Expression) 来判断前置条件，例如我判断前置 Stage 的选择是否为 “aaaa”</description>
    </item>
    <item>
      <title>Spinnaker 自定义Pipeline模板思路</title>
      <link>http://localhost:1313/2024/07/spinnaker-custom-template/</link>
      <pubDate>Sat, 27 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2024/07/spinnaker-custom-template/</guid>
      <description>流水线模板组合思路 官方流水线示例中没有给出完整的流水线模板和完整的字段，只给出了一个大致的 schema [1]，如下所示
json 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 { &amp;#34;schema&amp;#34;: &amp;#34;v2&amp;#34;, &amp;#34;variables&amp;#34;: [ { &amp;#34;type&amp;#34;: &amp;#34;&amp;lt;type&amp;gt;&amp;#34;, &amp;#34;defaultValue&amp;#34;: &amp;lt;value&amp;gt;, &amp;#34;description&amp;#34;: &amp;#34;&amp;lt;description&amp;gt;&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;&amp;lt;varName&amp;gt;&amp;#34; } ], &amp;#34;id&amp;#34;: &amp;#34;&amp;lt;templateName&amp;gt;&amp;#34;, # The pipeline instance references the template using this &amp;#34;protect&amp;#34;: &amp;lt;true | false&amp;gt;, &amp;#34;metadata&amp;#34;: { &amp;#34;name&amp;#34;: &amp;#34;displayName&amp;#34;, # The display name shown in Deck &amp;#34;description&amp;#34;: &amp;#34;&amp;lt;description&amp;gt;&amp;#34;, &amp;#34;owner&amp;#34;: &amp;#34;example@example.</description>
    </item>
    <item>
      <title>使用Spinnaker进行金丝雀分析</title>
      <link>http://localhost:1313/2023/12/spinnaker-canary/</link>
      <pubDate>Wed, 13 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2023/12/spinnaker-canary/</guid>
      <description>2018 年，Kayenta（一种用于自动化金丝雀分析的开源工具）作为 Spinnaker 项目的一部分推出。在本文中，我们描述了如何将 Kayenta 集成到我们现有的部署设施中，极大地提高了部署管道的可靠性并为自动化生产部署创造了先决条件。
概念理解 什么是金丝雀分析？ 金丝雀分析 (canary analysis) 是一个两步的过程，分析将根据选定的指标和日志评估金丝雀，以推断我们是否要升级或回滚新版本。因此，我们需要确保在测试过程中收集正确的信息（指标和日志）并进行可靠的分析。
金丝雀分析的执行步骤 指标选择 指标评估 指标选择 该步骤涉及选择正确的指标来监控应用程序和金丝雀健康状况。因此我们需要确保创建一套平衡的指标来评估指标。最后，需要根据彼此的相关性对指标进行分组。
对于指标的选择，根本不需要选择所有指标，因为目前流行的基于微服务的应用程序通常会生成大量监控指标数据，因此我们不能简单地分析所有指标。
指标评估标准 选择重要的业务指标 最重要的指标是值对 可以反应服务 “成功/失败” 最重要的指标。例如，在在线购物结帐系统中，一定要测量每分钟的交易次数、失败率等。如果这些指标中的任何一个超出基线，您可能会决定回滚金丝雀。再例如，可以检测服务的数据库连接状态，初始化状态等指标，一旦指标超出基线则表示服务异常，这时候需要回滚。
平衡一组慢速与快速指标 一个有意义的金丝雀流程来说，单个指标是不够的。一些要监控的重要指标是立即生成的，而另一些则需要一些时间才能生成，因为它们依赖于负载，网络流量，高内存使用率或其他因素。在快速指标和慢速指标之间平衡您选择的指标非常重要。例如，服务器查询时间和延迟检查可以分别是慢度量和快度量的示例。因此选择一组平衡的指标，是对金丝雀的健康状况有全面的了解。
冒烟测试 从平衡组测试中，我们必须确保我们拥有直接表明金丝雀中存在问题的指标。所以冒烟测试很适合在这里使用，尽管我们的目标是找出金丝雀的健康状况，但使用此类指标找出金丝雀是否存在潜在问题也同样重要。例如，404 响应或其他意外的 HTTP 返回代码（200 秒、300 秒）可能意味着您的测试应立即停止并进行调试。CPU 使用率、内存占用、HTTP 响应码（200 秒、300 秒等）、响应延迟、正确性是一组很好的指标，但 HTTP 返回代码和响应延迟表明影响用户和服务的实际问题。
metrics 标准范围 这些公制选择需要有一个可接受的发挥范围，通过商定的可接受的指标行为，这样将能够消除那些被错误评估为好金丝雀的坏金丝雀。
金丝雀判断 执行金丝雀分析的最后一步是评估指标的值。通过这个步骤，将能够评估金丝雀实例是否应该升级到生产环境。
在提出每个假设之前，我们将定义两个假设，并根据我们的数据证明其中一个假设是错误的。
Unacceptable：回滚 Acceptable：部署到生产 Kayenta 比较两个时间序列，并在偏差超过某个阈值时发出警报。作为这些应用程序指标的来源，我们使用 New Relic Insights。对于这个后端，我们还将代码作为开源代码贡献给Kayenta ³。还可以支持其他后端（Datadog、Prometheus 等）。有关自动金丝雀分析的一般信息，请参阅Google和Netflix的优秀文章。
Reference [1] Install Halyard on Docker
[2] ERROR Could not load &amp;ldquo;versions.yml&amp;rdquo; from config bucket: 403 #3920</description>
    </item>
    <item>
      <title>初识Argo cd - 注册/删除k8s集群</title>
      <link>http://localhost:1313/2023/11/ch03-argo-add-cluster/</link>
      <pubDate>Sun, 05 Nov 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2023/11/ch03-argo-add-cluster/</guid>
      <description>登录argo cd bash 1 argocd login argocd_server:argocd_port_here 执行后输入admin/sercert
bash 1 2 3 4 5 6 $ argocd login 10.0.0.5:30908 WARNING: server certificate had error: x509: cannot validate certificate for 10.0.0.5 because it doesn&amp;#39;t contain any IP SANs. Proceed insecurely (y/n)? y Username: admin Password: &amp;#39;admin:login&amp;#39; logged in successfully Context &amp;#39;10.0.0.5:30908&amp;#39; updated argocd cli 登录后的文件保存在 ~/.argocd/config 中
注册一个新集群 argocd 通过 kubectl 来获取集群的信息，所以 argocd 的主机上必须有 kubeconfig 文件
Note: KUBECONFIG 文件地址必须为实际路径，比如 ~/ 这种方式不可以</description>
    </item>
    <item>
      <title>深入Argo - Application resources</title>
      <link>http://localhost:1313/2023/11/ch04-application/</link>
      <pubDate>Sun, 05 Nov 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2023/11/ch04-application/</guid>
      <description>在安装和注册集群完成后，就需要引入第一个概念 “Application”（如何管理所有我的应用程序？）
什么是 Application 什么是 ArgoCD “Application”？ 对于 ArgoCD “Application”的快速解释：它是托管 ArgoCD 部署的 Kubernetes 集群 CRD 包含了应用程序的所有设置，如：
要部署到哪个集群？ 与哪个 Git 存储库进行同步？ 其他部署设置 应用程序的 YAML 包含了部署您的存储库资源所需的所有信息，充当了在 ArgoCD 中管理应用程序的关键控制点。
Reference [1] docs/operator-manual/argocd-cm.yaml
[2] Getting started with multi-cluster K8S deployments using Argo CD
[3] https://medium.com/notive/managing-argocd-application-resources-1b2b4742ab90</description>
    </item>
    <item>
      <title>初识Argo cd - 在k8s集群上安装argo cd</title>
      <link>http://localhost:1313/2023/10/argo-installtion/</link>
      <pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2023/10/argo-installtion/</guid>
      <description>GitOps 最初由 Weaveworks (weave cni的组织) 在 2017 年的博客中提出 [1]，使用 “Git” 作为 CI/CD 的 “单一事实来源”，将代码的更改集成到每个项目的存储库中，并使用拉取请求来管理 infra 和部署。 在理解上就可以理解为 “是一种基于 git 的操作框架”
Argo CD 是一种 kubernetes 之上的 “声明式” (declarative) 的 gitops CD， 在本文作为了解如何在 Kubernetes 集群中安装和配置 Argo CD。
前提准备 想要安装 Argo CD 首先环境需要具备如下：
已经安装好 kubectl 命令行工具 拥有 kubeconfig 文件 一个可供测试的 Kubernetes 集群，如：kind, minikube, kubeadm, binary 等任意的集群 步骤1 - 选择适配 kubernetes 版本的 Argo 根据官方的解释， Argo CD 在任何给定时刻所支持的版本，这些版本是 N 和 N - 1 次要版本的最新修补版本 (x.x.new)。这些 Argo CD 版本与 Kubernetes 项目官方支持的 Kubernetes 版本相一致，通常是 Kubernetes 的最近发布的 3 个版本。</description>
    </item>
    <item>
      <title>初识Argo cd - argo cd架构</title>
      <link>http://localhost:1313/2023/10/ch01-argo-beginning/</link>
      <pubDate>Sun, 22 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2023/10/ch01-argo-beginning/</guid>
      <description>Argo组件 API Server Repository Server Application Controller API Server：一个 gRPC/REST 服务器，提供了 “Web UI”、“CLI” 和 “CI/CD” 使用的 API
应用管理和状态报告 调用应用操作（例如同步、回滚、用户定义的操作） 存储库和 Cluster credential 管理（作为 kubernetes secret 存储） 为外部提供身份认证和代理授权功能 RBAC 试试 Git webhook 事件的 listener/forwarder Repository Server：内部服务，用于维护 git 中的应用清单 (manifests) 的本地缓存。负责接收生成和返回 kubernetes 清单
仓库URL revision (commit, tag, branch) APP PATH 模板特定的参数 Application Controller：Kubernetes controller，主要做的工作是持续监控运行的 Application，并于当前实时状态和目标所需状态进行对比（与 Kubernetes Controller 功能是相同的），并且不仅仅是 KC 还会和存储库中指定目标状态进行比较，检测到 OutOfSync 状态将进行纠正。
Argo 架构 Argo CD 时最常见的三种架构：单实例方案, 集群级方案，以及折衷方案 (compromise between the two)。</description>
    </item>
    <item>
      <title>无互联网环境下安装Spinnaker - Offline Install Spinnaker</title>
      <link>http://localhost:1313/2023/07/offline-installtation/</link>
      <pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2023/07/offline-installtation/</guid>
      <description>Prerequisites 具有一个 Kubernetes 集群 以部署 Spinnaker 可运行 Docker 的环境 (1 vCPU, 3.75 GB) 或者是 Ubuntu，用以安装 Halyard (用于 spinnaker 的服务) 对象存储 (MinIO)，用于持久化 Spinnaker 的数据 对象存储的 Bucket 的访问账号 安装执行步骤 安装 Halyard 可以直接使用 Docker 方式安装，这个没什么必要性，就是管理工具而已，参考附录1 [1]
首先创建映射目录
bash 1 2 mkdir ~/.hal -pv mkdir ~/.kubeconfig -pv 然后执行 docker run 运行容器
bash 1 2 3 4 5 6 7 docker run -d -p 8084:8084 -p 9000:9000 \ --name halyard --rm \ -v ~/.hal:/home/spinnaker/.hal \ -v ~/.</description>
    </item>
    <item>
      <title>jenkins pipline demo</title>
      <link>http://localhost:1313/2019/10/jenkins-pipline-demo/</link>
      <pubDate>Wed, 02 Oct 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2019/10/jenkins-pipline-demo/</guid>
      <description>pipline demo https://jenkins.io/zh/doc/book/pipeline/syntax/ git 插件 https://jenkins.io/doc/pipeline/steps/git/ pipline pipeline{agent anystages{stage(&amp;#34;build&amp;#34;){steps{echo &amp;#34;11111&amp;#34;}}}} pipeline总体介绍 基本结构
以下每一个部分都是必须的，少一个Jenkins都会报错
pipline pipeline{agent anystages{stage(&amp;#34;build&amp;#34;){steps{echo &amp;#34;hellp&amp;#34;}}}} pipeline 代表整个流水线，包含整条流水线的逻辑 stage 阶段，代表流水线的阶段，每个阶段都必须有名称。 stages 流水线中多个stage的容器，stages部分至少包含一个stage. steps 代表stage中的一个活多个具体步骤的容器，steps部分至少包含一个步骤 agent 制定流水线的执行位置，流水线中每个阶段都必须在某个地方执行（master节点/slave节点/物理机/虚拟机/docker容器），agent部分指定具体在哪里执行。agent { label &#39;***-slave&#39;} 可选步骤
post 包含的是在整个pipeline或stage完成后的附件条件
always 论Pipeline运行的完成状态如何都会执行这段代码 changes 只有当前Pipeline运行的状态与先前完成的Pipeline的状态不同时，才能触发运行。 failure 当前状态为失败时执行 success 当前完成状态为成功时执行 demo
使用${test}，可以引入自定义变量
pipeline post {always {script {allure includeProperties: false, jdk: &amp;#39;&amp;#39;,report: &amp;#39;jenkins-allure-report&amp;#39;, results: [[path: &amp;#39;allure-results&amp;#39;]] }}failure {script {if (gitpuller == &amp;#39;noerr&amp;#39;) {mail to: &amp;#34;${email_list}&amp;#34;,subject: &amp;#34;[jenkins Build Notification] ${JOB_NAME} - Build # ${BUILD_NUMBER} 构建失败&amp;#34;,body: &amp;#34;&amp;#39;${env.</description>
    </item>
    <item>
      <title>jenkins的用户授权与管理</title>
      <link>http://localhost:1313/2019/10/jenkins-user-authentication/</link>
      <pubDate>Wed, 02 Oct 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2019/10/jenkins-user-authentication/</guid>
      <description>需要安装的插件 Role-Based Strategy（可以对构建的项目进行授权管理，让不同的用户管理不同的项目，将测试和生产环境分开）
选择授权策略 当Role-based Authorization Strategy 这个插件安装好之后，授权策略会多出一个Role-Based Strategy 选项，选择此项
添加配置权限 系统设置 &amp;raquo; Manage and Assign Roles
Manage Roles 设置全局角色（全局角色可以对jenkins系统进行设置与项目的操作）
admin:对整个jenkins都可以进行操作 root:可以对所有的job进行管理 other:只有读的权限 other必须有，否则给用户分配角色时分配没有全局role会导致分配失效 Assign Roles为用户指派角色 项目角色是根据正则匹配的，</description>
    </item>
    <item>
      <title>jenkins历史比较</title>
      <link>http://localhost:1313/2019/10/jenkins-recode-history/</link>
      <pubDate>Wed, 02 Oct 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2019/10/jenkins-recode-history/</guid>
      <description>文中的代码来自可以从github下载： https://github.com/ciandcd
插件 jobConfigHistory，可以查看job配置的修改历史。
安装后重启jenkins，然后对job的配置修改后，可以点击job config history连接查看修改历史。
选择需要比较的版本，可以diff两个版本间的差别。</description>
    </item>
    <item>
      <title>jenkins在Mac OS下的迁移记录</title>
      <link>http://localhost:1313/2019/10/jenkens-migrant-in-macos/</link>
      <pubDate>Wed, 02 Oct 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2019/10/jenkens-migrant-in-macos/</guid>
      <description>修改启动用户
先停止jenkins服务
sh 1 2 sudo launchctl unload /Library/LaunchDaemons/org.jenkins-ci.plist sudo vim /Library/LaunchDaemons/org.jenkins-ci.plist 授权jenkins工作目录和临时目录
text 1 2 sudo chown -R zhulangren:wheel /Users/Shared/Jenkins/ sudo chown -R zhulangren:wheel /var/log/jenkins/ 启动jenkins
text 1 sudo launchctl load /Library/LaunchDaemons/org.jenkins-ci.plist jenkins自启动文件路径
text 1 /Library/LaunchDaemons/org.jenkins-ci.plist 卸载脚本文件
text 1 /Library/Application\ Support/Jenkins/Uninstall.command 修改jenkins启动端口
text 1 sudo defaults write /Library/Preferences/org.jenkins-ci httpPort &amp;#39;9999&amp;#39; 读取jenkins配置文件
text 1 defaults read /Library/Preferences/org.jenkins-ci 设置自启动
text 1 sudo launchctl load /Library/LaunchDaemons/org.jenkins-ci.plis 取消自启动
text 1 sudo launchctl unload /Library/LaunchDaemons/org.</description>
    </item>
    <item>
      <title>jenkins pipeline docker方式</title>
      <link>http://localhost:1313/2018/11/jenkins-docker/</link>
      <pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2018/11/jenkins-docker/</guid>
      <description>pipline def timestr() { script { return sh(script: &amp;#39;date +%Y%m%d%H%M%S&amp;#39;, returnStdout: true).trim()}}def dockerImagepipeline{agent anyenvironment {time = timestr()registry = &amp;#34;xxx.com/payapp-test&amp;#34;registryhub = &amp;#34;txhub.xxx.com&amp;#34;appName = &amp;#34;api&amp;#34;}options {timeout(time: 1, unit: &amp;#39;HOURS&amp;#39;)buildDiscarder(logRotator(numToKeepStr: &amp;#39;15&amp;#39;))disableConcurrentBuilds()}stages{stage(&amp;#34;Pull Code&amp;#34;){steps{git branch: &amp;#39;testing&amp;#39;, credentialsId: &amp;#39;422fb2c7-4d58-440a-98a4-e242b66f3800&amp;#39;, url: &amp;#39;http://gitlab.fgry45iy.com:90/pay/payGateway.git&amp;#39;}}stage(&amp;#34;Maven Package&amp;#34;){steps{withEnv([&amp;#39;PATH+EXTRA=/usr/local/sbin:/sbin:/bin:/usr/sbin:/usr/bin:/usr/local/apache-maven-3.6.2/bin:/usr/local/maven/bin:/root/bin&amp;#39;]) {sh &amp;#34;mvn package&amp;#34;}}}// stage(&amp;#39;Building Image&amp;#39;) {// steps{// script {// dockerImage = docker.</description>
    </item>
    <item>
      <title>Jenkins在windows平台自动化构建代码</title>
      <link>http://localhost:1313/2018/10/jenkins-in-windows/</link>
      <pubDate>Tue, 02 Oct 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2018/10/jenkins-in-windows/</guid>
      <description>Jenkins服务端：centos6.8
客户端：windows server2012 windows10
工具：cwRsync
注：复制为jenkins工作目录到网站目录，无需服务端。
配置安装slave端 所用的插件：Copy Data To Workspace Plugin
配置windows节点 \1. 主界面-&amp;gt;【系统管理】-&amp;gt;【管理节点】-&amp;gt;【新建节点】，进行节点的添加：
\2. 输入节点名称，选择【Permanent Agent】。如果添加过slave的话会出现【复制现有节点】操作
\3. 配置节点的详细信息
此处配置需要注意的有以下几个方面
【# of executors】：建议不要超过CPU核心数，一般不要写特别大。
【远程工作目录】：master将代码库中的代码复制到slave时，存放的临时目录，如slave的daemon服务也会放在此目录。一个job一个文件夹。
【用法】：选择【只允许运行绑定到这台机器的Job】，此模式下，Jenkins只会构建哪些分配到这台机器的Job。这允许一个节点专门保留给某种类型的Job。例如，在Jenkins上连续的执行测试，你可以设置执行者数量为1，那么同一时间就只会有一个构建，一个实行者不会阻止其它构建，其它构建会在另外的节点运行。
【启动方式】：选择【Launch agent via Java Web Start】，以windows服务的方式启动，这个为最好配置的。注意：2.x版本的默认没有这个选项，需要单独开启。
\4. 配置slave端并且添加至windows服务
在点击保存后，在node列表中会存在此列表默认是未连通状态
点击进入详情页面会提示slave端的安装方法，此处讲解下载文件方式。
【Launch】：浏览器下载文件方式
【Run from agent command line】：从远端代理命令运行
注意：这是java服务，每个slave端必须安装jdk后才可运行。
xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 &amp;lt;jnlp codebase=&amp;#34;http://10.0.0.11:8080/jenkins/computer/test/&amp;#34; spec=&amp;#34;1.0+&amp;#34;&amp;gt; &amp;lt;information&amp;gt; &amp;lt;title&amp;gt;Agent for test&amp;lt;/title&amp;gt; &amp;lt;vendor&amp;gt;Jenkins project&amp;lt;/vendor&amp;gt; &amp;lt;homepage href=&amp;#34;https://jenkins-ci.</description>
    </item>
    <item>
      <title>jenkins多个slave遇到的坑</title>
      <link>http://localhost:1313/2018/05/jenkins-multi-slave-problem/</link>
      <pubDate>Wed, 02 May 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2018/05/jenkins-multi-slave-problem/</guid>
      <description>jenkins配置如下 在Jenkins上添加了两个节点(Slave Node)，且为这两个节点设置了一个相同的标签 &amp;ldquo;windows&amp;rdquo;。创建了一个新Job – &amp;ldquo;test-windows&amp;rdquo;，选择的是”构建一个自由风格的软件项目”。并且为了使多个slave并行构建，我选择了&amp;quot;只允许绑定到这台机器的job”，在&amp;quot;Label Expression&amp;quot;中选择了&amp;quot;windows&amp;quot;。
然而这种方式并不能实现多个slave并行操作。网上90%说的都不靠谱。
在我使用的过程中，使用了label 去管理多个 Slave，给一个项目的构建指定了这个 label，会发现这个项目的多次构建，都使用同一个 Slave，并没有使用 label 里的其它 Slave去构建。
查了很多资料才发现原来从 jenkins 的调度算法使用了一致性的哈希算法，jenkins根据添加的信息评测出优先级列表，选择优先级最高的Slave去构建，当最优slave不满足条件或者没有可用的 execut时，才会选用下一个slave。
查了很多资料发现构造多配置项目可以选择构建时的slave。这样可以实现多slave并行构建。
multi configuration project比起构建自由风格的软件项目多个Configuration Matrix，在这里可以选择多个slave。这里选择lable的话，还是会使用默认算法从lable中选择最优slave进行构建。
配置完成后再构建时，会同时在多个slave上进行并行构建
禁止在master上运行job或和业务相关的操作
将 [executors] 设置为0</description>
    </item>
    <item>
      <title>jenkins检查代码 如没更新停止构建步骤</title>
      <link>http://localhost:1313/2018/05/jenkins-checkcode/</link>
      <pubDate>Wed, 02 May 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2018/05/jenkins-checkcode/</guid>
      <description>需求分析 在jenkins中没有找到构建前插件，每次构建时间很长，希望可以实现判断代码是否更新，如果没更细则停止构建步骤。
实现步骤 在构建时执行shell命令，而jenkins提供的的环境变量可以实现此判断 https://wiki.jenkins.io/display/JENKINS/Conditional+BuildStep+Plugin
text 1 2 3 4 5 6 GIT_COMMIT The commit hash being checked out. GIT_PREVIOUS_COMMIT The hash of the commit last built on this branch, if any. GIT_PREVIOUS_SUCCESSFUL_COMMIT The hash of the commit last successfully built on this branch, if any. GIT_COMMIT 当前拉取版本的commit id GIT_PREVIOUS_COMMIT 最后在此分支上构建的 commit id GIT_PREVIOUS_SUCCESSFUL_COMMIT 最后在此分支上成功构建的 commit id号
text 1 2 3 4 5 6 7 8 #!/bin/bash if [ $GIT_PREVIOUS_SUCCESSFUL_COMMIT == $GIT_COMMIT ];then echo &amp;#34;no change，skip build&amp;#34; exit 0 else echo &amp;#34;git pull commmit id not equals to current commit id trigger build&amp;#34; fi 注意，不能使用-eq 只能使用 “==” 提交新版本后，构建提示如下：</description>
    </item>
    <item>
      <title>jenkins github tag使用方式</title>
      <link>http://localhost:1313/2018/02/jenkins-github-tag/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2018/02/jenkins-github-tag/</guid>
      <description>jenkins github tag
测试项目地址：GitHub - go-redis\redis: Type-safe Redis client for Golang
插件下载地址：[git-parameter](http:\updates.jenkins-ci.org\download\plugins\git-parameter)
pt-online-schema-change
Jenkins中配置gradle项目的坑 - doctorq - CSDN博客</description>
    </item>
  </channel>
</rss>
