<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>kubernetes network on Cylon&#39;s Collection</title>
    <link>https://www.oomkill.com/tags/kubernetes-network/</link>
    <description>Recent content in kubernetes network on Cylon&#39;s Collection</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 21 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://www.oomkill.com/tags/kubernetes-network/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>在Kubernetes集群上安装 Calico cni 的注意事项</title>
      <link>https://www.oomkill.com/2023/06/calico-cni-deplyment/</link>
      <pubDate>Wed, 21 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2023/06/calico-cni-deplyment/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="开始前的实验环境">开始前的实验环境</h2>
<table>
<thead>
<tr>
<th style="text-align:center">Resources</th>
<th style="text-align:center">controller</th>
<th style="text-align:center">worker-1</th>
<th style="text-align:center">worker-2</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">OS</td>
<td style="text-align:center">CentOS 7.9</td>
<td style="text-align:center">CentOS 7.9</td>
<td style="text-align:center">CentOS 7.9</td>
</tr>
<tr>
<td style="text-align:center">Storage</td>
<td style="text-align:center">20GB</td>
<td style="text-align:center">20GB</td>
<td style="text-align:center">20GB</td>
</tr>
<tr>
<td style="text-align:center">vCPU</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">RAM</td>
<td style="text-align:center">4GB</td>
<td style="text-align:center">4GB</td>
<td style="text-align:center">4GB</td>
</tr>
<tr>
<td style="text-align:center">NIC</td>
<td style="text-align:center">10.0.0.4</td>
<td style="text-align:center">10.0.0.4</td>
<td style="text-align:center">10.0.0.4</td>
</tr>
<tr>
<td style="text-align:center">Kubernetes Version</td>
<td style="text-align:center">1.19.10</td>
<td style="text-align:center">1.19.10</td>
<td style="text-align:center">1.19.10</td>
</tr>
</tbody>
</table>
<h2 id="选择匹配-kubernetes-版本的-calico-版本">选择匹配 Kubernetes 版本的 Calico 版本</h2>
<p>通常情况下，查看 Calico 所支持的 Kubernetes 版本，可以通过路径 Install Calico ==&gt; Kubernetes ==&gt; System requirements 可以找到自己的 Kubernetes 集群所支持的 Calico 版本。</p>
<p>例如在实验环境中，Kubernetes 1.19 版本所支持的版本有 Calico 3.20，这个时候直接 apply 这个版本提供的资源清单即可</p>
<h2 id="如何开启纯-bgp-模式">如何开启纯 BGP 模式</h2>
<p>默认情况下下，Calico 使用的是 full mesh 和 IPIP， 如果想通过在部署时就修改关闭 IPIP 模式，可以通过修改资源清单中的环境变量来关闭 <code>CALICO_IPV4POOL_IPIP: Never</code>。</p>
<p>如果需要在安装时配置Pod 的 CIDR，需要修改 <code>CALICO_IPV4POOL_CIDR</code></p>
<h2 id="如果你需要切换-cni">如果你需要切换 CNI</h2>
<p>如果你的集群不是空的，而是存在很多 Pod 的集群，请注意，这个时候你的 flannel 或者其他 CNI 生成的网络接口是不会被销毁的，Pod 的 IP也是旧 CNI 生成的网段，此时 Calico 会按照原有的 IP 进行维护路由，可能会存在访问不了的情况，这时候不要随意切换 CNI</p>
<h2 id="如何检查-calico-使用的是什么模式">如何检查 Calico 使用的是什么模式</h2>
<p>在使用默认的资源清单安装完 Calico 后，实际上此时会表现为 BGP + IPIP 隧道模式，同节点 Pod 使用直连方式，跨节点 Pod 通讯使用 tunnel 隧道完成，表现形式为 <code>ip addr</code> 会看到 <code>tunl0</code> 设备</p>
<p>如果是纯 BGP 模式，那么表现形式为 <code>route -n</code> 看到的路由跨节点的都应该是 <code>eth0</code> 这样子的，如下所示</p>
<pre><code class="language-bash">$ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.0.0.2        0.0.0.0         UG    0      0        0 eth0
10.0.0.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0
10.244.196.128  0.0.0.0         255.255.255.255 UH    0      0        0 calia5f3c234a97
10.244.196.128  0.0.0.0         255.255.255.192 U     0      0        0 *
10.244.214.0    10.0.0.4        255.255.255.192 UG    0      0        0 eth0
169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0 eth0
172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0
</code></pre>
<p>当然此时一定是不存在 <code>tunl0</code> 设备的。</p>
<h2 id="reference">Reference</h2>
<p><sup id="1">[1]</sup> <a href="https://docs.tigera.io/archive/v3.20/reference/resources/bgpconfig" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>BGP configuration</strong></em></a></p>
<p><sup id="2">[2]</sup> <a href="https://docs.tigera.io/archive/v3.20/reference/resources/bgppeer" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>BGP peer</strong></em></a></p>
<p><sup id="3">[3]</sup> <a href="https://docs.tigera.io/archive/v3.20/reference/resources/ippool" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>IP pool</strong></em></a></p>
<p><sup id="4">[4]</sup> <a href="https://docs.tigera.io/archive/v3.20/getting-started/kubernetes/requirements" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>System requirements</strong></em></a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Linux网络栈</title>
      <link>https://www.oomkill.com/2022/10/network-stack/</link>
      <pubDate>Fri, 28 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/10/network-stack/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="linux-架构概述-supa-href11asup">Linux 架构概述 <sup><a href="#1">[1]</a></sup></h2>
<p>本章节简单阐述Linux系统的结构，并讨论子系统中的模块之间以及与其他子系统之间的关系。</p>
<p>Linux内核本身鼓励无用，是作为一个操作系统的一部分参与的，只有为一个整体时他才是一个有用的实体，下图展示了Linux操作系统的分层</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221028214224508.png" alt="image-20221028214224508" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Linux子系统分层图</center>
<center><em>Source：</em>https://docs.huihoo.com/linux/kernel/a1/index.html</center><br>
<p>由图可以看出Linux操作系统由四部分组成：</p>
<ul>
<li>用户应用</li>
<li>OS服务，操作系统的一部分（例如shell）内核编程接口等</li>
<li>内核</li>
<li>硬件控制器，CPU、内存硬件、硬盘和NIC等都数据这部分</li>
</ul>
<h2 id="linux内核阐述">Linux内核阐述</h2>
<p>Linux内核将所有硬件抽象为一致的接口，为用户进程提供了一个虚拟接口，使用户无需知道计算机上安装了哪些物理硬件即可编写进程，并且Linux支持用户进程的多任务处理，每个进程都可以视作为操作系统的唯一进程独享硬件资源。内核负责维护多个用户进程，并协调其对硬件资源的访问，使得每个进程都可以公平的访问资源，并保证进程间安全。</p>
<p>Linux内核主要为五个子系统组成：</p>
<ul>
<li>进程调度器(<em><strong>SCHED</strong></em>)， 控制进程对 CPU 的访问。调度程序执行策略，确保进程可以公平地访问 CPU。</li>
<li>内存管理器 (<em><strong>MM</strong></em>)， 允许多个进程安全地共享操作系统的内存</li>
<li>虚拟文件系统 (<em><strong>VFS</strong></em>)，向所有设备提供通用文件接口来抽象出各种硬件设备</li>
<li>网络接口 (<em><strong>NET</strong></em>)，提供对多种网络标准与各种网络硬件的访问</li>
<li>进程间通信 (<em><strong>IPC</strong></em>)，在单个操作系统上的多种机制进程间通信机制</li>
</ul>
<h2 id="网络子系统架构-supa-href22asup">网络子系统架构 <sup><a href="#2">[2]</a></sup></h2>
<p>网络子系统功能主要是允许 Linux 系统通过网络连接到其他系统。支持多种硬件设备，以及可以使用的多种网络协议。网络子系统抽象了这两个实现细节，以便用户进程和其他内核子系统可以访问网络，而不必知道使用什么物理设备或协议。</p>
<p>子系统模块包含</p>
<ul>
<li>网络设备驱动层 (<em><strong>Network device drivers</strong></em>)，网络设备驱动程序与硬件设备通信。每个硬件设备都有对应的设备驱动程序模块。</li>
<li>独立设备接口层(<em><strong>device independent interface</strong></em>)，设备独立接口提供了所有硬件设备的统一视图，因此在网络子系统之上的级别无需了解硬件信息</li>
<li>网络协议层 (<em><strong>network protocol</strong></em>)，网络协议实现了网络传输的协议</li>
<li>协议独立/无关接口层 (<em><strong>protocol independent interface</strong></em>)，提供了独立于硬件设备的网络接口，为内核内其他子系统访问网络时不依赖特定的协议和硬件接口。</li>
<li>系统调用层 (<em><strong>system call</strong></em>) 用于限制用户进程导出资源的访问</li>
</ul>
<p>网络子系统的结构图如下图所示，</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221029170129050.png" alt="image-20221029170129050" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：网络子系统中的上下文</center>
<center><em>Source：</em>https://docs.huihoo.com/linux/kernel/a1/index.html</center><br>
<p>当网络子系统转换为网络栈时，如下图所示</p>
<p><img loading="lazy" src="https://miro.medium.com/max/700/1*LcGaDm_ZOCbrIerM2UDj0g.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：ISO Stack与TCP/IP Stack</center>
<center><em>Source：</em>https://www.washington.edu/R870/Networking.html</center><br>
<p>当然Linux网络子系统是类似于TCP/IP栈的一种结构，当发生一个网络传输时，数据包会按照所经过的层进行封装。例如应用层应用提供了REST API，那么应用将要传输的数据封装为HTTP协议，然后传递给向下的传输层。传输层是TCP协议就会被添加对应的TCP包头。整个封装过程原始包保持不变，会根据所经过层的不同增加固定格式的包头。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/understandlni_1304.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：数据包传输在每层被封装的过程</center>
<center><em>Source：</em>http://www.embeddedlinux.org.cn/linux_net/0596002556/understandlni-CHP-13-SECT-1.html</center><br>
<p>对于Linux来说TCP/IP 的五层结构则是构成网络子系统的的核心组件，下图是Linux网络栈结构图</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221030005922405.png" alt="image-20221030005922405" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Linux网络栈的结构图</center>
<center><em>Source：</em>https://medium.com/geekculture/linux-networking-deep-dive-731848d791c0</center><br>
<ul>
<li>图中橙色部分是位于TCP/IP的五层结构中的应用层，应用层向下通讯通过 <code>system call</code> 与 socket接口进行交互</li>
<li>蓝色部分是位于内核空间，socket向下则是传输层与网络层</li>
<li>最底层是物理层包含网卡驱动与NIC</li>
</ul>
<p>通过图可以看出，NIC是发送与接收数据包的基本单位，当系统启动时内核通过驱动程序向操作系统注册网卡，当数据包到达网卡时，被放入队列中。内核通过硬中断，运行中断处理程序，为网络帧分配内核数据结构(sk_buff)，并将其拷贝到缓冲区中，此为内核与网卡交互的过程。</p>
<p>网卡硬中断只处理网卡核心数据的读取或发送，网络协议栈中的大部分处理都在软中断中进行处理。内核协议栈将从缓冲区中取出网络帧，通过网络协议栈，从下到上的根据网络栈结构逐层处理这个网络帧。</p>
<h2 id="socket-supa-href44asup">Socket <sup><a href="#4">[4]</a></sup></h2>
<p>Unix Socket是一种使用了Unix文件描述符的IPC机制，在网络栈中是位于内核空间网络栈的一层，是一个用户空间与传输层之间的一个接口，可以为网络连接, 文本文件, 终端或其他；他的行为很像一个文件描述符，因为信息的读写，<code>read()</code>, <code>write()</code>与文件的方式很相似。下图是socket通信模型。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221031203257214.png" alt="image-20221031203257214" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：socket通信模型</center>
<center><em>Source：</em>https://slideplayer.com/slide/10740698/</center><br>
<p>作为用户空间到内核空间的第一层，Socket位于两层之间，由于IPC机制支持不同的通讯协议以及需要对不同的网络协议进行访问，故这些协议实现为位于socket的层，这种情况下，用户空间仅通过系统调用socket接口，而内核空间负责一些其他工作，例如，缓冲区管理，标准协议接口，网络接口与各种不同的网络协议。</p>
<blockquote>
<p>Notes:</p>
<ul>
<li><code>/etc/protocols</code> 定义的协议号</li>
<li><code>/etc/services</code> 定义的服务的端口号</li>
</ul>
</blockquote>
<h2 id="网络栈的工作原理">网络栈的工作原理</h2>
<p>当网络包到达时，网卡（硬中断+DMA）通过DMA将网络数据包放入队列中，告知中断程序硬中断已收到网络数据包。</p>
<h3 id="数据包的发送">数据包的发送</h3>
<p>用户程序发送网络包时，通过网络栈模型自上而下逐层处理帧：</p>
<ul>
<li>应用层：通过系统调用，调用socket API发送网络包，会被限制在内核空间的socket层，socket层将数据包放入到缓冲区内。</li>
<li>传输层：网络栈从socket取出数据包，传输层添加TCP标头</li>
<li>网络层：将IP添加到数据标头，根据MTU大小分片</li>
<li>数据链路层：MAC地址寻址，并添加到帧头尾，将帧放入发送队列，触发软中断通知</li>
<li>物理层：网卡驱动通过DMA从发送队列读取网络帧，通过网卡发送出</li>
</ul>
<h3 id="数据包的接收">数据包的接收</h3>
<p>内核网络栈从缓冲区读取帧，通过网络栈模型自下而上逐层处理帧：</p>
<ul>
<li>数据链路层：
<ul>
<li>检查数据包的有效性</li>
<li>确定网络协议类型 IPV4 or IPV6</li>
<li>去除帧 头, 尾</li>
</ul>
</li>
<li>网络层：
<ul>
<li>取出IP头，确定网络流量的方向（转发或者本机流量）</li>
<li>删除标头，传递给传输层</li>
</ul>
</li>
<li>传输层：取出TCP/UDP协议头，根据源IP, 目的IP, 源端口, 目的端口作为标识找到socket，将数据报文放置socket缓冲区</li>
<li>应用层：应用程序通过socket来读数据</li>
</ul>
<p>下图为网络栈收/发数据的结构图</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221031210517384.png" alt="image-20221031210517384" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Linux网络进程接收网络数据包流程图</center>
<center><em>Source：</em>https://slideplayer.com/slide/10740698/</center><br>
<h2 id="网络子系统分层结构">网络子系统分层结构</h2>
<p>在了解了网络接受网络数据包的流程后，还需要对网络子系统中分层结构进行了解，在该结构中将需要基础掌握一些对于工作与网络子系统中的API的命令是如何调用的。</p>
<p>下图是结合 《深入理解Linux网络技术内幕》第13章 <sup><a href="#3">[3]</a></sup> 中插图13-2与 托马斯格拉夫发表于2019年的文章 &ldquo;How to Make Linux Microservice-Aware with Cilium and eBPF&rdquo; <sup><a href="#5">[5]</a></sup> 的结合旨在让零基础同学可以更好的了解到各API的分层调用</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20221104153434745.png" alt="image-20221104153434745" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Linux网络子系统分层调用</center><br>
<p>图中可以看出，是一个基于TCP/IP栈的调用模型，其中应用层包含了常用的工具：</p>
<ul>
<li>配置IP路由：<code>ip</code></li>
<li>ip防火墙（包过滤）：<code>iptables</code></li>
<li>流量整形：<code>tc</code></li>
<li>网络抓包：<code>tcpdump</code></li>
<li>网卡信息：<code>ethtool</code></li>
</ul>
<p>对于云原生网络中，了解完整的分层是非常重要的，这将有利于开发基于eBPF服务。下面就简单的论证下该图</p>
<p>正如图中所示，所有的网络命令都是提供给用户的用户空间API，当发生网络动作时是需要通过内核将数据导入/出，这里使用了系统调用，调用内核提供的导入到用户空间的接口，例如 <code>socket</code>，<code>sysctl</code> 等，更多的接口介绍可以详见《深入理解Linux网络技术内幕》第3章 <sup><a href="#6">[6]</a></sup></p>
<p>到达socket后，继续向下通信时，socket提供了几种级别的接口，这些可以在常见编程语言包中被提供</p>
<ul>
<li><code>AE_PACKAGE</code> / <code>PE_PACKAGE</code>：提供设备级别的API，通俗来讲，就是在网络层之下发送/接受消息的接口，工作于2层，这将允许用户在用户空间实现物理层数据包发送和接收</li>
<li><code>AF_INET</code> / <code>PE_INET</code>：是基于网络层Socket类型，<code>AF_INET</code>是指IPv4，<code>AF_INET6</code> 是IPv6，这里就是IP 地址和端口号。</li>
</ul>
<p>如图所示，对于 <code>PE_PACKAGE</code> 套接字类型而言，Linux在链路层捕捉帧并将其注入至链路层的方式，这样跳过了所有的中间层，例如 <code>tcpdump</code> 与 <code>ethtool</code>， <code>PE_PACKAGE</code> 套接字通过将帧直接交给 <code>dev_queue_xmit</code>。</p>
<ul>
<li><code>dev_queue_xmit</code> 是传输 buffer (<code>sk_buff</code>) 到网络设备中的函数，将封包传递给TC或QoS层，L3封包时调用</li>
</ul>
<p>接下来是iptables，netfilter，是工作与多层协议栈中一系列hook，用户端由命令行工具iptables/nftables控制，可以在数据包经由的数据点上被调用对应的hook函数来改变包的行为。所有的数据包都独立存在于对应的协议栈，经过的数据包会便利所有对应的hook，因为iptables(etables)支持工作于L2的ARP协议。所有的hook都存在与每个网络名称空间内，并且每个网络设备都拥有ingress hook，这也是云原生网络中提到的为什么使用eBPF 跳过netfilter框架可以提升网络性能。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/understandlni_1801.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Linux 栈中经由netfilter框架示意图</center>
<center><em>Source：</em>http://www.embeddedlinux.org.cn/linux_net/0596002556/understandlni-CHP-18-SECT-1.html</center><br>
<p>接下来就是传统的一些应用，例如telnet，ping都是使用了<code>AE_PACKAGE</code> / <code>PE_PACKAGE</code> 传统联网模式</p>
<p>最后一个点就是 <em><strong>traffic control</strong></em> TC，是工作与L2的一组队列与其机制组成的，通常情况下是一个队列，上面也提到，所有的设备都是使用队列来调度底层设备进入的数据包，liunx中默认的队列是 <code>qdisc </code> 。</p>
<h2 id="reference">Reference</h2>
<blockquote>
<p><sup id="1">[1]</sup> <a href="https://docs.huihoo.com/linux/kernel/a1/index.html" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>Conceptual Architecture of the Linux Kernel</strong></em></a></p>
<p><sup id="2">[2]</sup> <a href="https://medium.com/geekculture/linux-networking-deep-dive-731848d791c0" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>Linux — Networking Deep Dive</strong></em></a></p>
<p><sup id="3">[3]</sup> <a href="http://www.embeddedlinux.org.cn/linux_net/0596002556/understandlni-CHP-13-SECT-1.html" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>Network Stack Chapter13</strong></em></a></p>
<p><sup id="4">[4]</sup> <a href="https://notes.shichao.io/tcpv1/ch10/" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>User Datagram Protocol (UDP) and IP Fragmentation</strong></em></a></p>
<p><sup id="5">[5]</sup> <a href="https://www.infoq.com/presentations/linux-cilium-ebpf/" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>How to Make Linux Microservice-Aware with Cilium and eBPF</strong></em></a></p>
<p><sup id="6">[6]</sup> <a href="http://www.embeddedlinux.org.cn/linux_net/0596002556/understandlni-CHP-3-SECT-1.html" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>Network Stack Chapter13</strong></em></a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>为什么网络是分层的</title>
      <link>https://www.oomkill.com/2022/10/network-unit-in-osi/</link>
      <pubDate>Fri, 28 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/10/network-unit-in-osi/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="overview-supa-href11asup">Overview <sup><a href="#1">[1]</a></sup></h2>
<p>协议数据单元 <em><strong>Protocol Data Unit</strong></em> (PDU) 是应用于OSI模型中的数据结构，在OSI模型中每一层都会被添加一个header，tailer进行封装，header, tailer加原始报文的组合就是PDU。</p>
<p>在每层中，PDU的名称都是不同的，这也是很多人的疑问，一会数据报文称为数据包，一会数据报文成为数据帧，该文介绍网络中的单元，以了解之间的区别</p>
<h2 id="物理层">物理层</h2>
<p>物理层数据的呈现方式是以 “位” (<em><strong>bit</strong></em>) 为单位的，即0 1，在该层中数据以二进制形式进行传输</p>
<h2 id="数据链路层-supa-href22asup">数据链路层 <sup><a href="#2">[2]</a></sup></h2>
<p>到达数据链路层，实际上可以说进入了TCP/IP栈对底层，而该层的单位为 ”帧“ (<em><strong>frame</strong></em>)，该层中，MAC地址会被封装到数据包中，比如以太网帧，PPP帧都是指该层的数据包</p>
<p>该层中数据帧包含：</p>
<ul>
<li>源MAC</li>
<li>目的MAC</li>
<li>数据，由网络层给出的</li>
<li>数据的总长度</li>
<li>校验序列</li>
</ul>
<h2 id="网络层-supa-href33asup">网络层 <sup><a href="#3">[3]</a></sup></h2>
<p>在网络层中协议数据单元被称为数据 “包&quot; (<em><strong>package</strong></em>) ，是网络间节点通讯的基本单位。该层中IP地址会被封装到数据包内。</p>
<p>该层中数据包包含：</p>
<ul>
<li>标头：源IP，目的IP，协议，数据包编号，帮助数据包匹配网络的位</li>
<li>payload：数据包的主体</li>
<li>标尾：包含几个位，用于告知已到达数据包的末尾与错误检查（循环冗余检查 (<em><strong>CRC</strong></em>)）</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL3F1ZXN0aW9uNTI1LXBhY2tldC5naWYiLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjI5MH0sInRvRm9ybWF0IjoiYXZpZiJ9fQ%3D%3D" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：数据包组成</center>
<center><em>Source：</em>https://computer.howstuffworks.com/question525.htm</center><br>
<p>例如一个电子邮件，假设电子邮件大小尾3500bit，发送时使用1024的固定大小数据包进行发送，那么每个数据包标头为 96bits，标尾为 32bit，剩余 896bits 将用于实际的数据大小。这里为3500bits，会被分为4个数据包，前三个数据包为 896bits，最后一个数据包大小为 812bits。接收端会根据包编号进行解包重组</p>
<h2 id="传输层">传输层</h2>
<h3 id="segment">Segment</h3>
<p>在传输层TCP协议的协议数据单元被称为 ”段“  (<em><strong>Segment</strong></em>) ，上面讲到，IP数据包会以固定大小的数据包进行发送，如果超出大小的会被划分为多个数据包，每个数据包的碎片就被称之为<em><strong>Segment</strong></em>。</p>
<p>数据包分割通常会发生在该层，当发生下列场景时会需要分段</p>
<ul>
<li>数据包大于网络支持的最大传输单元 (<em><strong>MTU</strong></em>)</li>
<li>网络不可靠，将数据包分为更小的包</li>
</ul>
<h3 id="datagram-supa-href44asup">datagram <sup><a href="#4">[4]</a></sup></h3>
<p>在传输层UDP协议的协议数据单元被称为 ”数据报“ (<em><strong>datagram</strong></em>) ，datagram是一种逐层增加的设计，用于无连接通讯</p>
<p>下图是一个UDP数据报被封装位一个IP数据包：IPv4字段值位17 表示udp协议</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/figure_10-1_600.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：udp的IP包</center>
<center><em>Source：</em>https://notes.shichao.io/tcpv1/ch10</center><br>
<p>对于udp数据报的组成包含header与payload，udp的header大小为固定的8字节</p>
<ul>
<li><strong>源端口</strong>：可选</li>
<li><strong>目的端口</strong>：识别接收信息的进程</li>
<li><strong>Length</strong>：udp header + udp payload的长度，最小值为8</li>
<li><strong>checksum</strong>：与lenght一样其实是多余的，因为第三层包含了这两个信息</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/figure_10-2_600.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：udp数据报组成</center>
<center><em>Source：</em>https://notes.shichao.io/tcpv1/ch10</center><br>
<blockquote>
<p>Notes：使用UDP时应注意避免分段，例如帧中MTU为 1500 字节，假设 IPv4 header为 20 字节，UDP header 为 8 字节，则应用程序最多为数据留下 1472 字节以避免碎片</p>
</blockquote>
<h2 id="数据">数据</h2>
<p>对于传输层之上，协议数据单元没有特定的名词，可以统称为协议数据单元或者数据，整个PDU分层结构图如下图所示，其中 T 表示 Trailer，H 表示 Header，通常H包含源地址和目的地址及一些用于管理通信的控制信息。T含错误检查之类的信息或标志 PDU 结束的字段。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/page108.gif" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：PDU分层结构图</center>
<center><em>Source：</em>http://www.telecomworld101.com/Intro2dcRev2/page108.html</center><br>
<blockquote>
<p>Notes：每层的数据字段都由上一层PDU组成，通常情况下，每层只知道自己该层的信息，如网络层仅知道对端网络层，而不知道数据链路层或传输层</p>
</blockquote>
<h2 id="reference">Reference</h2>
<blockquote>
<p><sup id="1">[1]</sup> <a href="http://www.telecomworld101.com/Intro2dcRev2/page108.html" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>Protocol Data Unit</strong></em></a></p>
<p><sup id="2">[2]</sup> <a href="https://www.slashroot.in/difference-between-segments-packets-and-frames" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>difference between segments packets and frames</strong></em></a></p>
<p><sup id="3">[3]</sup> <a href="https://computer.howstuffworks.com/question525.htm" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>What is a packet?</strong></em></a></p>
<p><sup id="4">[4]</sup> <a href="https://notes.shichao.io/tcpv1/ch10/" target="_blank"
   rel="noopener nofollow noreferrer" ><em><strong>User Datagram Protocol (UDP) and IP Fragmentation</strong></em></a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>Kubernetes Pod网络排错思路</title>
      <link>https://www.oomkill.com/2022/08/pod-network-troubleshooting/</link>
      <pubDate>Wed, 17 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/08/pod-network-troubleshooting/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="overview">Overview</h2>
<p>本文将引入一个思路：“在Kubernetes集群发生网络异常时如何排查”。文章将引入Kubernetes 集群中网络排查的思路，包含网络异常模型，常用工具，并且提出一些案例以供学习。</p>
<ul>
<li>Pod常见网络异常分类</li>
<li>网络排查工具</li>
<li>Pod网络异常排查思路及流程模型</li>
<li>CNI网络异常排查步骤</li>
<li>案例学习</li>
</ul>
<h2 id="pod网络异常">Pod网络异常</h2>
<p>网络异常大概分为如下几类：</p>
<ul>
<li>
<p><strong>网络不可达</strong>，主要现象为ping不通，其可能原因为：</p>
<ul>
<li>源端和目的端防火墙（<code>iptables</code>, <code>selinux</code>）限制</li>
<li>网络路由配置不正确</li>
<li>源端和目的端的系统负载过高，网络连接数满，网卡队列满</li>
<li>网络链路故障</li>
</ul>
</li>
<li>
<p><strong>端口不可达</strong>：主要现象为可以ping通，但telnet端口不通，其可能原因为：</p>
<ul>
<li>源端和目的端防火墙限制</li>
<li>源端和目的端的系统负载过高，网络连接数满，网卡队列满，端口耗尽</li>
<li>目的端应用未正常监听导致（应用未启动，或监听为127.0.0.1等）</li>
</ul>
</li>
<li>
<p><strong>DNS解析异常</strong>：主要现象为基础网络可以连通，访问域名报错无法解析，访问IP可以正常连通。其可能原因为</p>
<ul>
<li>Pod的DNS配置不正确</li>
<li>DNS服务异常</li>
<li>pod与DNS服务通讯异常</li>
</ul>
</li>
<li>
<p><strong>大数据包丢包</strong>：主要现象为基础网络和端口均可以连通，小数据包收发无异常，大数据包丢包。可能原因为：</p>
<ul>
<li>数据包的大小超过了 <em>dockero</em>，<em>CNI</em> 插件，或者宿主机网卡的 <em>MTU</em> 值。
<ul>
<li>可使用 <code>ping -s</code> 指定数据包大小进行测试</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>CNI异常</strong>：主要现象为Node可以通，但Pod无法访问集群地址，可能原因有：</p>
<ul>
<li><em>kube-proxy</em> 服务异常，没有生成 <em>iptables</em> 策略或者 <em>ipvs</em> 规则导致无法访问</li>
<li>CIDR耗尽，无法为Node注入 <code>PodCIDR</code> 导致 <em>CNI</em> 插件异常</li>
<li>其他 <em>CNI</em> 插件问题</li>
</ul>
</li>
</ul>
<p>那么整个Pod网络异常分类可以如下图所示：</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821164836806.png" alt="image-20220821164836806" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Pod network trouble hirarchy</center><br>
<p>总结一下，Pod最常见的网络故障有，网络不可达（ping不通）；端口不可达（telnet不通）；DNS解析异常（域名不通）与大数据包丢失（大包不通）。</p>
<h2 id="常用网络排查工具">常用网络排查工具</h2>
<p>在了解到常见的网络异常后，在排查时就需要使用到一些网络工具才可以很有效的定位到网络故障原因，下面会介绍一些网络排查工具。</p>
<h3 id="tcpdump-supa-href11asup">tcpdump <sup><a href="#1">[1]</a></sup></h3>
<p>tcpdump网络嗅探器，将强大和简单结合到一个单一的命令行界面中，能够将网络中的报文抓取，输出到屏幕或者记录到文件中。</p>
<blockquote>
<p><strong>各系统下的安装</strong></p>
<ul>
<li>Ubuntu/Debian: <code>tcpdump</code>  ；<code>apt-get install -y tcpdump</code></li>
<li>Centos/Fedora: <code>tcpdump</code> ；<code>yum install -y tcpdump</code></li>
<li>Apline：<code>tcpdump </code> ；<code>apk add tcpdump --no-cache</code></li>
</ul>
</blockquote>
<p>查看指定接口上的所有通讯</p>
<p>语法</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>-i [interface]</td>
<td></td>
</tr>
<tr>
<td> -w [flle]</td>
<td>第一个n表示将地址解析为数字格式而不是主机名，第二个N表示将端口解析为数字格式而不是服务名</td>
</tr>
<tr>
<td>-n</td>
<td>不显示IP地址</td>
</tr>
<tr>
<td>-X</td>
<td>hex and ASCII</td>
</tr>
<tr>
<td>-A</td>
<td>ASCII（实际上是以人类可读懂的包进行显示）</td>
</tr>
<tr>
<td>-XX</td>
<td></td>
</tr>
<tr>
<td>-v</td>
<td>详细信息</td>
</tr>
<tr>
<td>-r</td>
<td>读取文件而不是实时抓包</td>
</tr>
<tr>
<td></td>
<td><strong>关键字</strong></td>
</tr>
<tr>
<td><strong>type</strong></td>
<td>host（主机名，域名，IP地址）, net, port, portrange</td>
</tr>
<tr>
<td><strong>direction</strong></td>
<td>src, dst, src or dst , src and ds</td>
</tr>
<tr>
<td><strong>protocol</strong></td>
<td>ether, ip，arp, tcp, udp, wlan</td>
</tr>
</tbody>
</table>
<h4 id="捕获所有网络接口">捕获所有网络接口</h4>
<pre><code class="language-bash">tcpdump -D
</code></pre>
<p>####按IP查找流量</p>
<p>最常见的查询之一 <code>host</code>，可以看到来往于 <code>1.1.1.1</code> 的流量。</p>
<pre><code class="language-bash">tcpdump host 1.1.1.1
</code></pre>
<p>####按源/目的 地址过滤</p>
<p>如果只想查看来自/向某方向流量，可以使用 <code>src</code> 和 <code>dst</code>。</p>
<pre><code class="language-bash">tcpdump src|dst 1.1.1.1
</code></pre>
<h4 id="通过网络查找数据包">通过网络查找数据包</h4>
<p>使用 <code>net</code> 选项，来要查找出/入某个网络或子网的数据包。</p>
<pre><code class="language-bash">tcpdump net 1.2.3.0/24
</code></pre>
<h4 id="使用十六进制输出数据包内容">使用十六进制输出数据包内容</h4>
<p><code>hex</code> 可以以16进制输出包的内容</p>
<pre><code class="language-bash">tcpdump -c 1 -X icmp
</code></pre>
<h4 id="查看特定端口的流量">查看特定端口的流量</h4>
<p>使用 <code>port</code> 选项来查找特定的端口流量。</p>
<pre><code class="language-bash">tcpdump port 3389
tcpdump src port 1025
</code></pre>
<h4 id="查找端口范围的流量">查找端口范围的流量</h4>
<pre><code class="language-bash">tcpdump portrange 21-23
</code></pre>
<h4 id="过滤包的大小">过滤包的大小</h4>
<p>如果需要查找特定大小的数据包，可以使用以下选项。你可以使用 <code>less</code>，<code>greater</code>。</p>
<pre><code class="language-bash">tcpdump less 32
tcpdump greater 64
tcpdump &lt;= 128
</code></pre>
<h4 id="捕获流量输出为文件">捕获流量输出为文件</h4>
<p><code>-w</code>  可以将数据包捕获保存到一个文件中以便将来进行分析。这些文件称为<code>PCAP</code>（PEE-cap）文件，它们可以由不同的工具处理，包括 <code>Wireshark</code> 。</p>
<pre><code class="language-bash">tcpdump port 80 -w capture_file
</code></pre>
<h4 id="组合条件">组合条件</h4>
<p>tcpdump也可以结合逻辑运算符进行组合条件查询</p>
<ul>
<li>
<p><strong>AND</strong>
<em><code>and</code></em> or <code>&amp;&amp;</code></p>
</li>
<li>
<p><strong>OR</strong>
<em><code>or</code></em> or <code>||</code></p>
</li>
<li>
<p><strong>EXCEPT</strong>
<em><code>not</code></em> or <code>!</code></p>
</li>
</ul>
<pre><code class="language-bash">tcpdump -i eth0 -nn host 220.181.57.216 and 10.0.0.1  # 主机之间的通讯
tcpdump -i eth0 -nn host 220.181.57.216 or 10.0.0.1
# 获取10.0.0.1与 10.0.0.9或 10.0.0.1 与10.0.0.3之间的通讯
tcpdump -i eth0 -nn host 10.0.0.1 and \(10.0.0.9 or 10.0.0.3\)
</code></pre>
<h4 id="原始输出">原始输出</h4>
<p>并显示人类可读的内容进行输出包（不包含内容）。</p>
<pre><code class="language-bash">tcpdump -ttnnvvS -i eth0 
tcpdump -ttnnvvS -i eth0 
</code></pre>
<h4 id="ip到端口">IP到端口</h4>
<p>让我们查找从某个IP到端口任何主机的某个端口所有流量。</p>
<pre><code class="language-bash">tcpdump -nnvvS src 10.5.2.3 and dst port 3389
</code></pre>
<h4 id="去除特定流量">去除特定流量</h4>
<p>可以将指定的流量排除，如这显示所有到192.168.0.2的 非ICMP的流量。</p>
<pre><code class="language-bash">tcpdump dst 192.168.0.2 and src net and not icmp
</code></pre>
<p>来自非指定端口的流量，如，显示来自不是SSH流量的主机的所有流量。</p>
<pre><code class="language-bash">tcpdump -vv src mars and not dst port 22
</code></pre>
<h4 id="选项分组">选项分组</h4>
<p>在构建复杂查询时，必须使用单引号 <code>'</code>。单引号用于忽略特殊符号 <code>()</code> ，以便于使用其他表达式（如host, port, net等）进行分组。</p>
<pre><code class="language-bash">tcpdump 'src 10.0.2.4 and (dst port 3389 or 22)'
</code></pre>
<h4 id="过滤tcp标记位">过滤TCP标记位</h4>
<p>TCP RST</p>
<p>The filters below find these various packets because tcp[13] looks at offset 13 in the TCP header, the number represents the location within the byte, and the !=0 means that the flag in question is set to 1, i.e. it’s on.</p>
<pre><code class="language-bash">tcpdump 'tcp[13] &amp; 4!=0'
tcpdump 'tcp[tcpflags] == tcp-rst'
</code></pre>
<p>TCP SYN</p>
<pre><code class="language-bash">tcpdump 'tcp[13] &amp; 2!=0'
tcpdump 'tcp[tcpflags] == tcp-syn'
</code></pre>
<p>同时忽略SYN和ACK标志的数据包</p>
<pre><code class="language-bash">tcpdump 'tcp[13]=18'
</code></pre>
<p>TCP URG</p>
<pre><code class="language-bash">tcpdump 'tcp[13] &amp; 32!=0'
tcpdump 'tcp[tcpflags] == tcp-urg'
</code></pre>
<p>TCP ACK</p>
<pre><code class="language-bash">tcpdump 'tcp[13] &amp; 16!=0'
tcpdump 'tcp[tcpflags] == tcp-ack'
</code></pre>
<p>TCP PSH</p>
<pre><code class="language-bash">tcpdump 'tcp[13] &amp; 8!=0'
tcpdump 'tcp[tcpflags] == tcp-push'
</code></pre>
<p>TCP FIN</p>
<pre><code class="language-bash">tcpdump 'tcp[13] &amp; 1!=0'
tcpdump 'tcp[tcpflags] == tcp-fin'
</code></pre>
<h4 id="查找http包">查找http包</h4>
<p>查找 <code>user-agent</code> 信息</p>
<pre><code class="language-bash">tcpdump -vvAls0 | grep 'User-Agent:'
</code></pre>
<p>查找只是 <code>GET</code> 请求的流量</p>
<pre><code class="language-bash">tcpdump -vvAls0 | grep 'GET'
</code></pre>
<p>查找http客户端IP</p>
<pre><code class="language-bash">tcpdump -vvAls0 | grep 'Host:'
</code></pre>
<p>查询客户端cookie</p>
<pre><code class="language-bash">tcpdump -vvAls0 | grep 'Set-Cookie|Host:|Cookie:'
</code></pre>
<h4 id="查找dns流量">查找DNS流量</h4>
<pre><code class="language-bash">tcpdump -vvAs0 port 53
</code></pre>
<h4 id="查找对应流量的明文密码">查找对应流量的明文密码</h4>
<pre><code class="language-bash">tcpdump port http or port ftp or port smtp or port imap or port pop3 or port telnet -lA | egrep -i -B5 'pass=|pwd=|log=|login=|user=|username=|pw=|passw=|passwd= |password=|pass:|user:|username:|password:|login:|pass |user '
</code></pre>
<h4 id="wireshark追踪流">wireshark追踪流</h4>
<p>wireshare追踪流可以很好的了解出在一次交互过程中都发生了那些问题。</p>
<p>wireshare选中包，右键选择 “追踪流“ 如果该包是允许的协议是可以打开该选项的</p>
<h4 id="关于抓包节点和抓包设备">关于抓包节点和抓包设备</h4>
<p>如何抓取有用的包，以及如何找到对应的接口，有以下建议</p>
<p><strong>抓包节点</strong>：</p>
<p>通常情况下会在==源端==和==目的端==两端同时抓包，观察数据包是否从源端正常发出，目的端是否接收到数据包并给源端回包，以及源端是否正常接收到回包。如果有丢包现象，则沿网络链路上各节点抓包排查。例如，A节点经过c节点到B节点，先在AB两端同时抓包，如果B节点未收到A节点的包，则在c节点同时抓包。</p>
<p><strong>抓包设备</strong>：</p>
<p>对于 Kubernetes 集群中的Pod，由于容器内不便于抓包，通常视情况在Pod数据包经过的veth设备，<em>docker0</em> 网桥，<em>CNI</em> 插件设备（如cni0，flannel.1 etc..）及Pod所在节点的网卡设备上指定Pod IP进行抓包。选取的设备根据怀疑导致网络问题的原因而定，比如范围由大缩小，从源端逐渐靠近目的端，比如怀疑是 <em>CNI</em> 插件导致，则在 <em>CNI</em> 插件设备上抓包。从pod发出的包逐一经过veth设备，<em>cni0</em> 设备，<em>flannel0</em>，宿主机网卡，到达对端，抓包时可按顺序逐一抓包，定位问题节点。</p>
<blockquote>
<p>需要注意在不同设备上抓包时指定的源目IP地址需要转换，如抓取某Pod时，ping <em>{host}</em> 的包，在 <em>veth</em> 和 <em>cni0</em> 上可以指定 Pod IP抓包，而在宿主机网卡上如果仍然指定Pod IP会发现抓不到包，因为此时Pod IP已被转换为宿主机网卡IP。</p>
</blockquote>
<p>下图是一个使用 <em>VxLAN</em> 模式的 <em>flannel</em> 的跨界点通讯的网络模型，在抓包时需要注意对应的网络接口</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821200501496.png" alt="image-20220821200501496" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：VxLAN in kubernetes</center><br>
<h3 id="nsenter">nsenter</h3>
<p>nsenter是一款可以进入进程的名称空间中。例如，如果一个容器以非 root 用户身份运行，而使用 <code>docker exec</code> 进入其中后，但该容器没有安装 <code>sudo</code> 或未 <code>netstat</code> ，并且您想查看其当前的网络属性，如开放端口，这种场景下将如何做到这一点？<em><strong>nsenter</strong></em> 就是用来解决这个问题的。</p>
<p><strong>nsenter</strong> (<em>namespace enter</em>) 可以在容器的宿主机上使用 <em>nsenter</em> 命令进入容器的命名空间，以容器视角使用宿主机上的相应网络命令进行操作。==当然需要拥有 <em>root</em> 权限==</p>
<blockquote>
<p><strong>各系统下的安装</strong> <sup><a href="#2">[2]</a></sup></p>
<ul>
<li>Ubuntu/Debian: <code>util-linux</code>  ；<code>apt-get install -y util-linux</code></li>
<li>Centos/Fedora: <code>util-linux</code> ；<code>yum install -y util-linux</code></li>
<li>Apline：<code>util-linux</code> ；<code>apk add util-linux --no-cache</code></li>
</ul>
</blockquote>
<p><em>nsenter</em> 的使用语法为，<code>nsenter -t pid -n &lt;commond&gt;</code>，<code>-t</code> 接 进程ID号，<code>-n</code> 表示进入名称空间内，<code>&lt;commond&gt;</code> 为执行的命令。更多的内容可以参考 <sup><a href="#3">[3]</a></sup></p>
<p>实例：如我们有一个Pod进程ID为30858，进入该Pod名称空间内执行 <code>ifconfig</code> ，如下列所示</p>
<pre><code class="language-bash">$ ps -ef|grep tail
root      17636  62887  0 20:19 pts/2    00:00:00 grep --color=auto tail
root      30858  30838  0 15:55 ?        00:00:01 tail -f

$ nsenter -t 30858 -n ifconfig
eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1480
        inet 192.168.1.213  netmask 255.255.255.0  broadcast 192.168.1.255
        ether 5e:d5:98:af:dc:6b  txqueuelen 0  (Ethernet)
        RX packets 92  bytes 9100 (8.8 KiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 92  bytes 8422 (8.2 KiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536
        inet 127.0.0.1  netmask 255.0.0.0
        loop  txqueuelen 1000  (Local Loopback)
        RX packets 5  bytes 448 (448.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 5  bytes 448 (448.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

net1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
        inet 10.1.0.201  netmask 255.255.255.0  broadcast 10.1.0.255
        ether b2:79:f9:dd:2a:10  txqueuelen 0  (Ethernet)
        RX packets 228  bytes 21272 (20.7 KiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 216  bytes 20272 (19.7 KiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
</code></pre>
<h4 id="如何定位pod名称空间">如何定位Pod名称空间</h4>
<p>首先需要确定Pod所在的节点名称</p>
<pre><code class="language-bash">$ kubectl get pods -owide |awk '{print $1,$7}'
NAME NODE
netbox-85865d5556-hfg6v master-machine
netbox-85865d5556-vlgr4 node01
</code></pre>
<p>如果Pod不在当前节点还需要用IP登录则还需要查看IP（可选）</p>
<pre><code class="language-bash">$ kubectl get pods -owide |awk '{print $1,$6,$7}'
NAME IP NODE
netbox-85865d5556-hfg6v 192.168.1.213 master-machine
netbox-85865d5556-vlgr4 192.168.0.4 node01
</code></pre>
<p>接下来，登录节点，获取容器lD，如下列所示，每个pod默认有一个 <em>pause</em> 容器，其他为用户yaml文件中定义的容器，理论上所有容器共享相同的网络命名空间，排查时可任选一个容器。</p>
<pre><code class="language-bash">$ docker ps |grep netbox-85865d5556-hfg6v
6f8c58377aae   f78dd05f11ff                                                    &quot;tail -f&quot;                45 hours ago   Up 45 hours             k8s_netbox_netbox-85865d5556-hfg6v_default_4a8e2da8-05d1-4c81-97a7-3d76343a323a_0
b9c732ee457e   registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1   &quot;/pause&quot;                 45 hours ago   Up 45 hours             k8s_POD_netbox-85865d5556-hfg6v_default_4a8e2da8-05d1-4c81-97a7-3d76343a323a_0
</code></pre>
<p>接下来获得获取容器在节点系统中对应的进程号，如下所示</p>
<pre><code class="language-bash">$ docker inspect --format &quot;{{ .State.Pid }}&quot; 6f8c58377aae
30858
</code></pre>
<p>最后就可以通过 <em>nsenter</em> 进入容器网络空间执行命令了</p>
<h3 id="paping">paping</h3>
<p><strong>paping</strong> 命令可对目标地址指定端口以TCP协议进行连续ping，通过这种特性可以弥补 <em>ping</em> ICMP协议，以及 <em>nmap</em> , <em>telnet</em> 只能进行一次操作的的不足；通常情况下会用于测试端口连通性和丢包率</p>
<p>paping download：<a href="https://code.google.com/archive/p/paping/" target="_blank"
   rel="noopener nofollow noreferrer" >paping</a></p>
<p><em>paping</em> 还需要安装以下依赖，这取决于你安装的 <em>paping</em> 版本</p>
<ul>
<li>RedHat/CentOS：<code>yum install -y libstdc++.i686 glibc.i686</code></li>
<li>Ubuntu/Debian：最小化安装无需依赖</li>
</ul>
<pre><code class="language-bash">$ paping -h
paping v1.5.5 - Copyright (c) 2011 Mike Lovell

Syntax: paping [options] destination

Options:
 -?, --help     display usage
 -p, --port N   set TCP port N (required)
     --nocolor  Disable color output
 -t, --timeout  timeout in milliseconds (default 1000)
 -c, --count N  set number of checks to N
</code></pre>
<h3 id="mtr">mtr</h3>
<p><strong>mtr</strong> 是一个跨平台的网络诊断工具，将 <strong>traceroute</strong> 和 <strong>ping</strong> 的功能结合到一个工具。与 <em>traceroute</em> 不同的是 <em>mtr</em> 显示的信息比起 <em>traceroute</em> 更加丰富：通过 <em>mtr</em> 可以确定网络的条数，并且可以同时打印响应百分比以及网络中各跳跃点的响应时间。</p>
<blockquote>
<p><strong>各系统下的安装</strong> <sup><a href="#2">[2]</a></sup></p>
<ul>
<li>Ubuntu/Debian: <code>mtr</code>  ；<code>apt-get install -y mtr</code></li>
<li>Centos/Fedora: <code>mtr</code> ；<code>yum install -y mtr</code></li>
<li>Apline：<code>mtr</code> ；<code>apk add mtr --no-cache</code></li>
</ul>
</blockquote>
<h4 id="简单的使用示例">简单的使用示例</h4>
<p>最简单的示例，就是后接域名或IP，这将跟踪整个路由</p>
<pre><code class="language-bash">$ mtr google.com

Start: Thu Jun 28 12:10:13 2018
HOST: TecMint                     Loss%   Snt   Last   Avg  Best  Wrst StDev
  1.|-- 192.168.0.1                0.0%     5    0.3   0.3   0.3   0.4   0.0
  2.|-- 5.5.5.211                  0.0%     5    0.7   0.9   0.7   1.3   0.0
  3.|-- 209.snat-111-91-120.hns.n 80.0%     5    7.1   7.1   7.1   7.1   0.0
  4.|-- 72.14.194.226              0.0%     5    1.9   2.9   1.9   4.4   1.1
  5.|-- 108.170.248.161            0.0%     5    2.9   3.5   2.0   4.3   0.7
  6.|-- 216.239.62.237             0.0%     5    3.0   6.2   2.9  18.3   6.7
  7.|-- bom05s12-in-f14.1e100.net  0.0%     5    2.1   2.4   2.0   3.8   0.5
</code></pre>
<p><code>-n</code> 强制 <em>mtr</em> 打印 IP地址而不是主机名</p>
<pre><code class="language-bash">$ mtr -n google.com

Start: Thu Jun 28 12:12:58 2018
HOST: TecMint                     Loss%   Snt   Last   Avg  Best  Wrst StDev
  1.|-- 192.168.0.1                0.0%     5    0.3   0.3   0.3   0.4   0.0
  2.|-- 5.5.5.211                  0.0%     5    0.9   0.9   0.8   1.1   0.0
  3.|-- ???                       100.0     5    0.0   0.0   0.0   0.0   0.0
  4.|-- 72.14.194.226              0.0%     5    2.0   2.0   1.9   2.0   0.0
  5.|-- 108.170.248.161            0.0%     5    2.3   2.3   2.2   2.4   0.0
  6.|-- 216.239.62.237             0.0%     5    3.0   3.2   3.0   3.3   0.0
  7.|-- 172.217.160.174            0.0%     5    3.7   3.6   2.0   5.3   1.4
</code></pre>
<p><code>-b</code> 同时显示IP地址与主机名</p>
<pre><code class="language-bash">$ mtr -b google.com

Start: Thu Jun 28 12:14:36 2018
HOST: TecMint                     Loss%   Snt   Last   Avg  Best  Wrst StDev
  1.|-- 192.168.0.1                0.0%     5    0.3   0.3   0.3   0.4   0.0
  2.|-- 5.5.5.211                  0.0%     5    0.7   0.8   0.6   1.0   0.0
  3.|-- 209.snat-111-91-120.hns.n  0.0%     5    1.4   1.6   1.3   2.1   0.0
  4.|-- 72.14.194.226              0.0%     5    1.8   2.1   1.8   2.6   0.0
  5.|-- 108.170.248.209            0.0%     5    2.0   1.9   1.8   2.0   0.0
  6.|-- 216.239.56.115             0.0%     5    2.4   2.7   2.4   2.9   0.0
  7.|-- bom07s15-in-f14.1e100.net  0.0%     5    3.7   2.2   1.7   3.7   0.9
</code></pre>
<p><code>-c</code> 跟一个具体的值，这将限制 <em>mtr</em> ping的次数，到达次数后会退出</p>
<pre><code class="language-bash">$ mtr -c5 google.com
</code></pre>
<p>如果需要指定次数，并且在退出后保存这些数据，使用 <code>-r</code> flag</p>
<pre><code class="language-bash">$ mtr -r -c 5 google.com &gt;  1
$ cat 1
Start: Sun Aug 21 22:06:49 2022
HOST: xxxxx.xxxxx.xxxx.xxxx Loss%   Snt   Last   Avg  Best  Wrst StDev
  1.|-- gateway                    0.0%     5    0.6 146.8   0.6 420.2 191.4
  2.|-- 212.xx.21.241              0.0%     5    0.4   1.0   0.4   2.3   0.5
  3.|-- 188.xxx.106.124            0.0%     5    0.7   1.1   0.7   2.1   0.5
  4.|-- ???                       100.0     5    0.0   0.0   0.0   0.0   0.0
  5.|-- 72.14.209.89               0.0%     5   43.2  43.3  43.1  43.3   0.0
  6.|-- 108.xxx.250.33             0.0%     5   43.2  43.1  43.1  43.2   0.0
  7.|-- 108.xxx.250.34             0.0%     5   43.7  43.6  43.5  43.7   0.0
  8.|-- 142.xxx.238.82             0.0%     5   60.6  60.9  60.6  61.2   0.0
  9.|-- 142.xxx.238.64             0.0%     5   59.7  67.5  59.3  89.8  13.2
 10.|-- 142.xxx.37.81              0.0%     5   62.7  62.9  62.6  63.5   0.0
 11.|-- 142.xxx.229.85             0.0%     5   61.0  60.9  60.7  61.3   0.0
 12.|-- xx-in-f14.1e100.net  0.0%     5   59.0  58.9  58.9  59.0   0.0
</code></pre>
<p>默认使用的是 ICMP 协议 <code>-i</code> ，可以指定 <code>-u</code>,  <code>-t</code> 使用其他协议</p>
<pre><code class="language-bash">mtr --tcp google.com
</code></pre>
<p><code>-m</code> 指定最大的跳数</p>
<pre><code class="language-bash">mtr -m 35 216.58.223.78
</code></pre>
<p><code>-s</code> 指定包的大小</p>
<h4 id="mtr输出的数据">mtr输出的数据</h4>
<table>
<thead>
<tr>
<th>colum</th>
<th>describe</th>
</tr>
</thead>
<tbody>
<tr>
<td>last</td>
<td>最近一次的探测延迟值</td>
</tr>
<tr>
<td>avg</td>
<td>探测延迟的平均值</td>
</tr>
<tr>
<td>best</td>
<td>探测延迟的最小值</td>
</tr>
<tr>
<td>wrst</td>
<td>探测延迟的最大值</td>
</tr>
<tr>
<td>stdev</td>
<td>标准偏差。越大说明相应节点越不稳定</td>
</tr>
</tbody>
</table>
<h4 id="丢包判断">丢包判断</h4>
<p>任一节点的 <code>Loss%</code>（丢包率）如果不为零，则说明这一跳网络可能存在问题。导致相应节点丢包的原因通常有两种。</p>
<ul>
<li>运营商基于安全或性能需求，人为限制了节点的ICMP发送速率，导致丢包。</li>
<li>节点确实存在异常，导致丢包。可以结合异常节点及其后续节点的丢包情况，来判定丢包原因。</li>
</ul>
<blockquote>
<p>Notes:</p>
<ul>
<li>如果随后节点均没有丢包，则通常说明异常节点丢包是由于运营商策略限制所致。可以忽略相关丢包。</li>
<li>如果随后节点也出现丢包，则通常说明节点确实存在网络异常，导致丢包。对于这种情况，如果异常节点及其后续节点连续出现丢包，而且各节点的丢包率不同，则通常以最后几跳的丢包率为准。如链路测试在第5、6、7跳均出现了丢包。最终丢包情况以第7跳作为参考。</li>
</ul>
</blockquote>
<h4 id="延迟判断">延迟判断</h4>
<p>由于链路抖动或其它因素的影响，节点的 <em>Best</em> 和 <em>Worst</em> 值可能相差很大。而 <em>Avg</em>（平均值）统计了自链路测试以来所有探测的平均值，所以能更好的反应出相应节点的网络质量。而 <em>StDev</em>（标准偏差值）越高，则说明数据包在相应节点的延时值越不相同（越离散）。所以标准偏差值可用于协助判断 <em>Avg</em> 是否真实反应了相应节点的网络质量。例如，如果标准偏差很大，说明数据包的延迟是不确定的。可能某些数据包延迟很小（例如：25ms），而另一些延迟却很大（例如：350ms），但最终得到的平均延迟反而可能是正常的。所以此时 <em>Avg</em> 并不能很好的反应出实际的网络质量情况。</p>
<p>这就需要结合如下情况进行判断：</p>
<ul>
<li>如果 <em>StDev</em> 很高，则同步观察相应节点的 <em>Best</em> 和 <em>wrst</em>，来判断相应节点是否存在异常。</li>
<li>如果<em>StDev</em> 不高，则通过Avg来判断相应节点是否存在异常。</li>
</ul>
<blockquote>
<p>Tips：对于更多的网络工具的使用可以参考这篇<a href="https://www.cnblogs.com/Cylon/p/14946935.html" target="_blank"
   rel="noopener nofollow noreferrer" >文章</a></p>
</blockquote>
<h2 id="pod网络排查流程">Pod网络排查流程</h2>
<p>Pod网络异常时排查思路，可以按照下图所示</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821225201747.png" alt="image-20220821225201747" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Pod network exception troubleshooting idea</center><br>
<h2 id="案例学习">案例学习</h2>
<h3 id="扩容节点访问service地址不通">扩容节点访问service地址不通</h3>
<p><strong>测试环境k8s节点扩容后无法访问集群clusterlP类型的registry服务</strong></p>
<p>环境信息：</p>
<table>
<thead>
<tr>
<th>IP</th>
<th>Hostname</th>
<th>role</th>
</tr>
</thead>
<tbody>
<tr>
<td>10.153.204.15</td>
<td>yxxx-xxx-xxxfu12</td>
<td>worknode节点（本次扩容的问题节点）</td>
</tr>
<tr>
<td>10.153.203.14</td>
<td>yxxx-xxx-xxxxfu31</td>
<td>master节点</td>
</tr>
<tr>
<td>10.61.187.42</td>
<td>yxxx-xxx-xxxxxxxxf8e9</td>
<td>master节点</td>
</tr>
<tr>
<td>10.61.187.48</td>
<td>yxxx-xxx-xxxxxx61e25</td>
<td>master节点（本次registry服务pod所在<br/>节点）</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p>cni插件：flannel vxlan</p>
</li>
<li>
<p>kube-proxy工作模式为iptables</p>
</li>
<li>
<p>registry服务</p>
<ul>
<li>单实例部署在10.61.187.48:5000</li>
<li>Pod IP：10.233.65.46，</li>
<li>Cluster IP：10.233.0.100</li>
</ul>
</li>
</ul>
<p>现象：</p>
<ul>
<li>
<p>所有节点之间的pod通信正常</p>
</li>
<li>
<p>任意节点和Pod curl registry的Pod 的 <em>IP:5000</em> 均可以连通</p>
</li>
<li>
<p>新扩容节点10.153.204.15 curl registry服务的 Cluster lP 10.233.0.100:5000不通，其他节点curl均可以连通</p>
</li>
</ul>
<p>分析思路：</p>
<ul>
<li>
<p>根据现象1可以初步判断 <em>CNI</em> 插件无异常</p>
</li>
<li>
<p>根据现象2可以判断 <em>registry</em> 的 <em>Pod</em> 无异常</p>
</li>
<li>
<p>根据现象3可以判断 <em>registry</em> 的 <em>service</em> 异常的可能性不大，可能是新扩容节点访问 <em>registry</em> 的 <em>service</em> 存在异常</p>
</li>
</ul>
<p>怀疑方向：</p>
<ul>
<li>问题节点的kube-proxy存在异常</li>
<li>问题节点的iptables规则存在异常</li>
<li>问题节点到service的网络层面存在异常</li>
</ul>
<p>排查过程：</p>
<ul>
<li>排查问题节点的<code> kube-proxy</code></li>
<li>执行 <code>kubectl get pod -owide -nkube-system l grep kube-proxy </code>查看 <em>kube-proxy</em> Pod的状态，问题节点上的 <em>kube-proxy</em> Pod为 <em><strong>running</strong></em> 状态</li>
<li>执行 <code>kubecti logs &lt;nodename&gt; &lt;kube-proxy pod name&gt; -nkube-system</code> 查看问题节点 <em>kube-proxy</em>的Pod日志，没有异常报错</li>
<li>在问题节点操作系统上执行 <code>iptables -S -t nat</code> 查看 <code>iptables </code>规则</li>
</ul>
<p>排查过程：</p>
<p>确认存在到 <em>registry</em> 服务的 Cluster lP <em>10.233.0.100</em> 的 <em>KUBE-SERVICES</em> 链，跳转至 <em>KUBE-SVC-*</em> 链做负载均衡，再跳转至 <em>KUBE-SEP-*</em> 链通过 <em>DNAT</em> 替换为服务后端Pod的IP 10.233.65.46。因此判断iptables规则无异常执行route-n查看问题节点存在访问10.233.65.46所在网段的路由，如图所示</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821231943753.png" alt="image-20220821231943753" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：10.233.65.46路由</center><br>
<p>查看对端的回程路由</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821232111046.png" alt="image-20220821232111046" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：回程路由</center><br>
<p>以上排查证明问题原因不是 <em>cni</em> 插件或者 <em>kube-proxy</em> 异常导致，因此需要在访问链路上抓包，判断问题原因、问题节点执行 <code>curl 10.233.0.100:5000</code>，在问题节点和后端pod所在节点的flannel.1上同时抓包发包节点一直在重传，Cluster lP已 <em>DNAT</em> 转换为后端Pod IP，如图所示</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821231845672.png" alt="image-20220821231845672" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：抓包过程，发送端</center><br>
<p>后端Pod（ <em>registry</em> 服务）所在节点的 <em>flannel.1</em> 上未抓到任何数据包，如图所示</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821231730846.png" alt="image-20220821231730846" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：抓包过程，服务端</center><br>
<p>请求 <em>service</em> 的 <em>ClusterlP</em> 时，在两端物理机网卡抓包，发包端如图所示，封装的源端节点IP是10.153.204.15，但一直在重传</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821232249344.png" alt="image-20220821232249344" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：包传送过程，发送端</center><br>
<p>收包端收到了包，但未回包，如图所示</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821232338410.png" alt="image-20220821232338410" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：包传送过程，服务端</center><br>
<p>由此可以知道，NAT的动作已经完成，而只是后端Pod（ <em>registry</em> 服务）没有回包，接下来在问题节点执行 <code>curl 10.233.65.46:5000</code>，在问题节点和后端（ <em>registry</em> 服务）Pod所在节点的 <em>flannel.1</em> 上同时抓包，两节点收发正常，发包如图所示</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821232550959.png" alt="image-20220821232550959" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：正常包发送端</center><br>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821232827589.png" alt="image-20220821232827589" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：正常包接收端</center><br>
<p>接下来在两端物理机网卡接口抓包，因为数据包通过物理机网卡会进行 <em>vxlan</em> 封装，需要抓 <em>vxlan</em> 设备的8472端口，发包端如图所示</p>
<p>发现网络链路连通，==但封装的IP不对==，封装的源端节点IP是10.153.204.228，但是存在问题节点的IP是10.153.204.15</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821233107112.png" alt="image-20220821233107112" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：问题节点物理机网卡接口抓包</center><br>
<p>后端Pod所在节点的物理网卡上抓包，注意需要过滤其他正常节点的请求包，如图所示；发现收到的数据包，源地址是10.153.204.228，但是问题节点的IP是10.153.204.15。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821233258211.png" alt="image-20220821233258211" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：对端节点物理机网卡接口抓包</center><br>
<p>此时问题以及清楚了，是一个Pod存在两个IP，导致发包和回包时无法通过隧道设备找到对端的接口，所以发可以收到，但不能回。</p>
<p>问题节点执行<code>ip addr</code>，发现网卡 <em>enp26s0f0</em>上配置了两个IP，如图所示</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821233642903.png" alt="image-20220821233642903" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：问题节点IP</center><br>
<p>进一步查看网卡配置文件，发现网卡既配置了静态IP，又配置了dhcp动态获取IP。如图所示</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821233741211.png" alt="image-20220821233741211" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：问题节点网卡配置</center><br>
<p>最终定位原因为问题节点既配置了dhcp 获取IP，又配置了静态IP，导致IP冲突，引发网络异常</p>
<p>解决方法：修改网卡配置文件 <code>/etc/sysconfig/network-scripts/ifcfg-enp26s0f0</code> 里 <code>BOOTPROTO=&quot;dhcp&quot;</code>
为 <code>BOOTPROTO=&quot;none&quot;</code>；重启 <em>docker</em> 和 <em>kubelet</em> 问题解决。</p>
<h3 id="集群外云主机调用集群内应用超时">集群外云主机调用集群内应用超时</h3>
<p>问题现象：Kubernetes 集群外云主机以 http post 方式访问Kubernetes 集群应用接口超时</p>
<p>环境信息：Kubernetes 集群：calicoIP-IP模式，应用接口以nodeport方式对外提供服务</p>
<p>客户端：Kubernetes 集群之外的云主机</p>
<p>排查过程：</p>
<ul>
<li>
<p>在云主机telnet应用接口地址和端口，可以连通，证明网络连通正常，如图所示</p>
</li>
<li>
<p>云主机上调用接口不通，在云主机和Pod所在 Kubernetes节点同时抓包，使用wireshark分析数据包</p>
</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821234238398.png" alt="image-20220821234238398" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>通过抓包结果分析结果为TCP链接建立没有问题，但是在传输大数据的时候会一直重传 **1514 **大小的第一个数据包直至超时。怀疑是链路两端MTU大小不一致导致（现象：某一个固定大小的包一直超时的情况）。如图所示，1514大小的包一直在重传。</p>
<p>报文1-3 TCP三次握手正常</p>
<p>报文1 info中MSS字段可以看到MSS协商为1460，MTU=1460+20bytes（IP包头）+20bytes（TCP包头）=1500</p>
<p>报文7 k8s主机确认了包4的数据包，但是后续再没有对数据的ACK</p>
<p>报文21-29 可以看到云主机一直在发送后面的数据，但是没有收到k8s节点的ACK，结合pod未收到任何报文，表明是k8s节点和POD通信出现了问题。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220821234410926.png" alt="image-20220821234410926" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：wireshark分析</center><br>
<p>在云主机上使用 <code>ping -s</code> 指定数据包大小，发现超过1400大小的数据包无法正常发送。结合以上情况，定位是云主机网卡配置的MTU是1500，<em>tunl0</em> 配置的MTU是1440，导致大数据包无法发送至 <em>tunl0</em> ，因此Pod没有收到报文，接口调用失败。</p>
<p>解决方法：修改云主机网卡MTU值为1440，或者修改calico的MTU值为1500，保持链路两端MTU值一致。</p>
<h3 id="集群pod访问对象存储超时">集群pod访问对象存储超时</h3>
<p>环境信息：公有云环境，Kubernetes 集群节点和对象存储在同一私有网络下，网络链路无防火墙限制k8s集群开启了节点自动弹缩（CA）和Pod自动弹缩（HPA），通过域名访问对象存储，Pod使用集群DNS服务，集群DNS服务配置了用户自建上游DNS服务器</p>
<p>排查过程：</p>
<ul>
<li>
<p>使用nsenter工具进入pod容器网络命名空间测试，ping对象存储域名不通，报错unknown server name，ping对象存储lP可以连通。</p>
</li>
<li>
<p><code>telnet</code> 对象存储80/443端口可以连通。</p>
</li>
<li>
<p><code>paping</code> 对象存储 80/443 端口无丢包。</p>
</li>
<li>
<p>为了验证Pod创建好以后的初始阶段网络连通性，将以上测试动作写入dockerfile，重新生成容器镜像并创pod，测试结果一致。</p>
</li>
</ul>
<p>通过上述步骤，判断Pod网络连通性无异常，超时原因为域名解析失败，怀疑问题如下：</p>
<ul>
<li>集群DNS服务存在异常</li>
<li>上游DNS服务存在异常</li>
<li>集群DNS服务与上游DNS通讯异常</li>
<li>pod访问集群DNS服务异常</li>
</ul>
<p>根据上述方向排查，集群DNS服务状态正常，无报错。测试Pod分别使用集群DNS服务和上游DNS服务解析域名，前者解析失败，后者解析成功。至此，证明上游DNS服务正常，并且集群DNS服务日志中没有与上游DNS通讯超时的报错。定位到的问题：==Pod访问集群DNS服务超时==</p>
<p>此时发现，出现问题的Pod集中在新弹出的 Kubernetes 节点上。这些节点的 <code>kube-proxy</code> Pod状态全部为<em>pending</em>，没有正常调度到节点上。因此导致该节点上其他Pod无法访问包括 dns 在内的所有Kubernetes service。</p>
<p>再进一步排查发现 <code>kube-proxy</code> Pod没有配置priorityclass为最高优先级，导致节点资源紧张时为了将高优先级的应用Pod调度到该节点，将原本已运行在该节点的kube-proxy驱逐。</p>
<p>解决方法：将 <code>kube-proxy</code> 设置 <code>priorityclass</code> 值为 <code>system-node-critical</code> 最高优先级，同时建议应用Pod配置就绪探针，测试可以正常连通对象存储域名后再分配任务。</p>
<h2 id="reference">Reference</h2>
<blockquote>
<p><sup id="1">[1]</sup> <a href="https://danielmiessler.com/study/tcpdump/#basic-communication" target="_blank"
   rel="noopener nofollow noreferrer" ><em>A tcpdump Tutorial with Examples</em></a></p>
<p><sup id="2">[2]</sup> <a href="https://laramatic.com/how-to-install-nsenter-in-debian-ubuntu-alpine-arch-kali-centos-fedora-raspbian-and-macos/" target="_blank"
   rel="noopener nofollow noreferrer" ><em>How to install nsenter</em></a></p>
<p><sup id="3">[3]</sup> <a href="https://man7.org/linux/man-pages/man1/nsenter.1.html" target="_blank"
   rel="noopener nofollow noreferrer" ><em>man nsenter</em></a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>详述Kubernetes网络模型</title>
      <link>https://www.oomkill.com/2022/08/kubernetes-network-model/</link>
      <pubDate>Wed, 17 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2022/08/kubernetes-network-model/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="overview">Overview</h2>
<p>本文将深入探讨Kubernetes中的网络模型，以及对各种网络模型进行分析。</p>
<h2 id="underlay-network-model">Underlay Network Model</h2>
<h3 id="什么是underlay-network">什么是Underlay Network</h3>
<p>底层网络 <em>Underlay Network</em> 顾名思义是指网络设备基础设施，如交换机，路由器, <em>DWDM</em> 使用网络介质将其链接成的物理网络拓扑，负责网络之间的数据包传输。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/download.png" alt="典型的底层网络" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Underlay network topology</center>
<center><em>Source：</em>https://community.cisco.com/t5/data-center-switches/understanding-underlay-and-overlay-networks/td-p/4295870</center><br>
<p><em>underlay network</em> 可以是二层，也可以是三层；二层 <em>underlay network</em> 的典型例子是以太网 <em>Ethernet</em>，三层是 <em>underlay network</em> 的典型例子是互联网 <em>Internet</em>。</p>
<p>而工作与二层的技术是 <em>vlan</em>，工作在三层的技术是由 <em>OSPF</em>, <em>BGP</em> 等协议组成</p>
<h3 id="kubernetes中的underlay-network">kubernetes中的underlay network</h3>
<p>在kubernetes中，<em>underlay network</em> 是将宿主机作为路由器设备而，Pod 的网络则通过学习成路由条目从而实现跨节点通讯。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220820230021593.png" alt="image-20220820230021593" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：underlay network topology in kubernetes</center><br>
<p>这种模型下典型的有 <em>flannel</em> 的 <em>host-gw</em> 模式与 <em>calico</em> <em>BGP</em> 模式。</p>
<h4 id="flannel-host-gw-supa-href11asup">flannel host-gw <sup><a href="#1">[1]</a></sup></h4>
<p><em>flannel host-gw</em> 模式中每个Node需要在同一个二层网络中，并将Node作为一个路由器，跨节点通讯将通过路由表方式进行，这样方式下将网络模拟成一个<em>underlay network</em>。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/SwitchDiagram1_update_feb16.jpeg" alt="网络交换机图 1" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：layer2 ethernet topology</center>
<center><em>Source：</em>https://www.auvik.com/franklyit/blog/layer-3-switches-layer-2/</center><br>
<blockquote>
<p>Notes：因为是通过路由方式，集群的cidr至少要配置16，因为这样可以保证，跨节点的Node作为一层网络，同节点的Pod作为一个网络。如果不是这种用情况，路由表处于相同的网络中，会存在网络不可达</p>
</blockquote>
<h4 id="calico-bgp-supa-href22asup">Calico BGP <sup><a href="#2">[2]</a></sup></h4>
<p>BGP（<em>Border Gateway Protocol</em>）是去中心化自治路由协议。它是通过维护IP路由表或&rsquo;前缀&rsquo;表来实现AS （<em>Autonomous System</em>）之间的可访问性，属于向量路由协议。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/ti020109.gif" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：BGP network topology</center>
<center><em>Source：</em>https://infocenter.nokia.com/public/7705SAR214R1A/index.jsp?topic=%2Fcom.sar.routing_protocols%</center><br>
<p>与 <em>flannel</em> 不同的是，<em>Calico</em> 提供了的 <em>BGP</em> 网络解决方案，在网络模型上，<em>Calico</em> 与 <em>Flannel host-gw</em> 是近似的，但在软件架构的实现上，<em>flannel</em> 使用 <em>flanneld</em> 进程来维护路由信息；而 <em>Calico</em> 是包含多个守护进程的，其中 <em>Brid</em> 进程是一个 <em>BGP</em> 的客户端 与路由反射器(<em>Router Reflector</em>)，<em>BGP</em> 客户端负责从 <em>Felix</em> 中获取路由并分发到其他 <em>BGP Peer</em>，而反射器在BGP中起了优化的作用。在同一个IBGP中，BGP客户端仅需要和一个 <em>RR</em> 相连，这样减少了<em>AS</em>内部维护的大量的BGP连接。通常情况下，<em>RR</em> 是真实的路由设备，而 <em>Bird</em> 作为 <em>BGP</em> 客户端工作。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/cisco-nx-os-calico-network-design_0.jpeg" alt="相关图片、图表或屏幕截图" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Calico Network Architecture</center>
<center><em>Source：</em>https://www.cisco.com/c/en/us/td/docs/dcn/whitepapers/cisco-nx-os-calico-network-design.html</center><br>
<h4 id="ipvlan--macvlan-supa-href44asup">IPVLAN &amp; MACVLAN <sup><a href="#4">[4]</a></sup></h4>
<p><em>IPVLAN</em> 和 <em>MACVLAN</em> 是一种网卡虚拟化技术，两者之间的区别为， <em>IPVLAN</em> 允许一个物理网卡拥有多个IP地址，并且所有的虚拟接口用同一个MAC地址；而 <em>MACVLAN</em> 则是相反的，其允许同一个网卡拥有多个MAC地址，而虚拟出的网卡可以没有IP地址。</p>
<p>因为是网卡虚拟化技术，而不是网络虚拟化技术，本质上来说属于 <em>Overlay network</em>，这种方式在虚拟化环境中与<em>Overlay network</em> 相比最大的特点就是可以将Pod的网络拉平到Node网络同级，从而提供更高的性能、低延迟的网络接口。本质上来说其网络模型属于下图中第二个。</p>
<ul>
<li>虚拟网桥：创建一个虚拟网卡对(veth pair)，一头栽容器内，一头栽宿主机的root namespaces内。这样一来容器内发出的数据包可以通过网桥直接进入宿主机网络栈，而发往容器的数据包也可以经过网桥进入容器。</li>
<li>多路复用：使用一个中间网络设备，暴露多个虚拟网卡接口，容器网卡都可以介入这个中间设备，并通过MAC/IP地址来区分packet应该发往哪个容器设备。</li>
<li>硬件交换，为每个Pod分配一个虚拟网卡，这样一来，Pod与Pod之间的连接关系就会变得非常清晰，因为近乎物理机之间的通信基础。如今大多数网卡都支持SR-IOV功能，该功能将单一的物理网卡虚拟成多个VF接口，每个VF接口都有单独的虚拟PCIe通道，这些虚拟的PCIe通道共用物理网卡的PCIe通道。</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/7a021d86-virtual-networking-1024x380.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Virtual networking modes: bridging, multiplexing and SR-IOV</center>
<center><em>Source：</em>https://thenewstack.io/hackers-guide-kubernetes-networking/</center><br>
<p>在kubernetes中 <em>IPVLAN</em> 这种网络模型下典型的CNI有，multus 与 danm。</p>
<h5 id="multus">multus</h5>
<p><em>multus</em> 是 intel 开源的CNI方案，是由传统的 <em>cni</em> 与 <em>multus</em>，并且提供了 SR-IOV CNI 插件使 K8s pod 能够连接到 SR-IOV VF 。这是使用了 <em>IPVLAN/MACVLAN</em> 的功能。</p>
<p>当创建新的Pod后，SR-IOV 插件开始工作。配置 VF 将被移动到新的 CNI 名称空间。该插件根据 CNI 配置文件中的 “name” 选项设置接口名称。最后将VF状态设置为UP。</p>
<p>下图是一个 Multus 和 SR-IOV CNI 插件的网络环境，具有三个接口的 pod。</p>
<ul>
<li><em>eth0</em> 是 <em>flannel</em> 网络插件，也是作为Pod的默认网络</li>
<li>VF 是主机的物理端口 <em>ens2f0</em> 的实例化。这是英特尔X710-DA4上的一个端口。 在Pod端的 VF 接口名称为 <em>south0</em> 。</li>
<li>这个VF使用了 DPDK 驱动程序，此 VF 是从主机的物理端口 <em>ens2f1</em> 实例化出的。这个是英特尔® X710-DA4上另外一个端口。 Pod 内的 VF 接口名称为 <em>north0</em>。该接口绑定到 DPDK 驱动程序 <em>vfio-pci</em> 。</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220817154334081.png" alt="image-20220817154334081" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Mutus networking Architecture overlay and SR-IOV</center>
<center><em>Source：</em>https://builders.intel.com/docs/networkbuilders/enabling_new_features_in_kubernetes_for_NFV.pdf</center><br>
<blockquote>
<p><strong>Notes：terminology</strong></p>
<ul>
<li>NIC：network interface card，网卡</li>
<li>SR-IOV：single root I/O virtualization，硬件实现的功能，允许各虚拟机间共享PCIe设备。</li>
<li>VF：Virtual Function，基于PF，与PF或者其他VF共享一个物理资源。</li>
<li>PF：PCIe Physical Function，拥有完全控制PCIe资源的能力</li>
<li>DPDK：Data Plane Development Kit</li>
</ul>
</blockquote>
<p>于此同时，也可以将主机接口直接移动到Pod的网络名称空间，当然这个接口是必须存在，并且不能是与默认网络使用同一个接口。这种情况下，在普通网卡的环境中，就直接将Pod网络与Node网络处于同一个平面内了。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/multus02.png" alt="布鲁吉" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Mutus networking Architecture overlay and ipvlan</center>
<center><em>Source：</em>https://devopstales.github.io/kubernetes/multus/</center><br>
<h5 id="danm">danm</h5>
<p>DANM是诺基亚开源的CNI项目，目的是将电信级网络引入kubernetes中，与multus相同的是，也提供了SR-IOV/DPDK 的硬件技术，并且支持IPVLAN.</p>
<h2 id="overlay-network-model">Overlay Network Model</h2>
<h3 id="什么是overlay">什么是Overlay</h3>
<p>叠加网络是使用网络虚拟化技术，在 <em>underlay</em> 网络上构建出的虚拟逻辑网络，而无需对物理网络架构进行更改。本质上来说，<em>overlay network</em> 使用的是一种或多种隧道协议 (<em>tunneling</em>)，通过将数据包封装，实现一个网络到另一个网络中的传输，具体来说隧道协议关注的是数据包（帧）。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/Example-Overlay-Network-built-on-top-of-an-Internet-style-Underlay.png" alt="图 4：建立在 Internet 样式底层之上的示例 Overlay 网络" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：overlay network topology</center>
<center><em>Source：</em>https://www.researchgate.net/figure/Example-Overlay-Network-built-on-top-of-an-Internet-style-Underlay_fig4_230774628</center><br>
<h3 id="常见的网络隧道技术">常见的网络隧道技术</h3>
<ul>
<li>通用路由封装 ( <em>Generic Routing Encapsulation</em> ) 用于将来自 IPv4/IPv6的数据包封装为另一个协议的数据包中，通常工作与L3网络层中。</li>
<li>VxLAN (<em>Virtual Extensible LAN</em>)，是一个简单的隧道协议，本质上是将L2的以太网帧封装为L4中UDP数据包的方法，使用 <strong>4789</strong> 作为默认端口。<em>VxLAN</em> 也是 <em>VLAN</em> 的扩展对于 4096（$2^{12}$ 位 <em>VLAN ID</em>） 扩展为1600万（$2^{24}$ 位 <em>VNID</em> ）个逻辑网络。</li>
</ul>
<p>这种工作在 <em>overlay</em> 模型下典型的有 <em>flannel</em> 与 <em>calico</em> 中的的 <em>VxLAN</em>, <em>IPIP</em> 模式。</p>
<h3 id="ipip">IPIP</h3>
<p><em>IP in IP</em> 也是一种隧道协议，与 <em>VxLAN</em> 类似的是，<em>IPIP</em> 的实现也是通过Linux内核功能进行的封装。<em>IPIP</em> 需要内核模块 <code>ipip.ko</code>  使用命令查看内核是否加载IPIP模块<code>lsmod | grep ipip</code> ；使用命令<code>modprobe ipip</code> 加载。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/IPIP_Process.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：A simple IPIP network workflow</center>
<center><em>Source：</em>https://ssup2.github.io/theory_analysis/IPIP_GRE_Tunneling/</center><br>
<p>Kubernetes中 <em>IPIP</em> 与 <em>VxLAN</em> 类似，也是通过网络隧道技术实现的。与 <em>VxLAN</em> 差别就是，<em>VxLAN</em> 本质上是一个 UDP包，而 <em>IPIP</em> 则是将包封装在本身的报文包上。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220817163743182.png" alt="image-20220817163743182" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：IPIP in kubernetes</center><br>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220817163814698.png" alt="image-20220817163814698" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：IPIP packet with wireshark unpack</center><br>
<blockquote>
<p>Notes：公有云可能不允许IPIP流量，例如Azure</p>
</blockquote>
<h3 id="vxlan">VxLAN</h3>
<p>kubernetes中不管是 <em>flannel</em> 还是 <em>calico</em> VxLAN的实现都是使用Linux内核功能进行的封装，Linux 对 vxlan 协议的支持时间并不久，2012 年 Stephen Hemminger 才把相关的工作合并到 kernel 中，并最终出现在 kernel 3.7.0 版本。为了稳定性和很多的功能，你可以会看到某些软件推荐在 3.9.0 或者 3.10.0 以后版本的 kernel 上使用 <em>VxLAN</em>。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220815232351298.png" alt="image-20220815232351298" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：A simple VxLAN network topology</center><br>
<p>在kubernetes中vxlan网络，例如 <em>flannel</em>，守护进程会根据kubernetes的Node而维护 <em>VxLAN</em>，名称为 <code>flannel.1</code> 这是 <em>VNID</em>，并维护这个网络的路由，当发生跨节点的流量时，本地会维护对端 <em>VxLAN</em> 设备的MAC地址，通过这个地址可以知道发送的目的端，这样就可以封包发送到对端，收到包的对端 VxLAN设备 <code>flannel.1</code>  解包后得到真实的目的地址。</p>
<p>查看 <em>Forwarding database</em> 列表</p>
<pre><code class="language-bash">$ bridge fdb 
26:5e:87:90:91:fc dev flannel.1 dst 10.0.0.3 self permanent
</code></pre>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220816161418748.png" alt="image-20220816161418748" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：VxLAN in kubernetes</center><br>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220816164301428.png" alt="image-20220816164301428" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：VxLAN packet with wireshark unpack</center><br>
<blockquote>
<p>Notes：VxLAN使用的4789端口，wireshark应该是根据端口进行分析协议的，而flannel在linux中默认端口是8472，此时抓包仅能看到是一个UDP包。</p>
</blockquote>
<p>通过上述的架构可以看出，隧道实际上是一个抽象的概念，并不是建立的真实的两端的隧道，而是通过将数据包封装成另一个数据包，通过物理设备传输后，经由相同的设备（网络隧道）进行解包实现网络的叠加。</p>
<h3 id="weave-vxlan-supa-href33asup">weave vxlan <sup><a href="#3">[3]</a></sup></h3>
<p>weave也是使用了 <em>VxLAN</em> 技术完成的包的封装，这个技术在 <em>weave</em> 中称之为 <em>fastdp (fast data path)</em>，与 <em>calico</em> 和 <em>flannel</em> 中用到的技术不同的，这里使用的是 Linux 内核中的 <em>openvswitch datapath module</em>。与其他的 <em>VxLAN</em> 模型不同的是，weave对网络流量进行了加密。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/weave-net-fdp1-1024x454.png" alt="Weave Net Encapsulation" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：weave fastdp network topology</center>
<center><em>Source：</em>https://www.weave.works/docs/net/latest/concepts/fastdp-how-it-works/</center><br>
<blockquote>
<p>Notes：fastdp工作在Linux 内核版本 3.12 及更高版本，如果低于此版本的例如CentOS7，weave将工作在用户空间，weave中称之为 <em>sleeve mode</em></p>
</blockquote>
<blockquote>
<p><strong>Reference</strong></p>
<p><sup id="1">[1]</sup> <a href="https://github.com/flannel-io/flannel/blob/master/Documentation/backends.md#host-gw" target="_blank"
   rel="noopener nofollow noreferrer" >flannel host-gw</a></p>
<p><sup id="2">[2]</sup> <a href="https://projectcalico.docs.tigera.io/networking/bgp" target="_blank"
   rel="noopener nofollow noreferrer" >calico bgp networking</a></p>
<p><sup id="3">[3]</sup> <a href="https://www.weave.works/docs/net/latest/concepts/router-encapsulation/" target="_blank"
   rel="noopener nofollow noreferrer" >calico bgp networking</a></p>
<p><sup id="4">[4]</sup> <a href="https://github.com/k8snetworkplumbingwg/sriov-network-device-plugin" target="_blank"
   rel="noopener nofollow noreferrer" >sriov network</a></p>
<p><sup id="4">[5]</sup> <a href="https://github.com/nokia/danm" target="_blank"
   rel="noopener nofollow noreferrer" >danm</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>calico网络策略</title>
      <link>https://www.oomkill.com/2021/02/calico-network-policy/</link>
      <pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2021/02/calico-network-policy/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="什么是网络策略">什么是网络策略</h2>
<p>在Kubernetes平台中，要实现零信任网络的安全架构，Calico与istio是在Kubernetes集群中构建零信任网络必不可少的组件。</p>
<p>而建立和维护整个集群中的“零信任网络”中，网络策略的功能在操作上大致可以总结为<strong>使用资源配置模板来管理控制平面数据流</strong>。说白了讲网络策略就是用来控制Pod间流量的规则。</p>
<h2 id="在calico中如何编写网络策略">在Calico中如何编写网络策略</h2>
<p>要使用网络策略就需要先了解Calico功能**：NetworkPolicy<strong>和</strong>GlobalNetworkPolicy**。</p>
<p><code>NetworkPolicy</code>资源，简称<code>np</code>；是命名空间级别资源。规则应用于与标签选择器匹配的endpoint的集合。</p>
<p><code>GlobalNetworkPolicy</code>资源，简称 <code>gnp</code>/<code>gnps</code>与<code>NetworkPolicy</code>功能一样，是整个集群级别的资源。</p>
<p><code>GlobalNetworkPolicy</code> 与 <code>NetworkPolicy</code>资源的管理也与calico的部署方式有关，使用etcd作为存储时，资源的管理只能使用 <code>calicoctl</code>进行管理</p>
<h3 id="networkpolicy与globalnetworkpolicy的构成">NetworkPolicy与GlobalNetworkPolicy的构成</h3>
<pre><code class="language-yaml">apiVersion: projectcalico.org/v3
kind: NetworkPolicy
metadata:
  name: allow-tcp-90
spec:
  selector: app == 'envoy' # 应用此策略的endpoint
  types: # 应用策略的流量方向
    - Ingress 
    - Egress
  ingress: # 入口的流量规则
    - action: Allow # 流量的行为
      protocol: ICMP # 流量的协议
      notProtocol: TCP # 匹配流量协议不为 值 的流量 
      source: # 流量的来源 src与dst的匹配关系为 与，所有的都生效即生效
        nets: # 有效的来源IP
        selector: # 标签选择器
        namespaceSelector: # 名称空间选择器
        ports: # 端口
        - 80 # 单独端口
        - 6040:6050	# 端口范围
      destination: # 流量的目标
  egress: # 出口的流量规则
    - action: Allow
  serviceAccountSelector: # 使用与此规则的serviceAccount
</code></pre>
<h3 id="networkpolicy使用">NetworkPolicy使用</h3>
<p>实例：允许6379流量可以被 <code>role=frontend</code>的pod访问</p>
<pre><code class="language-yaml">apiVersion: projectcalico.org/v3
kind: NetworkPolicy
metadata:
  name: allow-tcp-6379
  namespace: production
spec:
  selector: role == 'database'
  types:
  - Ingress
  - Egress
  ingress:
  - action: Allow
    metadata:
      annotations:
        from: frontend
        to: database
    protocol: TCP
    source:
      selector: role == 'frontend'
    destination:
      ports:
      - 6379
  egress:
  - action: Allow
</code></pre>
<p>实例：禁止ICMP流量</p>
<pre><code class="language-yaml">apiVersion: projectcalico.org/v3
kind: NetworkPolicy
metadata:
  name: allow-tcp-90
spec:
  selector: app == 'netbox'
  types:
    - Ingress
    - Egress
  ingress:
    - action: Deny
      protocol: ICMP
  egress:
    - action: Deny
      protocol: ICMP
</code></pre>
<p>实例：禁止访问指定服务</p>
<pre><code class="language-yaml">apiVersion: projectcalico.org/v3
kind: NetworkPolicy
metadata:
  name: allow-tcp-90
spec:
  selector: app == 'netbox'
  types:
    - Ingress
    - Egress
  ingress:
    - action: Allow
  egress:
    - action: Deny
      destination:
        selector: app == 'envoy'
</code></pre>
<h2 id="globalnetworkpolicy">GlobalNetworkPolicy</h2>
<p>GlobalNetworkPolicy与NetworkPolicy使用方法基本一致，只是作用域的不同，并且可以应用很多高级的网络策略：</p>
<ul>
<li><a href="https://docs.projectcalico.org/security/host-forwarded-traffic" target="_blank"
   rel="noopener nofollow noreferrer" >转发流量</a></li>
<li><a href="https://docs.projectcalico.org/security/defend-dos-attack" target="_blank"
   rel="noopener nofollow noreferrer" >防御DoS</a></li>
<li>&hellip;.</li>
</ul>
<p><strong>GlobalNetworkPolicy</strong> 中提供了一个preDNAT的功能，是kube-proxy对Node port的端口和IP的流量DNAT到所对应的Pod中的时候，为了既允许正常的ingress流量，又拒绝其他的ingress流量，这个时候必须要在DNAT前生效，这种情况需要使用<strong>preDNAT</strong>。</p>
<p><strong>preDNAT</strong> 适用的条件是，流量仅为ingress并且在DNAT之前。</p>
<h2 id="reference">Reference</h2>
<blockquote>
<p><a href="https://docs.projectcalico.org/reference/resources/networkpolicy#spec" target="_blank"
   rel="noopener nofollow noreferrer" >NetworkPolicy.spec</a></p>
<p><a href="https://docs.projectcalico.org/reference/resources/networkpolicy#rule" target="_blank"
   rel="noopener nofollow noreferrer" >NetworkPolicy.spec.ingress|egress</a></p>
<p><a href="https://docs.projectcalico.org/reference/resources/networkpolicy#entityrule" target="_blank"
   rel="noopener nofollow noreferrer" >NetworkPolicy.spec.ingress.src|dst</a></p>
<p><a href="https://docs.projectcalico.org/reference/resources/globalnetworkpolicy" target="_blank"
   rel="noopener nofollow noreferrer" >globalnetworkpolicy</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>基于混合云模式的calico部署</title>
      <link>https://www.oomkill.com/2021/02/calico-deploy-on-hybrid-cloud/</link>
      <pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2021/02/calico-deploy-on-hybrid-cloud/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="开始前准备">开始前准备</h2>
<p>确定calico数据存储</p>
<p>Calico同时支持kubernetes api和etcd数据存储。官方给出的建议是在本地部署中使用<strong>K8S API</strong>，仅支持Kubernetes模式。而官方给出的etcd则是混合部署（Calico作为Kubernetes和OpenStack的网络插件运行）的最佳数据存储。</p>
<p>使用etcd作为calico数据存储的好处：</p>
<ul>
<li>允许多平台混用calico，如Kubernetes OpenStack上运行Calico</li>
<li>Kubernetes资源与Calico资源分离</li>
<li>一个Calico群集，该群集不仅仅包含一个Kubernetes群集，如可与多个kubernetes集群互通。</li>
</ul>
<p>坏处：</p>
<ul>
<li>安装步骤繁琐</li>
<li>无法使用Kubernetes RBAC对calico资源的控制</li>
<li>无法使用Kubernetes资源对calico进行管理</li>
</ul>
<h3 id="下载calico部署清单">下载calico部署清单</h3>
<pre><code>curl https://docs.projectcalico.org/manifests/calico-etcd.yaml -o calico.yaml
</code></pre>
<h3 id="修改pod-cidr">修改Pod CIDR</h3>
<p>　Calico默认的Pod CIDR使用的是<code>192.168.0.0/16</code>，这里一般使用与controller-manager中的<code>--cluster-cidr</code> 保持一,取消资源清单内的 <code>CALICO_IPV4POOL_CIDR</code>变量的注释，并将其设置为与所选Pod CIDR相同的值。</p>
<h3 id="calico的ip分配范围">calico的IP分配范围</h3>
<p>　Calico IPAM从<code>ipPool</code>分配IP地址。修改Pod的默认IP范围则修改清单<code>calico.yaml</code>中的<code>CALICO_IPV4POOL_CIDR</code></p>
<h3 id="配置calico的-ip-in-ip">配置Calico的 <code>IP in IP</code></h3>
<p>默认情况下，Calico中的IPIP已经禁用，这里使用的v3.17.2 低版本默认会使用IPIP</p>
<p>要开启IPIP mode则需要修改配置清单内的 <code>CALICO_IPV4POOL_IPIP</code> 环境变量改为 <code>always</code></p>
<h3 id="修改secret">修改secret</h3>
<pre><code class="language-yaml">  # Populate the following with etcd TLS configuration if desired, but leave blank if
  # not using TLS for etcd.
  # The keys below should be uncommented and the values populated with the base64
  # encoded contents of each file that would be associated with the TLS data.
  # Example command for encoding a file contents: cat &lt;file&gt; | base64 -w 0
  # etcd的ca
etcd-ca: # 填写上面命令编码后的值
# etcd客户端key
etcd-key: # 填写上面命令编码后的值
# etcd客户端访问证书
etcd-cert: # 填写上面命令编码后的值
</code></pre>
<h3 id="修改configmap">修改configMap</h3>
<pre><code class="language-yaml">  etcd_endpoints: &quot;https://10.0.0.6:2379&quot;
  # If you're using TLS enabled etcd uncomment the following.
  # You must also populate the Secret below with these files.
  etcd_ca: &quot;/calico-secrets/etcd-ca&quot;
  etcd_cert: &quot;/calico-secrets/etcd-cert&quot;
  etcd_key: &quot;/calico-secrets/etcd-key&quot;
</code></pre>
<h2 id="开始安装">开始安装</h2>
<pre><code>kubectl apply -f calico.yaml
</code></pre>
<h2 id="安装出错">安装出错</h2>
<p><code>/calico-secrets/etcd-cert: permission denied</code></p>
<pre><code>2021-02-08 02:15:10.485 [INFO][1] main.go 88: Loaded configuration from environment config=&amp;config.Config{LogLevel:&quot;info&quot;, WorkloadEndpointWorkers:1, ProfileWorkers:1, PolicyWorkers:1, NodeWorkers:1, Kubeconfig:&quot;&quot;, DatastoreType:&quot;etcdv3&quot;}
2021-02-08 02:15:10.485 [FATAL][1] main.go 101: Failed to start error=failed to build Calico client: could not initialize etcdv3 client: open /calico-secrets/etcd-cert: permission denied
</code></pre>
<p>找到资源清单内的对应容器（<code>calico-kube-controllers</code>）的配置。在卷装载中设置440将解决此问题</p>
<pre><code class="language-yaml">volumes:
# Mount in the etcd TLS secrets with mode 400.
# See https://kubernetes.io/docs/concepts/configuration/secret/
- name: etcd-certs
  secret:
  secretName: calico-etcd-secrets
  defaultMode: 0400 # 改为0440
</code></pre>
<h2 id="修改calicoctl的数据源">修改calicoctl的数据源</h2>
<p>　使用单独的etcd作为calico数据存储还需要修改calicoctl数据存储访问配置</p>
<p>　<code>calicoctl</code> 在默认情况下，查找配置文件的路径为<code>/etc/calico/calicoctl.cfg</code>上。可以使用<code>--config</code>覆盖此选项默认配置（使用中测试不成功，官方给出有这个方法）。</p>
<p>　如果<code>calicoctl</code>无法获得配置文件，将检查环境变量。</p>
<pre><code class="language-yaml">apiVersion: projectcalico.org/v3
kind: CalicoAPIConfig
metadata:
spec:
  datastoreType: etcdv3
  etcdEndpoints: &quot;https://10.0.0.6:2379&quot;
  etcdCACert: |
    # 这里填写etcd ca证书文件的内容，无需转码base64
  etcdCert: |
    # 这里填写etcd client证书文件的内容，无需转码base64
  etcdKey: |
    # 这里填写etcd client秘钥文件的内容，无需转码base64
</code></pre>
<blockquote>
<p>reference：</p>
<p><a href="https://github.com/kubernetes/website/issues/25587" target="_blank"
   rel="noopener nofollow noreferrer" >Secret permission denied</a></p>
<p><a href="https://docs.projectcalico.org/getting-started/clis/calicoctl/configure/overview" target="_blank"
   rel="noopener nofollow noreferrer" >configuration calicoctl</a></p>
<p><a href="https://docs.projectcalico.org/reference/installation/api" target="_blank"
   rel="noopener nofollow noreferrer" >calico installation</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>calico network cni网络方案</title>
      <link>https://www.oomkill.com/2021/01/calico-network-cni/</link>
      <pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2021/01/calico-network-cni/</guid>
      <description></description>
      <content:encoded><![CDATA[<p>Calico针对容器、虚拟机的开源网络和网络安全解决方案。是纯三层的数据中心网络方案。</p>
<p>Calico在每一个计算节点利用Linux Kernel实现了一个高效的虚拟路由器<code>vRouter</code>来负责数据转发，而每个<code>vRouter</code>通过BGP协议负责把自己上运行的workload的路由信息向整个Calico网络内传播。（小规模部署可以直接互联 <code>BGP full mesh</code>，大规模下可通过指定的<code>BGP route reflector</code>来完成）。 这样保证最终所有的<code>workload</code>之间的数据流量都是通过IP路由的方式完成互联的。Calico节点组网可以直接利用数据中心的网络结构（无论是L2或者L3），不需要额外的<code>NAT</code>，隧道或者<code>Overlay Network</code>。</p>
<p>Calico还基于<code>iptables</code>还提供了丰富而灵活的网络<code>Policy</code>，保证通过各个节点上的<code>ACLs</code>来提供Workload的多租户隔离、安全组以及其他可达性限制等功能。</p>
<h3 id="calico组件">calico组件</h3>
<p>在Kubernetes平台之上<code>calico/node</code>容器会通过DaemonSet部署到每个节点，并运行三个守护程序：</p>
<ul>
<li>Felix：用于管理路由规则，负责状态上报。</li>
<li>BIRD：BGP的客户端，用于将Felix的路由信息加载到内核中，同时负责路由信息在集群中的分发。</li>
<li>confd：用于监视Calico存储（etcd）中的配置变更并更新<code>BIRD</code>的配置文件。</li>
</ul>
<p>calicoctl使用问题</p>
<pre><code>Failed to create Calico API client: invalid configuration: no configuration has been provided
</code></pre>
<p>默认情况下，<code>calicoctl</code> 将使用位于的默认<code>KUBECONFIG</code>从 Kubernetes APIServer 读取<code>$(HOME)/.kube/config</code> 。</p>
<p>如果默认的 <code>KUBECONFIG</code> 不存在，或者想从指定的存储访问信息，则需要单独配置。</p>
<pre><code class="language-bash">export DATASTORE_TYPE=kubernetes
export DATASTORE_TYPE=etcdv3
export KUBECONFIG=~/.kube/config
</code></pre>
<p><a href="https://docs.projectcalico.org/getting-started/clis/calicoctl/configure/" target="_blank"
   rel="noopener nofollow noreferrer" >reference for</a></p>
<h2 id="calico-安装配置">calico 安装配置</h2>
<p>开始前准备</p>
<p>确定calico数据存储</p>
<p>Calico同时支持kubernetes api和etcd数据存储。官方给出的建议是在本地部署中使用<strong>K8S API</strong>，仅支持Kubernetes模式。而官方给出的etcd则是混合部署（Calico作为Kubernetes和OpenStack的网络插件运行）的最佳数据存储。</p>
<p>使用kubernetes api作为数据存储的安装</p>
<pre><code>curl https://docs.projectcalico.org/manifests/calico.yaml -O
kubectl apply -f calico.yaml
</code></pre>
<p>修改Pod CIDR</p>
<p>Calico默认的Pod CIDR使用的是<code>192.168.0.0/16</code>，这里一般使用与controller-manager中的<code>--cluster-cidr</code> 保持一,取消资源清单内的 <code>CALICO_IPV4POOL_CIDR</code>变量的注释，并将其设置为与所选Pod CIDR相同的值。</p>
<p>calico的IP分配范围</p>
<p>Calico IPAM从<code>ipPool</code>分配IP地址。修改Pod的默认IP范围则修改清单<code>calico.yaml</code>中的 <code>CALICO_IPV4POOL_CIDR</code></p>
<p>配置Calico的 <code>IP in IP</code></p>
<p>默认情况下，Calico中的IPIP已经禁用，这里使用的v3.17.2 低版本默认会使用IPIP</p>
<p>要开启IPIP mode则需要修改配置清单内的 <code>CALICO_IPV4POOL_IPIP</code> 环境变量改为 <code>always</code></p>
<p>修改secret</p>
<pre><code class="language-yaml">  # Populate the following with etcd TLS configuration if desired, but leave blank if
  # not using TLS for etcd.
  # The keys below should be uncommented and the values populated with the base64
  # encoded contents of each file that would be associated with the TLS data.
  # Example command for encoding a file contents: cat &lt;file&gt; | base64 -w 0
  # etcd的ca
etcd-ca: # 填写上面命令编码后的值
# etcd客户端key
etcd-key: # 填写上面命令编码后的值
# etcd客户端访问证书
etcd-cert: # 填写上面命令编码后的值
</code></pre>
<p>修改configMap</p>
<pre><code class="language-yaml">  etcd_endpoints: &quot;https://10.0.0.6:2379&quot;
  # If you're using TLS enabled etcd uncomment the following.
  # You must also populate the Secret below with these files.
  etcd_ca: &quot;/calico-secrets/etcd-ca&quot;
  etcd_cert: &quot;/calico-secrets/etcd-cert&quot;
  etcd_key: &quot;/calico-secrets/etcd-key&quot;
</code></pre>
<p>在卷装载中设置440将解决此问题</p>
<p><code>/calico-secrets/etcd-cert: permission denied</code></p>
<pre><code>2021-02-08 02:15:10.485 [INFO][1] main.go 88: Loaded configuration from environment config=&amp;config.Config{LogLevel:&quot;info&quot;, WorkloadEndpointWorkers:1, ProfileWorkers:1, PolicyWorkers:1, NodeWorkers:1, Kubeconfig:&quot;&quot;, DatastoreType:&quot;etcdv3&quot;}
2021-02-08 02:15:10.485 [FATAL][1] main.go 101: Failed to start error=failed to build Calico client: could not initialize etcdv3 client: open /calico-secrets/etcd-cert: permission denied
</code></pre>
<p>找到资源清单内的对应容器（<code>calico-kube-controllers</code>）的配置。</p>
<pre><code class="language-yaml">volumes:
# Mount in the etcd TLS secrets with mode 400.
# See https://kubernetes.io/docs/concepts/configuration/secret/
- name: etcd-certs
  secret:
  secretName: calico-etcd-secrets
  defaultMode: 0400 # 改为0440
</code></pre>
<p>使用单独的etcd作为calico数据存储还需要修改calicoctl数据存储访问配置</p>
<p><code>calicoctl</code> 在默认情况下，查找配置文件的路径为<code>/etc/calico/calicoctl.cfg</code>上。可以使用<code>--config</code>覆盖此选项默认配置。</p>
<p>如果<code>calicoctl</code>无法获得配置文件，将检查环境变量。</p>
<pre><code class="language-yaml">apiVersion: projectcalico.org/v3
kind: CalicoAPIConfig
metadata:
spec:
  datastoreType: etcdv3
  etcdEndpoints: &quot;https://10.0.0.6:2379&quot;
  etcdCACert: |
    # 这里填写etcd ca证书文件的内容，无需转码base64
  etcdCert: |
    # 这里填写etcd client证书文件的内容，无需转码base64
  etcdKey: |
    # 这里填写etcd client秘钥文件的内容，无需转码base64
</code></pre>
<blockquote>
<p>reference：</p>
<p><a href="https://github.com/kubernetes/website/issues/25587" target="_blank"
   rel="noopener nofollow noreferrer" >Secret permission denied</a></p>
<p><a href="https://docs.projectcalico.org/getting-started/clis/calicoctl/configure/overview" target="_blank"
   rel="noopener nofollow noreferrer" >configuration calicoctl</a></p>
</blockquote>
<pre><code>eb  7 21:25:13 master01 etcd: recognized environment variable ETCD_NAME, but unused: shadowed by corresponding flag
Feb  7 21:25:13 master01 etcd: unrecognized environment variable ETCD_SERVER_NAME=hk.etcd
Feb  7 21:25:13 master01 etcd: recognized environment variable ETCD_DATA_DIR, but unused: shadowed by corresponding flag
Feb  7 21:25:13 master01 etcd: recognized environment variable ETCD_LISTEN_CLIENT_URLS, but unused: shadowed by corresponding flag
Feb  7 21:25:13 master01 etcd: etcd Version: 3.3.11
Feb  7 21:25:13 master01 etcd: Git SHA: 2cf9e51
Feb  7 21:25:13 master01 etcd: Go Version: go1.10.3
Feb  7 21:25:13 master01 etcd: Go OS/Arch: linux/amd64
Feb  7 21:25:13 master01 etcd: setting maximum number of CPUs to 2, total number of available CPUs is 2
Feb  7 21:25:13 master01 etcd: the server is already initialized as member before, starting as etcd member...
Feb  7 21:25:13 master01 etcd: peerTLS: cert = /etc/etcd/pki/peer.crt, key = /etc/etcd/pki/peer.key, ca = , trusted-ca = /etc/etcd/pki/ca.crt,
 client-cert-auth = true, crl-file =
Feb  7 21:25:13 master01 etcd: listening for peers on https://10.0.0.5:2380
Feb  7 21:25:13 master01 etcd: listening for client requests on 10.0.0.5:2379
Feb  7 21:25:13 master01 etcd: panic: freepages: failed to get all reachable pages (page 3471766746605708656: out of bounds: 1633)
</code></pre>
<p>集群节点损坏</p>
<pre><code>panic: freepages: failed to get all reachable pages (page 3471766746605708656: out of bounds: 1633)
</code></pre>
<p>这是k8s不支持当前calico版本的原因, calico版本与k8s版本支持关系可到calico官网查看:</p>
<pre><code class="language-bash">error: unable to recognize &quot;calico.yaml&quot;: no matches for kind &quot;PodDisruptionBudget&quot; in version &quot;policy/v1&quot;
</code></pre>
<p>配置SW</p>
<pre><code>system-view
sysname SW1
vlan batch 10 20 30

interface GigabitEthernet0/0/1
port link-type trunk
port trunk allow-pass vlan 10 20 30

interface GigabitEthernet0/0/2
port link-type trunk
port trunk allow-pass vlan 10 20 30

interface GigabitEthernet0/0/3
port link-type trunk
port trunk allow-pass vlan 10 20 30
</code></pre>
<p>配置路由器间的ospf</p>
<pre><code>interface l0
ip address 1.1.1.1 32
quit
ospf router-id 1.1.1.1
area 0
network 1.1.1.1 0.0.0.0
network 10.0.0.253 0.0.0.0
dis this

interface l0
ip address 2.2.2.2 32
quit
ospf router-id 2.2.2.2
area 0
network 2.2.2.2 0.0.0.0
network 10.0.0.254 0.0.0.0
dis this
</code></pre>
<p>配置两个k8s节点与路由器之间的bgp</p>
<pre><code>system-view
sysname R1

interface GigabitEthernet0/0/0
ip address 10.0.0.253 24
dis this
quit

bgp 64512
router-id 10.0.0.253
peer 10.0.0.5 as-number 64512
peer 10.0.0.5 reflect-client
dis ip interface brief



system-view
sysname R2

interface GigabitEthernet0/0/0
ip address 10.0.0.254 24
dis this
quit

bgp 63400
router-id 10.0.0.254
peer 10.0.0.6 as-number 63400
peer 10.0.0.6 reflect-client
dis ip interface brief

bgp 64512
router-id 10.0.0.253 
peer 2.2.2.2 as-number 63400


bgp 63400
router-id 10.0.0.254
peer 1.1.1.1 as-number 64512
</code></pre>
]]></content:encoded>
    </item>
    
    <item>
      <title>Linux虚拟网络技术</title>
      <link>https://www.oomkill.com/2021/01/virtual-networking/</link>
      <pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2021/01/virtual-networking/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="overview">Overview</h2>
<p>本文将介绍Kubernetes中使用的相关虚拟网络功能，目的是为了任何无相关网络背景经历的人都可以了解这些技术在kubernetes中式如何应用的。</p>
<h2 id="vlan">VLAN</h2>
<p><em><strong>VLAN</strong></em> (Virtual local area networks)是逻辑上的LAN而不受限于同一物理网络交换机上。同样的VLAN也可以将同一台交换机/网桥下的设备/划分为不同的子网。</p>
<p><em><strong>VLAN</strong></em> 区分的广播域的标准是VLAN ID，此功能是Linux内核3.8中引入的</p>
<p>在Linux中创建一个VLAN</p>
<pre><code class="language-bash">ip link add link eth0 name eth0.2 type vlan id 2
</code></pre>
<h2 id="veth-supa-href11asup">VETH <sup><a href="#1">[1]</a></sup></h2>
<p><em><strong>VETH</strong></em> (Virtual Ethernet device)，是一个本地的以太网隧道，创建出的设备是成对的，通常会存在两个名称空间内，例如在docker中创建出的设备一端在root名称空间内，一端被挂在到容器的名称空间内。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/1tOiYnJv7sx0twVBJGX_zgg.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：veth topology</center>
<center><em>Source：</em>https://medium.com/@arpitkh96/basics-of-container-networking-with-linux-part-1-3a3cdc64c87a</center><br>
<pre><code class="language-bash">ip link add &lt;p1-name&gt; type veth peer name &lt;p2-name&gt;
</code></pre>
<h2 id="bridge">Bridge</h2>
<h2 id="目的">目的</h2>
<p>Linux <strong>bridge</strong>（又称为网桥、VLAN交换机）是Linux内核中集成的功能，用来做tcp/ip做二层协议交换的设备，虽然是软件实现的，但它与普通的二层物理交换机功能一样。<em><strong>bridge</strong></em>  就是为了解决虚拟机网卡连接问题。可以添加若干个网络设备到 <em><strong>bridge</strong></em> 上作为其接口，添加到 <em><strong>bridge</strong></em> 上的设备被设置为只接受二层数据帧并且转发所有收到的数据包到 <em><strong>bridge</strong></em> 中。</p>
<p>由于 Linux <em><strong>bridge</strong></em> 是二层设备，故数据包是根据MAC地址而不是IP转发的。因此所有协议都可以透明地通过网桥。Linux <em><strong>bridge</strong></em> 广泛用于虚拟机，名称空间等。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/1NZpkyrCpcQMxkUHNsNtFVA.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：Linux Bridge</center>
<center><em>Source：</em>https://kbespalov.medium.com/linux-linux-bridge-7e0e887edd01</center><br>
<h2 id="macvlan-supa-href22asup">MACVLAN <sup><a href="#2">[2]</a></sup></h2>
<p><em><strong>MACVLAN</strong></em> 允许在一个物理接口创建多个子接口，并且每个子接口都拥有一个随机生成的MAC地址，与IP地址。</p>
<p><em><strong>MACVLAN</strong></em> 中子接口不能与与父接口直接通讯，例如在虚拟化环境中，容器是不能ping通宿主机的IP，如果子接口需要和父接口进行通讯，需要将子接口分配给父接口。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/linux-macvlan.png" alt="Linux macvlan" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：MACVLAN</center>
<center><em>Source：</em>https://hicu.be/bridge-vs-macvlan</center><br>
<p>从 Linux 内核3.0起，MAC已经是linux内核中的一部分。</p>
<ul>
<li>
<p>查看内核是否加载 <code>lsmod | grep macvlan</code></p>
</li>
<li>
<p>加载macvlan模块 <code>modprobe macvlan</code></p>
</li>
<li>
<p>如果需要每次启动时都加载该模块，<code>echo &quot;macvlan&quot; &gt;&gt; /etc/modules</code></p>
</li>
</ul>
<h3 id="macvlan的限制">MACVLAN的限制</h3>
<p>限制：</p>
<ul>
<li>使用MACVLAN技术需要开启网卡的混杂模式</li>
<li>授予NIC支持的MAC数量限制，超出限制会影响性能</li>
<li>MACVLAN不能工作在wireless网络环境中 <sup><a href="#3">[3]</a></sup></li>
</ul>
<h3 id="macvlan的模式">MACVLAN的模式</h3>
<p>MACVLAN又五种类型：</p>
<ul>
<li>Private</li>
<li>VEPA</li>
<li>Bridge</li>
<li>Passthru</li>
<li>Source</li>
</ul>
<h4 id="private-mode">Private mode</h4>
<p>Private模式下的同一物理接口下的子接口将不允许通讯，即使物理设备支持hairpin也不行。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/linux-macvlan-private-mode.png" alt="Macvlan 私有模式" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：MACVLAN Private mod</center>
<center><em>Source：</em>https://hicu.be/bridge-vs-macvlan</center><br>
<blockquote>
<p><em><strong>hairpin</strong></em> 有多个名称，<em><strong>U-turn NAT</strong></em>, <em><strong>NAT loopback</strong></em>，实际上就是一种网络转换，在一个网络中的两个设备使用外部IP进行通讯。在MACVLAN这个例子中，veth1发往veth2的流量通过外部设备switch进行一个回转，这个行为称为为 <em><strong>hairpin turn</strong></em>。从上图也可以看出，是一个U形的转换。</p>
</blockquote>
<h4 id="vpea-mode">VPEA mode</h4>
<p><em><strong>VPEA</strong></em> 将会将来自子接口的通过父接口转发，这将要求物理交换机需要支持 <em><strong>hairpin</strong></em></p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/linux-macvlan-802.1qbg-vepa-mode.png" alt="Macvlan 802.1qbg VEPA 模式" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：MACVLAN VPEA mode</center>
<center><em>Source：</em>https://hicu.be/bridge-vs-macvlan</center><br>
<h4 id="bridge-mode">Bridge mode</h4>
<p><em><strong>Bridge</strong></em> 是指父接口与所有子接口是通过网桥相连的，因为连接在网桥上，不需要学习MAC地址。这也是容器网络中常用到的模式</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/linux-macvlan-bridge-mode.png" alt="Macvlan 桥接模式" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：MACVLAN bridge mode</center>
<center><em>Source：</em>https://hicu.be/bridge-vs-macvlan</center><br>
<h4 id="passthru">Passthru</h4>
<p><em><strong>passthru</strong></em> 是 pass through，由名字也可以得知，是指允许单个VM与物理接口连接。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/linux-macvlan-passthru-mode.png" alt="Macvlan 直通模式" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：MACVLAN passthru mode</center>
<center><em>Source：</em>https://hicu.be/bridge-vs-macvlan</center><br>
<h4 id="source">Source</h4>
<p>这个模式是Linux中的一个 Patch，是流量仅允许被允许的MAC地址列表</p>
<h2 id="ipvlan">IPVLAN</h2>
<p>IPVLAN与MACVLAN类似，只有一个不同的地方是，IPVLAN所有的MAC地址都是一样的，就是使用相同的MAC地址去创建子接口。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/linux-ipvlan.png" alt="Linux Ipvlan" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：IPVLAN</center>
<center><em>Source：</em>https://hicu.be/bridge-vs-macvlan</center><br>
<h3 id="ipvlan-modes">IPVLAN modes</h3>
<p>在使用IPVLAN时，只能选择下面两种模式中的一种，选择后，所有的子节接口将工作在这个模式下。</p>
<h4 id="l2">L2</h4>
<p><em><strong>IPVLAN</strong></em> L2模式与 <em><strong>MACVLAN</strong></em> 的 <em><strong>brigde</strong></em> 模式工作原理很相似，父接口是作为交换机的角色，同一个物理接口上的子接口可以通过父接口来转发数据，而如果要发送数据到其他的网络，报文则会通过父接口的路由转发出去。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/linux-ipvlan-l2-mode.png" alt="Linux Ipvlan - L2 模式" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：IPVLAN L2</center>
<center><em>Source：</em>https://hicu.be/bridge-vs-macvlan</center><br>
<blockquote>
<p>Notes: IPVLAN 是 linux kernel 比较新的特性，linux kernel 3.19 开始支持 ipvlan，但是比较稳定推荐的版本是 &gt;=4.2</p>
</blockquote>
<h4 id="l3">L3</h4>
<p>在 <em><strong>L3</strong></em> 模式下也就是 物理接口 是作为路由器，这种情况下就要求子接口之间需要处在不同子网中才可以。因为广播域是 <em><strong>L2</strong></em> 的，所以 <em><strong>IPVLAN L3</strong></em> 不支持多播和广播。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/linux-ipvlan-l3-mode-1.png" alt="Linux Ipvlan - L3 模式" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：IPVLAN L3</center>
<center><em>Source：</em>https://hicu.be/bridge-vs-macvlan</center><br>
<h3 id="ipvlan与macvlan如何选择">IPVLAN与MACVLAN如何选择</h3>
<ul>
<li>在于<em><strong>MACVLAN</strong></em>在wireless环境中的不友好，wireless选择 <em><strong>IPVLAN</strong></em></li>
<li>对于外部设备有MAC地址限制的，或者混杂模式限制NIC性能</li>
</ul>
<h2 id="vxlan">VxLAN</h2>
<h3 id="vxlan-introduction">VxLAN Introduction</h3>
<p><em><strong>VxLAN</strong></em> (Virtual eXtensible Local Area Network) 是一种 <code>MAC-over-IP</code> 或者称为 UDP隧道机制，本质上来说是使用网络隧道技术将L3网络扩展为一个L2网络。</p>
<h4 id="为什么将-vxlan-视为l2网络呢">为什么将 <em><strong>VxLAN</strong></em> 视为L2网络呢？</h4>
<p>虽说 <em><strong>VxLAN</strong></em> 是将L2的以太网帧封装到UDP报文中（L2 over L4）中，并在L3网络中传输。但是 <em><strong>VxLAN</strong></em> 最终是基于 <em><strong>MAC</strong></em> 地址的二层网络（可以无需路由设备），而不像 <em><strong>IPIP</strong></em> 的隧道技术网络通讯是基于路由的。</p>
<p>下图是一个使用 <em><strong>VxLAN</strong></em> 技术的网络拓扑，整个篮筐部分可以视为一个二层的虚拟交换机，连接的各设备都可以直连。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/download-16615328145948.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：VXLAN tunneling technology</center>
<center><em>Source：</em>https://support.huawei.com/enterprise/en/doc/EDOC1100086966</center><br>
<h4 id="vni">VNI</h4>
<p><em><strong>VNI</strong></em> (VXLAN Network Identifier) 是类似于VLAN ID的标识符，不同的<em><strong>VNI</strong></em> 之间不能进行二层通讯</p>
<h4 id="vept">VEPT</h4>
<p><em><strong>VTEP</strong></em> (VxLAN tunnel endpoint) 是指数据包封包与解包的实体，<em><strong>VTEP</strong></em> 既可以是一台独立的网络设备，也可以是一个基于软件的虚拟交换机。当源服务器发出包时，会在 <em><strong>VTEP</strong></em> 上封装成 <em><strong>VxLAN</strong></em> 格式的报文；当传送到对端时，会在对端的 <em><strong>VTEP</strong></em> 进行解包</p>
<p>下图是一个VxLAN网络拓扑图，其中建立隧道的两端就是 <em><strong>VTEP</strong></em>，这里的 <em><strong>VTEP</strong></em> 是两台 TOR 交换机，通过两个 <em><strong>VTEP</strong></em> 来对数据包的解封装。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/download-16615321616635.png" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：VXLAN network model</center>
<center><em>Source：</em>https://support.huawei.com/enterprise/en/doc/EDOC1100086966</center><br>
<p>下图是Linux <em><strong>VxLAN</strong></em> 类型的网络拓扑，<em><strong>VTEP</strong></em> 可以理解为是一种网络接口，通过该接口与内核功能进行解封包，而实际的流量也是通过物理设备进行传输。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/vxlan%20in%20linux.png" alt="vxlan in linux" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：VxLAN in Linux</center>
<h4 id="preliminary-knowledge-三层分级网络-supa-href44asup">Preliminary knowledge 三层分级网络 <sup><a href="#4">[4]</a></sup></h4>
<h5 id="三层分级网络">三层分级网络?</h5>
<p>思科的三层分级网络(<em><strong>three-layer hierarchical model</strong></em>) 包含三层：</p>
<ul>
<li>核心层 (<em><strong>Core</strong></em>)：网络骨干，提供不同分布层之间的高速连接和最优传送路径</li>
<li>分布层 (<em><strong>distribution</strong></em>) 将连接接入层到核心层，并且实施安全，流量负载和路由相关的策略</li>
<li>接入层 (<em><strong>access</strong></em>) 为用户终端初始网络的接入点。</li>
</ul>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/distribution-layer-diagram-1621937301-ES7wiU19cL.jpg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：three-layer hierarchical model</center>
<center><em>Source：</em>https://community.fs.com/blog/how-to-choose-the-right-distribution-switch.html</center><br>
<h4 id="为什么需要vxlan-supa-href55asup">为什么需要VxLAN <sup><a href="#5">[5]</a></sup></h4>
<p>下图是一个 <em><strong>CSP</strong></em> (Cloud Service Provider ) 的 <em><strong>DC</strong></em> 网络，</p>
<ul>
<li>接入层：48口交换机20个</li>
<li>分布层：两台分布式交换机，共同组成一个虚拟化交换机。默认网关位于分布式交换机中。</li>
<li>核心层：两个核心交换机</li>
</ul>
<blockquote>
<p>Notes：工作在分布层的交换机被称为分布式交换机 (<em><strong>Distribution Switch</strong></em>)，分布式交换机会将来自访问层的流量转发至核心层，并提供一些连接策略。</p>
</blockquote>
<p>每台接入交换机连接48台物理服务器。这些服务器中的每一个都包含五个不同的租户，它们拥有自己的虚拟路由 (VRF)。一个租户由三个广播域组成：<code>Presiontation</code>， <code>Application</code> 和 <code>Database</code> ，每层都是互备的。在管理租户时，可以定义 <em><strong>VLAN ID</strong></em>、虚拟机的 <em><strong>MAC</strong></em> 地址和 <em><strong>IP</strong></em> 地址。虚拟机时可移动的，存在如下信息：</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/Figure1-1_Topology.jpeg" alt="img" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：CSP DC network</center>
<center><em>Source：</em>https://nwktimes.blogspot.com/2018/02/vxlan-part-i-why-vxlan-is-needed.html</center><br>
<p>通过上述信息可以得知有如下：</p>
<ul>
<li>服务器：$20\times48=960$, 20为ToR交换机数量，48为每个ToR的接口</li>
<li>虚拟机/MAC地址/ARP：28800个虚拟机（每个物理机30个虚拟机）</li>
<li>广播域：每个租户+每个租户的VLAN+所拥有的物理机，$5\times3\times960=14400$</li>
<li>VRF：4800，5个租户+960个虚拟机</li>
</ul>
<p>在这种网络中存在的挑战如下：</p>
<ul>
<li><strong>VLAN ID的限制</strong>，通常来说VLAN ID只有12位，4096个，这意味着不够用</li>
<li><strong>多租户</strong>，多租户场景下，广播域等都是用户自己定义的，此时可能发生客户定义的ID为相同的</li>
<li><strong>MAC表大小限制</strong>，在一个租户下有28800个机器，意味着交换机MAC地址表存放28800个MAC地址。会出现老化过程。（Notes：<em>Cisco Nexus 9500/9300</em> 系列支持90000个MAC地址表）</li>
<li><strong>APR表大小限制</strong>，分布式交换机中存在超过28800条MAC-IP的数量（ Notes：<em>Cisco Nexus 9500</em>系列交换机支持 60,000 个 IPv4 ARP 和 30,000 个 IPv6 ND）</li>
<li><strong>生成树协议</strong>，在这种网络拓扑结构下，由于 STP 不支持链路之间的负载均衡，因此某些链路可能不会用于流量传输，这种情况下使带宽利用率下降。</li>
</ul>
<p>由于 <em><strong>VxLAN</strong></em> 通过L3建立隧道，因此不需要生成树协议。在基于 <em><strong>VxLAN</strong></em> 技术的 DC 中，VLAN将不再具有意义，因为 VLAN 是交换机甚至交换机端口特定的。</p>
<p>在基于 <em><strong>VxLAN</strong></em>  <em><strong>Leaf-Spine</strong></em> 的网络架构中，通过将网络压缩为一个L2的网络架构，所有的节点在访问其他节点时，都将仅需要两部，因此除了Leaf交换机之外，其余并不清楚虚拟机的MAC地址。</p>
<p>下图是<em><strong>Leaf-Spine</strong></em>网络拓扑图， 在该架构中，每个较低级别的接入（leaf）交换机都以全网状连接到每个较高级别的核心（spine）交换机。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/Tripp_Lite_3.2.width-880.png" alt="Tripp 精简版 3.2.png" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：spine-leaf network</center>
<center><em>Source：</em>https://www.datacenterdynamics.com/en/marketwatch/spine-and-leaf-network-architecture-explained/</center><br>
<h3 id="vxlan-in-linux">VxLAN in Linux</h3>
<p>Linux 对 VxLAN 协议的支持时间并不久，2012 年 Stephen Hemminger 才把相关的工作合并到 kernel 中，并最终出现在 kernel 3.7.0 版本。为了稳定性和很多的功能，你可以会看到某些软件推荐在 3.9.0 或者 3.10.0 以后版本的 kernel 上使用 vxlan。</p>
<h4 id="linux实现vxlan网络">linux实现VxLAN网络</h4>
<p>两台机器构成一个VxLAN网络，每台机器上有一个 VTEP，VTEP 通过它们的 IP 互相通信。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/vxlan%20in%20linux.png" alt="vxlan in linux" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：VxLAN in Linux</center>
<p>这个图创建的VxLAN0设备模拟了VTEP隧道端点，实现了一个大二层域，突破了虚拟化网络的物理界限。</p>
<p>node01</p>
<pre><code class="language-bash">ip link add vxlan1 type vxlan id 1 remote 10.0.0.3 dstport 4789 dev ens33
ip link set vxlan1 up
ip addr add 192.168.100.1/24 dev vxlan1
</code></pre>
<p>node02</p>
<pre><code>ip link add vxlan1 type vxlan id 1 remote 10.0.0.14 dstport 4789 dev eth0
ip link set vxlan1 up
ip addr add 192.168.100.2/24 dev vxlan1
</code></pre>
<p>上述命令创建了一个类型为vxlan，名为vxlan1的网络接口，期后面的为配置这个网络设备的内容：</p>
<ul>
<li><code>id 1</code>  类似CE设备的<code>vxlan vni 10</code> 设置的桥接域，只有相同的VNI之间可以直接进行二层通信。</li>
<li><code>dstport</code> VTEP 通信的端口，这里会监听一个udp端口</li>
<li><code>remote 10.0.0.3</code> 类似<code>vni 10 head-end peer-list 2.2.2.2</code> 用来设置隧道对端的 VTEP 地址，因为这里使用的为单播模式。</li>
<li><code>local 10.0.0.4</code> 与 <code>dev eth0</code> 类似于 <code>source 1.1.1.1</code> 配置源VTEP的IP地址。</li>
</ul>
<pre><code class="language-bash">$ tcpdump -np -i vxlan1 -vv
tcpdump: listening on vxlan1, link-type EN10MB (Ethernet), snapshot length 262144 bytes

05:07:20.589942 ARP, Ethernet (len 6), IPv4 (len 4), Request who-has 192.168.100.1 tell 192.168.100.2, length 28
05:07:20.589963 ARP, Ethernet (len 6), IPv4 (len 4), Reply 192.168.100.1 is-at ca:21:c6:01:f9:d5, length 28
05:07:20.590509 IP (tos 0x0, ttl 64, id 26921, offset 0, flags [DF], proto ICMP (1), length 84)
    192.168.100.2 &gt; 192.168.100.1: ICMP echo request, id 1225, seq 1, length 64
05:07:20.590525 IP (tos 0x0, ttl 64, id 1264, offset 0, flags [none], proto ICMP (1), length 84)
    192.168.100.1 &gt; 192.168.100.2: ICMP echo reply, id 1225, seq 1, length 64
05:07:21.593791 IP (tos 0x0, ttl 64, id 27468, offset 0, flags [DF], proto ICMP (1), length 84)
</code></pre>
<p>抓包查看对应的数据包  [vxlan_linux.cap](......\images\vxlan in linux\vxlan_linux.cap)</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20210203232317906.png" alt="image-20210203232317906" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>清理数据</p>
<pre><code>ip link set vxlan1 down
ip link delete vxlan1
</code></pre>
<h4 id="多播模式的-vxlan">多播模式的 vxlan</h4>
<p>“多播”即“多点传送”(multicast)，也就是一台主机发出的包可以同时被其他多个有资格的主机接收，这台主机和那些有资格的主机就形成了一个组，他们在组内的通信是广播式的。多播的工作原理是，将一个网络上的某些主机的网卡设置成多播传送工作模式，指定其不过滤以某一个多播传送地址作为目的物理地址的数据帧，这样，这些主机的驱动程序中就可以同时接收以该多播传送地址作为目的物理地址的数据帧，而其他主机的驱动程序却接收不到，这些主机在逻辑上便形成了一个“多播”组。采用这种技术，相对广播而言，可有效减轻网络上“多播”组之外的其他主机的负担，因为发送给“多播”组的数据不会被传送到它们的驱动程序中去处理，避免资源的无谓浪费。</p>
<p>多播的IP范围为：从224.0.0.0到239.255.255.255。能够接收发往一个特定多播组地址数据的主机集合称为主机组 (host group)。一个主机组可跨越多个网络。主机组中成员可随时加入或离开主机组。主机组中对主机的数量没有限制，同时不属于某一主机组的主机可以向该组发送信息。</p>
<p><code>239.1.1.1</code> IIANA保留地址用于多播（多点传送）的IP，其mac地址为 <code>01:00:5e:01:01:01</code>(参考：<a href="https://blog.51cto.com/361531/891466" target="_blank"
   rel="noopener nofollow noreferrer" >组播地址</a>)</p>
<p>要组成同一个 vxlan 网络，vtep 必须能感知到彼此的存在。多播组本来的功能就是把网络中的某些节点组成一个虚拟的组。</p>
<p>实验使用的为多播组组成一个虚拟的整体，通过多播组，组成可容纳多个主机组成 vxlan 网络</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20210203232408799.png" alt="image-20210203232408799" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：muticast VxLAN in Linux</center>
<pre><code class="language-bash">ip link add vxlan2 type vxlan id 10 group 239.1.1.1 dstport 4789 dev eth0
ip link set vxlan2 up
ip addr add 192.168.100.10/24 dev vxlan2
</code></pre>
<p>node01</p>
<pre><code class="language-bash">ip link add vxlan2 type vxlan id 10 group 239.1.1.1 dstport 4789 dev eth0
ip link set vxlan2 up
ip addr add 192.168.100.20/24 dev vxlan2
</code></pre>
<p><em><strong>FDB</strong></em> 是 Linux 网桥维护的一个二层转发表，用于保存远端虚拟机/容器的 MAC地址，远端 VTEP IP，以及 VNI 的映射关系，可以通过 <code>bridge fdb</code> 命令来对 <code>FDB</code> 表进行操作：</p>
<p>vxlan接口在创建后，fdb只有一个表项，就是所有<code>vxlan2</code>的流量都发往多播组</p>
<pre><code>$ bridge fdb
33:33:00:00:00:01 dev eth0 self permanent
01:00:5e:00:00:01 dev eth0 self permanent
01:00:5e:01:01:01 dev eth0 self permanent
00:00:00:00:00:00 dev vxlan2 dst 239.1.1.1 via eth0 self permanent
</code></pre>
<p>组播路由方式过程</p>
<ol>
<li>当发送<code>ping 192.168.100.10</code>时在同一个局域网内会先发送ARP广播，为组播方式，node1与node2（10.0.0.4）均受到广播，而node3（10.0.0.6）未受到</li>
<li>ARP报文要获得的内容为vxlan的mac地址，目的地址为全1的广播地址</li>
<li>vxlan隧道封装VNI=10，因为不知道目的地址，所以会发送多播报文</li>
<li>受到报文后进行解包，取出真实的报文，如果发现是自己的，经由隧道封装后传递</li>
<li>vtep 通过源报文学习到了 vtep 所在的主机，因此会直接单播发送给目的 vtep。发送方主机根据 VNI 把报文转发给 vtep，vtep 解包取出 ARP 应答报文，添加 arp 缓存到内核。并根据报文学习到目的 vtep 所在的主机地址，添加到 fdb 表中</li>
</ol>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20210204010726897.png" alt="image-20210204010726897" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>而没在多播组中的同网段主机没有受到对应的ARP广播</p>
<p>而在加入多播组中会受到多播的信息，确定不是自己后没有reply</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20210204010149338.png" alt="image-20210204010149338" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>此实验的报文内容</p>
<p>[192.168.10.30 加入同多播组](......\images\vxlan in linux\10.30.cap)</p>
<p>[192.168.10.20 发起端](......\images\vxlan in linux\10.20.cap)</p>
<p>[192.168.10.30 不在多播组内的报文](......\images\vxlan in linux\10.30 exit multicast.cap)</p>
<p>清除配置</p>
<pre><code class="language-bash">ip link set vxlan2 down
ip link delete vxlan2 
</code></pre>
<h2 id="实验一linux-bridgel2">实验一：Linux Bridge[L2]</h2>
<p>该实验包含 <em><strong>veth</strong></em>, <em><strong>vlan</strong></em>, <em><strong>Linux bridge</strong></em> 方面的</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20210201195306279-166133333718927.png" alt="image-20210201195306279" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：L2 vn topology</center><br>
<p>加载vlan模块</p>
<pre><code class="language-bash">modprobe 8021q
## 查看核心是否提供VLAN 功能
dmesg | grep -i 802
[    1.592802] pci 0000:00:15.0: PME# supported from D0 D3hot D3cold
[ 1755.995461] 8021q: 802.1Q VLAN Support v1.8
[ 1755.995485] 8021q: adding VLAN 0 to HW filter on device eth0
</code></pre>
<p>安装命令</p>
<pre><code class="language-bash">yum install vconfig -y
apt install vlan
</code></pre>
<p>创建vlan</p>
<pre><code class="language-bash"># 创建bridge
brctl addbr vlan10
brctl show
	
ip link add veth01 type veth peer name eth01
ip link add veth02 type veth peer name eth02

# 将veth对的一端加入网桥
brctl addif vlan10 veth01
brctl addif vlan10 veth02
# 启动对应设备
ip link set dev vlan10 up
ip link set dev veth01 up
ip link set dev veth02 up
ip link set dev eth01 up
ip link set dev eth02 up
# 创建ns
ip netns add net1
ip netns add net2
# 将veth关联到对应名称空间内
ip link set eth01 netns net1
ip link set eth02 netns net2
</code></pre>
<p>网络名称空间net1内的操作，在vlan一端添加接口，与关联到该名称空间内的 <em>veth</em> 关联</p>
<pre><code>vconfig add eth01 3001
vconfig add eth01 3002

ip link set eth01 up
ip link set eth01.3001 up
ip link set eth01.3002 up

ip addr add 192.168.100.1/24 dev eth01.3001
ip addr add 192.168.100.2/24 dev eth01.3002
</code></pre>
<p>网络名称空间net2与net1的类似</p>
<pre><code>vconfig add eth02 3001
vconfig add eth02 3002

ip link set dev eth02 up
ip link set dev eth02.3001 up
ip link set dev eth02.3002 up

ip addr add 192.168.100.10/24 dev eth02.3001
ip addr add 192.168.100.11/24 dev eth02.3002
</code></pre>
<p>验证连通性，可以看到发送的包带有tag的标签</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20210201211400463-166133333718928.png" alt="image-20210201211400463" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h2 id="实验二ipvlan-l2">实验二：IPVLAN L2</h2>
<p>实验结果，通过namespace模拟Pod的网络，做到各Pod间的网络通讯。</p>
<p><code>ip netns list</code> 查看网络命名空间</p>
<p><code>ip netns add net2</code> 创建一个网络命名空间</p>
<p><code>ip link add &lt;name&gt; link eth0 type ipvlan mode l2</code> 在当前名称空间创建一个类型为IPVLAN L2模式的接口，将该接口关联至父接口eth0上。</p>
<p><code>ip link set $name netns $nsName</code> 将接口加入到对应网络名称空间内</p>
<p><code>ip netns exec $nsName $cmd</code>  在对应的网络名称空间内运行命令</p>
<p>创建两个网络名称空间</p>
<pre><code class="language-bash">$ ip netns add net1
$ ip netns add net2
$ ip netns list
net2
net1
</code></pre>
<p>创建 IPVLAN 接口</p>
<pre><code class="language-bash">$ ip link add ipvlan01 link eth0 type ipvlan mode l2
$ ip link add ipvlan02 link eth0 type ipvlan mode l2

$ ip link set ipvlan01 netns net1
$ ip link set ipvlan02 netns net2
</code></pre>
<p>给对应接口添加IP地址</p>
<pre><code class="language-bash">ip netns exec net1 ifconfig ipvlan01 192.168.0.1/24 up
ip netns exec net2 ifconfig ipvlan02 192.168.0.2/24 up

# 这两个名称空间内的mac地址是一样的
$ ip netns exec net2 ifconfig
ipvlan02: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
        inet 192.168.0.2  netmask 255.255.255.0  broadcast 192.168.0.255
        inet6 fe80::da78:c800:27a:fb26  prefixlen 64  scopeid 0x20&lt;link&gt;
        ether da:78:c8:7a:fb:26  txqueuelen 1000  (Ethernet)
        RX packets 39007  bytes 2394577 (2.2 MiB)
        RX errors 0  dropped 27  overruns 0  frame 0
        TX packets 11  bytes 866 (866.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

$ ip netns exec net1 ifconfig
ipvlan01: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
        inet 192.168.0.1  netmask 255.255.255.0  broadcast 192.168.0.255
        inet6 fe80::da78:c800:17a:fb26  prefixlen 64  scopeid 0x20&lt;link&gt;
        ether da:78:c8:7a:fb:26  txqueuelen 1000  (Ethernet)
        RX packets 132823  bytes 8184548 (7.8 MiB)
        RX errors 0  dropped 93  overruns 0  frame 0
        TX packets 12  bytes 936 (936.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
</code></pre>
<p>测试两个名称空间是否互通</p>
<p>结论：可以看到两个名称空间内的子接口 (<em><strong>sub-interface</strong></em>) 通过其父接口 (<em><strong>parent-interface</strong></em>) 可以达到互通。子接口与父接口之间的不互通。<strong>IPVLAN L2模式仅限于子接口之间的互通</strong></p>
<pre><code class="language-bash">$ ip netns exec net1 ping 192.168.0.2
PING 192.168.0.2 (192.168.0.2) 56(84) bytes of data.
64 bytes from 192.168.0.2: icmp_seq=1 ttl=64 time=0.285 ms
64 bytes from 192.168.0.2: icmp_seq=2 ttl=64 time=0.077 ms
^C
--- 192.168.0.2 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1027ms
rtt min/avg/max/mdev = 0.077/0.181/0.285/0.104 ms

$ ip netns exec net2 ping 192.168.0.1
PING 192.168.0.1 (192.168.0.1) 56(84) bytes of data.
64 bytes from 192.168.0.1: icmp_seq=1 ttl=64 time=0.051 ms
64 bytes from 192.168.0.1: icmp_seq=2 ttl=64 time=0.059 ms
^C
--- 192.168.0.1 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1056ms
rtt min/avg/max/mdev = 0.051/0.055/0.059/0.004 ms
</code></pre>
<p>遇到问题</p>
<ul>
<li>
<p><strong>RTNETLINK answers: Operation not supported</strong>： CentOS 7默认内核版本为3.10 IPVLAN 3.19开始支持，推荐内核为4.2+</p>
</li>
<li>
<p>子接口ping父接口不通，源MAC与目标MAC是一致，而mac接口是mac地址与接口绑定，因为三个接口的mac地址都相同，此时区分不了是哪个接口。</p>
</li>
<li>
<p>ping公网地址不通，查看路由表中没有对外的路由，手动添加即可</p>
<pre><code class="language-bash">ip netns exec net1 route -n
ip netns exec net1 route add -net 0.0.0.0/0 gw 10.0.0.2
</code></pre>
</li>
<li>
<p>IPVLAN L2模式中，父接口是可以没有IP地址的。不影响子接口的使用</p>
</li>
</ul>
<p>清除所有网络名称空间</p>
<pre><code class="language-bash">for n in $(ip netns list|awk '{print $1}');do ip netns del $n;done
</code></pre>
<h3 id="实验三ipvlan-l3">实验三：IPVLAN L3</h3>
<p>先创建两个用做测试的 network namespace</p>
<pre><code class="language-bash">ip netns add net3
ip netns add net4
</code></pre>
<p>创建出 IPVLAN 的虚拟网卡接口，创建 IPVLAN 虚拟接口的命令和 MACVLAN 格式相同：</p>
<pre><code class="language-bash">ip link add ipvl01 link ens33 type ipvlan mode l3
ip link add ipvl02 link ens33 type ipvlan mode l3
</code></pre>
<p>把 IPVLAN 接口放到前面创建好的 namespace 中</p>
<pre><code class="language-bash">ip link set ipvl01 netns net3
ip link set ipvl02 netns net4
# 给对应设备设置IP地址
ip netns exec net3 ifconfig ipvl01 192.168.10.1/24 up
ip netns exec net4 ifconfig ipvl02 192.168.20.1/24 up
# 设置对应的路由
ip netns exec net4 route add -net 192.168.10.0/24 dev ipvl02
ip netns exec net3 route add -net 192.168.20.0/24 dev ipvl01
</code></pre>
<p>结果是可以通的</p>
<pre><code class="language-bash">$ ip netns exec net3 ping 192.168.20.1
PING 192.168.20.1 (192.168.20.1) 56(84) bytes of data.
64 bytes from 192.168.20.1: icmp_seq=1 ttl=64 time=0.026 ms
64 bytes from 192.168.20.1: icmp_seq=2 ttl=64 time=0.119 ms
^C
--- 192.168.20.1 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1028ms
rtt min/avg/max/mdev = 0.026/0.072/0.119/0.046 ms
</code></pre>
<h3 id="实验四macvlan">实验四：MACVLAN</h3>
<p>创建两个名称空间</p>
<pre><code class="language-bash">ip netns add net1
ip netns add net2
</code></pre>
<p>创建两个 MACVLAN 接口</p>
<pre><code class="language-bash">ip link add link eth0 name macv1 type macvlan mode bridge
ip link add link eth0 name macv2 type macvlan mode bridge
## 持久化创建
echo &quot;ip link add eth0 eth0.1 address 52:54:00:cc:ee:aa link enp0s31f6 type macvlan&quot; &gt; /sbin/ifup-pre-local2
</code></pre>
<p>把 MACVLAN 接口放到前面创建好的 namespace 中</p>
<pre><code class="language-bash">ip link set macv1 netns net1
ip link set macv2 netns net2
# 给对应设备设置IP地址
ip netns exec net1 ifconfig ipvl01 192.168.10.1/24 up
ip netns exec net2 ifconfig ipvl02 192.168.20.1/24 up
# 设置对应的路由
ip netns exec net1 route add -net 192.168.10.0/24 dev ipvl02
ip netns exec net2 route add -net 192.168.20.0/24 dev ipvl01
</code></pre>
<p>可以看到两个网卡的MAC地址是不同的</p>
<pre><code class="language-bash">$ ip netns exec net2 ifconfig
macv2: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
        inet 192.168.10.1  netmask 255.255.255.0  broadcast 192.168.10.255
        inet6 fe80::a830:c9ff:fe9a:7c33  prefixlen 64  scopeid 0x20&lt;link&gt;
        ether aa:30:c9:9a:7c:33  txqueuelen 1000  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 7  bytes 586 (586.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

$ ip netns exec net1 ifconfig
macv1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
        inet 192.168.10.1  netmask 255.255.255.0  broadcast 192.168.10.255
        inet6 fe80::d448:c5ff:fec7:76a3  prefixlen 64  scopeid 0x20&lt;link&gt;
        ether d6:48:c5:c7:76:a3  txqueuelen 1000  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 8  bytes 656 (656.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
</code></pre>
<h2 id="reference">Reference</h2>
<blockquote>
<p><sup id="1">[1]</sup> <a href="https://man7.org/linux/man-pages/man4/veth.4.html" target="_blank"
   rel="noopener nofollow noreferrer" >man veth</a></p>
<p><sup id="2">[2]</sup> <a href="https://hicu.be/bridge-vs-macvlan" target="_blank"
   rel="noopener nofollow noreferrer" >macvlan</a></p>
<p><sup id="3">[3]</sup> <a href="https://superuser.com/questions/1113812/how-to-configure-macvlan-interface-for-getting-the-ip" target="_blank"
   rel="noopener nofollow noreferrer" >how to configure macvlan interface for getting the IP?</a></p>
<p><sup id="4">[4]</sup> <a href="https://community.fs.com/blog/how-to-choose-the-right-distribution-switch.html" target="_blank"
   rel="noopener nofollow noreferrer" >distribution switch</a></p>
<p><sup id="5">[5]</sup> <a href="https://nwktimes.blogspot.com/2018/02/vxlan-part-i-why-vxlan-is-needed.html" target="_blank"
   rel="noopener nofollow noreferrer" >why vxlan is needed</a></p>
<p><sup id="4">[4]</sup> <a href="">distribution switch</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>使用eNSP构建calico BGP网络</title>
      <link>https://www.oomkill.com/2021/01/ensp-calico-bgp/</link>
      <pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2021/01/ensp-calico-bgp/</guid>
      <description></description>
      <content:encoded><![CDATA[<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20210129230307007.png" alt="image-20210129230307007" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<p>实验文件： [calico BGP.zip](<a href="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/calico" target="_blank"
   rel="noopener nofollow noreferrer" >https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/calico</a> BGP.zip)</p>
<p>R1</p>
<pre><code>system-view 
sysname R1

interface l0
ip address 1.1.1.1 32

interface g0/0/0
ip address 10.1.0.1 24

interface g0/0/1
ip address 10.3.0.1 24

bgp 100
router-id 1.1.1.1
peer 10.1.0.2 as-number 123
peer 10.3.0.2 as-number 456
dis this
dis ip interface b
</code></pre>
<p>R2</p>
<pre><code>system-view 
sysname R2

interface l0
ip address 2.2.2.2 32

interface g0/0/0
ip address 10.2.0.1 24

interface g0/0/1
ip address 10.4.0.1 24

bgp 200
router-id 2.2.2.2
peer 10.4.0.2 as-number 123
peer 10.2.0.2 as-number 456
dis ip interface b
</code></pre>
<p>从下至上配置</p>
<p>R3</p>
<pre><code>system-view 
sysname R3

interface l0
ip address 3.3.3.3 32

interface g0/0/0
ip address 10.1.0.2 24

interface g0/0/1
ip address 10.5.0.1 24

vlan 2
int vlan 2
ip address 10.6.0.1 24
in e0/0/0
port link-type access 
port default vlan 2
dis ip interface brief

vlan 3
int vlan 3
ip address 10.4.0.2 24
in e0/0/1
port link-type access 
port default vlan 3
dis ip interface brief 

ospf router-id 3.3.3.3
area 0
network 10.1.0.0 0.0.0.255
network 10.5.0.0 0.0.0.255
network 3.3.3.3 0.0.0.0
network 10.4.0.0 0.0.0.255
network 10.6.0.0 0.0.0.255
dis this

bgp 123
router-id 3.3.3.3
peer 5.5.5.5 as-number 123
peer 5.5.5.5 connect-interface l0
peer 6.6.6.6 as-number 123
peer 6.6.6.6 connect-interface l0
dis this
peer 5.5.5.5 reflect-client
peer 6.6.6.6 reflect-client

peer 10.1.0.1 as-number 100
peer 10.4.0.1 as-number 200
dis this
</code></pre>
<p>R5</p>
<p>注意这里OSPF宣告的路由，OSPF优先级高于BGP，此处不能宣告<code>0.0.0.0 255.255.255.255</code></p>
<pre><code>system-view 
sysname R5

interface l0
ip address 5.5.5.5 32
quit

vlan 2
int vlan 2
ip address 10.5.0.2 24
in e0/0/0
port link-type access 
port default vlan 2

dis ip interface brief 

ospf router-id 5.5.5.5
area 0
network 5.5.5.5 0.0.0.0
network 10.5.0.0 0.0.0.255
dis this

bgp 123
router-id 5.5.5.5
peer 3.3.3.3 as-number 123
peer 3.3.3.3 connect-interface l0
dis this
</code></pre>
<p>R6</p>
<pre><code>system-view 
sysname R6

interface l0
ip address 6.6.6.6 32
quit

vlan 2
int vlan 2
ip address 10.6.0.2 24
in e0/0/0
port link-type access 
port default vlan 2

dis ip interface brief 

ospf router-id 6.6.6.6
area 0
network 6.6.6.6 0.0.0.0
network 10.6.0.0 0.0.0.255
dis this

bgp 123
router-id 6.6.6.6
peer 3.3.3.3 as-number 123
peer 3.3.3.3 connect-interface l0
dis this
</code></pre>
<p>R4</p>
<pre><code>system-view 
sysname R4

interface l0
ip address 4.4.4.4 32

interface g0/0/0
ip address 10.2.0.2 24

interface g0/0/1
ip address 10.7.0.1 24

vlan 2
int vlan 2
ip address 10.8.0.1 24
in e0/0/0
port link-type access 
port default vlan 2
dis ip interface brief

vlan 3
int vlan 3
ip address 10.3.0.2 24
in e0/0/1
port link-type access 
port default vlan 3
dis ip interface brief 

ospf router-id 4.4.4.4
area 0
network 10.2.0.0 0.0.0.255
network 10.3.0.0 0.0.0.255
network 4.4.4.4 0.0.0.0
network 10.7.0.0 0.0.0.255
network 10.8.0.0 0.0.0.255
dis this

bgp 456
router-id 4.4.4.4
peer 7.7.7.7 as-number 456
peer 7.7.7.7 connect-interface l0
peer 8.8.8.8 as-number 456
peer 8.8.8.8 connect-interface l0
dis this
peer 7.7.7.7 reflect-client
peer 8.8.8.8 reflect-client

peer 10.3.0.1 as-number 100
peer 10.2.0.1 as-number 200
dis this
</code></pre>
<p>R7</p>
<pre><code>system-view 
sysname R7

interface l0
ip address 7.7.7.7 32
quit

vlan 2
int vlan 2
ip address 10.7.0.2 24
in e0/0/0
port link-type access 
port default vlan 2

dis ip interface brief 

ospf router-id 7.7.7.7
area 0
network 7.7.7.7 0.0.0.0
network 10.7.0.0 0.0.0.255
dis this

bgp 456
router-id 7.7.7.7
peer 4.4.4.4 as-number 456
peer 4.4.4.4 connect-interface l0
dis this
</code></pre>
<p>R8</p>
<pre><code>system-view 
sysname R8

interface l0
ip address 8.8.8.8 32

interface g0/0/0
ip address 10.8.0.2 24

dis ip interface brief 

ospf router-id 8.8.8.8
area 0
network 8.8.8.8 0.0.0.0
network 10.8.0.0 0.0.0.255
dis this

bgp 456
router-id 8.8.8.8
peer 4.4.4.4 as-number 456
peer 4.4.4.4 connect-interface l0
dis this
</code></pre>
<p>在R7与R5各添加一条路由</p>
<pre><code>interface L11
ip address 77.77.77.77 32
quit
bgp 456
network 77.77.77.77 255.255.255.255

interface L11
ip address 55.55.55.55 32
quit
bgp 123
network 55.55.55.55 255.255.255.255
</code></pre>
<p>可以看到R1 R2 与 R6 R8都通过对应的bgp协议学习到相应的路由。</p>
<pre><code>[R2]dis bgp routing-table 

 BGP Local router ID is 2.2.2.2 
 Status codes: * - valid, &gt; - best, d - damped,
               h - history,  i - internal, s - suppressed, S - Stale
               Origin : i - IGP, e - EGP, ? - incomplete

 Total Number of Routes: 4
      Network            NextHop        MED        LocPrf  PrefVal Path/Ogn
 *&gt;   55.55.55.55/32     10.4.0.2                            0      123i
 *                       10.2.0.2                            0      456 100 123i
 *&gt;   77.77.77.77/32     10.2.0.2                            0      456i
 *                       10.4.0.2                            0      123 100 456i


[R6-bgp]dis bgp routing-table 

 BGP Local router ID is 6.6.6.6 
 Status codes: * - valid, &gt; - best, d - damped,
               h - history,  i - internal, s - suppressed, S - Stale
               Origin : i - IGP, e - EGP, ? - incomplete

 Total Number of Routes: 2
      Network            NextHop        MED        LocPrf    PrefVal Path/Ogn
 *&gt;i  55.55.55.55/32     5.5.5.5         0          100        0      i
 *&gt;i  77.77.77.77/32     10.1.0.1                   100        0      100 456i
[R6-bgp]
</code></pre>
<p>遇到问题：</p>
<p>vlan未启动，需要查看对应绑定的端口是否正确</p>
<p>ospf配置错误，<code>undo ospf 1 </code> 重启ospf</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>网络隧道技术</title>
      <link>https://www.oomkill.com/2021/01/network-tunnel-technology/</link>
      <pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2021/01/network-tunnel-technology/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="隧道技术概要">隧道技术概要</h2>
<p>隧道技术（<em><strong>Tunneling</strong></em>）是网络基础设置在网络之间传递数据的方式，使用隧道技术传递可以是不同协议的数据包，隧道协议将这些其他协议的数据包重新封装在新的包头中发送。被封装的数据包在隧道的两个端点之间通过网络进行路由，<strong>被封装数据包在网络上传递时所经历的逻辑路径称为隧道</strong>。</p>
<p>简单来说，<font style="background:#f8070d;" size=3>隧道技术是一类网络协议</font>，是将一个数据包封装在另一个数据包中进行传输的技术；**使用隧道的原因是在不兼容的网络上传输数据，或在不安全网络上提供一个安全路径。**通过网络隧道技术，可以使隧道两端的网络组成一个更大的内部网络。（把不支持的协议数据包打包成支持的协议数据包之后进行传输）。</p>
<h2 id="隧道协议">隧道协议</h2>
<p>要创建隧道，隧道的客户机和服务器双方必须使用相同的隧道技术，隧道协议有二层隧道协议与三层隧道协议两类。</p>
<p>二层隧道协议对应OSI模型中数据链路层，使用 <strong>帧</strong> 作为数据交换单位，PPTP、L2TP、L2F都属于二层隧道协议。是将数据封装在点对点协议的帧中通过互联网络发送。</p>
<p>三层隧道协议对应OSI模型中网络层，使用 <strong>包</strong> 作为数据交换单位，GRE、IPSec 都属于三层隧道协议。都是数据包封装在附加的IP包头中通过IP网络传送。</p>
<p>在例如VxLAN，工作在传输层和网络层之间。具体来说，将运行在用户数据报协议 (UDP) 和网络数据报协议 (IP) 之间，以便在网络中建立安全的通信通道。</p>
<h2 id="网络隧道技术应用">网络隧道技术应用</h2>
<h3 id="隧道在linux-中应用">隧道在Linux 中应用</h3>
<p>IP隧道是指一种可在两网络间进行通信的通道。在该通道里，会先封装其他网络协议的数据包，之后再传输信息。</p>
<p>Linux原生共支持5种IPIP隧道：</p>
<ul>
<li>ipip: 普通的IPIP隧道，就是在报文的基础上再封装成一个IPv4报文</li>
<li>gre: 通用路由封装（Generic Routing Encapsulation），定义了在任意一种网络层协议上封装其他任意一种网络层协议的机制，所以对于IPv4和IPv6都适用</li>
<li>sit: sit模式主要用于IPv4报文封装IPv6报文，即IPv6 over IPv4</li>
<li>isatap: 站内自动隧道寻址协议（Intra-Site Automatic Tunnel Addressing Protocol），类似于sit也是用于IPv6的隧道封装</li>
<li>vti: 即虚拟隧道接口（Virtual Tunnel Interface），是一种IPsec隧道技术</li>
</ul>
<p>像IPVS/LVS中的 <code>Virtual Server via IP Tunneling</code>，就是使用了IPIP隧道</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/1b499670.png" alt="1b499670" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h3 id="ssh隧道技术">SSH隧道技术</h3>
<p>SSH提供了一个重要功能，称为转发 <font color=#f8070d size=3><code>forwarding</code></font> 或者称为隧道传输<font color=#f8070d size=3><code>tunneling</code></font>，它可以通过加密频道将明文流量导入隧道中，在创建SSH隧道时， SSH客户端要设置并转交一个特定本地端口号到远程机器上；一旦SSH隧道创建，用户可以连到指定的本地端口号以访问网络服务。本地端口号不用与远地端口号一样。</p>
<p>SSH隧道主要使用场景一般为 <strong>规避防火墙</strong>、<strong>加密网络流量</strong></p>
<p><strong>规避防火墙</strong>，SSH隧道可以使一个被防火墙阻挡的协议可被包在另一个没被防火墙阻挡的协议里，这技巧可用来逃避防火墙政策。而这种操作符合“数据包封装在另一个数据包中进行传输的技术”，故称为SSH隧道技术。</p>
<h3 id="ssh隧道类型">SSH隧道类型</h3>
<p>在ssh连接的基础上，指定 <code>ssh client</code> 或 <code>ssh server</code> 的某个端口作为源地址，所有发至该端口的数据包都会透过ssh连接被转发出去；至于转发的目标地址，目标地址既可以指定，也可以不指定，如果指定了目标地址，称为定向转发，如果不指定目标地址则称为动态转发：</p>
<p><strong>定向转发</strong></p>
<p>定向转发把数据包转发到指定的目标地址。目标地址不限定是ssh client 或 ssh server，既可以是二者之一，也可以是二者以外的其他机器。</p>
<p><strong>动态转发</strong></p>
<p>动态转发不指定目标地址，数据包转发的目的地是动态决定的。</p>
<h4 id="本地端口转发">本地端口转发</h4>
<p>本地转发中的本地是指将本地的某个端口(1024-65535)通过SSH隧道转发至其他主机的套接字，这样当我们的程序连接本地的这个端口时，其实间接连上了其他主机的某个端口，当我们发数据包到这个端口时数据包就自动转发到了那个远程端口上了</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20200730182255288.png" alt="image-20200730182255288" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="远程端口转发">远程端口转发</h4>
<p>远程转发和本地很相似，原理也差不多，但是不同的是，本地转发是在本地主机指定的一个端口，而远程转发是由SSH服务器经由SSH客户端转发，连接至目标服务器上。本质一样，区别在于需要转发的端口是在远程主机上还是在本地主机上</p>
<p>现在SSH就可以把连接从（39.104.112.253:80）转发到（10.0.0.10:85）。</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20200730182352895.png" alt="image-20200730182352895" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<h4 id="动态端口转发">动态端口转发</h4>
<p>定向转发（包括本地转发和远程转发）的局限性是必须指定某个目标地址，如果需要借助一台中间服务器访问很多目标地址，一个一个地定向转发显然不是好办法，这时就要用的是ssh动态端口转发，它相当于建立一个SOCKS服务器。各种应用经由SSH客户端转发，经过SSH服务器，到达目标服务器，不固定端口。</p>
<h3 id="ssh隧道的本质">SSH隧道的本质</h3>
<p><strong>SSH隧道可以被认为是一种应用层隧道</strong>，与其他隧道类型（如IPIP, VxLAN）不同的是，SSH隧道是基于SSH协议的一种应用，而IPIP, VxLAN这种，则是基于IP协议，UDP协议的一种封包机制。</p>
<p>SSH（<em><strong>Secure Shell</strong></em>）是一种网络协议，支持远程登录和其他安全网络服务的加密通信。SSH隧道属于SSH协议中的一种应用场景，用于在SSH加密连接上建立通信隧道。SSH隧道允许用户通过加密终端 (SSH客户端) 和远程服务之间的连接，在不暴露底层网络协议的信息（例如IP地址、端口号等）的情况下，传输数据。</p>
<p>SSH隧道工作方式如下：</p>
<ul>
<li>首先，在本地主机和目标服务器之间建立SSH连接，SSH连接是一条安全加密的连接管道，连接过程中对数据进行加密传输。</li>
<li>连接建立后，通过SSH隧道在本地主机和目标服务器之间建立一个TCP连接，并将本地主机上的数据通过SSH隧道加密传输到目标服务器，目标服务器接收数据，解密后将数据传输到最终目的地。</li>
<li>同样，当接收数据时，目标服务器会将数据加密再通过SSH隧道传输回本地主机。</li>
</ul>
<p>由于SSH隧道在SSH连接上建立通信隧道，因此可以将其视为应用层隧道。应用层隧道是在应用层协议上建立的隧道，用于将应用程序传输的数据加密传输到目标地址。SSH隧道给用户提供了一种安全的数据通信方法，在安全性上比普通TCP/IP连接更具有优势。</p>
<p>SSH隧道也可以成为一种代理模式，常用于越过不可访问的网络时使用</p>
<p><img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/1%20s8z9sil7EnwspH77kdrzjg.webp" alt="1 s8z9sil7EnwspH77kdrzjg" onerror="this.onerror=null;this.src='/placeholder.svg';this.className='pe-image-placeholder'" /></p>
<center>图：SSH隧道应用图解</center>
<center><em>Source：</em>https://infosecwriteups.com/bypass-the-firewall-with-ssh-tunnelling-711fa78ea97f</center><br>
<h3 id="其他隧道协议">其他隧道协议</h3>
<p>对于隧道，上面也提到了，隧道就是网络数据包封包一种协议，那就是说很多常见的协议其实都是隧道技术</p>
<ul>
<li>工作与数据链路层的隧道技术：
<ol>
<li>PPP隧道协议（Point-to-Point Protocol）：PPP隧道协议是一种在两个点之间建立可靠连接的协议，它能够在一条串行线路上同时传输多种网络层协议。PPP隧道协议通过在两个点之间建立隧道，将其他协议的数据封装起来进行传输。</li>
<li>L2TP协议（Layer 2 Tunnel Protocol）：L2TP协议是一种在不安全的公共网络上传输数据的加密协议，常用于建立VPN（Virtual Private Network）隧道。L2TP协议将PPP协议属性和L2TP控制消息封装在IP（Internet Protocol）数据报中。</li>
<li>PPTP协议（Point-to-Point Tunneling Protocol）：PPTP协议是一种在不安全的公共网络上传输数据的加密协议，也常用于建立VPN隧道。PPTP协议通过在数据包中添加PPTP头和PPP协议数据负载来传输数据。</li>
<li>GRE协议（Generic Routing Encapsulation）：GRE协议是一种通用路由封装协议，它可以将其他协议的数据封装在IP数据报中进行传输。GRE协议主要用于连接不同类型的网络，通常用于建立VPN隧道。</li>
</ol>
</li>
<li>工作与网络层的隧道协议：
<ol>
<li>负载均衡协议 (LBP) 是一种在网络层以上实现的协议，用于在二层 (链路层) 上实现数据包的转发。LBP 可以将数据包转发到多个服务器上，从而实现负载均衡。LBP 可以用于实现网站负载均衡、存储集群等功能。</li>
<li>协议映射协议 (PMP) 是一种在网络层以下实现的协议，用于在网络层以上实现数据包的映射。PMP  可以将一个数据包映射到另一个数据包中，从而实现数据包的转发。PMP 可以用于实现虚拟专用网络 (Virtual Private  Network,VPN) 和防火墙等功能。</li>
<li>虚拟隧道协议 (Virtual Tunneling Protocol,VTP) 是一种在网络层以下实现的协议，用于在网络中创建和管理隧道。VTP 可以将一个网络中的多个子网互联，使得数据包可以在这些子网之间传输。VTP 可以用于实现数据包的路由、负载均衡和安全性等方面。</li>
</ol>
</li>
<li>工作与应用层的隧道技术：
<ol>
<li>HTTP隧道：HTTP隧道通过HTTP连接创建隧道，将其他协议的数据封装在HTTP报文中，传输到目标地址。HTTP隧道通常用于访问受限制的服务器，如防火墙后的服务器。</li>
<li>SSL/TLS隧道：SSL/TLS隧道也是基于加密传输的应用层隧道。通过SSL/TLS加密传输，将通信数据封装在加密连接中，传输到目标服务器。SSL/TLS隧道通常用于保护Web应用程序中传输的机密数据。</li>
<li>SOCKS代理隧道：SOCKS代理隧道是一种应用层代理协议，用于将流量转发到目标地址并代理转发返回数据。SOCKS代理隧道通常用于隐藏客户端的真实IP地址和身份。</li>
<li>DNS隧道：DNS隧道是通过将数据封装在DNS请求或响应中来传输数据的应用层隧道。DNS隧道通常被用于绕过安全防护措施或访问受限制的服务器。</li>
</ol>
</li>
</ul>
<h2 id="ccp常提到的非法信道中的信道和隧道是一样的吗">CCP常提到的“非法信道”中的“信道”和“隧道”是一样的吗？</h2>
<p>首先，“信道”和“隧道” 是两种不同的概念，就和“男人”和“女人”一样，同属于人但完全不同，常见的表示形式如下：</p>
<ol>
<li>意义不同：<strong>信道</strong>是指物理媒介或虚拟路径，用于数据的传输，例如网络电缆或无线信道。<strong>隧道</strong>则是一种逻辑隧道，通过在底层通信协议的基础上创建加密通道来传输数据。</li>
<li>位置不同：<strong>信道</strong>通常是指在通信的物理媒介上的传输路径，而<strong>隧道</strong>则是在信道之上的OSI模型层协上创建加密通道的逻辑概念。</li>
<li>传输方式不同：<strong>信道</strong>是直接用于传输数据的物理媒介，信号通过信道进行传输；<strong>隧道</strong>则是在传输数据时，将数据封装成新的协议格式，通过信道进行加密传输。</li>
<li>使用场景不同：<strong>信道</strong>常用于介质访问控制、传输层控制、传输介质选择等方面，例如在局域网中使用以太网电缆传送数据。<strong>隧道</strong>则通常用于保障企业内部网络安全、建立虚拟专用网络、跨越防火墙等隧道服务需求。</li>
<li>技术特点不同：<strong>信道</strong>是一种物理层或数据链路层技术，而<strong>隧道</strong>是一种应用层或数据链路层技术。</li>
</ol>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
