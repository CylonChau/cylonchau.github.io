<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Interview on Cylon&#39;s Collection</title>
    <link>https://www.oomkill.com/tags/interview/</link>
    <description>Recent content in Interview on Cylon&#39;s Collection</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 01 May 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://www.oomkill.com/tags/interview/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>interview retrospective 2304</title>
      <link>https://www.oomkill.com/2023/05/interview-retrospective-2304/</link>
      <pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2023/05/interview-retrospective-2304/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="cloud-controller-manage">cloud-controller-manage</h2>
<p>controller相关 <code>cloud-controller-manage</code> 没有听清楚名称</p>
<h2 id="云平台lb">云平台LB</h2>
<p>答的方向是metalLB设计，而interviewer想听的是云平台方向</p>
<h2 id="容器底座实现技术方向">容器底座实现技术方向</h2>
<p>contrainerd方向问题</p>
<h2 id="linux内存和cpu的调度问题">Linux内存和cpu的调度问题</h2>
<p>没有答上</p>
<h2 id="kubernetes集群在扩容需要考虑到的问题">kubernetes集群在扩容需要考虑到的问题</h2>
<ul>
<li>APIServer方向：kubernetes官方提供了集群规模的配置</li>
<li>控制平面方向： contorller, sheduler 日志的输出（可以不需要管理）</li>
<li>worker节点： 镜像仓库的压力（P2P仓库）</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>go面试题收集</title>
      <link>https://www.oomkill.com/2021/10/interview-go/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2021/10/interview-go/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="数据结构">数据结构</h2>
<h3 id="数据类型总结">数据类型总结</h3>
<p>Go语言将数据类型分为四类：基础类型、复合类型、引用类型和接口类型。</p>
<p>基础数据类型包括：</p>
<ul>
<li>基础类型：
<ul>
<li>布尔型、整型、浮点型、复数型、字符型、字符串型、错误类型。</li>
</ul>
</li>
<li>复合数据类型包括：
<ul>
<li>指针、数组、切片、字典、通道、结构体、接口。</li>
</ul>
</li>
</ul>
<h3 id="什么是反射">什么是反射</h3>
<p>在计算机科学领域，反射是指一类应用，它们能够<em><strong>自描述</strong></em>和<em><strong>自控制</strong></em>。</p>
<p>在go中，编译时不知道类型的情况下，可更新变量、运行时查看值、调用方法以及直接对他们的布局进行操作的机制，称为反射。</p>
<p>场景：无法透视一个未知类型的时候，这时候就需要有反射来帮忙你处理，反射使用TypeOf和ValueOf函数从接口中获取目标对象的信息，轻松完成目的。</p>
<h3 id="rune与byte的区别">rune与byte的区别</h3>
<ul>
<li>byte是uint8、rune为uint32，一个仅限于ascii码的值，一个支持更多的值。rune比byte能表达更多的数。</li>
<li>golang默认使用utf8编码，一个中文占用3字节，一个utf8数字占用1字节，utf8字母占用1字节</li>
</ul>
<h3 id="切片">切片</h3>
<p><strong>切片的扩容</strong>：切片扩容，一般方式：上一次容量的2倍，超过1024字节，每次扩容上一次的1/4</p>
<p><strong>切片的截取</strong>：在截取时，capacity 不能超过原slice的 capacity</p>
<h3 id="new-与-make-的区别">new() 与 make() 的区别</h3>
<p><code>new(T)</code>  和 <code>make(T, args)</code>  是Go语言内建函数，用来分配内存，但适用的类型不用。</p>
<ul>
<li><code>new</code>函数用于分配指定类型的零值对象，并返回指向其内存地址的指针。例如，<code>new(int)</code>将分配一个类型为<code>int</code>且值为0的对象，并返回一个指向该地址的指针。可以使用<code>*</code>运算符访问指针指向的值。</li>
<li><code>make</code>函数用于创建和初始化内置类型（如<code>map</code>、<code>slice</code>、<code>channel</code>）的数据结构，并返回其指针。它比<code>new</code>函数更加复杂很多，因为它需要知道类型的大小和结构，以便为其分配内存并初始化其字段或元素。例如，<code>make(map[string]int)</code>将创建一个空的<code>map</code>。它有一个<code>string</code>类型的键和一个<code>int</code>类型的值。</li>
</ul>
<h3 id="nil切片和空切片指向的地址一样吗">nil切片和空切片指向的地址一样吗？</h3>
<ul>
<li>nil切片和空切片指向的地址==不一样==。nil空切片引用数组指针地址为0（无指向任何实际地址）</li>
<li>空切片的引用数组指针地址是有的，且固定为一个值</li>
</ul>
<h3 id="什么是receiver">什么是Receiver</h3>
<p>Golang的Receiver是绑定<code>function</code>到特定<code>type</code>成为其<code>method</code>的一个参数，即一个<code>function</code>加了<code>receiver</code>就成为一个type的method。</p>
<h3 id="构体方法跟结构体指针方法的区别receiver和指针receiver的区别">构体方法跟结构体指针方法的区别（Receiver和指针Receiver的区别）</h3>
<ul>
<li>T 的方法集仅拥有 T Receiver。</li>
<li>*T 方法集则包含全部方法 (<code>Receiver</code>  + <code>*Receiver</code>)。</li>
</ul>
<h3 id="synconce">sync.once</h3>
<ul>
<li>
<p>是 Golang package 中使方法只执行一次的对象实现，作用与 init 函数类似。但也有所不同</p>
</li>
<li>
<p>init 函数是在文件包首次被加载的时候执行，且只执行一次</p>
</li>
<li>
<p>sync.Onc 是在代码运行中需要的时候执行，且只执行一次</p>
</li>
<li>
<p>当一个函数不希望程序在一开始的时候就被执行的时候，我们可以使用 sync.Once</p>
</li>
<li>
<p>实现：sync.Once 的源码实现非常简单，采用的是双重检测锁机制 (Double-checked Locking)，是并发场景下懒汉式单例模式的一种实现方式</p>
<ul>
<li>首先判断 done 是否等于 0，等于 0 则表示回调函数还未被执行</li>
<li>加锁，确保并发安全</li>
<li>在执行函数前，二次确认 done 是否等于 0，等于 0 则执行</li>
<li>将 done 置 1，同时释放锁
疑问一: 为什么不使用乐观锁 CAS
简单的来说就是 f() 的执行结果最终可能是不成功的，所以你会看到现在采用的是双重检测锁机制来实现，同时需要等 f() 执行完成才修改 done 值
疑问二: 为什么读取 done 值的方式没有统一
比较 done 是否等于 0，为什么有的地方用的是 atomic.LoadUint32，有的地方用的却是 o.done。主要原因是 atomic.LoadUint32 可以保证原子读取到 done 值，是并发安全的，而在 doSlow 中，已经加锁了，那么临界区就是并发安全的，使用 o.done 就可以来读取值就可以了</li>
</ul>
</li>
</ul>
<h3 id="原子操作和互斥锁的区别">原子操作和互斥锁的区别</h3>
<p>文档：https://zhuanlan.zhihu.com/p/147618421</p>
<h3 id="gmp模型">GMP模型</h3>
<p>文档：https://zhuanlan.zhihu.com/p/261590663
文档：https://juejin.cn/post/6844904104343388168</p>
<ul>
<li>
<p>G：goroutine</p>
</li>
<li>
<p>M：Machine，内核线程</p>
</li>
<li>
<p>P：Logical Processor，处理器；代表了M所需要的上下文环境</p>
<ul>
<li>runtime.GOMAXPROCS (numLogicalProcessors)可以设置多少个处理器，go 1.5开始，默认是CPU核数；</li>
<li>实际运行时P和CPU核心数并无任何关联，P最大不超过256；P可以理解为并行度的多少，也就是说当前最多只能有P个线程在运行；(是不是很像线程池)</li>
<li>P一旦初始化了，就不能修改了
<strong>三者关系</strong></li>
</ul>
</li>
<li>
<p>M的数量和P不一定匹配，可以设置很多M，M和P绑定后才可运行，多余的M处于休眠状态。</p>
</li>
<li>
<p>P包含一个LRQ（Local Run Queue）本地运行队列，这里面保存着P需要执行的协程G的队列。</p>
</li>
<li>
<p>除了每个P自身保存的G的队列外，调度器还拥有一个全局的G队列GRQ（Global Run Queue），这个队列存储的是所有未分配的协程G。</p>
</li>
</ul>
<h3 id="go-func执行流程">go func()执行流程</h3>
<ul>
<li>创建一个G对象，加入到本地队列或全局队列；</li>
<li>如果还有空闲的P，则创建一个M；</li>
<li>M会启动一个底层线程，并结合P，循环执行G；</li>
<li>P执行G的顺序是，先从本地队列找，没有则到全局队列找（一次性转移[全局G个数/P个数]），再到其他P中找（一次性转移一半）；</li>
<li>G是执行顺序是按照队列顺序的；</li>
<li>P管理着G队列，但是G要运行，还需要M的绑定；</li>
<li>runtime.GOMAXPROCS只会影响P的数量，不会影响M的数量；</li>
<li>P和M的关系，就好比用户线程和内核线程的N：M模型；</li>
<li>没有足够的M关联P时，会创建M；在runtime执行系统监控或垃圾回收等任务的时候也会导致新的M的创建。 所以，runtime.GOMAXPROCS只是类似线程池的大小设置而已；</li>
<li>当然，go也可以通过runtime/debug.SeMaxThreads限制操作系统线程数；SetMaxThreads主要用于限制程序无限制的创造线程导致的灾难。目的是让程序在干掉操作系统之前，先干掉它自己。</li>
<li>goroutine是按照抢占式调度的，一个goroutine最多执行10ms就会换作下一个；</li>
</ul>
<h3 id="死锁">死锁</h3>
<p><strong>死锁是</strong>：多个进（线）程是相互竞争的关系，并且互持资源，相互等待，这样产生的永久阻塞的现象称为死锁。</p>
<p><strong>死锁产生的原因</strong>：</p>
<ul>
<li>互斥</li>
<li>占有且等待</li>
<li>不可抢占</li>
<li>循环等待</li>
</ul>
<p><strong>死锁如何解决</strong>：死锁的发生很难通过人为干预来解决，只能避免（打破死锁产生的条件）</p>
<ul>
<li>互斥：线程安全是通过互斥来实现的（无法干预）</li>
<li>占有且等待：申请资源时获取所有所需资源</li>
<li>不可抢占：占用资源的进程在进一步申请其他资源时，如申请不到主动释放已占有的资源</li>
<li>循环等待：按需预防，对所需资源进行排序，按照大小依次申请</li>
</ul>
<blockquote>
<p>Refer <a href="https://cylonchau.github.io/ch11-deadlock.html#%E6%AD%BB%E9%94%81%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95">deadlock</a></p>
</blockquote>
<p><strong>Go中产生死锁的原因</strong>：</p>
<ul>
<li>无缓冲；解决：缓冲或先读后写</li>
<li>缓冲已满（只写不读）；解决，需要有消费端</li>
<li>读写互斥；（读写加锁导致一段阻塞变成死锁）</li>
<li>未初始化的channel（读，写，关闭）</li>
<li>多线程只要保证个线程的执行，可以允许死锁
<ul>
<li>如主进程只读不写造成阻塞，这种情况在没有子线程情况下是死锁</li>
</ul>
</li>
</ul>
<h3 id="slice和map区别">slice和map区别</h3>
<ul>
<li>slice是有序的，map是无序的，在每次迭代时，无法确定其顺序</li>
<li>slice有容量，map没有容量，map是由go内部控制的数据结构</li>
<li>slice可以使用appen()，map不可以</li>
<li>slice和map都是引用类型，当作为参数传递时共享相同地址</li>
</ul>
<h2 id="如何复制slicemap和interface">如何复制slice、map和interface？</h2>
<p>这些类型的变量是内存引用类型，可以使用内置函数 <code>copy()</code> 来完成复制 <a href="https://www.toptal.com/go/interview-questions">Refer to</a></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="nx">a</span> <span class="o">:=</span> <span class="p">[]</span><span class="kt">int</span><span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="nx">b</span> <span class="o">:=</span> <span class="p">[]</span><span class="kt">int</span><span class="p">{</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="nx">check</span> <span class="o">:=</span> <span class="nx">a</span>
</span></span><span class="line"><span class="cl"><span class="nb">copy</span><span class="p">(</span><span class="nx">a</span><span class="p">,</span> <span class="nx">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">a</span><span class="p">,</span> <span class="nx">b</span><span class="p">,</span> <span class="nx">check</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1">// Output: [3 4] [3 4] [3 4]
</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="什么是goroutine">什么是goroutine</h3>
<p>go的多线程是包含在运行时内的一种机制，用的模型是两级，即runtime帮助申请和释放线程，而这个gorutine可以为一对一，也可以为一对多，即操作系统中的 “两级模型”（<code>Two-Level</code>）是严格意义上的多对多模型，可以为单个用户线程专门一对一绑定内核线程的能力的模型</p>
<p>用户线程的缺点：</p>
<ul>
<li>用户级线程与操作系统的集成度不高；如用空闲线程调度进程，阻塞其线程发起 I/O 的进程，即使该进程有其他线程可以运行，以及有锁的线程取消调度进程。</li>
<li>用户级线程需要非阻塞系统调用，否则，当一个线程阻塞，即使进程中还有可运行的线程，整个进程也会在内核中阻塞。例如，如果一个线程导致页面错误，则进程阻塞。</li>
<li>用户线程和操作系统内核之间缺乏协调性；无论进程有 1 个线程还是 1000 个线程，都仅能获得一个CPU时间片。由每个线程主动将控制权交给其他线程。</li>
<li>由于进程时资源分配的最小单位，多线程情况下，每个线程得到的时间片较少，执行会较慢。</li>
</ul>
<h3 id="c语言的线程和goroutine的区别主要表现在以下几个方面">C语言的线程和Goroutine的区别主要表现在以下几个方面</h3>
<ol>
<li>实现方式不同：C语言的线程是由操作系统内核来实现的，而Goroutine则是通过Go语言的runtime来实现的。</li>
<li>内存分配方式不同：C语言的线程需要在内存中分配一定的栈空间，而Goroutine则通过自动扩展栈来实现。</li>
<li>调度方式不同：C语言的线程是由操作系统内核来调度的，而Goroutine是通过Go语言的runtime自己实现的调度器来调度的。</li>
<li>轻量级：Goroutine是轻量级的线程，一个Goroutine只需要2KB的栈空间，而C语言的线程需要占用更多的内存空间。</li>
<li>效率高：由于Goroutine是由Go语言的runtime来实现的，因此它具有非常高的执行效率和并发性能，比C语言的线程更加高效。</li>
</ol>
<p>总的来说，Goroutine是Go语言的并发特性中非常重要的一部分，通过Goroutine可以非常方便地实现高效的并发程序。而C语言的线程则更多地是由操作系统来实现，对于一些需要最大化利用机器性能的场景会更为适合。</p>
<h2 id="应用">应用</h2>
<h3 id="go语言创建tcp连接">Go语言创建TCP连接</h3>
<ul>
<li>conn.dial</li>
<li>conn.write/read</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>kubernetes面试题收集</title>
      <link>https://www.oomkill.com/2021/10/interview-kubernetes/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2021/10/interview-kubernetes/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="kubernetes概念">Kubernetes概念</h2>
<h3 id="ingress和loadbalancer的区别">Ingress和LoadBalancer的区别</h3>
<ul>
<li>Ingress通常用于将HTTP(S)流量路由到Kubernetes群集内部的服务，支持复杂路径路由和负载均衡算法</li>
<li>LB则是通过提供商提供一种外部流量引入到集群内的组件，通常为2 3层</li>
<li>Ingress本身是基于service的，引入流量时依赖 kube-proxy</li>
<li>LB则是独立的组件，最小接入单元也是service，而通过2 3层的广播等功能可以提供多节点的引入</li>
<li>功能：Ingress是一个规范，LB则是一种实现</li>
<li>实现方式：ingress通过扩展Kubernetes API+controller, 而LB除此外还需要外部设备提供（软硬件，云组件）</li>
</ul>
<h3 id="kubernetes之最小单元">kubernetes之最小单元</h3>
<ul>
<li>Pod最小可调度单元，最小部署单元</li>
<li>容器：容器是最小的执行单元</li>
<li>Namespace：最小隔离单元</li>
<li>Service：最小接入单元</li>
</ul>
<h3 id="etcd用的什么算法简单解释一下">etcd用的什么算法，简单解释一下</h3>
<p>raft算法 强一致性 同一时间只能有一个leader,所有的操作都在leader上。</p>
<h3 id="pod-的生命周期">Pod 的生命周期</h3>
<p>Pod 状态始终处于一下几个状态之一:</p>
<ul>
<li>Pending: 部署 Pod 事务已被集群受理，但当前容器镜像还未下载完或现有资源无法满足 Pod 的资源需求</li>
<li>Running: 所有容器已被创建，并被部署到节点上</li>
<li>Successed: Pod 成功退出，并不会被重启</li>
<li>Failed: Pod 中有容器被终止</li>
<li>Unknown: 未知原因，如 kube-apiserver 无法与 Pod 进行通讯</li>
</ul>
<h3 id="kubernetes有哪些不同类型的服务">Kubernetes有哪些不同类型的服务？</h3>
<ul>
<li>cluster ip</li>
<li>Node Port</li>
<li>Load Balancer</li>
<li>Extrenal Name</li>
</ul>
<h3 id="什么是etcd">什么是ETCD？</h3>
<p>Etcd是用Go编程语言编写的，是一个分布式键值存储，用于协调分布式工作。因此，Etcd存储Kubernetes集群的配置数据，表示在任何给定时间点的集群状态。</p>
<h3 id="什么是ingress网络它是如何工作的">什么是Ingress网络，它是如何工作的？</h3>
<p><a href="https://link.zhihu.com/?target=https%3A//www.edureka.co/blog/kubernetes-networking%3Futm_source%3Dmedium%26utm_medium%3Dcontent-link%26utm_campaign%3Dkubernetes-interview-questions%26source%3Dpost_page---------------------------">Ingress网络</a>是一组规则，充当Kubernetes集群的入口点。这允许入站连接，可以将其配置为通过可访问的URL，负载平衡流量或通过提供基于名称的虚拟主机从外部提供服务。因此，Ingress是一个API对象，通常通过HTTP管理集群中服务的外部访问，是暴露服务的最有效方式。</p>
<h3 id="什么是headless-service">什么是Headless Service？</h3>
<p>Headless Service类似于“普通”服务，但没有群集IP。此服务使您可以直接访问pod，而无需通过代理访问它。</p>
<h3 id="什么是集群联邦">什么是集群联邦？</h3>
<p>在联邦集群的帮助下，可以将多个Kubernetes集群作为单个集群进行管理。因此，您可以在数据中心/云中创建多个Kubernetes集群，并使用联邦来在一个位置控制/管理它们。</p>
<p>联合集群可以通过执行以下两项操作来实现此目的。请参考下图。</p>
<h3 id="kube-proxy的作用">kube-proxy的作用</h3>
<p>kube-proxy运行在所有节点上，它监听apiserver中service和endpoint的变化情况，创建路由规则以提供服务IP和负载均衡功能。简单理解此进程是Service的透明代理兼负载均衡器，其核心功能是将到某个Service的访问请求转发到后端的多个Pod实例上。</p>
<h3 id="kube-proxy-iptables的原理">kube-proxy iptables的原理</h3>
<p>Kubernetes从1.2版本开始，将iptables作为kube-proxy的默认模式。iptables模式下的kube-proxy不再起到Proxy的作用，其核心功能：通过API  Server的Watch接口实时跟踪Service与Endpoint的变更信息，并更新对应的iptables规则，Client的请求流量则通过iptables的NAT机制“直接路由”到目标Pod。</p>
<h3 id="kube-proxy-ipvs的原理">kube-proxy ipvs的原理</h3>
<p>IPVS在Kubernetes1.11中升级为GA稳定版。IPVS则专门用于高性能负载均衡，并使用更高效的数据结构（Hash表），允许几乎无限的规模扩张，因此被kube-proxy采纳为最新模式。</p>
<p>在IPVS模式下，使用iptables的扩展ipset，而不是直接调用iptables来生成规则链。iptables规则链是一个线性的数据结构，ipset则引入了带索引的数据结构，因此当规则很多时，也可以很高效地查找和匹配。</p>
<p>可以将ipset简单理解为一个IP（段）的集合，这个集合的内容可以是IP地址、IP网段、端口等，iptables可以直接添加规则对这个“可变的集合”进行操作，这样做的好处在于可以大大减少iptables规则的数量，从而减少性能损耗。</p>
<h3 id="kube-proxy-ipvs和iptables的异同">kube-proxy ipvs和iptables的异同</h3>
<p>iptables与IPVS都是基于Netfilter实现的，但因为定位不同，二者有着本质的差别：iptables是为防火墙而设计的；IPVS则专门用于高性能负载均衡，并使用更高效的数据结构（Hash表），允许几乎无限的规模扩张。</p>
<p>与iptables相比，IPVS拥有以下明显优势：</p>
<ul>
<li>为大型集群提供了更好的可扩展性和性能；</li>
<li>支持比iptables更复杂的复制均衡算法（最小负载、最少连接、加权等）；</li>
<li>支持服务器健康检查和连接重试等功能；</li>
<li>可以动态修改ipset的集合，即使iptables的规则正在使用这个集合。</li>
</ul>
<h3 id="kubernetes镜像的下载策略">Kubernetes镜像的下载策略</h3>
<p>Kubernetes的镜像下载策略有三种：Always、Never、IFNotPresent。</p>
<ul>
<li>Always：镜像标签为latest时，总是从指定的仓库中获取镜像。</li>
<li>Never：禁止从仓库中下载镜像，也就是说只能使用本地镜像。</li>
<li>IfNotPresent：仅当本地没有对应镜像时，才从目标仓库中下载。默认的镜像下载策略是：当镜像标签是latest时，默认策略是Always；当镜像标签是自定义时（也就是标签不是latest），那么默认策略是IfNotPresent。</li>
</ul>
<h3 id="简述kubernetes-scheduler使用哪两种算法将pod绑定到worker节点">简述Kubernetes Scheduler使用哪两种算法将Pod绑定到worker节点</h3>
<p>Kubernetes Scheduler根据如下两种调度算法将 Pod 绑定到最合适的工作节点：</p>
<ul>
<li>预选（Predicates）：输入是所有节点，输出是满足预选条件的节点。kube-scheduler根据预选策略过滤掉不满足策略的Nodes。如果某节点的资源不足或者不满足预选策略的条件则无法通过预选。如“Node的label必须与Pod的Selector一致”。</li>
<li>优选（Priorities）：输入是预选阶段筛选出的节点，优选会根据优先策略为通过预选的Nodes进行打分排名，选择得分最高的Node。例如，资源越富裕、负载越小的Node可能具有越高的排名。</li>
</ul>
<h3 id="有了解过qos吗-怎么实现的">有了解过qos吗？ 怎么实现的？</h3>
<p>服务质量 Quality of Service有三种 Guaranteed, Burstable, and Best-Effort，它们的QoS级别依次递减。</p>
<ul>
<li><strong>Guaranteed</strong>：确保的，只设置 <code>limits</code> 或者 <code>requests</code> 与 <code>limits</code> 为相同时则为该等级</li>
<li><strong>Burstable</strong>：可突发的，只设置 <code>requests</code> 或 <code>requests</code> 低于  <code>limits</code> 的场景</li>
<li><strong>Best-effort</strong>： 默认值，如果不设置则为这个等级</li>
</ul>
<p>node资源不足时会按qos级别驱逐pod。 最先驱逐的是Best-Effort ,重要组件一定要设置limit和request.</p>
<p>驱逐顺序根据 <strong>BestEffort</strong> ==》<strong>Burstable</strong> ==》<strong>Guaranteed</strong> 进行驱逐</p>
<h2 id="kubernetes-开发">Kubernetes 开发</h2>
<h3 id="资源和类型">资源和类型</h3>
<p><strong>Kind</strong>：实体的类型</p>
<p><strong>resources</strong>：resources<strong>是</strong>，restful中的资源，标识一组HTTP端点（paths），可以理解为kind的实例化。</p>
<p>例如：Pod是etcd中的数据，而resources对应的 path上的resources</p>
<h4 id="resources和kinds区别">Resources和kinds区别</h4>
<p>
  <img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/d14b874da710" alt="img"  /></p>
<ul>
<li>Resources与HTTP paths关联，</li>
<li>Resources始终是API Group和Version的一部分。</li>
<li>kind是这些endpoint返回并接收的objects的类型，并持久存在于etcd中。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:left">Kubernetes</th>
<th style="text-align:left">OOP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Kind</td>
<td style="text-align:left">Class</td>
</tr>
<tr>
<td style="text-align:left">Resource</td>
<td style="text-align:left">Object</td>
</tr>
</tbody>
</table>
<p>Kind 其实就是一个类，用于描述对象的；而 Resource 就是具体的 Kind，可以理解成类已经实例化成对象了。</p>
<h4 id="gvr与gvk有什么区别">GVR与GVK有什么区别？</h4>
<ul>
<li>GVR = Group Version Resources</li>
<li>GVK = Group Version Kind</li>
</ul>
<p>每个kind都属于一个Group和Version中，通过GVK标识，GVR是GVK对外提供服务的入口，GVK与GVR之间的映射过程交 REST mapping</p>
<h3 id="client-go-客户端类型有哪些">client-go 客户端类型有哪些？</h3>
<ul>
<li>RestClient：是最基础的客户端，其作用是将http client进行封装成rest api格式。位于rest目录</li>
<li>ClientSet：基于RestClient进行封装对 Resource 与 version 管理集合，</li>
<li>DiscoverySet：RestClient进行封装，可动态发现kube-apiserver所支持的GVR（Group Version Resource）。</li>
<li></li>
<li>：基于RestClient，包含动态的客户端，可以对Kubernetes所支持的 API对象进行操作，包括CRD。</li>
</ul>
<h3 id="kubernetes-调度过程">kubernetes 调度过程</h3>
<p>kubernetes调度过程就是调度上下文，而调度上下文就是执行 scheduleOne 这个函数中线性执行的。</p>
<p>调度上下文的过程分为两阶段，调度和绑定</p>
<p>调度：指的是SchedulePod -&gt; findNodesThatFitPod 这是 prefilter 阶段，如果通过 prefilter</p>
<ul>
<li>
<p>prefilter 做预检查动作，如获取node列表，检查提名node是否满足，满足则评估，不满足则从PreFilterPlugins获取node list，满足所有条件执行 filter plugin；PreFilterPlugins返回的是一组Node name</p>
</li>
<li>
<p>filter 做过滤操作，满足的条件是至少配置了一个filter plugin，filter是线性的，如一个扩展不满足则标记为不可用</p>
</li>
<li>
<p>postFilter 是抢占的触发条件，即filter阶段没有FN时被触发，满足条件是需要配置至少一个该类型plugin</p>
<ul>
<li>这里存在 Unschedulable 不可调用则执行postfilter，否则都不可调用</li>
</ul>
</li>
<li>
<p>preScore, score 会在 prioritizeNodes 中执行对应的 插件</p>
</li>
<li>
<p>接下来是 Reserve, 为了避免Pod在绑定到节点前时，调度一个新的Pod，使节点使用资源超过可用资源情况。</p>
</li>
<li>
<p>Premit ，阻止或延迟 Pod 的绑定</p>
</li>
</ul>
<p>绑定：绑定操作时异步进行的，即通过了打分阶段，基本上等于调度成功</p>
<ul>
<li>这个异步线程会从延迟队列中拿到调度的pod，即Premit 的延迟</li>
<li>这里关联的上面的reserve 与 premit，如果不可调用则调用unreserved回滚，否则会调用 bind</li>
<li>prebind 与 bind 的失败都会放入到回滚队列中</li>
<li>bind 当 执行了unreserve 则忘记这个pod 否则成功的绑定了node</li>
</ul>
<h3 id="client-go的架构">client-go的架构</h3>
<ul>
<li>
<p>Reflector deltafifo的生产者 就是将 （监控）Etcd 里面的数据反射到本地存储（DeltaFIFO）中</p>
</li>
<li>
<p>deltaFIFO， Delta 表示的是变化的资源对象存储 先进先出的队列</p>
</li>
<li>
<p>workqueue kubernetes中使用的队列，即每次触发的事件都被塞入到queue中进行处理</p>
<ul>
<li><strong>去重</strong></li>
<li><strong>delay</strong>：如 cronjob 依赖延迟队列实现定时功能</li>
<li>限速：</li>
</ul>
</li>
<li>
<p>Indexer deltaFIFO消费者，是Informer的本地存储。</p>
</li>
</ul>
<h3 id="workqueue算法实现">workqueue算法实现</h3>
<p>已知workqueue主要作用是为了去重，延迟，限速，那么他是通过什么算法实现的呢？</p>
<ul>
<li>延迟主要使用了 <em><strong>Binary Heap</strong></em> 数据类型实现的延迟，而这种queue称为优先级队列
<ul>
<li>Heap是一个二叉树数据结构，即每个节点包含的元素大于或等于该节点子节点的元素，如果新元素的值大于父元素，将新元素与父元素交换，直到达到新元素到根，这个过程叫向上调整</li>
<li>元素被放置在结构中时，按照优先级排列</li>
<li>优先级最高的元素最先离开</li>
</ul>
</li>
<li>限速队列时在延迟队列的基础上扩展的，使用的令牌桶和漏桶算法实现的</li>
</ul>
<h3 id="kube-proxy作用">kube-proxy作用</h3>
<p>kube-proxy作用是位于工作节点上，通过ipvs提供service功能，本质上来说是一个controller，通过监听 node, endpoints， service等资源的变动从而生成proixer的规则</p>
<h3 id="什么是endpointslice">什么是endpointslice</h3>
<ul>
<li>Endpoints 与 EndpointSlices 均是为service提供端点的</li>
<li>Service规模越大，那么Endpoints中的 Pod 数量越大，传输的 EndPoints 对象就越大。集群中 Pod 更改的频率越高，也意味着传输在网络中发生的频率就越高</li>
<li>Endpoints 对象在大规模集群场景下存在下列问题：
<ul>
<li>增加网络流量（etcd最大请求大小为 1.5 MiB），隐性增加对控制平面的影响，service的可扩展性将降低</li>
<li>超大规模的 service 理论上会无法存储 该 Endpoints</li>
<li>处理Endpoints资源的 worker 会消耗更多的计算资源</li>
</ul>
</li>
<li>Endpointslices 解决了：
<ul>
<li>部分更新，更少的网络流量</li>
<li>Worker 处理 Endpoints 更新所需的资源更少</li>
<li>减少对控制平面的影响，提升的性能和 service 规模</li>
</ul>
</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>操作系统类面试题收集</title>
      <link>https://www.oomkill.com/2021/10/interview-linux/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2021/10/interview-linux/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="linux-基础">Linux 基础</h2>
<h3 id="守护僵孤进程的概念">守护、僵⼫、孤⼉进程的概念</h3>
<p>【答】</p>
<ul>
<li>守护进程：运⾏在后台的⼀种特殊进程，独⽴于控制终端并周期性地执⾏某些任务。</li>
<li>僵⼫进程：⼀个进程 fork ⼦进程，⼦进程退出，⽽⽗进程没有 wait/waitpid⼦进程，那么⼦进程的进程描述符仍保存在系统中，这样的进程称为僵⼫进程。</li>
<li>孤⼉进程：⼀个⽗进程退出，⽽它的⼀个或多个⼦进程还在运⾏，这些⼦进程称为孤⼉进程。（孤⼉进程将由 init 进程收养并对它们完成状态收集⼯作）</li>
</ul>
<h3 id="进程间通讯方式有哪些">进程间通讯方式有哪些？</h3>
<ul>
<li><strong>Pipe</strong>：无名管道，最基本的IPC，单向通信，仅在父/子进程之间，也就是将一个程序的输出直接交给另一个程序的输入。常见使用为 <code>ps -ef|grep xxx</code></li>
<li><strong>FIFO [<code>(First in, First out)</code>] 或  有名管道（<code>named pipe</code>）</strong>:与Pipe不同，<strong>FIFO</strong>可以让两个不相关的进程可以使用FIFO。单向。</li>
<li><strong>Socket 和 Unix Domain Socket</strong>：socket和Unix套接字，双向。适用于网络通信，但也可以在本地使用。适用于不同的协议。</li>
<li><strong>消息队列 <code>Message Queue</code></strong>:  SysV 消息队列、POSIX 消息队列。</li>
<li><strong>Signal</strong>: 信号，是发送到正在运行的进程通知以触发其事件的特定行为，是IPC的一种有限形式。</li>
<li><strong>Semaphore</strong>：信号量，通常用于IPC或同一进程内的线程间通信。他们之间使用队列进行消息传递、控制或内容的传递。（常见SysV 信号量、POSIX 信号量）</li>
<li><strong>Shared memory</strong>：（常见SysV 共享内存、POSIX 共享内存）。共享内存，是在进程（程序）之间传递数据的有效方式，目的是在其之间提供通信。</li>
</ul>
<h3 id="bash和dos控制台之间的主要区别在于3个方面">BASH和DOS控制台之间的主要区别在于3个方面：</h3>
<p><strong>答案</strong>：</p>
<ul>
<li>BASH命令区分大小写，而DOS命令则不区分;</li>
<li>在BASH下，/ character是目录分隔符，\ 作为转义字符。在DOS下，/ 用作命令参数分隔符，\ 是目录分隔符</li>
<li>DOS遵循命名文件中的约定，即8个字符的文件名后跟一个点，扩展名为3个字符。BASH没有遵循这样的惯例。</li>
</ul>
<h3 id="linux-中进程有哪几种状态在-ps-显示出来的信息中分别用什么符号表示的">Linux 中进程有哪几种状态？在 ps 显示出来的信息中，分别用什么符号表示的？</h3>
<p><strong>答案</strong>：</p>
<ul>
<li>
<p>R runnable (on run queue) 运行 (正在运行或在运行队列中等待)</p>
</li>
<li>
<p>S 中断 sleeping(休眠中, 受阻, 在等待某个条件的形成或接受到信号)</p>
</li>
<li>
<p>D 不可中断 uninterruptible sleep (usually IO)(收到信号不唤醒和不可运行, 进程必须等待直到有中断发生)</p>
</li>
<li>
<p>Z 僵尸 a defunct (”zombie”) process (进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放)</p>
</li>
<li>
<p>T 停止 traced or stopped (进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行)</p>
</li>
</ul>
<h3 id="系统目前有许多正在运行的任务在不重启机器的条件下有什么方法可以把所有正在运行的进程移除呢">系统目前有许多正在运行的任务，在不重启机器的条件下，有什么方法可以把所有正在运行的进程移除呢？</h3>
<p>答案：使用linux命令 ’disown -r ’可以将所有正在运行的进程移除。</p>
<h3 id="linux-粘滞位作用">Linux 粘滞位作用</h3>
<p><strong>答案</strong>：</p>
<p>粘滞位(sticky bit)权限是针对目录的，对文件无效，设置了sticky位表示这个目录里的文件只能被owner和root删除。</p>
<h3 id="什么是inode">什么是inode？</h3>
<p><strong>答案</strong>：</p>
<p>inode是Linux(Unix)操作系统中文件系统的一个概念。inode的全称为index node，也就是索引节点。那么inode是用来索引什么的呢？其实inode表示的是一个文件，它是用来索引文件数据的。</p>
<h3 id="磁盘报错no-space-left-on-device但是通过命令df-h查看磁盘空间没有满请问为什么">磁盘报错”No space left on device”，但是通过命令df –h查看磁盘空间没有满，请问为什么？</h3>
<p><strong>答案</strong>：</p>
<p>该磁盘的inode数量被用尽，无法再写入文件。
企业工作中邮件临时队列 <code>/var/spool/clientmquene</code>或<code>/var/spool/postfix/maildrop</code>这里很容易被大量小文件占满导致<code>No space left on device</code>的错误。<code>clientmquene</code>目录只有安装了<code>sendmail</code>服务，才会有，是<code>sendmail</code>的临时队列。</p>
<h3 id="一个100m的磁盘分区分别写入1k的文件及写入1m的文件分别可以写多少个">一个100M的磁盘分区，分别写入1K的文件，及写入1M的文件，分别可以写多少个？</h3>
<p><strong>答案</strong>：</p>
<p>在linux文件系统中，iNode用来存放文件的属性信息，而Block用来存放文件实际内容，默认大小1K(boot)或4K(非系统分区默认为4k)。</p>
<p>写入1M文件的数量为100/1，且不会存在磁盘浪费情况（这也说明了一般情况下，inode和block的数量都是足够的）；</p>
<p>而写入1K文件时，inode和block同时被消耗，但一般block数量远大于inode的数量，因此写入的数量就是inode的数量，并且这样会浪费3/4的磁盘容量。</p>
<h3 id="nohup">nohup</h3>
<p>nohup 执行会忽略信号 <code>SIGHUP</code>，并将 <code>stdout/stderr</code> 重定向到文件 <code>nohup.out</code>。以便shell在关闭或注销后命令可以在后台继续运行 。nohup做的工作就是让 nohup 后的命令不在是当前 shell 的子命令。而是PPID=1的进程（进程的PPID=1）。这种情况下不能被带回到前台。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="n">signal</span> <span class="p">(</span><span class="n">SIGHUP</span><span class="p">,</span> <span class="n">SIG_IGN</span><span class="p">);</span> <span class="c1">// 忽略信号SIGHUP
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="kt">char</span> <span class="o">**</span><span class="n">cmd</span> <span class="o">=</span> <span class="n">argv</span> <span class="o">+</span> <span class="n">optind</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">execvp</span> <span class="p">(</span><span class="o">*</span><span class="n">cmd</span><span class="p">,</span> <span class="n">cmd</span><span class="p">);</span> <span class="c1">// 在执行这个命令，而不是当前shell
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>对于输出的重定向，对于STDOUT/STDERR会忽略，然后写入到 <code>nohup.out</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl">  <span class="n">ignoring_input</span> <span class="o">=</span> <span class="n">isatty</span> <span class="p">(</span><span class="n">STDIN_FILENO</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">redirecting_stdout</span> <span class="o">=</span> <span class="n">isatty</span> <span class="p">(</span><span class="n">STDOUT_FILENO</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">stdout_is_closed</span> <span class="o">=</span> <span class="p">(</span><span class="o">!</span><span class="n">redirecting_stdout</span> <span class="o">&amp;&amp;</span> <span class="n">errno</span> <span class="o">==</span> <span class="n">EBADF</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">redirecting_stderr</span> <span class="o">=</span> <span class="n">isatty</span> <span class="p">(</span><span class="n">STDERR_FILENO</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="cm">/* If standard input is a tty, replace it with /dev/null if possible.
</span></span></span><span class="line"><span class="cl"><span class="cm">     Note that it is deliberately opened for *writing*,
</span></span></span><span class="line"><span class="cl"><span class="cm">     to ensure any read evokes an error.  */</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="p">(</span><span class="n">ignoring_input</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="p">(</span><span class="n">fd_reopen</span> <span class="p">(</span><span class="n">STDIN_FILENO</span><span class="p">,</span> <span class="s">&#34;/dev/null&#34;</span><span class="p">,</span> <span class="n">O_WRONLY</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">error</span> <span class="p">(</span><span class="n">exit_internal_failure</span><span class="p">,</span> <span class="n">errno</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">               <span class="n">_</span><span class="p">(</span><span class="s">&#34;failed to render standard input unusable&#34;</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">redirecting_stdout</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">redirecting_stderr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">error</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">_</span><span class="p">(</span><span class="s">&#34;ignoring input&#34;</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="cm">/* If standard output is a tty, redirect it (appending) to a file.
</span></span></span><span class="line"><span class="cl"><span class="cm">     First try nohup.out, then $HOME/nohup.out.  If standard error is
</span></span></span><span class="line"><span class="cl"><span class="cm">     a tty and standard output is closed, open nohup.out or
</span></span></span><span class="line"><span class="cl"><span class="cm">     $HOME/nohup.out without redirecting anything.  */</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="p">(</span><span class="n">redirecting_stdout</span> <span class="o">||</span> <span class="p">(</span><span class="n">redirecting_stderr</span> <span class="o">&amp;&amp;</span> <span class="n">stdout_is_closed</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="kt">char</span> <span class="o">*</span><span class="n">in_home</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">      <span class="kt">char</span> <span class="k">const</span> <span class="o">*</span><span class="n">file</span> <span class="o">=</span> <span class="s">&#34;nohup.out&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">      <span class="kt">int</span> <span class="n">flags</span> <span class="o">=</span> <span class="n">O_CREAT</span> <span class="o">|</span> <span class="n">O_WRONLY</span> <span class="o">|</span> <span class="n">O_APPEND</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">      <span class="n">mode_t</span> <span class="n">mode</span> <span class="o">=</span> <span class="n">S_IRUSR</span> <span class="o">|</span> <span class="n">S_IWUSR</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">      <span class="n">mode_t</span> <span class="n">umask_value</span> <span class="o">=</span> <span class="n">umask</span> <span class="p">(</span><span class="o">~</span><span class="n">mode</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">      <span class="n">out_fd</span> <span class="o">=</span> <span class="p">(</span><span class="n">redirecting_stdout</span>
</span></span><span class="line"><span class="cl">                <span class="o">?</span> <span class="n">fd_reopen</span> <span class="p">(</span><span class="n">STDOUT_FILENO</span><span class="p">,</span> <span class="n">file</span><span class="p">,</span> <span class="n">flags</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="o">:</span> <span class="n">open</span> <span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">flags</span><span class="p">,</span> <span class="n">mode</span><span class="p">));</span>
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>Referece <a href="https://askubuntu.com/questions/995179/what-is-the-function-of-the-nohup-command">what is the function of the nohup command</a></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>监控类面试题</title>
      <link>https://www.oomkill.com/2021/10/interview-monitor/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2021/10/interview-monitor/</guid>
      <description></description>
      <content:encoded><![CDATA[<h3 id="prometheus的四种数据类型">Prometheus的四种数据类型</h3>
<ul>
<li>Counter(计数器类型) Counter类型的指标的工作方式和计数器一样，只增不减</li>
<li>Gauge(仪表盘类型) Gauge是可增可减的指标类，通常用于反应当前应用的状态。</li>
<li>Histogram 主要用于表示一段时间范围内对数据进行采样</li>
<li>Summary(摘要类型) Summary类型和Histogram类型相似，主要用于表示一段时间内数据采样结果</li>
</ul>
<h3 id="prometheus-的局限">Prometheus 的局限</h3>
<ul>
<li>Prometheus 是基于 Metric 的监控，不适用于日志（Logs）、事件(Event)、调用链(Tracing)。</li>
<li>Prometheus 默认是 Pull 模型，合理规划你的网络，尽量不要转发。对于集群化和水平扩展，官方和社区都没有银弹，需要合理选择 Federate、Cortex、Thanos等方案。</li>
<li>监控系统一般情况下可用性大于一致性，容忍部分副本数据丢失，保证查询请求成功。这个后面说Thanos 去重的时候会提到。</li>
<li>Prometheus 不一定保证数据准确，这里的不准确一是指 rate、histogram_quantile 等函数会做统计和推断，产生一些反直觉的结果，这个后面会详细展开。二来查询范围过长要做降采样，势必会造成数据精度丢失，不过这是时序数据的特点，也是不同于日志系统的地方</li>
</ul>
<h3 id="采集组件-all-in-one">采集组件 All IN One</h3>
<p>Prometheus 体系中 Exporter 都是独立的，每个组件各司其职，如机器资源用 Node-Exporter，Gpu 有Nvidia Exporter等等。但是 Exporter 越多，运维压力越大，尤其是对 Agent做资源控制、版本升级。我们尝试对一些Exporter进行组合，方案有二：</p>
<ol>
<li>通过主进程拉起N个 Exporter 进程，仍然可以跟着社区版本做更新、bug fix。</li>
<li>用Telegraf来支持各种类型的 Input，N 合 1。另外，Node-Exporter 不支持进程监控，可以加一个Process-Exporter，也可以用上边提到的Telegraf，使用 procstat 的 input来采集进程指标。</li>
</ol>
<h3 id="合理选择黄金指标">合理选择黄金指标</h3>
<p>采集的指标有很多，我们应该关注哪些？Google 在 <em>“Sre Handbook”</em> 中提出了“四个黄金信号”：延迟、流量、错误数、饱和度。实际操作中可以使用 Use 或 Red 方法作为指导，Use 用于资源，Red 用于服务。</p>
<ul>
<li>Use 方法：Utilization、Saturation、Errors。如 Cadvisor 数据</li>
<li>Red 方法：Rate、Errors、Duration。如 Apiserver 性能指标</li>
</ul>
<p>Prometheus 采集中常见的服务分三种：</p>
<ul>
<li>在线服务：如 Web 服务、数据库等，一般关心请求速率，延迟和错误率即 RED 方法</li>
<li>离线服务：如日志处理、消息队列等，一般关注队列数量、进行中的数量，处理速度以及发生的错误即 Use 方法</li>
<li>批处理任务：和离线任务很像，但是离线任务是长期运行的，批处理任务是按计划运行的，如持续集成就是批处理任务，对应 K8S 中的 job 或 cronjob， 一般关注所花的时间、错误数等，因为运行周期短，很可能还没采集到就运行结束了，所以一般使用 Pushgateway，改拉为推。</li>
</ul>
<h3 id="如何采集-lb-后面的-rs-的-metric">如何采集 LB 后面的 RS 的 Metric</h3>
<p>假如你有一个负载均衡 LB，但网络上 Prometheus 只能访问到 LB 本身，访问不到后面的 RS，应该如何采集 RS 暴露的 Metric？</p>
<ul>
<li>RS 的服务加 Sidecar Proxy，或者本机增加 Proxy 组件，保证 Prometheus 能访问到。</li>
<li>LB 增加 /backend1 和 /backend2请求转发到两个单独的后端，再由 Prometheus 访问 LB 采集。</li>
</ul>
<h3 id="prometheus-大内存问题">Prometheus 大内存问题</h3>
<p>随着规模变大，Prometheus 需要的 CPU 和内存都会升高，内存一般先达到瓶颈，这个时候要么加内存，要么集群分片减少单机指标。这里我们先讨论单机版 Prometheus 的内存问题。</p>
<p>原因：</p>
<ul>
<li>Prometheus 的内存消耗主要是因为每隔2小时做一个 Block 数据落盘，落盘之前所有数据都在内存里面，因此和采集量有关。</li>
<li>加载历史数据时，是从磁盘到内存的，查询范围越大，内存越大。这里面有一定的优化空间。</li>
<li>一些不合理的查询条件也会加大内存，如 Group 或大范围 Rate。</li>
</ul>
<p>我的指标需要多少内存：作者给了一个计算器，设置指标量、采集间隔之类的，计算Prometheus 需要的理论内存值：计算公式</p>
<p>以我们的一个 Prometheus Server为例，本地只保留 2 小时数据，95 万 Series，大概占用的内存如下：</p>
<p>
  <img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/image-20220713210003976.png" alt="image-20220713210003976"  /></p>
<p>有什么优化方案：</p>
<ul>
<li>Sample 数量超过了 200 万，就不要单实例了，做下分片，然后通过 Victoriametrics，Thanos，
Trickster 等方案合并数据。</li>
<li>评估哪些 Metric 和 Label 占用较多，去掉没用的指标。2.14 以上可以看 Tsdb 状态</li>
<li>查询时尽量避免大范围查询，注意时间范围和 Step 的比例，慎用 Group。</li>
<li>如果需要关联查询，先想想能不能通过 Relabel 的方式给原始数据多加个 Label，一条Sql 能查出
来的何必用Join，时序数据库不是关系数据库。</li>
</ul>
<p>Prometheus 内存占用分析：</p>
<ul>
<li><a href="https://www.robustperception.io/optimising-prometheus-2-6-0-memory-usage-with-pprof/">通过 pprof分析</a></li>
<li><a href="https://www.robustperception.io/how-much-ram-does-my-prometheus-need-for-ingestion">1.X 版本的内存</a></li>
<li>相关 issue：
<ul>
<li><a href="https://groups.google.com/forum/#!searchin/prometheus-users/memory%7Csort:date/prometheus-users/q4oiVGU6Bxo/uifpXVw3CwAJ">https://groups.google.com/forum/#!searchin/prometheus-users/memory%7Csort:date/prometheus-users/q4oiVGU6Bxo/uifpXVw3CwAJ</a></li>
<li><a href="https://github.com/prometheus/prometheus/issues/5723">https://github.com/prometheus/prometheus/issues/5723</a></li>
<li><a href="https://github.com/prometheus/prometheus/issues/1881">https://github.com/prometheus/prometheus/issues/1881</a></li>
</ul>
</li>
</ul>
<h3 id="prometheus-容量规划">Prometheus 容量规划</h3>
<p>容量规划除了上边说的内存，还有磁盘存储规划，这和你的 Prometheus 的架构方案有关。</p>
<ul>
<li>如果是单机Prometheus，计算本地磁盘使用量。</li>
<li>如果是 Remote-Write，和已有的 Tsdb 共用即可。</li>
<li>如果是 Thanos 方案，本地磁盘可以忽略（2H)，计算对象</li>
</ul>
<p>Prometheus 每2小时将已缓冲在内存中的数据压缩到磁盘上的块中。包括Chunks、Indexes、Tombstones、Metadata，这些占用了一部分存储空间。一般情况下，Prometheus中存储的每一个样本大概占用1-2字节大小（1.7Byte）。可以通过Promql来查看每个样本平均占用多少空间：</p>
<p>如果大致估算本地磁盘大小，可以通过以下公式：$磁盘大小=保留时间<em>每秒获取样本数</em>样本大小$</p>
<p>保留时间(retention_time_seconds)和样本大小(bytes_per_sample)不变的情况下，如果想减少本地磁
盘的容量需求，只能通过减少每秒获取样本数(ingested_samples_per_second)的方式。</p>
<p>查看当前每秒获取的样本数：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">rate(prometheus_tsdb_head_samples_appended_total[1h])
</span></span></code></pre></td></tr></table>
</div>
</div><p>有两种手段，一是减少时间序列的数量，二是增加采集样本的时间间隔。考虑到 Prometheus 会对时间
序列进行压缩，因此减少时间序列的数量效果更明显。</p>
<p>举例说明：</p>
<ul>
<li>采集频率 30s，机器数量1000，Metric种类6000，1000600026024 约 200 亿，30G 左右磁盘。</li>
<li>只采集需要的指标，如 match[], 或者统计下最常使用的指标，性能最差的指标。</li>
</ul>
<p>以上磁盘容量并没有把 wal 文件算进去，wal 文件(Raw Data)在 Prometheus 官方文档中说明至少会保存3个 Write-Ahead Log Files，每一个最大为128M(实际运行发现数量会更多)。</p>
<p>因为我们使用了 Thanos 的方案，所以本地磁盘只保留2H 热数据。Wal 每2小时生成一份Block文件，Block文件每2小时上传对象存储，本地磁盘基本没有压力。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>网络基础面试题收集</title>
      <link>https://www.oomkill.com/2021/10/interview-network/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2021/10/interview-network/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="域名相关">域名相关</h2>
<h3 id="什么是dns劫持">什么是DNS劫持</h3>
<p>DNS劫持就是通过劫持了DNS服务器，通过某些手段取得某域名的解析记录控制权，进而修改此域名的解析结果，导致对该域名的访问由原IP地址转入到修改后的指定IP，其结果就是对特定的网址不能访问或访问的是假网址，从而实现窃取资料或者破坏原有正常服务的目的。DNS劫持通过篡改DNS服务器上的数据返回给用户一个错误的查询结果来实现的。</p>
<p>通俗来讲：DNS劫持就是指用户访问一个被标记的地址时，DNS服务器故意将此地址指向一个错误的IP地址的行为。范例，网通、电信、铁通的某些用户有时候会发现自己打算访问一个地址，却被转向了各种推送广告等网站，这就是DNS劫持。</p>
<p>DNS劫持症状：在某些地区的用户在成功连接宽带后，首次打开任何页面都指向ISP提供的“电信互联星空”、“网通黄页广告”等内容页面。还有就是曾经出现过用户访问Google域名的时候出现了百度的网站。这些都属于DNS劫持。</p>
<p><strong>解决</strong>：对于DNS劫持，可以采用使用国外免费公用的DNS服务器解决。例如OpenDNS（208.67.222.222）或GoogleDNS（8.8.8.8）。</p>
<h3 id="什么是dns污染">什么是DNS污染</h3>
<p>DNS污染是指在DNS服务器中修改DNS解析结果的过程，以便将用户重定向到恶意网站或欺骗性网站，而不是所期望的目标网站。</p>
<p>攻击者可以通过多种方式进行DNS污染攻击。最常见的手段是在用户的网络中添加一个恶意DNS服务器，或者在受感染的计算机上运行一个恶意DNS服务器。当用户试图连接到互联网上的某个网站时，计算机将查询DNS服务器以查找目标网站的IP地址。如果攻击者控制的恶意DNS服务器已将相应的IP地址修改为攻击者的网站，则用户将被重定向到恶意网站或欺骗性网站。</p>
<p>DNS污染发生在用户请求的第一步上，直接从协议上对用户的DNS请求进行干扰。
DNS污染症状：目前一些被禁止访问的网站很多就是通过DNS污染来实现的，例如YouTube、Facebook等网站。</p>
<p><strong>解决</strong>：</p>
<ul>
<li>可靠的DNS服务器，但这种方式效果不佳</li>
<li>手动修改Hosts文件</li>
<li>使用VPN或域名远程解析
<ul>
<li>加密通信：VPN可以加密整个通信过程，这意味着攻击者无法窃取UDP数据包中的任何信息，包括DNS查询请求和响应。这样可以避免DNS查询被篡改的风险。</li>
<li>虚拟IP地址：VPN会给每个用户分配其所连接的虚拟IP地址，使用户的真实IP地址不会暴露在公共互联网中。这样，DNS服务器只能看到VPN服务器的IP地址，而无法识别用户的IP地址。这意味着攻击者无法跟踪用户的访问历史，从而减少遭受DNS污染攻击的风险。</li>
</ul>
</li>
</ul>
<p><strong>总结</strong>：</p>
<p>DNS污染，指的是用户访问一个地址，国内的服务器(非DNS)监控到用户访问的已经被标记地址时，服务器伪装成DNS服务器向用户发回错误的地址的行为。范例，访问Youtube、Facebook之类网站等出现的状况。</p>
<h3 id="什么是域名被墙">什么是域名被墙</h3>
<p>这种情况一般出现在解析为国外地址的域名上，假如域名下的网站非法信息多，敏感，又不整改，会直接被G.F.W墙掉，就是通常所说的被封锁、被屏蔽、被和谐，结果就是访问域名是打不开的，但是解析是正常的。此时域名在国内是无法使用的，国外可以访问和使用。</p>
<p>主要有以下几种情况：</p>
<ul>
<li>ip 被墙</li>
<li>解决：换 ip 。</li>
<li>域名被 url 重置（访问时出现ERR_CONNECTION_RESET 或 “连接重置”
<ul>
<li>换域名</li>
<li>做301跳转，(有专门服务商)，域名通过解析到国内301服务商，重定向到真是国外IP，以减少流量和权重的丢失。</li>
<li>上 https或域名备案，智能解析分国内，国外 。
<ul>
<li>可以使用HTTPS；一般来讲解析到国外的IP的域名，有敏感词会被重置，GFW可以进行敏感词检测（http为明文），使用https加密GFW无法检测数据包内容 ，（客户端与服务端默认会有公钥私钥，而GFW没有）。</li>
</ul>
</li>
</ul>
</li>
<li>域名被国家出口 dns 污染，解决：用国内 dns ，备案回国。</li>
<li>域名被省级 dns 污染，解决：能做到这个这里可能为内部或对应运营商被黑（只能进行dns清洗，一般大流量域名了）</li>
</ul>
<h3 id="什么是dns清洗">什么是DNS清洗？</h3>
<p>DNS清洗是一项旨在阻止访问特定网站和域名的措施，在该措施中，Internet服务提供商（ISP）通过其服务器筛选特定网站的DNS查询，并将查询重定向到一个错误的IP地址（通常是一个不存在的地址），从而防止用户访问该网站。这种措施通常是由政府、公司或组织实施，旨在防止用户接触到不适当、危险或非法的内容。</p>
<h2 id="网络攻击相关">网络攻击相关</h2>
<h3 id="什么是tcp的syn攻击如何预防">什么是TCP的SYN攻击？如何预防？</h3>
<p>TCP SYN攻击是一种利用TCP协议三次握手机制的攻击。攻击者发送大量伪造的TCP SYN请求（数据包），然后在TCP三次握手建立连接的第二步时停止（使服务器不断地向攻击者发送SYN-ACK确认，但攻击者不回复ACK确认），从而导致服务器等待客户端的确认信号很长时间，最终占用服务器的资源而无法处理新的请求。</p>
<p>为了预防TCP SYN攻击，可以采取以下措施：</p>
<ol>
<li>服务器操作系统的设置：可以设置TCP的连接数和时间等参数，限制每个IP地址的连接数，设置连接超时时间。</li>
<li>防火墙设置：可以设置防火墙规则，根据IP地址、端口等信息对连接进行过滤，控制IP地址的访问等。</li>
<li>加强网络监测：使用入侵检测系统（IDS）对流量进行实时监控，并对异常流量进行报警处理。</li>
<li>使用SYN Cookies：SYN cookies是一种可以防止SYN攻击的技术，它通过特殊的算法对TCP连接进行加密，并保存在服务器端，当客户端发送响应时，服务器端可以对连接进行识别和验证，从而防止SYN攻击。</li>
<li>增加硬件设备：可以增加具有流量分析和过滤功能的硬件设备来协助防御SYN攻击，这种设备可以通过分析流量实现精细化的流量分析和识别。</li>
</ol>
<h3 id="ddos攻击的类型">ddos攻击的类型</h3>
<p>DDoS攻击（Distributed Denial of Service）是一种利用许多计算机和网络设备构成的“僵尸网络”对一个或多个目标服务器发起攻击，从而占用大量的网络资源，耗尽系统资源，导致服务拒绝的攻击方式。DDoS攻击的类型可以分为以下几种：</p>
<ol>
<li>带宽攻击（Bandwidth-based Attack）：利用大量的数据流或报文，通过消耗目标系统的网络带宽使其服务不能正常传输。</li>
<li>应用层攻击（Application-Layer Attack）：利用正常流量模拟合法用户的请求，通过消耗服务器CPU和内存资源使其无法处理合法请求。</li>
<li>反射式攻击（Reflection Attack）：使用伪造的IP地址向网络中的一个或多个服务器发起请求，这些服务器会响应请求，但响应信息将被发回目标服务器，从而形成了一次反射式攻击。</li>
<li>慢速攻击（Slowloris Attack）：利用HTTP协议的设计漏洞，向目标服务器发送大量不完整请求，从而占用目标服务器处理请求的线程资源。</li>
<li>IoT攻击（IoT Attack）：通过侵入大量的物联网设备，如路由器、摄像头、智能家居等，利用这些设备来发起攻击，构建大规模的“僵尸网络”。</li>
<li>DNS Amplification攻击：攻击者向域名服务器发送请求，利用伪造的IP地址和请求报文，让服务器向目标主机发送大量的DNS解析响应数据包，从而使目标系统在短时间内遭受网络拥塞。</li>
<li>NTP Amplification攻击：攻击者伪造IP地址，向其余互联网上安装有网络时间服务器（Network Time Protocol，NTP）软件的服务器发送请求，从而获取大量NTP响应包，最终将其转发到目标IP地址，从而占用目标系统的网络带宽。</li>
<li>SYN Flood攻击：攻击者向目标服务器发送大量的TCP SYN请求，但却不发送客户端的应答确认，造成服务器长时间处于等待状态，无法接受正常的TCP连接请求。</li>
<li>HTTP Flood攻击：攻击者利用HTTP叠加攻击、HTTP POST攻击等手段，向目标系统发送大量HTTP请求和数据包，造成目标系统资源的耗尽，从而导致服务不可用。</li>
<li>ICMP Flood攻击：攻击者向目标系统发送大量的ICMP数据包，造成目标系统CPU和内存资源的消耗，从而导致系统缓慢或崩溃。</li>
</ol>
<h3 id="什么是反射式攻击">什么是反射式攻击</h3>
<p>反射式攻击（Reflection  Attack）是一种利用网络协议的设计缺陷进行攻击的方式。攻击者通常会利用一些可以进行源地址欺骗或反射的协议，例如Domain Name  System（DNS），Simple Network Management Protocol（SNMP），和Network Time  Protocol（NTP）等。攻击者利用这些协议在网络中进行广播，构造一些请求消息，伪造源IP地址为目标IP地址，将请求消息发送给网络上的服务器，要求其向目标IP地址回送响应。这样攻击者就可以通过伪造的IP地址对目标系统进行攻击，占用它的网络带宽和资源，极大地降低了目标系统的可用性。</p>
<p>反射式攻击的原理：</p>
<ol>
<li>攻击者使用一个随机IP地址，向一个有可能反射请求的服务器发送一个请求包。</li>
<li>攻击者伪造请求包的源IP地址为目标IP地址。</li>
<li>服务器收到请求包后，会根据请求包中的信息回复一个响应包到目标IP地址。</li>
<li>攻击者的随机IP地址会收到一个错误的响应包，而目标IP地址会收到大量的响应包，引起服务器的网络拥塞和系统负载过高。</li>
<li>反射式攻击的特点是可以发动大规模的攻击，难以追踪攻击者的真实身份。</li>
</ol>
<p>为了避免反射式攻击带来的影响，应加强对网络设备的安全性监管，限制端口映射或在系统中配置反射式攻击防御机制等。</p>
<h3 id="什么是cc攻击">什么是CC攻击</h3>
<p>CC攻击是一种网络攻击，也称为HTTP CC攻击。</p>
<p>CC是英文“Challenge Collapsar”的缩写，意思是“挑战式崩溃”。这种攻击通常是攻击者使用大量的机器在同一时间，对目标网站发送数以万计的HTTP请求，耗费网站的带宽和Web服务器资源，从而使得目标网站难以提供正常的服务。</p>
<p>CC 攻击的原理：</p>
<ol>
<li>攻击者使用大量的机器，在短时间内对目标网站发送大量的请求，即HTTP GET和HTTP POST请求。</li>
<li>攻击者使用IP地址欺骗进行伪造，以避免被目标网站发现。</li>
<li>目标网站在处理大量请求的同时，网络带宽和服务器资源被消耗，导致无法正常处理合法用户的请求。</li>
<li>这种攻击方式是一种专门针对Web应用的攻击，能够对目标网站造成极大的破坏。</li>
</ol>
<p>CC攻击具有隐蔽性强、攻击目标精准、攻击规模大的特点，对于商业网站和金融机构等重要场所，尤其危害性较高。为了防范CC攻击，应采用一系列的安全措施，包括但不限于：IP限制、用户访问控制、流量清洗系统、高级请求监控和识别等。</p>
<h3 id="cc攻击和ddos攻击有什么区别">cc攻击和ddos攻击有什么区别</h3>
<p>CC攻击和DDoS攻击都是一种网络攻击方式，但它们具有不同的特点和目的，可以通过以下几个维度进行区分：</p>
<ol>
<li>发起机制：DDoS攻击通常使用由许多受感染的计算机组成的僵尸网络向目标服务器发起攻击；而CC攻击则利用大量的请求浪费目标网站的资源，其通常由单个或少量主机发起。</li>
<li>对服务器的影响：DDoS攻击通常通过占用服务器的网络带宽和处理能力消耗服务器资源，从而使服务器无法处理合法的请求。而CC攻击通常会利用大量的HTTP请求消耗目标服务器的网络带宽和Web服务器资源，从而使目标网站无法提供正常的服务。</li>
<li>目的不同：DDoS攻击的目的通常是摧毁或瘫痪目标网站，其目的往往是为了实现利润或危害竞争对手。而CC攻击通常用于使目标网站的网络带宽和服务器资源不可用，以达到一定的干扰或损坏目的。</li>
<li>防御方式：DDoS攻击通常需要综合多种防护手段，包括入侵检测系统、防火墙、流量清洗系统等；而CC攻击通常可以通过增加带宽、配置IP限制、使用反垃圾过滤系统等简单的措施进行防御。</li>
</ol>
<p>总的来说，CC攻击主要针对Web应用程序和网站，其攻击手段比DDoS攻击更加简单和直接，而DDoS攻击则涉及到更多的计算机协调，其对目标服务器造成的影响也更为广泛和严重。</p>
<h3 id="dbus攻击">DBus攻击</h3>
<p>DBus（Desktop Bus）是用于在Linux系统中应用程序之间进行通信的一种机制。DBus通信协议是所有Linux桌面环境（如GNOME和KDE）的核心组件。DBus协议本身并没有安全问题，但是由于应用程序在通信时可能会使用明文传输敏感信息（例如登录密码），因此DBus协议仍然存在被黑客攻击的风险。</p>
<p>DBus攻击主要有以下几种方式</p>
<ol>
<li>端口监听攻击：DBus默认使用unix-socket，如果未被正确配置只能在特定用户之间使用。如果DBus暴露在公网上，并启用了TCP/IP支持，则可能会受到端口监听攻击。</li>
<li>消息劫持攻击：假冒攻击者可以伪造DBus通信的结构头和消息体，并将其发送到目标程序。这样可以使目标程序对不良消息进行响应并以不合适的方式执行命令或泄漏敏感信息。</li>
<li>执行命令攻击：攻击者可以通过发送DBus消息来请求目标程序执行特定的操作。如果目标程序没有执行严格的访问控制，那么攻击者可能会成功执行恶意操作。</li>
</ol>
<p>为了防止DBus攻击，可以采取以下预防措施：</p>
<ol>
<li>使用策略控制：通过在DBus配置文件中设置安全策略，在文件中定义一系列规则，以控制哪些应用程序可以访问DBus总线，以及哪些应用程序可以以哪种方式访问DBus总线。</li>
<li>使用加密通信：可以使用SSL或TLS等安全协议对DBus通信进行加密，以确保DBus通信传输的数据不会被窃取或篡改。</li>
<li>调用API实现过滤和审核：可以通过DBus接口的API调用来检查和验证DBus消息中的请求和响应是否合法，如果失败，则拒绝执行DBus请求命令。</li>
<li>更新操作系统和软件：可以定期更新Linux操作系统和DBus相关软件的版本，以修复可能出现的安全漏洞，从而提高DBus协议的安全性。</li>
</ol>
<p>综上所述，DBus协议是任何Linux桌面环境中的核心组件，因此必须采取一系列的安全预防措施防止攻击者利用漏洞对DBus协议进行攻击。</p>
<h2 id="网络相关">网络相关</h2>
<h3 id="osi模型和tcpip模型有什么区别">OSI模型和TCP/IP模型有什么区别？</h3>
<p>OSI模型和TCP/IP模型都是网络通信时使用的通信协议模型</p>
<ul>
<li>
<p>OSI模型通常表示一个网络请求的完整路径，而TCP/IP模型通常表示Linux 内核网络栈中的模型</p>
</li>
<li>
<p>OSI模型包括7个层次：物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。</p>
</li>
<li>
<p>TCP/IP模型则是由4个层次组成：网络接口层、网络层、传输层和应用层</p>
</li>
</ul>
<h3 id="简述tcp重传时的ack机制">简述TCP重传时的ACK机制？</h3>
<p>TCP协议中的重传机制是保证数据传输可靠性的关键，它使用一个称为确认（ACK）的机制来标记接收到的数据段。TCP准确地检测丢失或重复数据包，并要求发送方重发丢失的数据包，直到接收方确认收到该数据包。</p>
<p>当TCP发送方发现某个数据包未收到确认时，会启动重传机制。它会重发此数据包并设置一个计时器，在计时器超时前等待接收方的确认，并在接收方回复确认后将计时器停止。如果在计时器超时之前，没有收到确认，则认为此数据包丢失，就会重发相同的数据包，并随之设置新的计时器。</p>
<p>每次成功发送数据包后，TCP发送方将等待接收方发回一个相应的确认，以确认数据包已经被正确接收。接收方会在ACK中包含一个确认号（ACK number），该数值表示收到的最后一个正确的数据包的编号，这表明它准备接收下一数据包并告诉发送端可以继续发送数据。</p>
<p>总之，TCP重传时的ACK机制，是通过发送数据包、等待接收方确认、超时时间检测等多步操作来检查数据包传输是否能够成功到达，同时保证数据的可靠传输。</p>
<h3 id="常见的tcp连接报错有哪些">常见的TCP连接报错有哪些?</h3>
<ul>
<li>
<p><strong>Connection reset by peer</strong>：通常是由于远程端重置连接造成的，发送的是 <code>RST</code> 强制中断连接</p>
<ul>
<li>
<p>这类问题主要发生在连接关闭的情况下，在tcp连接中，双方是对等连接 <code>peer</code>，当数据包从连接的一端发送，但另一端无法识别到连接时，会返回设置了<code>RST</code>位的数据包，用来强制关闭连接。</p>
</li>
<li>
<p>通常情况下，会立即中断连接，并且绕过了正常关闭的2MSL时间。例如：</p>
<ul>
<li>客户端关闭了连接，而服务器还在给客户端发送数据。</li>
<li>服务器超载，服务端强制关闭掉一些连接。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Connection timeout</strong>：般为建立连接在最大超时时间后没有收到来自服务端的相应，此时客户端将收到错误信息。</p>
</li>
<li>
<p><strong>Connection refused</strong>：通常出现在连接某一服务的端口时发生（拒绝机制是 TCP <code>RST</code> 标志），通常情况下包含一下情况：</p>
<ul>
<li>目标主机端口未开放</li>
<li>端口开放了，但处理其连接堆积或已满。</li>
<li>客户端与服务端防火墙阻碍其连接。（客户端和服务端防火墙均会发生）</li>
</ul>
</li>
<li>
<p><strong>Port Unavailable</strong>：通常由于TCP连接的目标端口已经被占用, 或是网络路由器的设置引起的。</p>
</li>
<li>
<p><strong>Host Unreachable</strong>：主机不可达错误通常由于网络路由故障引起的，它表示目标主机无法被连接，有可能是由于网络故障或是DNS解析错误引起的。</p>
</li>
</ul>
<h3 id="什么是tcp-resetrst">什么是TCP Reset（RST）</h3>
<p>当收到意外数据包（非正常3次握手进行的连接）到达主机时，此时会重置连接，重置的数据包是设置了<code>RST位</code>的数据包。</p>
<p>常见的有以下情况：</p>
<ul>
<li>一个初始数据包 (初始数据包<code>SYN</code>) 尝试向一个没有任何进程的监听地址发起连接时，会出现次状态（如：<code>curl localhost $non-listen-port</code>）</li>
<li>在之前建立的连接，并且本地已经关闭socket或退出。</li>
<li>防火墙的拦截</li>
</ul>
<p>数据包到达先前建立的TCP连接，但本地应用程序已关闭其套接字或退出，并且操作系统已关闭该套接字。</p>
<h3 id="常见tcp的连接状态有哪些">常见TCP的连接状态有哪些？</h3>
<p><strong>三次握手期间</strong>：</p>
<ul>
<li>
<p>CLOSED：初始状态。</p>
</li>
<li>
<p>LISTEN：服务器处于监听状态。</p>
</li>
<li>
<p>SYN_SEND：客户端socket执行CONNECT连接，发送SYN包，进入此状态。</p>
</li>
<li>
<p>SYN_RECV：服务端收到SYN包并发送服务端SYN包，进入此状态。</p>
</li>
<li>
<p>ESTABLISH：表示连接建立。客户端发送了最后一个ACK包后进入此状态，服务端接收到ACK包后 进入此状态。</p>
</li>
</ul>
<p><strong>四次挥手期间</strong>：</p>
<ul>
<li>FIN_WAIT_1：终止连接的一方（通常是客户机）发送了FIN报文后进入。等待对方FIN。</li>
<li>CLOSE_WAIT：（假设服务器）接收到客户机FIN包之后等待关闭的阶段。在接收到对方的FIN包之  后，自然是需要立即回复ACK包的，表示已经知道断开请求。但是本方是否立即断开连接（发送FIN  包）取决于是否还有数据需要发送给客户端，若有，则在发送FIN包之前均为此状态。</li>
<li>FIN_WAIT_2：此时是半连接状态，即有一方要求关闭连接，等待另一方关闭。客户端接收到服务器 的ACK包，但并没有立即接收到服务端的FIN包，进入FIN_WAIT_2状态。</li>
<li>LAST_ACK：服务端发动最后的FIN包，等待最后的客户端ACK响应，进入此状态。</li>
<li>TIME_WAIT：客户端收到服务端的FIN包，并立即发出ACK包做最后的确认，为此之后的2MSL时间 客户端为TIME_WAIT状态。</li>
</ul>
<h3 id="close_wait状态的产生危害如何避免">CLOSE_WAIT状态的产生、危害、如何避免？</h3>
<p>客户端TCP状态迁移：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">CLOSED-&gt;SYN_SENT-&gt;ESTABLISHED-&gt;FIN_WAIT_1-&gt;FIN_WAIT_2-&gt;TIME_WAIT-&gt;CLOSED
</span></span></code></pre></td></tr></table>
</div>
</div><p>服务器TCP状态迁移：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">CLOSED-&gt;LISTEN-&gt;SYN_RECV-&gt;ESTABLISHED-&gt;CLOSE_WAIT-&gt;LAST_ACK-&gt;CLOSED
</span></span></code></pre></td></tr></table>
</div>
</div><p>
  <img loading="lazy" src="https://cdn.jsdelivr.net/gh/CylonChau/imgbed/img/1380340-20220408183308968-1567213936.png" alt=""  /></p>
<p>【答】：</p>
<p><strong>产生</strong>: TCP连接的两端都可以发起关闭连接的请求，若对端发起了关闭连接，但本地没有进行后续的关闭连接操作，那么该链接就会处于<code>CLOSE_WAIT</code>状态。</p>
<ul>
<li>在某种情况下应用关闭了socket连接,但是服务端忙于读或者写，没有关闭连接。</li>
<li>在被动关闭连接情况下，在已经接收到FIN，但是还没有发送自己的FIN的时刻，连接处于CLOSE_WAIT状态。通常来讲，CLOSE_WAIT状态的持续时间应该很短，正如SYN_RCVD状态。但是在一些特殊情况下，就会出现连接长时间处于CLOSE_WAIT状态的情况。</li>
</ul>
<p><strong>危害</strong>：<code>CLOSE_WAIT</code> 会使连接处于假死状态，连接本身占用的资源不会被释放。网络服务器程序要同时管理大量连接，所以很有必要保证无用连接完全断开，否则大量僵死的连接会浪费许多服务器资源。</p>
<p><strong>如何避免</strong>：</p>
<p>更详细分析可以看：https://www.cnblogs.com/shengs/p/4495998.html</p>
<h3 id="tcp的关闭">TCP的关闭</h3>
<p>TCP 支持两种类型的连接释放：</p>
<ul>
<li>
<p>优雅关闭：正常的四次挥手</p>
</li>
<li>
<p>突然关闭：发送RST段，即TCP Reset</p>
<ul>
<li>当为不存在的 TCP 连接接收到非 SYN 段时</li>
<li>在已打开的连接中，某些 TCP 实现会在收到具有无效标头的段时会发送 RST 段。  这将通过关闭相应的连接来防止攻击。</li>
<li>当某些实现需要关闭现有的 TCP 连接时，它们会发送一个 RST 段。  将立即关闭现有的 TCP 连接：
<ul>
<li>缺乏支持连接的资源</li>
<li>远程主机现在无法访问并且已停止响应</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="time_wait-状态的产生危害如何避免">TIME_WAIT 状态的产生、危害、如何避免？</h3>
<p>【答】：</p>
<p><strong>产生</strong>：TCP在关闭连接的四次挥手中，为了应对最后一个ACK 丢失的情况，Client(主动关闭的一方)需要维持TIME_WAIT状态，并停留2MSL的时间。</p>
<p><strong>危害</strong>：</p>
<ul>
<li>浪费系统资源：大量的TIME_WAIT状态会占用系统资源（用户的文件句柄 如端口）</li>
<li>降低系统性能：</li>
</ul>
<p><strong>如何避免</strong>：在 <code>/etc/sysctl.conf</code>文件中开启 <code>net.ipv4.tcp_tw_reuse</code>重用，和<code>net_ipv4.tcp.tw_recycle</code> 快速回收。</p>
<h3 id="time_wait-和-close_wait区别">TIME_WAIT 和 CLOSE_WAIT区别</h3>
<ul>
<li>主动关闭的一端是 <code>TIME_WAIT</code>；即客户端主动关闭<code>TIME_WAIT</code>出现在客户端，服务端主动关闭 <code>TIME_WAIT</code>出现在服务端</li>
<li>被动关闭的一端是 <code>CLOSE_WAIT</code>；通常情况下，服务端会维护大量的<code>CLOSE_WAIT</code></li>
<li>服务端出现 <code>CLOSE_WAIT</code>则客户端永远不会出现 <code>TIME_WAIT</code>
<ul>
<li><code>CLOSE_WAIT</code> 一般发生在服务在接收到关闭信号后没有正确关闭连接</li>
<li><code>TIME_WAIT</code> 会随着2MSL的时长而积压</li>
<li>服务端 在 发送 两次 ACK 与 FIN后，即收到<code>FIN</code>后客户端（主动断开端）才会转变为 <code>TIME_WAIT</code></li>
<li>结束CLOSE_WAIT状态，对应的应用程序必须显式关闭打开套接字（或退出）</li>
</ul>
</li>
</ul>
<blockquote>
<p>ss命令可以强制关闭套接字
ss &ndash;tcp state CLOSE-WAIT &ndash;kill 关闭对应状态的连接
ss &ndash;tcp state CLOSE-WAIT &lsquo;( dport = 22 or dst 1.1.1.1 )&rsquo; &ndash;kill 过滤操作</p>
</blockquote>
<h3 id="2msl的值是多少">2MSL的值是多少？</h3>
<p>2MSL (<em><strong>Maximum Segment Lifetime</strong></em>) 作为TCP 连接的“关闭”过程的一部分，是在 <a href="https://datatracker.ietf.org/doc/html/rfc793">RFC 793(TCP)</a>，Linux内核的默认MSL设置为 60 秒，2MSL为120s，可以通过<code>cat /proc/sys/net/ipv4/tcp_fin_timeout</code>查看。</p>
<p>在 Check Point VPN网关中，R80.20 及更高版本中，默认的 TCP 超时5秒。</p>
<blockquote>
<p>Reference</p>
<p><a href="https://supportcenter.checkpoint.com/supportcenter/portal?eventSubmit_doGoviewsolutiondetails=&amp;solutionid=sk121673">2MSL</a></p>
</blockquote>
<h3 id="为什么客户端要等2msl">为什么客户端要等2MSL</h3>
<p>TCP / IP协议中使用2MSL来等待连接中的可能尚未到达的遗留数据包。当一个TCP连接关闭时，每个端口必须等待2MSL时间，以确保对方端口正确接收了所有数据段。以下是对不同情况下等待时间的解释：</p>
<ul>
<li>如果等待时间小于1MSL，可能会有数据包丢失，从而导致通信不完整。</li>
<li>如果等待时间等于1MSL，TCP连接完成后，存在某些可能尚未到达的数据包，这些数据包在此时间段内将没有机会重传，因此可能会导致通信不完整。</li>
<li>如果等待时间大于2MSL，虽然可以确保数据包被完全接收并处理，但是长时间的等待可能会影响网络效率并占用网络资源。</li>
</ul>
<p>因此，2MSL时间是一个标准和安全的等待时间，可确保TCP连接关闭时没有未接收的数据包。</p>
<p>《UNIX网络编程(卷1)》提到，TIME_WAIT的作用大概是下述两部分：</p>
<ul>
<li>实现可靠地TCP连接终止
<ul>
<li>为了可靠的终止TCP的全双工连接，当客户端发送的最后一个ACK丢失，服务端会重传FIN，为了接收超时并重传FIN，客户端就需要一个TIME_WAIT，如果RTO（<code>Retransmission Timeout</code>）小于MSL，那么TIME_WAIT的大小为MSL就足够了，如果RTO大于2MSL，则TIME_WAIT大小为2MSL已经不够了，所以只有TIME_WAIT状态介于 MSL与2MSL之间，才实现可靠地TCP连接终止。通常情况下RTO要比MSL小很多，但是考虑到最糟糕的情况，RTO是2MSL</li>
</ul>
</li>
<li>允许旧的重复段在网络中过期
<ul>
<li>为了保证在这个连接期间产生的所有数据包都从网络中消失，即保证在建立新的TCP连接时，来自该连接的旧的重复数据包已经在网络中消失了；</li>
<li>此时存在一个问题：当客户端回复最后一个ACK后，用一个MSL时间就可以断开双方的连接（所有的数据包都消失）。为什么需要2MSL才可以？
<ul>
<li>这是因为假设在客户端发送ACK刚刚过了一个MSL时间，而服务端在收到这个ACK之前一瞬间刚好启动超时重传FIN，所以要等这个FIN也消失，就是2MSL了。文中所指的另一个方向的应答应该就是这个超时重传的FIN。</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Reference</p>
<p><a href="https://stackoverflow.com/questions/25338862/why-time-wait-state-need-to-be-2msl-long">why time wait state need to be 2msl long</a></p>
<p><a href="https://www.ques10.com/p/21499/in-the-tcp-state-transition-diagram-why-do-we-have/">in the tcp state transition diagram why do we have</a></p>
</blockquote>
<h3 id="rto和msl">RTO和MSL</h3>
<p>RTO和MSL是两个完全独立的定义，它们之间没有特定的依赖关系。RTO是一个时间间隔，在未收到对方确认的情况下触发重传，并根据网络连接的延迟和拥塞情况进行调整。而MSL则是一个固定的时间，在TCP连接关闭后，用于保持最后的ACK数据包保持活动状态的时间。</p>
<p>尽管RTO和MSL没有直接关联，但是RTO和MSL都涉及到TCP数据包的传输和处理。RTO值需要在某些情况下限制其最小值，以避免过度等待，例如在快速重传和快速恢复等TCP机制中。而MSL在TCP数据包传输网络中扮演着非常重要的角色，以确保在TCP连接关闭后遗留的数据包都能达到其目的地，同时避免后续的混淆与冲突。</p>
<p>RTO和MSL是TCP / IP协议中的两个超时机制，这些机制都与传输控制协议（TCP）的数据包传输相关。以下是它们之间的区别：</p>
<ul>
<li>RTO (Retransmission Time Out)：是指在TCP / IP网络中，当一个数据包发送后，期望在多长时间内收到对方回应的时间。如果在该时间内没有收到回应，则认为该数据包已丢失，发起重传。RTO时间间隔通常根据TCP窗口大小调整，一般都比MSL的时间间隔短。</li>
<li>MSL (Maximum Segment Lifetime)：是指在TCP网络中，一个数据包在网络中传输的最长时间。当超过这个时间后，该数据包将被认为已经过期并被丢弃。通常，MSL是30秒，是一个相对不变的时间阈值，不会随着网络的突发变化而发生变化。</li>
</ul>
<p>总的来说，RTO和MSL都是与TCP传输相关的超时机制，但它们的目的和应用场景略有区别：RTO用于控制未收到响应时的重传时间间隔，而MSL用于控制关闭连接后等待可能未到达的数据包的最长时间。</p>
<h3 id="tcp-和-udp-的区别">TCP 和 UDP 的区别？</h3>
<p>TCP是稳定、可靠、⾯向连接的传输层协议，它在传递数据前要三次握⼿建⽴连接，在数据传递时，有确认机制、重传机制、流量控制、拥塞控制等，可以保证数据的正确性和有序性。
UDP是⽆连接的数据传输协议，端与端之间不需要建⽴连接，且没有类似TCP的那些机制，会发⽣丢包、乱序等情况。</p>
<p><em><strong>TCP是数据流模式，⽽UDP是数据报模式。</strong></em></p>
<h3 id="为什么-tcp-叫数据流模式-udp-叫数据报模式">为什么 TCP 叫数据流模式？ UDP 叫数据报模式？</h3>
<p>【答】：<strong>最大的一个区别就是，TCP包头允许数据的分段，会携带每段的编号，而UDP只携带数据长度及校验码</strong></p>
<p>所谓的“流模式”，是指TCP发送端发送⼏次数据和接收端接收⼏次数据是没有必然联系的，⽐如你通过 TCP 连接给另⼀端发送数据，你只调⽤了⼀次 write，发送了100个字节，但是对⽅可以分10次收完，每次10个字节；你也可以调⽤10次 write，每次10个字节，但是对⽅可以⼀次就收完。</p>
<p>原因：这是因为TCP是⾯向连接的，⼀个 socket 中收到的数据都是由同⼀台主机发出，且有序地到达，所以每次读取多少数据都可以。</p>
<p>所谓的“数据报模式”，是指UDP发送端调⽤了⼏次 write，接收端必须⽤相同次数的 read 读完。UDP 是基于报⽂的，在接收的时候，每次最多只能读取⼀个报⽂，报⽂和报⽂是不会合并的，如果缓冲区⼩于报⽂⻓度，则多出的部分会被丢弃。</p>
<p>原因：这是因为UDP是⽆连接的，只要知道接收端的 IP 和端⼝，任何主机都可以向接收端发送数据。 这时候， 如果⼀次能读取超过⼀个报⽂的数据， 则会乱套</p>
<h3 id="tcp建连接为什么需要三次断开连接为什么需要四次">TCP建⽴连接为什么需要三次？断开连接⼜为什么需要四次？</h3>
<p>【答】：</p>
<p><strong>“三次握⼿”的主要⽬的是为了防⽌已失效的连接请求报⽂段突然⼜传送到了服务端，因⽽产⽣错误。</strong></p>
<p>例如：client发出的第⼀个连接请求报⽂段并没有丢失，⽽是在某个⽹络结点⻓时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是⼀个早已失效的报⽂段。但server收到此失效的连接请求报⽂段后，就误认为是client再次发出的⼀个新的连接请求。于是就向client发出确认报⽂段，同意建⽴连接。假设不采⽤“三次握⼿”，那么只要server发出确认，新的连接就建⽴了。由于现在client并没有发出建⽴连接的请求，因此不会理睬server的确认，也不会向server发送ack包。</p>
<p><strong>“四次挥⼿”主要是为了确保数据能够完成传输。</strong></p>
<p>因为TCP连接是全双⼯的(即数据可在两个⽅向上同时传递)，关闭连接时，当收到对⽅的FIN报⽂通知时，它仅仅表示对⽅没有数据发送给你了；但未必你所有的数据都全部发送给对⽅了，所以你可以未必会⻢上会关闭SOCKET,也即你可能还需要发送⼀些数据给对⽅之后，再发送FIN报⽂给对⽅来表示你同意现在可以关闭连接了，所以它这⾥的ACK报⽂和FIN报⽂多数情况下都是分开发送的。</p>
<h3 id="tcp协议如何提供可靠性的">TCP协议如何提供可靠性的？</h3>
<p>TCP的可靠，因为它使用校验和进行错误检测，尝试通过重新传输、确认策略和计时器来恢复丢失或损坏的数据包。它使用字节数和序列号以及确认号等特性来确保可靠性。</p>
<h3 id="tcp-flags">TCP Flags</h3>
<p>TCP有6个Flag</p>
<ul>
<li>SYN <strong>(synchronize)</strong>，初始化一个连接的标识</li>
<li>ACK <strong>(acknowledgment)</strong>；用于确认数据包已收到，用于确认建立连接和关闭连接的</li>
<li>RST <strong>(reset)</strong>；表示连接已关闭，或者服务可能不接受请求</li>
<li>FIN <strong>(finish)</strong>；表示正在断开连接。发送方和接收方都发送 FIN 数据包以优雅地终止连接</li>
<li>PSH <strong>(push)</strong>；表示传入的数据应该直接传递给应用程序，而不是被缓冲</li>
<li>URG <strong>(urgent)</strong>；表示数据包所携带的数据应立即由 TCP 堆栈处理</li>
</ul>
<h3 id="dns使什么协议">DNS使⽤什么协议？</h3>
<p>DNS服务器间进⾏域传输的时候使⽤ TCP 53；</p>
<p>客户端查询DNS服务器时使⽤ UDP 53，但当DNS查询超过512字节，TC标志出现时，使⽤TCP发送。</p>
<p>这是因为以太⽹(Ethernet)数据帧的⻓度必须在46-1500字节之间，这是由以太⽹的物理特性决定的。这个数据帧⻓度被称为链路层的MTU（最⼤传输单元）—— 实际Internet上的标准MTU值为576字节，也就是说链路层的数据区（不包括链路层的头部和尾部）被限制在576字节，所以这也就是⽹络层IP数据报的⻓度限制。</p>
<p>因为IP数据报的⾸部为20字节，所以IP数据报的数据区⻓度最⼤为556字节。⽽这个556字节就是⽤来放TCP报⽂段或UDP数据报的。我们知道UDP数据报的⾸部8字节，所以UDP数据报的数据区最⼤⻓度为548字节。—— 如果UDP数据报的数据区⼤于这个⻓度，那么总的IP数据包就会⼤于MTU，这个时候发送⽅IP层就需要分⽚(fragmentation)，把数据报分成若⼲⽚，使每⼀⽚都⼩于MTU，⽽接收⽅IP层则需要进⾏数据报的重组。由于UDP的特性，当某⼀⽚数据传送中丢失时，接收⽅将⽆法重组数据报，从⽽导致丢弃整个UDP数据报。所以通常UDP的最⼤报⽂⻓度就限制为512字节或更⼩。</p>
<h3 id="tcp的拥塞控制机制是什么请简单说说">TCP的拥塞控制机制是什么？请简单说说。</h3>
<h3 id="ip报文中ttl字段作用">IP报文中TTL字段作用</h3>
<p>可用于防止数据包循环</p>
<h3 id="什么是tcp-rto">什么是TCP RTO？</h3>
<p>TCP RTO是TCP数据包在发送后到接收ACK之间的超时时间。如果在这个时间内没有收到ACK，则认为数据包已经丢失，需要进行重传。RTO的值是根据网络延迟、带宽和网络拥堵等多种因素计算得出的。</p>
<h3 id="如何调整tcp-rto">如何调整TCP RTO？</h3>
<p>TCP RTO的调整需要根据实际的网络环境进行，可以通过以下几种方法进行：</p>
<ul>
<li>内核参数调整：可以通过调整内核参数来改变TCP RTO的计算公式，从而适应不同的网络环境；</li>
<li>使用拥塞控制算法：可以通过改变TCP的拥塞控制算法来影响RTO的调整；</li>
<li>优化网络拓扑结构：通过优化网络拓扑结构，如改变路由器的位置、增加网络带宽等，可以有效地降低RTO的值。</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>运维类面试题收集</title>
      <link>https://www.oomkill.com/2021/10/interview-om/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.oomkill.com/2021/10/interview-om/</guid>
      <description></description>
      <content:encoded><![CDATA[<h2 id="如何优化-linux系统笼统">如何优化 Linux系统（笼统）</h2>
<ul>
<li>不用root，添加普通用户，通过sudo授权管理</li>
<li>更改默认的远程连接SSH服务端口及禁止root用户远程连接</li>
<li>定时自动更新服务器时间</li>
<li>配置国内yum源</li>
<li>关闭selinux及iptables（iptables工作场景如果有外网IP一定要打开，高并发除外）</li>
<li>调整文件描述符的数量</li>
<li>精简开机启动服务（crond rsyslog network sshd）</li>
<li>内核参数优化（/etc/sysctl.conf）</li>
<li>更改字符集，支持中文，但建议还是用英文字符集，防止乱码</li>
<li>锁定关键系统文件</li>
<li>清空/etc/issue，去除系统及内核版本登录前的屏幕显示</li>
</ul>
<h3 id="基础命令">基础命令</h3>
<h3 id="ps-aux-中的vsz代表什么意思rss代表什么意思">ps aux 中的VSZ代表什么意思，RSS代表什么意思</h3>
<ul>
<li>VSZ:虚拟内存集,进程占用的虚拟内存空间</li>
<li>RSS:物理内存集,进程战用实际物理内存空间</li>
</ul>
<h3 id="shell下32位随机密码生成">shell下32位随机密码生成</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">cat /dev/urandom | head -1 | md5sum | head -c 32 &gt;&gt; /pass
</span></span></code></pre></td></tr></table>
</div>
</div><p>将生成的32位随机数 保存到/pass文件里了</p>
<h3 id="统计出nginx的accesslog中访问量最多的5个ip">统计出nginx的access.log中访问量最多的5个IP</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">cat access_log | awk  &#39;{print $1}&#39; | sort | uniq -c | sort -n -r | head -5
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="web与lb">web与lb</h2>
<h2 id="讲述一下lvs三种模式的工作过程">讲述一下LVS三种模式的工作过程</h2>
<h3 id="lvs负载的原理和nginx负载有啥区别">LVS负载的原理，和Nginx负载有啥区别</h3>
<ul>
<li>
<p><strong>VS/NAT：（Virtual Server via Network Address Translation）</strong></p>
<p>也就是网络地址翻译技术实现虚拟服务器，当用户请求到达调度器时，调度器将请求报文的目标地址（即虚拟IP地址）改写成选定的Real Server地址，同时报文的目标端口也改成选定的Real Server的相应端口，最后将报文请求发送到选定的Real Server。在服务器端得到数据后，Real Server返回数据给用户时，需要再次经过负载调度器将报文的源地址和源端口改成虚拟IP地址和相应端口，然后把数据发送给用户，完成整个负载调度过程。</p>
<p>可以看出，在NAT方式下，用户请求和响应报文都必须经过Director Server地址重写，当用户请求越来越多时，调度器的处理能力将称为瓶颈。</p>
</li>
<li>
<p><strong>VS/TUN ：即（Virtual Server via IP Tunneling）</strong></p>
<p>也就是IP隧道技术实现虚拟服务器。它的连接调度和管理与VS/NAT方式一样，只是它的报文转发方法不同，VS/TUN方式中，调度器采用IP隧道技术将用户请求转发到某个Real Server，而这个Real Server将直接响应用户的请求，不再经过前端调度器，此外，对Real Server的地域位置没有要求，可以和Director Server位于同一个网段，也可以是独立的一个网络。因此，在TUN方式中，调度器将只处理用户的报文请求，集群系统的吞吐量大大提高。</p>
</li>
<li>
<p><strong>VS/DR： 即（Virtual Server via Direct Routing）</strong></p>
<p>也就是用直接路由技术实现虚拟服务器。它的连接调度和管理与VS/NAT和VS/TUN中的一样，但它的报文转发方法又有不同，VS/DR通过改写请求报文的MAC地址，将请求发送到Real Server，而Real Server将响应直接返回给客户，免去了VS/TUN中的IP隧道开销。这种方式是三种负载调度机制中性能最高最好的，但是必须要求Director Server与Real Server都有一块网卡连在同一物理网段上。</p>
</li>
</ul>
<p>回答负载调度算法，IPVS实现在八种负载调度算法，我们常用的有四种调度算法（轮叫调度、加权轮叫调度、最少链接调度、加权最少链接调度）。一般说了这四种就够了，也不会需要你详细解释这四种算法的。你只要把上面3种负载均衡技术讲明白面试官就对这道问题很满意了。</p>
<h3 id="lvs与nginx的区别">lvs与nginx的区别：</h3>
<p>LVS的优点：</p>
<ul>
<li>抗负载能力强、工作在第4层仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的；无流量，同时保证了均衡器IO的性能不会受到大流量的影响；</li>
<li>工作稳定，自身有完整的双机热备方案，如LVS+Keepalived和LVS+Heartbeat；</li>
<li>应用范围比较广，可以对所有应用做负载均衡；</li>
<li>配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率。</li>
</ul>
<p>LVS的缺点：</p>
<ul>
<li>软件本身不支持正则处理，不能做动静分离，这就凸显了Nginx/HAProxy+Keepalived的优势。</li>
<li>如果网站应用比较庞大，LVS/DR+Keepalived就比较复杂了，特别是后面有Windows Server应用的机器，实施及配置还有维护过程就比较麻烦，相对而言，Nginx/HAProxy+Keepalived就简单一点</li>
</ul>
<p>Nginx的优点：</p>
<ul>
<li>工作在OSI第7层，可以针对http应用做一些分流的策略。比如针对域名、目录结构。它的正则比HAProxy更为强大和灵活；</li>
<li>Nginx对网络的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势所在；</li>
<li>Nginx安装和配置比较简单，测试起来比较方便；</li>
<li>可以承担高的负载压力且稳定，一般能支撑超过几万次的并发量；</li>
<li>Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点；</li>
<li>Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。LNMP现在也是非常流行的web环境，大有和LAMP环境分庭抗礼之势，Nginx在处理静态页面、特别是抗高并发方面相对apache有优势；</li>
</ul>
<p>Nginx的缺点：</p>
<ul>
<li>Nginx不支持url来检测。</li>
<li>Nginx仅能支持http和Email，这个它的弱势。</li>
<li>Nginx的Session的保持，Cookie的引导能力相对欠缺。</li>
</ul>
<h3 id="apache工作模式">apache工作模式</h3>
<p>查看apache工作模式
<code>apachectl -l|sed -n '/worker\|prefork/p'</code></p>
<ul>
<li>
<p>prefork使用的是多个子进程，而每个子进程只有一个线程，每个进程在某个确定的时间只能维持一个连接.</p>
</li>
<li>
<p>worker模式是Apache2.X新引进来的模式，是线程与进程的结合，在worker模式下会有多个子进程，每个进程又会有多个线程。每个线程在某个确定的时间只能维持一个连接。</p>
</li>
<li>
<p>event模式：event和 worker模式很像，最大的区别在于，它解决了<code>keep-alive</code>场景下 ，长期被占用的线程的资源浪费问题。</p>
<p><code>event</code> MPM中，会有一个专门的线程来管理这些<code>keep-alive</code>类型的线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放。这样，一个线程就能处理几个请求了，实现了异步非阻塞。</p>
<p><code>event</code> MPM在遇到某些不兼容的模块时，会失效，将会回退到worker模式，一个工作线程处理一个请求。官方自带的模块，全部是支持<code>event</code>MPM的。</p>
</li>
</ul>
<p>优缺点</p>
<ul>
<li>
<p>优点：内存占用比prefork模式低，适合高并发高流量HTTP服务。</p>
</li>
<li>
<p>缺点：假如一个线程崩溃，整个进程就会连同其任何线程一起“死掉”.由于线程贡献内存空间，所以一个程序在运行时必须被系统识别为“每个线程都是安全的”服务稳定性不如prefork模式。</p>
</li>
</ul>
<p><a href="https://github.com/PlutoaCharon/LiunxNotes/blob/master/Liunx%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/Linux%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%E7%B1%BB/Apache.md">https://github.com/PlutoaCharon/LiunxNotes/blob/master/Liunx%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/Linux%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%E7%B1%BB/Apache.md</a></p>
<h3 id="kubernetes">kubernetes</h3>
<h3 id="kubernetes有哪些不同类型的服务">Kubernetes有哪些不同类型的服务？</h3>
<ul>
<li>cluster ip</li>
<li>Node Port</li>
<li>Load Balancer</li>
<li>Extrenal Name</li>
</ul>
<h3 id="什么是etcd">什么是ETCD？</h3>
<p>Etcd是用Go编程语言编写的，是一个分布式键值存储，用于协调分布式工作。因此，Etcd存储Kubernetes集群的配置数据，表示在任何给定时间点的集群状态。</p>
<h3 id="什么是ingress网络它是如何工作的">什么是Ingress网络，它是如何工作的？</h3>
<p><a href="https://link.zhihu.com/?target=https%3A//www.edureka.co/blog/kubernetes-networking%3Futm_source%3Dmedium%26utm_medium%3Dcontent-link%26utm_campaign%3Dkubernetes-interview-questions%26source%3Dpost_page---------------------------">Ingress网络</a>是一组规则，充当Kubernetes集群的入口点。这允许入站连接，可以将其配置为通过可访问的URL，负载平衡流量或通过提供基于名称的虚拟主机从外部提供服务。因此，Ingress是一个API对象，通常通过HTTP管理集群中服务的外部访问，是暴露服务的最有效方式。</p>
<h3 id="什么是headless-service">什么是Headless Service？</h3>
<p>Headless Service类似于“普通”服务，但没有群集IP。此服务使您可以直接访问pod，而无需通过代理访问它。</p>
<h3 id="什么是集群联邦">什么是集群联邦？</h3>
<p>在联邦集群的帮助下，可以将多个Kubernetes集群作为单个集群进行管理。因此，您可以在数据中心/云中创建多个Kubernetes集群，并使用联邦来在一个位置控制/管理它们。</p>
<p>联合集群可以通过执行以下两项操作来实现此目的。请参考下图。</p>
<h3 id="kube-proxy的作用">kube-proxy的作用</h3>
<p>kube-proxy运行在所有节点上，它监听apiserver中service和endpoint的变化情况，创建路由规则以提供服务IP和负载均衡功能。简单理解此进程是Service的透明代理兼负载均衡器，其核心功能是将到某个Service的访问请求转发到后端的多个Pod实例上。</p>
<h3 id="kube-proxy-iptables的原理">kube-proxy iptables的原理</h3>
<p>Kubernetes从1.2版本开始，将iptables作为kube-proxy的默认模式。iptables模式下的kube-proxy不再起到Proxy的作用，其核心功能：通过API  Server的Watch接口实时跟踪Service与Endpoint的变更信息，并更新对应的iptables规则，Client的请求流量则通过iptables的NAT机制“直接路由”到目标Pod。</p>
<h3 id="kube-proxy-ipvs的原理">kube-proxy ipvs的原理</h3>
<p>IPVS在Kubernetes1.11中升级为GA稳定版。IPVS则专门用于高性能负载均衡，并使用更高效的数据结构（Hash表），允许几乎无限的规模扩张，因此被kube-proxy采纳为最新模式。</p>
<p>在IPVS模式下，使用iptables的扩展ipset，而不是直接调用iptables来生成规则链。iptables规则链是一个线性的数据结构，ipset则引入了带索引的数据结构，因此当规则很多时，也可以很高效地查找和匹配。</p>
<p>可以将ipset简单理解为一个IP（段）的集合，这个集合的内容可以是IP地址、IP网段、端口等，iptables可以直接添加规则对这个“可变的集合”进行操作，这样做的好处在于可以大大减少iptables规则的数量，从而减少性能损耗。</p>
<h3 id="kube-proxy-ipvs和iptables的异同">kube-proxy ipvs和iptables的异同</h3>
<p>iptables与IPVS都是基于Netfilter实现的，但因为定位不同，二者有着本质的差别：iptables是为防火墙而设计的；IPVS则专门用于高性能负载均衡，并使用更高效的数据结构（Hash表），允许几乎无限的规模扩张。</p>
<p>与iptables相比，IPVS拥有以下明显优势：</p>
<ul>
<li>为大型集群提供了更好的可扩展性和性能；</li>
<li>支持比iptables更复杂的复制均衡算法（最小负载、最少连接、加权等）；</li>
<li>支持服务器健康检查和连接重试等功能；</li>
<li>可以动态修改ipset的集合，即使iptables的规则正在使用这个集合。</li>
</ul>
<h3 id="kubernetes镜像的下载策略">Kubernetes镜像的下载策略</h3>
<p>Kubernetes的镜像下载策略有三种：Always、Never、IFNotPresent。</p>
<ul>
<li>Always：镜像标签为latest时，总是从指定的仓库中获取镜像。</li>
<li>Never：禁止从仓库中下载镜像，也就是说只能使用本地镜像。</li>
<li>IfNotPresent：仅当本地没有对应镜像时，才从目标仓库中下载。默认的镜像下载策略是：当镜像标签是latest时，默认策略是Always；当镜像标签是自定义时（也就是标签不是latest），那么默认策略是IfNotPresent。</li>
</ul>
<h3 id="简述kubernetes-scheduler使用哪两种算法将pod绑定到worker节点">简述Kubernetes Scheduler使用哪两种算法将Pod绑定到worker节点</h3>
<p>Kubernetes Scheduler根据如下两种调度算法将 Pod 绑定到最合适的工作节点：</p>
<ul>
<li>预选（Predicates）：输入是所有节点，输出是满足预选条件的节点。kube-scheduler根据预选策略过滤掉不满足策略的Nodes。如果某节点的资源不足或者不满足预选策略的条件则无法通过预选。如“Node的label必须与Pod的Selector一致”。</li>
<li>优选（Priorities）：输入是预选阶段筛选出的节点，优选会根据优先策略为通过预选的Nodes进行打分排名，选择得分最高的Node。例如，资源越富裕、负载越小的Node可能具有越高的排名。</li>
</ul>
<h2 id="zabbix">zabbix</h2>
<h3 id="简述zabbix-proxy使用场景">简述Zabbix-proxy使用场景</h3>
<ul>
<li>监控远程位置，解决跨机房</li>
<li>监控主机多，性能跟不上，延迟大</li>
<li>解决网络不稳定</li>
</ul>
<h3 id="zabbix-是怎么实施监控的">zabbix 是怎么实施监控的</h3>
<p>agentd需要安装到被监控的主机上，它负责定期收集各项数据，并发送到zabbix server端，zabbix server将数据存储到数据库中，zabbix web根据数据在前端进行展现和绘图。这里agentd收集数据分为主动和被动两种模式：</p>
<p>主动：agent请求server获取主动的监控项列表，并主动将监控项内需要检测的数据提交给server/proxy</p>
<p>被动：server向agent请求获取监控项的数据，agent返回数据。</p>
<ul>
<li>
<p>主动模式被动模式：默认为zabbix-agent被动模式</p>
</li>
<li>
<p>1.被动模式（zabbix-server轮询检测zabbix-agent）</p>
</li>
<li>
<p>2.主动模式（zabbix-agent主动上报给zabbix-server）优</p>
</li>
<li>
<p>1.当（Queue）队列中有大量的延迟监控项</p>
</li>
<li>
<p>2.当监控主机超过300+ ,建议使用主动模式</p>
</li>
</ul>
<h3 id="zabbix-怎么开启自定义监控">zabbix 怎么开启自定义监控</h3>
<p>1、写一个脚本用于获取待监控服务的一些状态信息。</p>
<p>2、在zabbix客户端的配置文件zabbix_agentd.conf中添加上自定义的“UserParameter”，目的是方便zabbix调用我们上面写的那个脚本去获取待监控服务的信息。</p>
<p>3、在zabbix服务端使用zabbix_get测试是否能够通过第二步定义的参数去获取zabbix客户端收集的数据。</p>
<p>4、在zabbix服务端的web界面中新建模板，同时第一步的脚本能够获取什么信息就添加上什么监控项，“键值”设置成前面配置的“UserParameter”的值。</p>
<p>5、数据显示图表，直接新建图形并选择上一步的监控项来生成动态图表即可。</p>
<h2 id="iptables">iptables</h2>
<h3 id="iptables四表五链必问题">iptables四表五链（必问题）</h3>
<p>表：</p>
<ul>
<li>nat 用于网络地址解析</li>
<li>mangle mangle包， 特定数据包的更改，好比head,content</li>
<li>filter default表，用于过滤包</li>
<li>raw 优先级最高，用于pretouting和output ,使用raw表，能够跳过NAT表和ip_conntrack处理,即再也不作地址转换和数据包的连接跟踪处理了</li>
</ul>
<p>链：</p>
<ul>
<li>
<p>prerouting,</p>
</li>
<li>
<p>input</p>
</li>
<li>
<p>forword</p>
</li>
<li>
<p>output</p>
</li>
<li>
<p>postrouting</p>
</li>
</ul>
<h3 id="iptables和firewalld的基本区别是什么呢">iptables和firewalld的基本区别是什么呢？</h3>
<p>在linux中，防火墙的概念是 Linux 内核网络堆栈中的网络数据包进行操作的规则集合，而iptables则是这些用来操作这些规则的<strong>用户空间</strong>命令行工具，通过将规则格式化为内核数据结构转发为内核。</p>
<p>firewalld是fedora的一个开源项目，是iptables/nftables命令的封装，实现了更多动态防火墙的概念，并且加入更多用户鉴权，GUI管理等。</p>
<p>类似于http是tcp的wapper，firewalld则是iptables的wapper。</p>
<h3 id="什么是iptables中的目标值能被指定为目标他们有什么用">什么是iptables中的目标值（能被指定为目标），他们有什么用</h3>
<p>下面是在iptables中可以指定为目标的值：</p>
<ul>
<li>ACCEPT : 接受包</li>
<li>QUEUE : 将包传递到用户空间 (应用程序和驱动所在的地方)</li>
<li>DROP : 丢弃包</li>
<li>RETURN : 将控制权交回调用的链并且为当前链中的包停止执行下一调用规则</li>
</ul>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
