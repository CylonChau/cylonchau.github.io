<!doctype html><html lang=zh dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Ceph概念 - 初识Ceph | Cylon's Collection</title><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NP3JNCPR" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><meta name=keywords content="ceph"><meta name=description content="初识Ceph Ceph 是一个开源分布式存储系统系统，它不是一种单一的存储，而是面向云提供一种统一存储平台，包含块存储 RBD, 文件存储 CephFS, 以及对象存储 RGW，这种存储的出现允许用户拜托供应商的绑定，它可以提供块存储到 “云平台”，也可以提供对象存储到 “应用”，并支持理论上的无限扩展性，数千客户端访问 PB 甚至 EB 级别的数据
SAN VS Ceph 与传统 SAN 存储相比，Ceph 客户端会计算他们所需的数据所在的位置，这消除了存储系统中需要在“中心化查找”的瓶颈。 这使得 Ceph 集群可以在不损失性能的情况下进行扩展。
Ceph 集群架构组成 Ceph 集群核心是 RADOS，而基于 RADOS，构建出多种类型存储，块存储, 文件系统, 对象存储，而一个基础的 Ceph 集群的组件由 &ldquo;Ceph monitor&rdquo; 与 &ldquo;Ceph OSD Daemon&rdquo; 组成
Ceph Monitor（进程名称为 ceph-mon，下文中以 ceph-mon 代表 Ceph Monitor） 维护集群映射的主副本。 ceph集群中的monitor，可确保 ceph-mon 守护进程在失败时的高可用性。客户端从 ceph-mon 检索集群映射的副本。 Ceph OSD Daemon 检查”自身“及”其他“ OSD 的状态并报告给 Monitor。 Ceph 中的常见术语 Application 用于使用 Ceph 集群的任何 Ceph 外部的应用程序
Block Device 也称为 “RADOS 块设备” 或 ”RBD“ ，协调基于块的数据存储的工具，Ceph块设备拆分基于块的应用程序数据 成“块”。 RADOS 将这些块存储为对象。 Ceph 块 设备协调这些对象的存储 存储集群。"><meta name=author content="cylon"><link rel=canonical href=http://localhost:1313/2019/06/01-1-ceph-acquaintance/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/favicon.ico><link rel=mask-icon href=http://localhost:1313/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=http://localhost:1313/2019/06/01-1-ceph-acquaintance/><noscript><style>#theme-toggle,#top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link crossorigin=anonymous href=/assets/css/pe.min.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/pe.min.js></script><link rel=stylesheet href=https://cdn.staticfile.net/font-awesome/6.5.1/css/all.min.css><link rel=stylesheet href=https://cdn.staticfile.net/font-awesome/6.5.1/css/v4-shims.min.css><script id=MathJax-script async src=https://cdn.staticfile.net/mathjax/3.2.2/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["$$","$$"]],inlineMath:[["\\$","\\$"]]}}</script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"><script>(function(e,t,n,s,o){e[s]=e[s]||[],e[s].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var a=t.getElementsByTagName(n)[0],i=t.createElement(n),r=s!="dataLayer"?"&l="+s:"";i.async=!0,i.src="https://www.googletagmanager.com/gtm.js?id="+o+r,a.parentNode.insertBefore(i,a)})(window,document,"script","dataLayer","GTM-NP3JNCPR")</script><meta property="og:title" content="Ceph概念 - 初识Ceph"><meta property="og:description" content="初识Ceph Ceph 是一个开源分布式存储系统系统，它不是一种单一的存储，而是面向云提供一种统一存储平台，包含块存储 RBD, 文件存储 CephFS, 以及对象存储 RGW，这种存储的出现允许用户拜托供应商的绑定，它可以提供块存储到 “云平台”，也可以提供对象存储到 “应用”，并支持理论上的无限扩展性，数千客户端访问 PB 甚至 EB 级别的数据
SAN VS Ceph 与传统 SAN 存储相比，Ceph 客户端会计算他们所需的数据所在的位置，这消除了存储系统中需要在“中心化查找”的瓶颈。 这使得 Ceph 集群可以在不损失性能的情况下进行扩展。
Ceph 集群架构组成 Ceph 集群核心是 RADOS，而基于 RADOS，构建出多种类型存储，块存储, 文件系统, 对象存储，而一个基础的 Ceph 集群的组件由 &ldquo;Ceph monitor&rdquo; 与 &ldquo;Ceph OSD Daemon&rdquo; 组成
Ceph Monitor（进程名称为 ceph-mon，下文中以 ceph-mon 代表 Ceph Monitor） 维护集群映射的主副本。 ceph集群中的monitor，可确保 ceph-mon 守护进程在失败时的高可用性。客户端从 ceph-mon 检索集群映射的副本。 Ceph OSD Daemon 检查”自身“及”其他“ OSD 的状态并报告给 Monitor。 Ceph 中的常见术语 Application 用于使用 Ceph 集群的任何 Ceph 外部的应用程序
Block Device 也称为 “RADOS 块设备” 或 ”RBD“ ，协调基于块的数据存储的工具，Ceph块设备拆分基于块的应用程序数据 成“块”。 RADOS 将这些块存储为对象。 Ceph 块 设备协调这些对象的存储 存储集群。"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/2019/06/01-1-ceph-acquaintance/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-06-30T00:00:00+00:00"><meta property="article:modified_time" content="2023-08-20T23:10:36+08:00"><meta property="og:site_name" content="Cylon's Collection"><meta name=twitter:card content="summary"><meta name=twitter:title content="Ceph概念 - 初识Ceph"><meta name=twitter:description content="初识Ceph Ceph 是一个开源分布式存储系统系统，它不是一种单一的存储，而是面向云提供一种统一存储平台，包含块存储 RBD, 文件存储 CephFS, 以及对象存储 RGW，这种存储的出现允许用户拜托供应商的绑定，它可以提供块存储到 “云平台”，也可以提供对象存储到 “应用”，并支持理论上的无限扩展性，数千客户端访问 PB 甚至 EB 级别的数据
SAN VS Ceph 与传统 SAN 存储相比，Ceph 客户端会计算他们所需的数据所在的位置，这消除了存储系统中需要在“中心化查找”的瓶颈。 这使得 Ceph 集群可以在不损失性能的情况下进行扩展。
Ceph 集群架构组成 Ceph 集群核心是 RADOS，而基于 RADOS，构建出多种类型存储，块存储, 文件系统, 对象存储，而一个基础的 Ceph 集群的组件由 &ldquo;Ceph monitor&rdquo; 与 &ldquo;Ceph OSD Daemon&rdquo; 组成
Ceph Monitor（进程名称为 ceph-mon，下文中以 ceph-mon 代表 Ceph Monitor） 维护集群映射的主副本。 ceph集群中的monitor，可确保 ceph-mon 守护进程在失败时的高可用性。客户端从 ceph-mon 检索集群映射的副本。 Ceph OSD Daemon 检查”自身“及”其他“ OSD 的状态并报告给 Monitor。 Ceph 中的常见术语 Application 用于使用 Ceph 集群的任何 Ceph 外部的应用程序
Block Device 也称为 “RADOS 块设备” 或 ”RBD“ ，协调基于块的数据存储的工具，Ceph块设备拆分基于块的应用程序数据 成“块”。 RADOS 将这些块存储为对象。 Ceph 块 设备协调这些对象的存储 存储集群。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"Ceph概念 - 初识Ceph","item":"http://localhost:1313/2019/06/01-1-ceph-acquaintance/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Ceph概念 - 初识Ceph","name":"Ceph概念 - 初识Ceph","description":"初识Ceph Ceph 是一个开源分布式存储系统系统，它不是一种单一的存储，而是面向云提供一种统一存储平台，包含块存储 RBD, 文件存储 CephFS, 以及对象存储 RGW，这种存储的出现允许用户拜托供应商的绑定，它可以提供块存储到 “云平台”，也可以提供对象存储到 “应用”，并支持理论上的无限扩展性，数千客户端访问 PB 甚至 EB 级别的数据\nSAN VS Ceph 与传统 SAN 存储相比，Ceph 客户端会计算他们所需的数据所在的位置，这消除了存储系统中需要在“中心化查找”的瓶颈。 这使得 Ceph 集群可以在不损失性能的情况下进行扩展。\nCeph 集群架构组成 Ceph 集群核心是 RADOS，而基于 RADOS，构建出多种类型存储，块存储, 文件系统, 对象存储，而一个基础的 Ceph 集群的组件由 \u0026ldquo;Ceph monitor\u0026rdquo; 与 \u0026ldquo;Ceph OSD Daemon\u0026rdquo; 组成\nCeph Monitor（进程名称为 ceph-mon，下文中以 ceph-mon 代表 Ceph Monitor） 维护集群映射的主副本。 ceph集群中的monitor，可确保 ceph-mon 守护进程在失败时的高可用性。客户端从 ceph-mon 检索集群映射的副本。 Ceph OSD Daemon 检查”自身“及”其他“ OSD 的状态并报告给 Monitor。 Ceph 中的常见术语 Application 用于使用 Ceph 集群的任何 Ceph 外部的应用程序\nBlock Device 也称为 “RADOS 块设备” 或 ”RBD“ ，协调基于块的数据存储的工具，Ceph块设备拆分基于块的应用程序数据 成“块”。 RADOS 将这些块存储为对象。 Ceph 块 设备协调这些对象的存储 存储集群。","keywords":["ceph"],"articleBody":"初识Ceph Ceph 是一个开源分布式存储系统系统，它不是一种单一的存储，而是面向云提供一种统一存储平台，包含块存储 RBD, 文件存储 CephFS, 以及对象存储 RGW，这种存储的出现允许用户拜托供应商的绑定，它可以提供块存储到 “云平台”，也可以提供对象存储到 “应用”，并支持理论上的无限扩展性，数千客户端访问 PB 甚至 EB 级别的数据\nSAN VS Ceph 与传统 SAN 存储相比，Ceph 客户端会计算他们所需的数据所在的位置，这消除了存储系统中需要在“中心化查找”的瓶颈。 这使得 Ceph 集群可以在不损失性能的情况下进行扩展。\nCeph 集群架构组成 Ceph 集群核心是 RADOS，而基于 RADOS，构建出多种类型存储，块存储, 文件系统, 对象存储，而一个基础的 Ceph 集群的组件由 “Ceph monitor” 与 “Ceph OSD Daemon” 组成\nCeph Monitor（进程名称为 ceph-mon，下文中以 ceph-mon 代表 Ceph Monitor） 维护集群映射的主副本。 ceph集群中的monitor，可确保 ceph-mon 守护进程在失败时的高可用性。客户端从 ceph-mon 检索集群映射的副本。 Ceph OSD Daemon 检查”自身“及”其他“ OSD 的状态并报告给 Monitor。 Ceph 中的常见术语 Application 用于使用 Ceph 集群的任何 Ceph 外部的应用程序\nBlock Device 也称为 “RADOS 块设备” 或 ”RBD“ ，协调基于块的数据存储的工具，Ceph块设备拆分基于块的应用程序数据 成“块”。 RADOS 将这些块存储为对象。 Ceph 块 设备协调这些对象的存储 存储集群。\n也称为 “RADOS Block Device” 或 “RBD”。一种用于协调 Ceph 中基于块的数据的存储的软件。 Ceph 块设备将基于块的应用程序数据拆分为 “Chunk”。 RADOS 将这些块存储为对象。\nChunk 与 Block 是两种不同的概念\nChunk 存储是类似于 Key-Value 存储和对象存储，是一种结构化数据，并固定大小的块\nBlock 通常被提到的上下文是作为硬件接口提供的，通常代表硬件裸设备\n所以说 Block Device 是将数据划分为固定大小的 Chunk，存储在 Block 上。\nMGR (Manager) Ceph Manager 又称为 Ceph Manager Daemon，进程名称为 ceph-mgr, 是与 Ceph Monitoring 一起运行的守护进程，用于提供监视以及与外部监视和管理系统的接口。自 Luminous 版本 (12) 起，ceph-mgr 没有运行的情况下 Ceph 集群无法正常运行。\nMON (Monitor) Ceph Monitor 维护集群状态影视的守护进程，这些“集群状态”包括 Monitor map、Manager map、OSD map 和 CRUSH map。 Ceph 集群必须至少包含三个正在运行的 Monitor，才能实现冗余和高可用性。\nOSD Ceph Object Storage Daemon，又被称为 OSD, 在 “research and industry” 中 OSD 表示 ”对象存储设备“，而 Ceph 社区将 OSD 称为 OSD daemon，用于与逻辑磁盘交互的进程。\nOSD fsid 用于标识 OSD 的唯一标识符。它可以在 OSD 路径中名为 osd_fsid 的文件中找到。术语 “fsid” 与 “uuid” 互换使用\nOSD id 定义 OSD 的 integer，它是在创建每个 OSD 期间由监视器生成的。\nHybrid OSD 指同时拥有 HDD 和 SSD 的 OSD\nCluster Map 由 monitor map、OSD Map、PG Map、MDS Map 和 CRUSH Map 组成的一组 Map，它们共同报告 Ceph 集群的状态。有关详细信息。\nCRUSH CRUSH Controlled Replication Under Scalable Hashing 可扩展散列下的受控复制，Ceph 用于计算对象存储位置的算法。\nDAS DAS Direct-Attached Storage 直接附加存储，无需访问网络直接连接计算机的存储。例如 SSD\nLVM tags Logical Volume Manager tags 逻辑卷管理器标签，LVM “卷” 和 “组” 的可扩展元数据。它们用于存储有关设备及其与 OSD 关系的 Ceph 特定信息。\nPGs (Placement Groups) “放置组” 是每个逻辑 Ceph Pool 的子集。放置组执行将对象（作为一个组）放置到 OSD 中的功能。 Ceph 在内部以“放置组粒度”来管理数据：这比管理单个RADOS 对象的扩展性将更好。具有较大数量放置组的集群比具有较少数量放置组的其他相同集群具有更好的平衡性。\nPools 池是用于存储对象的逻辑分区。\nRADOS Reliable Autonomic Distributed Object Store 可靠的自动分布对象存储，RADOS 是为可变大小的对象提供可扩展服务的对象存储。 RADOS 对象存储是 Ceph 集群的核心组件。\nBlock Storage 块存储是 Ceph支持的三种存储类型之一。 Ceph 块存储指的是块存储 结合使用时的相关服务和功能 集合\nCeph File System Ceph File System (CephFS) 是一个兼容 POSIX 的文件系统，构建在 RADOS 之上，可根据按需部署\nMDS (Metadata Server) Ceph MetaData Server daemon MDS，构建在 RADOS 之上，存储所有文件的元数据作为”文件系统“类型的存储提供给用户，运行的程序名为 ceph-mds，故 也是是否使用 CephFS 的标记\nRGW (Radow Gateway) Ceph 提供兼容 Amazon S3 RESTful API 和 OpenStack Swift API 的组件，可根据按需部署\nRealm 是位于对象存储中的上下文，领域 (Realm) 是一个全局唯一的命名空间，由一个或多个区域组组成。\nZone 是位于对象存储中的上下文，区域 (zone) 是由一个或多个 RGW 实例组成的逻辑组。“zone” 的配置状态存储在 \"\" 中\nPeriod 是位于对象存储中的上下文，Period 是 Realm 的配置状态。该 Period 存储多站点配置的配置状态。当 Period 被更新时，“epoch” 被认为已经改变。\nCephX CephX Ceph authentication protocol；CephX 是用于对用户和守护进程进行身份验证。 CephX 的运行方式类似于 Kerberos，但它没有单点故障。\nSecrets Secret 是用户访问是需要提供的身份验证的系统用于执行数字身份验证的凭据。\nCeph存储集群组成 Ceph 存储集群由多种类型的守护进程组成：\nCeph Monitor Ceph OSD Daemon Ceph Manager Ceph Metadata Server OSD (Object Storage Device) 对象存储设备 OSD (Object Storage Device) 通常是指==单独的磁盘设备==，每个 Ceph Node 上有一个或多个o OSD，每一个 OSD 是真正存放数据的地方（在文件系统中同样概念为文件与目录）；OSD不是主机。由多个 Ceph Node 组合起来称为 RADOS Cluster\n为了使每个 OSD 能够被单独使用和管理，每个 OSD 都会有一个单独的专用的守护进程被称为 ceph-osd。OSD 本身用来存储数据，还包括数据复制、恢复、数据重新均衡、提供监视信息给mon和mgr\n一个集群至少有 3个 Ceph OSDs，已确保高可用。选择 OSD 冗余时，应自己指定故障率，故障转移率或故障容忍率。OSD级别故障就在OSD级别冗余，主机级别就跨主机冗余，故障率是机架级别就机架冗余。 在做crush运行图的设定时是应该自己指定的。\n(MGR Manager) Mgr (Manager) 集群元数据服务器，维护集群映射的主副本。Ceph 监视器集群可确保监视器守护进程发生故障时的高可用性。存储集群客户端从 Ceph Monitor 检索集群映射的副本。\nmonitor在每一次读数据都是实时查询的，故monitor不适用频繁周期性采集数据的监控操作。在Ceph新版中引入新组建mgr，（早期Ceph版本是没有mgr的）用来专门维护查询类操作，将查询操作按照自己内部空闲方式缓存下来，一旦有监控可及时响应。\nmgr是在一类节点上运行的守护进程，一般为两个活以上节点，此类守护进程被称为ceph-mgr。主要功能在于跟踪运行时的指标数据。如磁盘使用率、CPU使用率。以及集群当前状态，此状态不是内部运行状态，而是查询做监控时的状态。包括存储空间利用率、当前性能指标、节点负载（系统级）等\nMON (Monitor) 一个 Ceph 集群内除了存储节点之外，还有另外一种节点 Monitor ，用来管理整个集群的，如有多少个节点，每个节点上有多少个OSD，每个OSD是否健康，他会持有整个集群的运行图（运行状态）。mon是用来集中维护集群元数据而非文件元数据。为了维护整个集群能够正常运行而设定的节点，离开此节点集群内部就无法协调。\n在一个主机上运行的守护进程 ceph-mon，守护进程扮演、监视着整个集群所有组件的角色，被称为集群运行图的持有者cluster map（整个集群有多少存储池，每个池中有多少PG，每个PG映射哪个OSD，有多少OSD等等）集群运行图 Cluster Map\nmonitor负责维护整个进群的认证信息并实行认证，认证协议叫 ==CephX== 协议（ceph内部的认证协议）。monitor用来维护认证信息并实行认证。认证中心 monitor自身是无状态的，所以实现均衡认证负载。\nmonitor的高可用自己内部直接使用POSIX协议来实现数据冗余，monitor也是节点级冗余，为了确保各节点数据是强一致的，每个节点都可写，写完后会同步到其他节点。为了避免同时写导致的冲突，使用了分布式一致性协议，monitor就是使用POSIX协议来进行分布式协作的。\nMDS (Metadata Server) ==Ceph Metadata Server== 用来代表ceph文件系统而提供的守护进程ceph-mds，如不使用CephFS，此进程是无需启动的。利用底层RADOS存储空间，将存储空间抽象成文件系统，来兼容POSIX file system 提供服务。\nNote: 一个基础的 Ceph 存储集群由，OSD, Monitor, Manager 组成\nCeph集群中其他概念 客户端接口 Ceph 存储集群提供了基础的对象数据存储服务，客户端可基于RADOS协议和 librados API 直接与存储系统交互进行对象数据存取 Librados Librados提供了访问 RADOS 在存储集群支持 “异步” 通信的 API 接口，支持对集群中对象数据的的直接并行访问，用户可通过支持的编程语言开发自定义客户端程序通过RADOS协议与存储系统进行交互 客户端应用程序必须与librados绑定方可连接到RADOS存储集群，因此，用户必须实现安装librados及其依赖后才能编写使用librados的应用程序。 librados API本身使用 C++ 编写的，它额外支持C、Python、Java、和PHP等开发接口 当然，并非所有用户都有能力自定义开发接口以接入RADOS存储集群的需要，为此，Ceph也原生提供了几个较高级别的各户端接口，它们分别是 RADOS GateWay (RGW), Reliable Block Device (RBD) 和 MDS (MetaData Server)，分别为用户提供 RESTFUL、块和 POSIX 文件系统接口 管理节点 (Admin Host) Ceph通常是分布式集群，为了便于去管理维护整个集群，通常在Ceph集群中找一个专门的节点用来当管理节点。此节点可以连接至每一个节点用来管理节点上的Ceph守护进程。\nCeph的管理接口是一系列命令行工具，例如 rados, ceph, rbd 等命令，管理员可以从某个特定的MON节点执行管理操作，但也有人更倾向于使用专用的管理节点。\nNote: 在早期 (Ceph-deploy) 部署的集群，通常管理节点是必要的，但使用 cephadm 部署的集群，实际上管理管理节点可以在任何位置\nPool Ceph所提供的存储空间（没有目录之类一说）是将“所有对象都是存储在数据平面上”，因此，所有对象都不能同名。RADOS 将他的存储空间切分为多个分区以便好进行管理。每一个分区叫做一个“存储池”。存储池的大小是取决于底层的存储空间的。与真正意义上的分区不是一回事。在Ceph中每一个存储池存放的数据了也可能会太大，所以存储池也可以进一步划分（可选）。被称为名称空间（先切分为存储池，每个存储池可进一步被划分成名称空间） 两级逻辑组件。\n第三级 PG 每一个存储池内部会有多个PG（Placement Groups 规置组）存在。Pool 与 pg 都是抽象的概念。\nObject 对象是自带元数据的组件，\n对象id，每一个对象应有一个对象ID在集群内部来引用对象 数据 元数据 key vlaue类型的数据 这些类型打包成一起存储，被称为一个对象。RADOS集群会吧真正存储的每一个文件，切分成N个对象来进行存储的。（切分个数与默认对象切分大小有关）。\n每一个对象都是被单独管理的，都拥有自己的标识符。因此， 同一个文件的object有可能被映射到不同的PG上，PG提交给主机的，由主机负责将对象存储在磁盘（OSD）被存储在不同的OSD上。\n文件存储到RADOS集群 一般要接入RADOS集群必须通过客户端来实现(LIBRADOS、RBD、CephFS、RADOSGW)，才能接入到集群中来。\n当将文件存入Ceph中时，需要通过某一类客户端接入，客户端接入时，需要借助于 Ceph 存储API接口将其切分为固定大小的存储对象(Date object)，此数据对象究竟被放置在哪个 OSD 上存放这中间是靠 crush 来完成的。数据对象被存放在哪个存储池上是固定的。存储池需创建才可使用。但PG是虚拟的中间层。\n","wordCount":"528","inLanguage":"zh","datePublished":"2019-06-30T00:00:00Z","dateModified":"2023-08-20T23:10:36+08:00","author":{"@type":"Person","name":"cylon"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/2019/06/01-1-ceph-acquaintance/"},"publisher":{"@type":"Organization","name":"Cylon's Collection","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/><img src=http://localhost:1313/favicon.ico alt aria-label=logo height=20>Cylon's Collection</a><div class=logo-switches><button id=theme-toggle><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/archives><span>归档</span></a></li><li><a href=http://localhost:1313/tags><span>标签</span></a></li><li><a href=http://localhost:1313/search><span>搜索</span></a></li><li><a href=http://localhost:1313/about accesskey=/><span>关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Ceph概念 - 初识Ceph</h1><div class=post-meta><span class=pe-post-meta-item><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select:text"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select:text"/><line x1="16" y1="2" x2="16" y2="6" style="user-select:text"/><line x1="8" y1="2" x2="8" y2="6" style="user-select:text"/><line x1="3" y1="10" x2="21" y2="10" style="user-select:text"/></svg><span>2019-06-30</span></span>&nbsp;·&nbsp;<span class=pe-post-meta-item><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text" style="user-select:text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z" style="user-select:text"/><polyline points="14 2 14 8 20 8" style="user-select:text"/><line x1="16" y1="13" x2="8" y2="13" style="user-select:text"/><line x1="16" y1="17" x2="8" y2="17" style="user-select:text"/><polyline points="10 9 9 9 8 9" style="user-select:text"/></svg><span>528 字</span></span>&nbsp;·&nbsp;<span class=pe-post-meta-item><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><span>3 分钟</span></span>
<span class=pe-post-meta-item>&nbsp;·&nbsp;<svg t="1714036239378" fill="currentcolor" class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" p-id="6659" width="256" height="256"><path d="M690 78.2c-18.6-18.8-49-19-67.8-.4s-19 49-.4 67.8l255.4 258.6c67.8 68.6 67.8 178.8.0 247.4L653.4 878.2c-18.6 18.8-18.4 49.2.4 67.8s49.2 18.4 67.8-.4l224-226.4c104.8-106 104.8-276.4.0-382.4L690 78.2zM485.4 101.4c-24-24-56.6-37.4-90.6-37.4H96C43 64 0 107 0 160v299c0 34 13.4 66.6 37.4 90.6l336 336c50 50 131 50 181 0l267-267c50-50 50-131 0-181l-336-336zM96 160h299c8.4.0 16.6 3.4 22.6 9.4l336 336c12.4 12.4 12.4 32.8.0 45.2l-267 267c-12.4 12.4-32.8 12.4-45.2.0l-336-336c-6-6-9.4-14.2-9.4-22.6V160zm192 128a64 64 0 10-128 0 64 64 0 10128 0z" p-id="6660"/></svg></span><ul class=pe-post-meta-item><a href=http://localhost:1313/tags/storage/>#Storage</a></ul></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details><summary><span class=details>目录</span></summary><div class=inner><ul><li><a href=#%e5%88%9d%e8%af%86ceph aria-label=初识Ceph>初识Ceph</a><ul><li><a href=#san-vs-ceph aria-label="SAN VS Ceph">SAN VS Ceph</a><li><a href=#ceph-%e9%9b%86%e7%be%a4%e6%9e%b6%e6%9e%84%e7%bb%84%e6%88%90 aria-label="Ceph 集群架构组成">Ceph 集群架构组成</a><li><a href=#ceph-%e4%b8%ad%e7%9a%84%e5%b8%b8%e8%a7%81%e6%9c%af%e8%af%ad aria-label="Ceph 中的常见术语">Ceph 中的常见术语</a><ul><li><a href=#application aria-label=Application>Application</a><li><a href=#block-device aria-label="Block Device">Block Device</a><li><a href=#mgr-manager aria-label="MGR (Manager)">MGR (Manager)</a><li><a href=#mon-monitor aria-label="MON (Monitor)">MON (Monitor)</a><li><a href=#osd aria-label=OSD>OSD</a><li><a href=#osd-fsid aria-label="OSD fsid">OSD fsid</a><li><a href=#osd-id aria-label="OSD id">OSD id</a><li><a href=#hybrid-osd aria-label="Hybrid OSD">Hybrid OSD</a><li><a href=#cluster-map aria-label="Cluster Map">Cluster Map</a><li><a href=#crush aria-label=CRUSH>CRUSH</a><li><a href=#das aria-label=DAS>DAS</a><li><a href=#lvm-tags aria-label="LVM tags">LVM tags</a><li><a href=#pgs-placement-groups aria-label="PGs (Placement Groups)">PGs (Placement Groups)</a><li><a href=#pools aria-label=Pools>Pools</a><li><a href=#rados aria-label=RADOS>RADOS</a><li><a href=#block-storage aria-label="Block Storage">Block Storage</a><li><a href=#ceph-file-system aria-label="Ceph File System">Ceph File System</a><li><a href=#mds-metadata-server aria-label="MDS (Metadata Server)">MDS (Metadata Server)</a><li><a href=#rgw-radow-gateway aria-label="RGW (Radow Gateway)">RGW (Radow Gateway)</a><li><a href=#realm aria-label=Realm>Realm</a><li><a href=#zone aria-label=Zone>Zone</a><li><a href=#period aria-label=Period>Period</a><li><a href=#cephx aria-label=CephX>CephX</a><li><a href=#secrets aria-label=Secrets>Secrets</a></ul></ul><li><a href=#ceph%e5%ad%98%e5%82%a8%e9%9b%86%e7%be%a4%e7%bb%84%e6%88%90 aria-label=Ceph存储集群组成>Ceph存储集群组成</a><ul><li><a href=#osd-object-storage-device aria-label="OSD (Object Storage Device)">OSD (Object Storage Device)</a><li><a href=#mgr-manager-1 aria-label="(MGR Manager)">(MGR Manager)</a><li><a href=#mon-monitor-1 aria-label="MON (Monitor)">MON (Monitor)</a><li><a href=#mds-metadata-server-1 aria-label="MDS (Metadata Server)">MDS (Metadata Server)</a></ul><li><a href=#ceph%e9%9b%86%e7%be%a4%e4%b8%ad%e5%85%b6%e4%bb%96%e6%a6%82%e5%bf%b5 aria-label=Ceph集群中其他概念>Ceph集群中其他概念</a><ul><li><a href=#%e5%ae%a2%e6%88%b7%e7%ab%af%e6%8e%a5%e5%8f%a3 aria-label=客户端接口>客户端接口</a><li><a href=#%e7%ae%a1%e7%90%86%e8%8a%82%e7%82%b9-admin-host aria-label="管理节点 (Admin Host)">管理节点 (Admin Host)</a><li><a href=#pool aria-label=Pool>Pool</a><li><a href=#%e7%ac%ac%e4%b8%89%e7%ba%a7-pg aria-label="第三级 PG">第三级 PG</a><li><a href=#object aria-label=Object>Object</a><li><a href=#%e6%96%87%e4%bb%b6%e5%ad%98%e5%82%a8%e5%88%b0rados%e9%9b%86%e7%be%a4 aria-label=文件存储到RADOS集群>文件存储到RADOS集群</a></li></div></details></div></aside><script src=/js/pe-toc.min.445eb1bfc5e85dd13b9519fcc2a806522e9629b6224a2974052789ba00ab78af.js integrity="sha256-RF6xv8XoXdE7lRn8wqgGUi6WKbYiSil0BSeJugCreK8="></script><div class=post-content><h2 id=初识ceph>初识Ceph<a hidden class=anchor aria-hidden=true href=#初识ceph>#</a></h2><p>Ceph 是一个开源分布式存储系统系统，它不是一种单一的存储，而是面向云提供一种统一存储平台，包含块存储 RBD, 文件存储 CephFS, 以及对象存储 RGW，这种存储的出现允许用户拜托供应商的绑定，它可以提供块存储到 “云平台”，也可以提供对象存储到 “应用”，并支持理论上的无限扩展性，数千客户端访问 PB 甚至 EB 级别的数据</p><h3 id=san-vs-ceph>SAN VS Ceph<a hidden class=anchor aria-hidden=true href=#san-vs-ceph>#</a></h3><p>与传统 SAN 存储相比，Ceph 客户端会计算他们所需的数据所在的位置，这消除了存储系统中需要在“中心化查找”的瓶颈。 这使得 Ceph 集群可以在不损失性能的情况下进行扩展。</p><h3 id=ceph-集群架构组成>Ceph 集群架构组成<a hidden class=anchor aria-hidden=true href=#ceph-集群架构组成>#</a></h3><p>Ceph 集群核心是 RADOS，而基于 RADOS，构建出多种类型存储，块存储, 文件系统, 对象存储，而一个基础的 Ceph 集群的组件由 &ldquo;Ceph monitor&rdquo; 与 &ldquo;Ceph OSD Daemon&rdquo; 组成</p><ul><li>Ceph Monitor（进程名称为 ceph-mon，下文中以 ceph-mon 代表 Ceph Monitor） 维护集群映射的主副本。 ceph集群中的monitor，可确保 ceph-mon 守护进程在失败时的高可用性。客户端从 ceph-mon 检索集群映射的副本。</li><li>Ceph OSD Daemon 检查”自身“及”其他“ OSD 的状态并报告给 Monitor。</li></ul><h3 id=ceph-中的常见术语>Ceph 中的常见术语<a hidden class=anchor aria-hidden=true href=#ceph-中的常见术语>#</a></h3><h4 id=application>Application<a hidden class=anchor aria-hidden=true href=#application>#</a></h4><p>用于使用 Ceph 集群的任何 Ceph 外部的应用程序</p><h4 id=block-device>Block Device<a hidden class=anchor aria-hidden=true href=#block-device>#</a></h4><p>也称为 “RADOS 块设备” 或 ”RBD“ ，协调基于块的数据存储的工具，Ceph块设备拆分基于块的应用程序数据 成“块”。 RADOS 将这些块存储为对象。 Ceph 块 设备协调这些对象的存储 存储集群。</p><p>也称为 “RADOS Block Device” 或 “RBD”。一种用于协调 Ceph 中基于块的数据的存储的软件。 Ceph 块设备将基于块的应用程序数据拆分为 “Chunk”。 RADOS 将这些块存储为对象。</p><p>Chunk 与 Block 是两种不同的概念</p><ul><li><p>Chunk 存储是类似于 Key-Value 存储和对象存储，是一种结构化数据，并固定大小的块</p></li><li><p>Block 通常被提到的上下文是作为硬件接口提供的，通常代表硬件裸设备</p></li></ul><p>所以说 Block Device 是将数据划分为固定大小的 Chunk，存储在 Block 上。</p><h4 id=mgr-manager>MGR (Manager)<a hidden class=anchor aria-hidden=true href=#mgr-manager>#</a></h4><p>Ceph Manager 又称为 Ceph Manager Daemon，进程名称为 <code>ceph-mgr</code>, 是与 Ceph Monitoring 一起运行的守护进程，用于提供监视以及与外部监视和管理系统的接口。自 Luminous 版本 (12) 起，ceph-mgr 没有运行的情况下 Ceph 集群无法正常运行。</p><h4 id=mon-monitor>MON (Monitor)<a hidden class=anchor aria-hidden=true href=#mon-monitor>#</a></h4><p>Ceph Monitor 维护集群状态影视的守护进程，这些“集群状态”包括 Monitor map、Manager map、OSD map 和 CRUSH map。 Ceph 集群必须至少包含三个正在运行的 Monitor，才能实现冗余和高可用性。</p><h4 id=osd>OSD<a hidden class=anchor aria-hidden=true href=#osd>#</a></h4><p>Ceph <strong>O</strong>bject <strong>S</strong>torage <strong>D</strong>aemon，又被称为 OSD, 在 “research and industry” 中 OSD 表示 ”对象存储设备“，而 Ceph 社区将 OSD 称为 OSD daemon，用于与逻辑磁盘交互的进程。</p><h4 id=osd-fsid>OSD fsid<a hidden class=anchor aria-hidden=true href=#osd-fsid>#</a></h4><p>用于标识 OSD 的唯一标识符。它可以在 OSD 路径中名为 osd_fsid 的文件中找到。术语 “fsid” 与 “uuid” 互换使用</p><h4 id=osd-id>OSD id<a hidden class=anchor aria-hidden=true href=#osd-id>#</a></h4><p>定义 OSD 的 integer，它是在创建每个 OSD 期间由监视器生成的。</p><h4 id=hybrid-osd>Hybrid OSD<a hidden class=anchor aria-hidden=true href=#hybrid-osd>#</a></h4><p>指同时拥有 HDD 和 SSD 的 OSD</p><h4 id=cluster-map>Cluster Map<a hidden class=anchor aria-hidden=true href=#cluster-map>#</a></h4><p>由 monitor map、OSD Map、PG Map、MDS Map 和 CRUSH Map 组成的一组 Map，它们共同报告 Ceph 集群的状态。有关详细信息。</p><h4 id=crush>CRUSH<a hidden class=anchor aria-hidden=true href=#crush>#</a></h4><p>CRUSH <strong>C</strong>ontrolled <strong>R</strong>eplication <strong>U</strong>nder <strong>S</strong>calable <strong>H</strong>ashing 可扩展散列下的受控复制，Ceph 用于计算对象存储位置的算法。</p><h4 id=das>DAS<a hidden class=anchor aria-hidden=true href=#das>#</a></h4><p>DAS <strong>D</strong>irect-<strong>A</strong>ttached <strong>S</strong>torage 直接附加存储，无需访问网络直接连接计算机的存储。例如 SSD</p><h4 id=lvm-tags>LVM tags<a hidden class=anchor aria-hidden=true href=#lvm-tags>#</a></h4><p><strong>L</strong>ogical <strong>V</strong>olume <strong>M</strong>anager tags 逻辑卷管理器标签，LVM “卷” 和 “组” 的可扩展元数据。它们用于存储有关设备及其与 OSD 关系的 Ceph 特定信息。</p><h4 id=pgs-placement-groups>PGs (Placement Groups)<a hidden class=anchor aria-hidden=true href=#pgs-placement-groups>#</a></h4><p>“放置组” 是每个逻辑 Ceph Pool 的子集。放置组执行将对象（作为一个组）放置到 OSD 中的功能。 Ceph 在内部以“放置组粒度”来管理数据：这比管理单个RADOS 对象的扩展性将更好。<strong>具有较大数量放置组的集群比具有较少数量放置组的其他相同集群具有更好的平衡性</strong>。</p><h4 id=pools>Pools<a hidden class=anchor aria-hidden=true href=#pools>#</a></h4><p>池是用于存储对象的逻辑分区。</p><h4 id=rados>RADOS<a hidden class=anchor aria-hidden=true href=#rados>#</a></h4><p><strong>R</strong>eliable <strong>A</strong>utonomic <strong>D</strong>istributed <strong>O</strong>bject <strong>S</strong>tore 可靠的自动分布对象存储，RADOS 是为可变大小的对象提供可扩展服务的对象存储。 RADOS 对象存储是 <strong>Ceph 集群的核心组件</strong>。</p><h4 id=block-storage>Block Storage<a hidden class=anchor aria-hidden=true href=#block-storage>#</a></h4><p>块存储是 Ceph支持的三种存储类型之一。 Ceph 块存储指的是块存储 结合使用时的相关服务和功能 集合</p><h4 id=ceph-file-system>Ceph File System<a hidden class=anchor aria-hidden=true href=#ceph-file-system>#</a></h4><p>Ceph File System (CephFS) 是一个兼容 POSIX 的文件系统，构建在 RADOS 之上，可根据按需部署</p><h4 id=mds-metadata-server>MDS (Metadata Server)<a hidden class=anchor aria-hidden=true href=#mds-metadata-server>#</a></h4><p>Ceph <strong>M</strong>eta<strong>D</strong>ata <strong>S</strong>erver daemon MDS，构建在 RADOS 之上，存储所有文件的元数据作为”文件系统“类型的存储提供给用户，运行的程序名为 <code>ceph-mds</code>，故 也是是否使用 CephFS 的标记</p><h4 id=rgw-radow-gateway>RGW (Radow Gateway)<a hidden class=anchor aria-hidden=true href=#rgw-radow-gateway>#</a></h4><p>Ceph 提供兼容 Amazon S3 RESTful API 和 OpenStack Swift API 的组件，可根据按需部署</p><h4 id=realm>Realm<a hidden class=anchor aria-hidden=true href=#realm>#</a></h4><p>是位于对象存储中的上下文，领域 (Realm) 是一个全局唯一的命名空间，由一个或多个区域组组成。</p><h4 id=zone>Zone<a hidden class=anchor aria-hidden=true href=#zone>#</a></h4><p>是位于对象存储中的上下文，区域 (zone) 是由一个或多个 RGW 实例组成的逻辑组。&ldquo;zone&rdquo; 的配置状态存储在 "" 中</p><h4 id=period>Period<a hidden class=anchor aria-hidden=true href=#period>#</a></h4><p>是位于对象存储中的上下文，Period 是 Realm 的配置状态。该 Period 存储多站点配置的配置状态。当 Period 被更新时，“epoch” 被认为已经改变。</p><h4 id=cephx>CephX<a hidden class=anchor aria-hidden=true href=#cephx>#</a></h4><p>CephX Ceph authentication protocol；CephX 是用于对用户和守护进程进行身份验证。 CephX 的运行方式类似于 Kerberos，但它没有单点故障。</p><h4 id=secrets>Secrets<a hidden class=anchor aria-hidden=true href=#secrets>#</a></h4><p>Secret 是用户访问是需要提供的身份验证的系统用于执行数字身份验证的凭据。</p><h2 id=ceph存储集群组成>Ceph存储集群组成<a hidden class=anchor aria-hidden=true href=#ceph存储集群组成>#</a></h2><p>Ceph 存储集群由多种类型的守护进程组成：</p><ul><li>Ceph Monitor</li><li>Ceph OSD Daemon</li><li>Ceph Manager</li><li>Ceph Metadata Server</li></ul><h3 id=osd-object-storage-device>OSD (Object Storage Device)<a hidden class=anchor aria-hidden=true href=#osd-object-storage-device>#</a></h3><p>对象存储设备 OSD (Object Storage Device) 通常是指==单独的磁盘设备==，每个 Ceph Node 上有一个或多个o OSD，每一个 OSD 是真正存放数据的地方（在文件系统中同样概念为文件与目录）；OSD不是主机。由多个 Ceph Node 组合起来称为 RADOS Cluster</p><p>为了使每个 OSD 能够被单独使用和管理，每个 OSD 都会有一个单独的专用的守护进程被称为 <code>ceph-osd</code>。OSD 本身用来存储数据，还包括数据复制、恢复、数据重新均衡、提供监视信息给mon和mgr</p><p>一个集群至少有 3个 Ceph OSDs，已确保高可用。选择 OSD 冗余时，应自己指定故障率，故障转移率或故障容忍率。OSD级别故障就在OSD级别冗余，主机级别就跨主机冗余，故障率是机架级别就机架冗余。 在做crush运行图的设定时是应该自己指定的。</p><h3 id=mgr-manager-1>(MGR Manager)<a hidden class=anchor aria-hidden=true href=#mgr-manager-1>#</a></h3><p>Mgr (Manager) 集群元数据服务器，维护集群映射的主副本。Ceph 监视器集群可确保监视器守护进程发生故障时的高可用性。存储集群客户端从 Ceph Monitor 检索集群映射的副本。</p><p>monitor在每一次读数据都是实时查询的，故monitor不适用频繁周期性采集数据的监控操作。在Ceph新版中引入新组建mgr，（早期Ceph版本是没有mgr的）用来专门维护查询类操作，将查询操作按照自己内部空闲方式缓存下来，一旦有监控可及时响应。</p><p>mgr是在一类节点上运行的守护进程，一般为两个活以上节点，此类守护进程被称为<code>ceph-mgr</code>。主要功能在于跟踪运行时的指标数据。如磁盘使用率、CPU使用率。以及集群当前状态，此状态不是内部运行状态，而是查询做监控时的状态。包括存储空间利用率、当前性能指标、节点负载（系统级）等</p><h3 id=mon-monitor-1>MON (Monitor)<a hidden class=anchor aria-hidden=true href=#mon-monitor-1>#</a></h3><p>一个 Ceph 集群内除了存储节点之外，还有另外一种节点 Monitor ，用来管理整个集群的，如有多少个节点，每个节点上有多少个OSD，每个OSD是否健康，他会持有整个集群的运行图（运行状态）。mon是用来集中维护集群元数据而非文件元数据。为了维护整个集群能够正常运行而设定的节点，离开此节点集群内部就无法协调。</p><p>在一个主机上运行的守护进程 <code>ceph-mon</code>，守护进程扮演、监视着整个集群所有组件的角色，被称为集群运行图的持有者cluster map（整个集群有多少存储池，每个池中有多少PG，每个PG映射哪个OSD，有多少OSD等等）集群运行图 <code>Cluster Map</code></p><p>monitor负责维护整个进群的认证信息并实行认证，认证协议叫 ==CephX== 协议（ceph内部的认证协议）。monitor用来维护认证信息并实行认证。<code>认证中心</code> monitor自身是无状态的，所以实现均衡认证负载。</p><p>monitor的高可用自己内部直接使用POSIX协议来实现数据冗余，monitor也是节点级冗余，为了确保各节点数据是强一致的，每个节点都可写，写完后会同步到其他节点。为了避免同时写导致的冲突，使用了分布式一致性协议，monitor就是使用POSIX协议来进行分布式协作的。</p><h3 id=mds-metadata-server-1>MDS (Metadata Server)<a hidden class=anchor aria-hidden=true href=#mds-metadata-server-1>#</a></h3><p>==Ceph Metadata Server== 用来代表ceph文件系统而提供的守护进程<code>ceph-mds</code>，如不使用CephFS，此进程是无需启动的。利用底层RADOS存储空间，将存储空间抽象成文件系统，来兼容POSIX file system 提供服务。</p><blockquote><p>Note: 一个基础的 Ceph 存储集群由，OSD, Monitor, Manager 组成</p></blockquote><h2 id=ceph集群中其他概念>Ceph集群中其他概念<a hidden class=anchor aria-hidden=true href=#ceph集群中其他概念>#</a></h2><h3 id=客户端接口>客户端接口<a hidden class=anchor aria-hidden=true href=#客户端接口>#</a></h3><ul><li><strong>Ceph</strong> 存储集群提供了基础的对象数据存储服务，客户端可基于RADOS协议和 librados API 直接与存储系统交互进行对象数据存取</li><li><strong>Librados</strong><ul><li>Librados提供了访问 RADOS 在存储集群支持 “异步” 通信的 API 接口，支持对集群中对象数据的的直接并行访问，用户可通过支持的编程语言开发自定义客户端程序通过RADOS协议与存储系统进行交互</li><li>客户端应用程序必须与librados绑定方可连接到RADOS存储集群，因此，用户必须实现安装librados及其依赖后才能编写使用librados的应用程序。</li><li>librados API本身使用 C++ 编写的，它额外支持C、Python、Java、和PHP等开发接口</li></ul></li><li>当然，并非所有用户都有能力自定义开发接口以接入RADOS存储集群的需要，为此，Ceph也原生提供了几个较高级别的各户端接口，它们分别是 <em><strong>RADOS GateWay</strong></em> (RGW), <em><strong>Reliable Block Device</strong></em> (RBD) 和 <em><strong>MDS</strong></em> (MetaData Server)，分别为用户提供 RESTFUL、块和 POSIX 文件系统接口</li></ul><h3 id=管理节点-admin-host>管理节点 (Admin Host)<a hidden class=anchor aria-hidden=true href=#管理节点-admin-host>#</a></h3><p>Ceph通常是分布式集群，为了便于去管理维护整个集群，通常在Ceph集群中找一个专门的节点用来当管理节点。此节点可以连接至每一个节点用来管理节点上的Ceph守护进程。</p><p>Ceph的管理接口是一系列命令行工具，例如 <code>rados</code>, <code>ceph</code>, <code>rbd </code>等命令，管理员可以从某个特定的MON节点执行管理操作，但也有人更倾向于使用专用的管理节点。</p><blockquote><p>Note: 在早期 (Ceph-deploy) 部署的集群，通常管理节点是必要的，但使用 cephadm 部署的集群，实际上管理管理节点可以在任何位置</p></blockquote><h3 id=pool>Pool<a hidden class=anchor aria-hidden=true href=#pool>#</a></h3><p>Ceph所提供的存储空间（没有目录之类一说）是将“所有对象都是存储在数据平面上”，因此，所有对象都不能同名。RADOS 将他的存储空间切分为多个分区以便好进行管理。每一个分区叫做一个“<strong>存储池</strong>”。存储池的大小是取决于底层的存储空间的。与真正意义上的分区不是一回事。在Ceph中每一个存储池存放的数据了也可能会太大，所以存储池也可以进一步划分（可选）。被称为名称空间（先切分为存储池，每个存储池可进一步被划分成名称空间） 两级逻辑组件。</p><h3 id=第三级-pg>第三级 PG<a hidden class=anchor aria-hidden=true href=#第三级-pg>#</a></h3><p>每一个存储池内部会有多个PG（<strong>P</strong>lacement <strong>G</strong>roups 规置组）存在。Pool 与 pg 都是抽象的概念。</p><h3 id=object>Object<a hidden class=anchor aria-hidden=true href=#object>#</a></h3><p>对象是自带元数据的组件，</p><ul><li>对象id，每一个对象应有一个对象ID在集群内部来引用对象</li><li>数据</li><li>元数据 key vlaue类型的数据</li></ul><p>这些类型打包成一起存储，被称为一个对象。RADOS集群会吧真正存储的每一个文件，切分成N个对象来进行存储的。（切分个数与默认对象切分大小有关）。</p><p>每一个对象都是被单独管理的，都拥有自己的标识符。因此， 同一个文件的object有可能被映射到不同的PG上，PG提交给主机的，由主机负责将对象存储在磁盘（OSD）被存储在不同的OSD上。</p><h3 id=文件存储到rados集群>文件存储到RADOS集群<a hidden class=anchor aria-hidden=true href=#文件存储到rados集群>#</a></h3><p>一般要接入RADOS集群必须通过客户端来实现(LIBRADOS、RBD、CephFS、RADOSGW)，才能接入到集群中来。</p><p>当将文件存入Ceph中时，需要通过某一类客户端接入，客户端接入时，需要借助于 Ceph 存储API接口将其切分为固定大小的存储对象(Date object)，此数据对象究竟被放置在哪个 OSD 上存放这中间是靠 crush 来完成的。数据对象被存放在哪个存储池上是固定的。存储池需创建才可使用。但PG是虚拟的中间层。</p></div><div class=pe-copyright><hr><blockquote><p>本文为原创内容，版权归作者所有。如需转载，请在文章中声明本文标题及链接。</p><p>文章标题：Ceph概念 - 初识Ceph</p><p>文章链接：<a href=http://localhost:1313/2019/06/01-1-ceph-acquaintance/ target=_blank>http://localhost:1313/2019/06/01-1-ceph-acquaintance/</a></p><p>许可协议：<a href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></p></blockquote></div><div class=comments-separator></div><h3 class=relatedContentTitle>相关阅读</h3><ul class=relatedContent><li><a href=/2019/06/07-1-cephx/><span>Ceph安全 - CephX</span></a></li><li><a href=/2019/06/08-1-ceph-crush/><span>Ceph算法 - crush</span></a></li><li><a href=/2019/06/01-2-cloud-base/><span>Cloud基础设施 - 初识Ceph</span></a></li><li><a href=/2016/09/vsftp-network-filesystem/><span>网络共享 - centos7安装vsftpd</span></a></li><li><a href=/2016/09/samba-network-filesystem/><span>网络共享 - centos7安装samba</span></a></li></ul><div class=comments-separator></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/storage/>Storage</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/2019/06/07-1-cephx/><span class=title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left" style="user-select:text"><line x1="19" y1="12" x2="5" y2="12" style="user-select:text"/><polyline points="12 19 5 12 12 5" style="user-select:text"/></polyline></svg>&nbsp;</span>
<span>Ceph安全 - CephX</span>
</a><a class=next href=http://localhost:1313/2019/06/08-1-ceph-crush/><span class=title></span>
<span>Ceph算法 - crush&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right" style="user-select:text"><line x1="5" y1="12" x2="19" y2="12" style="user-select:text"/><polyline points="12 5 19 12 12 19" style="user-select:text"/></svg></span></a></nav></footer><div class=pe-comments-decoration><p class=pe-comments-title></p><p class=pe-comments-subtitle></p></div><div id=pe-comments></div><script src=/js/pe-go-comment.min.86a214102576ba5f9b7bdc29eed8d58dd56e34aef80b3c65c73ea9cc88443696.js integrity="sha256-hqIUECV2ul+be9wp7tjVjdVuNK74Czxlxz6pzIhENpY="></script><script>const getStoredTheme=()=>localStorage.getItem("pref-theme")==="dark"?"dark":"light",setGiscusTheme=()=>{const e=e=>{const t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:e},"https://giscus.app")};e({setConfig:{theme:getStoredTheme()}})};document.addEventListener("DOMContentLoaded",()=>{const s={src:"https://giscus.app/client.js","data-repo":"cylonchau/cylonchau.github.io","data-repo-id":"R_kgDOIRlNSQ","data-category":"Announcements","data-category-id":"DIC_kwDOIRlNSc4CXy1U","data-mapping":"pathname","data-term":"posts/01-1-ceph-acquaintance","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"top","data-theme":getStoredTheme(),"data-lang":"zh-TW","data-loading":"lazy",crossorigin:"anonymous",async:""},e=document.createElement("script");Object.entries(s).forEach(([t,n])=>e.setAttribute(t,n)),document.querySelector("#pe-comments").appendChild(e);const t=document.querySelector("#theme-toggle");t&&t.addEventListener("click",setGiscusTheme);const n=document.querySelector("#theme-toggle-float");n&&n.addEventListener("click",setGiscusTheme)})</script></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Cylon's Collection</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> on
<a href=https://pages.github.com/ rel=noopener target=_blank>GitHub Pages</a> & Theme
        <a href=https://github.com/tofuwine/PaperMod-PE rel=noopener target=_blank>PaperMod-PE</a></span></footer><div class=pe-right-sidebar><a href=javascript:void(0); id=theme-toggle-float class=pe-float-btn><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</a><a href=#top class=pe-float-btn id=top-link><span id=pe-read-progress></span></a></div><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>