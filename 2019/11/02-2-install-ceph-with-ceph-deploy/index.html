<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Ceph集群安装 - ceph-deploy | Cylon's Collection</title><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NP3JNCPR" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><meta name=keywords content="Install Ceph with ceph-deploy on Centos7,在Centos7上使用ceph-deploy安装ceph集群,ceph-deploy,ceph install"><meta name=description content="环境配置 Ceph 是一个开源去中心化存储平台，专为满足现代存储需求而设计。 Ceph可扩展至 EB 级，并且设计为无单点故障，使其成为需要高度可用的灵活存储的应用程序的理想选择。
下图显示了具有 Ceph 存储的示例 3 节点集群的布局。 两个网络接口可用于增加带宽和冗余，这有助于保持足够的带宽来满足存储要求，而不影响客户端应用程序。
图：Ceph存储集群 Source：https://www.jamescoyle.net/how-to/1244-create-a-3-node-ceph-storage-cluster
图中架构表示了一个无单点故障的 3 节点 Ceph 集群，以提供高度冗余的存储。 每个节点都配置了两个磁盘； 一台运行 Linux 操作系统，另一台将用于 Ceph 存储。 下面的输出显示了可用的存储空间，每个主机上的存储空间完全相同。 /dev/sda 是包含操作系统安装的根分区， /dev/sdb 是一个未触及的分区，将用于部署 Ceph 集群，对应的硬件信息如下表所示。
主机名 public IP cluster IP 数据盘 ceph-nautilus01 10.0.0.50 10.0.0.50 /dev/sda
/dev/sdb ceph-nautilus02 10.0.0.51 10.0.0.51 /dev/sda/dev/sdb ceph-nautilus03 10.0.0.52 10.0.0.52 /dev/sda/dev/sdb ceph-control 10.0.0.49 10.0.0.49 /dev/sda 部署工具 ceph-deploy 工具是在 “管理节点” (ceph-admin) 上的目录中运行。
ceph-deploy 部署ceph的原生工具 (最后支持版本 octopus 15) 借助于ssh来管理目标主机，sudo,和一些 python 模块来完成 ceph 集群的部署和后期维护。 一般讲 ceph-deploy 放置在专用节点，作为 ceph 集群的管理节点。 ceph-deploy 不是一个通用的部署工具，只是用于管理Ceph集群的，专门为用户快速部署并运行一个Ceph集群，这些功能和特性不依赖于其他的编排工具。 它无法处理客户端的配置，因此在部署客户端时就无法使用此工具。 下图是来自 ceph 官网的 ceph-deploy 部署工具的一个模型图"><meta name=author content="cylon"><link rel=canonical href=https://www.oomkill.com/2019/11/02-2-install-ceph-with-ceph-deploy/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://www.oomkill.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://www.oomkill.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://www.oomkill.com/favicon-32x32.png><link rel=apple-touch-icon href=https://www.oomkill.com/favicon.ico><link rel=mask-icon href=https://www.oomkill.com/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://www.oomkill.com/2019/11/02-2-install-ceph-with-ceph-deploy/><noscript><style>#theme-toggle,#top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link crossorigin=anonymous href=/assets/css/pe.min.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/pe.min.js></script><link rel=stylesheet href=https://cdn.staticfile.net/font-awesome/6.5.1/css/all.min.css><link rel=stylesheet href=https://cdn.staticfile.net/font-awesome/6.5.1/css/v4-shims.min.css><script defer src=https://cdn.staticfile.net/jquery/3.5.1/jquery.min.js></script><link rel=stylesheet href=https://cdn.staticfile.net/fancybox/3.5.7/jquery.fancybox.min.css><script defer src=https://cdn.staticfile.net/fancybox/3.5.7/jquery.fancybox.min.js></script><script id=MathJax-script async src=https://cdn.staticfile.net/mathjax/3.2.2/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["$$","$$"]],inlineMath:[["\\$","\\$"]]}}</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-H94HZ5S19Y"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-H94HZ5S19Y")</script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"><meta property="og:title" content="Ceph集群安装 - ceph-deploy"><meta property="og:description" content="环境配置 Ceph 是一个开源去中心化存储平台，专为满足现代存储需求而设计。 Ceph可扩展至 EB 级，并且设计为无单点故障，使其成为需要高度可用的灵活存储的应用程序的理想选择。
下图显示了具有 Ceph 存储的示例 3 节点集群的布局。 两个网络接口可用于增加带宽和冗余，这有助于保持足够的带宽来满足存储要求，而不影响客户端应用程序。
图：Ceph存储集群 Source：https://www.jamescoyle.net/how-to/1244-create-a-3-node-ceph-storage-cluster
图中架构表示了一个无单点故障的 3 节点 Ceph 集群，以提供高度冗余的存储。 每个节点都配置了两个磁盘； 一台运行 Linux 操作系统，另一台将用于 Ceph 存储。 下面的输出显示了可用的存储空间，每个主机上的存储空间完全相同。 /dev/sda 是包含操作系统安装的根分区， /dev/sdb 是一个未触及的分区，将用于部署 Ceph 集群，对应的硬件信息如下表所示。
主机名 public IP cluster IP 数据盘 ceph-nautilus01 10.0.0.50 10.0.0.50 /dev/sda
/dev/sdb ceph-nautilus02 10.0.0.51 10.0.0.51 /dev/sda/dev/sdb ceph-nautilus03 10.0.0.52 10.0.0.52 /dev/sda/dev/sdb ceph-control 10.0.0.49 10.0.0.49 /dev/sda 部署工具 ceph-deploy 工具是在 “管理节点” (ceph-admin) 上的目录中运行。
ceph-deploy 部署ceph的原生工具 (最后支持版本 octopus 15) 借助于ssh来管理目标主机，sudo,和一些 python 模块来完成 ceph 集群的部署和后期维护。 一般讲 ceph-deploy 放置在专用节点，作为 ceph 集群的管理节点。 ceph-deploy 不是一个通用的部署工具，只是用于管理Ceph集群的，专门为用户快速部署并运行一个Ceph集群，这些功能和特性不依赖于其他的编排工具。 它无法处理客户端的配置，因此在部署客户端时就无法使用此工具。 下图是来自 ceph 官网的 ceph-deploy 部署工具的一个模型图"><meta property="og:type" content="article"><meta property="og:url" content="https://www.oomkill.com/2019/11/02-2-install-ceph-with-ceph-deploy/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-11-18T00:00:00+00:00"><meta property="article:modified_time" content="2023-09-10T23:10:36+08:00"><meta property="og:site_name" content="Cylon's Collection"><meta name=twitter:card content="summary"><meta name=twitter:title content="Ceph集群安装 - ceph-deploy"><meta name=twitter:description content="环境配置 Ceph 是一个开源去中心化存储平台，专为满足现代存储需求而设计。 Ceph可扩展至 EB 级，并且设计为无单点故障，使其成为需要高度可用的灵活存储的应用程序的理想选择。
下图显示了具有 Ceph 存储的示例 3 节点集群的布局。 两个网络接口可用于增加带宽和冗余，这有助于保持足够的带宽来满足存储要求，而不影响客户端应用程序。
图：Ceph存储集群 Source：https://www.jamescoyle.net/how-to/1244-create-a-3-node-ceph-storage-cluster
图中架构表示了一个无单点故障的 3 节点 Ceph 集群，以提供高度冗余的存储。 每个节点都配置了两个磁盘； 一台运行 Linux 操作系统，另一台将用于 Ceph 存储。 下面的输出显示了可用的存储空间，每个主机上的存储空间完全相同。 /dev/sda 是包含操作系统安装的根分区， /dev/sdb 是一个未触及的分区，将用于部署 Ceph 集群，对应的硬件信息如下表所示。
主机名 public IP cluster IP 数据盘 ceph-nautilus01 10.0.0.50 10.0.0.50 /dev/sda
/dev/sdb ceph-nautilus02 10.0.0.51 10.0.0.51 /dev/sda/dev/sdb ceph-nautilus03 10.0.0.52 10.0.0.52 /dev/sda/dev/sdb ceph-control 10.0.0.49 10.0.0.49 /dev/sda 部署工具 ceph-deploy 工具是在 “管理节点” (ceph-admin) 上的目录中运行。
ceph-deploy 部署ceph的原生工具 (最后支持版本 octopus 15) 借助于ssh来管理目标主机，sudo,和一些 python 模块来完成 ceph 集群的部署和后期维护。 一般讲 ceph-deploy 放置在专用节点，作为 ceph 集群的管理节点。 ceph-deploy 不是一个通用的部署工具，只是用于管理Ceph集群的，专门为用户快速部署并运行一个Ceph集群，这些功能和特性不依赖于其他的编排工具。 它无法处理客户端的配置，因此在部署客户端时就无法使用此工具。 下图是来自 ceph 官网的 ceph-deploy 部署工具的一个模型图"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://www.oomkill.com/posts/"},{"@type":"ListItem","position":2,"name":"Ceph集群安装 - ceph-deploy","item":"https://www.oomkill.com/2019/11/02-2-install-ceph-with-ceph-deploy/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Ceph集群安装 - ceph-deploy","name":"Ceph集群安装 - ceph-deploy","description":"环境配置 Ceph 是一个开源去中心化存储平台，专为满足现代存储需求而设计。 Ceph可扩展至 EB 级，并且设计为无单点故障，使其成为需要高度可用的灵活存储的应用程序的理想选择。\n下图显示了具有 Ceph 存储的示例 3 节点集群的布局。 两个网络接口可用于增加带宽和冗余，这有助于保持足够的带宽来满足存储要求，而不影响客户端应用程序。\n图：Ceph存储集群 Source：https://www.jamescoyle.net/how-to/1244-create-a-3-node-ceph-storage-cluster\n图中架构表示了一个无单点故障的 3 节点 Ceph 集群，以提供高度冗余的存储。 每个节点都配置了两个磁盘； 一台运行 Linux 操作系统，另一台将用于 Ceph 存储。 下面的输出显示了可用的存储空间，每个主机上的存储空间完全相同。 /dev/sda 是包含操作系统安装的根分区， /dev/sdb 是一个未触及的分区，将用于部署 Ceph 集群，对应的硬件信息如下表所示。\n主机名 public IP cluster IP 数据盘 ceph-nautilus01 10.0.0.50 10.0.0.50 /dev/sda\n/dev/sdb ceph-nautilus02 10.0.0.51 10.0.0.51 /dev/sda/dev/sdb ceph-nautilus03 10.0.0.52 10.0.0.52 /dev/sda/dev/sdb ceph-control 10.0.0.49 10.0.0.49 /dev/sda 部署工具 ceph-deploy 工具是在 “管理节点” (ceph-admin) 上的目录中运行。\nceph-deploy 部署ceph的原生工具 (最后支持版本 octopus 15) 借助于ssh来管理目标主机，sudo,和一些 python 模块来完成 ceph 集群的部署和后期维护。 一般讲 ceph-deploy 放置在专用节点，作为 ceph 集群的管理节点。 ceph-deploy 不是一个通用的部署工具，只是用于管理Ceph集群的，专门为用户快速部署并运行一个Ceph集群，这些功能和特性不依赖于其他的编排工具。 它无法处理客户端的配置，因此在部署客户端时就无法使用此工具。 下图是来自 ceph 官网的 ceph-deploy 部署工具的一个模型图","keywords":["Install Ceph with ceph-deploy on Centos7","在Centos7上使用ceph-deploy安装ceph集群","ceph-deploy","ceph install"],"articleBody":"环境配置 Ceph 是一个开源去中心化存储平台，专为满足现代存储需求而设计。 Ceph可扩展至 EB 级，并且设计为无单点故障，使其成为需要高度可用的灵活存储的应用程序的理想选择。\n下图显示了具有 Ceph 存储的示例 3 节点集群的布局。 两个网络接口可用于增加带宽和冗余，这有助于保持足够的带宽来满足存储要求，而不影响客户端应用程序。\n图：Ceph存储集群 Source：https://www.jamescoyle.net/how-to/1244-create-a-3-node-ceph-storage-cluster\n图中架构表示了一个无单点故障的 3 节点 Ceph 集群，以提供高度冗余的存储。 每个节点都配置了两个磁盘； 一台运行 Linux 操作系统，另一台将用于 Ceph 存储。 下面的输出显示了可用的存储空间，每个主机上的存储空间完全相同。 /dev/sda 是包含操作系统安装的根分区， /dev/sdb 是一个未触及的分区，将用于部署 Ceph 集群，对应的硬件信息如下表所示。\n主机名 public IP cluster IP 数据盘 ceph-nautilus01 10.0.0.50 10.0.0.50 /dev/sda\n/dev/sdb ceph-nautilus02 10.0.0.51 10.0.0.51 /dev/sda/dev/sdb ceph-nautilus03 10.0.0.52 10.0.0.52 /dev/sda/dev/sdb ceph-control 10.0.0.49 10.0.0.49 /dev/sda 部署工具 ceph-deploy 工具是在 “管理节点” (ceph-admin) 上的目录中运行。\nceph-deploy 部署ceph的原生工具 (最后支持版本 octopus 15) 借助于ssh来管理目标主机，sudo,和一些 python 模块来完成 ceph 集群的部署和后期维护。 一般讲 ceph-deploy 放置在专用节点，作为 ceph 集群的管理节点。 ceph-deploy 不是一个通用的部署工具，只是用于管理Ceph集群的，专门为用户快速部署并运行一个Ceph集群，这些功能和特性不依赖于其他的编排工具。 它无法处理客户端的配置，因此在部署客户端时就无法使用此工具。 下图是来自 ceph 官网的 ceph-deploy 部署工具的一个模型图\n图：ceph-deploy部署模型 Source：https://docs.ceph.com/en/nautilus/start/quick-start-preflight/\nCEPH 集群拓扑及网络 在Ceph内部存在两种流量：\nCeph内部各节点之间用来处理OSD之间数据复制，因此为了避免正常向客户端提供服务请求， public network 必须，所有客户端都应位于public network cluster network 可选 ceph-deploy 先决条件配置 将 Ceph 安装仓库添加到 “管理节点”。然后，安装 ceph-deploy。\nDebian/Ubuntu 添加 release key bash 1 wget -q -O- 'https://download.ceph.com/keys/release.asc' | sudo apt-key add - 将 Ceph deb添加到您的存储库。并替换为安装的 Ceph 版本（例如 nautilus）。例如： bash 1 2 export CEPH_VERSION=nautilus echo deb https://download.ceph.com/debian-${CEPH_VERSION}/ $(lsb_release -sc) main | sudo tee /etc/apt/sources.list.d/ceph.list 更新仓库并安装 ceph-deploy bash 1 2 sudo apt update sudo apt install ceph-deploy RHEL/CentOS 安装 epel 源，这里方式很多可以任意选择 “你所在地区可用的 epel 源” bash 1 sudo yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm 添加 Ceph rpm 仓库 bash 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 export CEPH_VERSION=nautilus cat \u003c\u003c EOF \u003e /etc/yum.repos.d/ceph.repo [ceph] name=Ceph packages for $basearch baseurl=https://download.ceph.com/rpm-${CEPH_VERSION}/el7/\\$basearch enabled=1 priority=2 gpgcheck=1 gpgkey=https://download.ceph.com/keys/release.asc [ceph-noarch] name=Ceph noarch packages baseurl=https://download.ceph.com/rpm-${CEPH_VERSION}/el7/noarch enabled=1 priority=2 gpgcheck=1 gpgkey=https://download.ceph.com/keys/release.asc [ceph-source] name=Ceph source packages baseurl=https://download.ceph.com/rpm-${CEPH_VERSION}/el7/SRPMS enabled=0 priority=2 gpgcheck=1 gpgkey=https://download.ceph.com/keys/release.asc EOF 更新缓存并安装 ceph-deploy bash 1 2 sudo yum clean all \u0026\u0026 sudo yum makecache sudo yum install ceph-deploy 安装集群的预先条件 - CEPH NODE 管理节点必须拥有所有 ceph node 的无密码登录权限 ntp 开放端口 关闭 selinux 创建用于 ceph-deploy 的用户 ceph-deploy 实用程序必须以具有无密码 sudo 权限的用户身份登录 Ceph node，因为它需要在不提示输入密码的情况下安装软件和配置文件。\n最新版本的 ceph-deploy 支持 –username 选项，因此您可以指定任何具有无密码的 sudo 用户（包括 root，但不推荐）。要使用 ceph-deploy –username {username}，“所指定的用户必须具有对 Ceph Node 的无密码 SSH 访问权限”，因为 ceph-deploy 不会提示您输入密码。\nCeph 官方建议在集群中的所有 Ceph 节点上为 ceph-deploy 创建特定用户。==请不要使用 “ceph” 作为用户名==。整个集群中的统一用户名可能会提高易用性（不是必需的），但您应该避免使用明显的用户名，因为黑客通常会通过暴力破解来使用它们（例如 root, admin, 或使用项目名称）。以下过程将 {username} 替换为您定义的用户名，描述了如何使用无密码 sudo 创建用户。\n在每个 Ceph Node 创建一个用户 bash 1 2 3 export CEPH_USERNAME=ceph sudo useradd -d /home/${CEPH_USERNAME} -m ${CEPH_USERNAME} echo 1|sudo passwd ${CEPH_USERNAME} --stdin 对于添加到每个 Ceph Node 的新用户，请确保该用户具有 sudo 权限。 bash 1 2 echo \"${CEPH_USERNAME} ALL = (root) NOPASSWD:ALL\" | sudo tee /etc/sudoers.d/${CEPH_USERNAME} sudo chmod 0440 /etc/sudoers.d/${CEPH_USERNAME} 启用 SSH 无密码登录 由于 ceph-deploy 不会提示输入密码，因此必须在管理节点上生成 SSH 密钥并将公钥分发到每个 Ceph 节点。 ceph-deploy 将尝试为初始 monitor 生成 SSH 密钥。\n生成 ssh key，不要使用 sudo 或者是 root 用户 bash 1 2 3 4 5 6 7 8 $ ssh-keygen Generating public/private key pair. Enter file in which to save the key (/ceph-admin/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /ceph-admin/.ssh/id_rsa. Your public key has been saved in /ceph-admin/.ssh/id_rsa.pub. 将 SSH 密钥复制到每个 Ceph Node，将变量 “CEPH_USERNAME” 替换为创建 Ceph 部署用户创建的用户名。 通常情况下，主机名需要解析的，如果没有需要配置在 /etc/hosts 内\nbash 1 2 3 4 5 6 7 ssh-copy-id ${CEPH_USERNAME}@ceph-nautilus01 ssh-copy-id ${CEPH_USERNAME}@ceph-nautilus02 ssh-copy-id ${CEPH_USERNAME}@ceph-nautilus03 # 如果是 root 用户执行下面命令 sudo -u ${CEPH_USERNAME} ssh-copy-id ${CEPH_USERNAME}@ceph-nautilus01 sudo -u ${CEPH_USERNAME} ssh-copy-id ${CEPH_USERNAME}@ceph-nautilus02 sudo -u ${CEPH_USERNAME} ssh-copy-id ${CEPH_USERNAME}@ceph-nautilus03 添加主机名到 /etc/hosts (可选) bash 1 2 3 4 5 $ tee \u003e\u003e /etc/hosts \u003c\u003c EOF 10.0.0.50 ceph-nautilus01 10.0.0.51 ceph-nautilus02 10.0.0.52 ceph-nautilus03 EOF 网卡开机自启动 Ceph OSD Peer 并通过网络向 Ceph monitor 报告。如果默认情况下网络处于关闭状态，则在启用网络之前，Ceph 集群无法在启动期间联机。\n在一些 Linux 发行版下（例如 CentOS）上的默认配置默认关闭网络接口。确保在启动过程中网络接口打开，以便 Ceph 守护进程可以通过网络进行通信。(如果你的系统是新装的)\n开放所需端口 Ceph Monitor (ceph-mon) 默认使用端口 6789 进行通信。默认情况下，Ceph OSD 在 6800:7300 端口范围内进行通信。详细信息请参见网络配置参考 [1]。\n确保关闭 SELinux 在 CentOS 和 RHEL 上，SELinux 默认设置为“Enforcing”。为了简化您的安装，我们建议将 SELinux 设置为 Permissive 或完全禁用，这是 Ceph 官方给出的建议\nbash 1 sudo setenforce 0 要持久配置 SELinux（如果 SELinux 存在问题，则建议这样做），请修改 /etc/selinux/config 中的配置文件。\nPreferences 确保您的 “包管理器” 已安装并启用 “priority/preferences”。在 CentOS 上，您可能需要安装 EPEL。在 RHEL 上，您可能需要启用可选存储库。\nbash 1 sudo yum install yum-plugin-priorities 例如，在 RHEL 7 服务器上，执行以下命令安装 yum-plugin-priorities 并启用 rhel-7-server-optional-rpms 存储库：\nbsah sudo yum install yum-plugin-priorities --enablerepo=rhel-7-server-optional-rpms 初始化新的 CEPH 集群 在这里我们创建一个包含一个 Ceph Monitor (ceph-mon) 和 三个 Ceph OSD (osd daemon) 的 Ceph 集群。通常使用 ceph-deploy 部署集群，最佳方式是在 “管理节点” 上创建一个目录，用于维护 ceph-deploy 为集群生成的配置文件和密钥。\nbash 1 mkdir ceph-cluster \u0026\u0026 cd ceph-cluster 需要注意的是，ceph-deploy 将文件输出到当前目录。执行 ceph-deploy 时需要确保位于此目录中。\n还需要注意的是，需要使用 “SSH 免密的那个用户”\n确保集群节点清洁性 如果在任何时候遇到问题后并想重新开始，可以执行下列命令清除所有安装包和配置：\nbash 1 2 3 4 ceph-deploy purge {ceph-node} [{ceph-node}] ceph-deploy purgedata {ceph-node} [{ceph-node}] ceph-deploy forgetkeys rm ceph.* 需要注意的是，执行 ceph-deploy，必须执行第四条命令 rm ceph.*\n创建集群 创建集群会生成配置文件保存到当前工作目录中，使用 ceph-deploy 执行命令新建一个集群。\n创建集群 bash 1 2 3 4 # 语法 ceph-deploy new {initial-monitor-node(s)} # 示例, 指定节点的 hostname, fqdn or hostname:fqdn ceph-deploy new ceph-nautilus01 ceph-nautilus02 ceph-nautilus03 ceph-deploy 会输出到当前文件夹下的文件包含，Ceph 配置文件 (ceph.conf)、ceph-mon 的 keyring 文件 (ceph.mon.keyring) 以及新集群的日志文件。\n如果主机存在多个网络接口（即公共网络和集群网络是分开的），需要在 Ceph 配置文件的 [global] 部分下添加公共网络设置。 bash 1 2 3 public network = {ip-address}/{bits} # 示例 public network = 10.1.2.0/24 或者通过命令指定两个网络的 IP\nbash 1 2 3 ceph-deploy new ceph-nautilus01 ceph-nautilus02 ceph-nautilus03 \\ --cluster-network 172.18.0.0/24 \\ --public-network 10.0.0.0/24 如果在 IPv6 环境中部署，请将以下内容添加到本地目录中的 ceph.conf 中： bash 1 echo ms bind ipv6 = true \u003e\u003e ceph.conf 现在可以安装 ceph 软件包了，执行下列命令 bash 1 2 3 ceph-deploy install {ceph-node} [...] # 示例 ceph-deploy install ceph-nautilus01 ceph-nautilus02 ceph-nautilus03 在命令执行后，ceph-deploy 将在每个节点上安装 Ceph，所以要确保对应节点需要提前安装好了 ceph yum 仓库文件\n也可以通过 --release 指定版本进行安装\nbash 1 ceph-deploy install --release=nautilus ceph-nautilus01 ceph-nautilus02 ceph-nautilus03 部署 ceph-mon 并收集密钥： bash 1 ceph-deploy mon create-initial ​\t通常完成步骤5后，本地工作目录应具有以下 keyring 文件：\nceph.client.admin.keyring ceph.bootstrap-mgr.keyring ceph.bootstrap-osd.keyring ceph.bootstrap-mds.keyring ceph.bootstrap-rgw.keyring ceph.bootstrap-rbd.keyring ceph.bootstrap-rbd-mirror.keyring 使用 ceph-deploy 将配置文件和管理密钥复制到管理节点和 Ceph Node，以便可以在这些节点上使用 ceph CLI 时而无需在每次执行命令时指定 ceph-mon 地址和 keyring文件 (ceph.client.admin.keyring)。 bash 1 2 3 ceph-deploy admin {ceph-node(s)} # 示例 ceph-deploy admin ceph-nautilus01 ceph-nautilus02 ceph-nautilus03 部署 CEPH MANAGER (ceph-mgr)，此步骤仅需要 ==luminous+== 以上版本 bash 1 2 3 ceph-deploy mgr create {ceph-node(s)} *Required only for luminous+ builds, i.e \u003e= 12.x builds* # 示例 ceph-deploy mgr create ceph-nautilus01 到步骤8时，只差 OSD 就完成了 RADOS 集群的安装，下面为集群添加 OSD bash 1 2 3 4 5 ceph-deploy osd create --data {device} {ceph-node} # 示例 ceph-deploy osd create --data /dev/sdb ceph-nautilus01 ceph-deploy osd create --data /dev/sdb ceph-nautilus02 ceph-deploy osd create --data /dev/sdb ceph-nautilus03 Note：如果要在 LVM 卷上创建 OSD，则 –data 的参数必须是 {volume_group}/{lv_name}，而不是卷的块设备的路径\n检查集群状态 bash 1 2 3 ssh node1 sudo ceph health # or ceph -s Troubleshooting No module named pkg_resources bash 1 2 3 4 5 6 7 $ ceph-deploy new ceph-nautilus01 ceph-nautilus02 ceph-nautilus03 Traceback (most recent call last): File \"/usr/bin/ceph-deploy\", line 18, in from ceph_deploy.cli import main File \"/usr/lib/python2.7/site-packages/ceph_deploy/cli.py\", line 1, in import pkg_resources ImportError: No module named pkg_resources 解决：This issue can be solved by installing yum install -y python-setuptools.\nRuntimeError: NoSectionError: No section: ‘ceph’ bash 1 2 3 4 5 6 7 8 9 10 [2019-09-11 05:31:42,640][ceph-nautilus01][DEBUG ] Installing : ceph-release-1-1.el7.noarch 1/1 [2019-09-11 05:31:42,640][ceph-nautilus01][DEBUG ] warning: /etc/yum.repos.d/ceph.repo created as /etc/yum.repos.d/ceph.repo.rpmnew [2019-09-11 05:31:42,759][ceph-nautilus01][DEBUG ] Verifying : ceph-release-1-1.el7.noarch 1/1 [2019-09-11 05:31:42,759][ceph-nautilus01][DEBUG ] [2019-09-11 05:31:42,759][ceph-nautilus01][DEBUG ] Installed: [2019-09-11 05:31:42,759][ceph-nautilus01][DEBUG ] ceph-release.noarch 0:1-1.el7 [2019-09-11 05:31:42,759][ceph-nautilus01][DEBUG ] [2019-09-11 05:31:42,759][ceph-nautilus01][DEBUG ] Complete! [2019-09-11 05:31:42,759][ceph-nautilus01][WARNING] ensuring that /etc/yum.repos.d/ceph.repo contains a high priority [2019-09-11 05:31:42,767][ceph_deploy][ERROR ] RuntimeError: NoSectionError: No section: 'ceph' 解决：CEPH Node 上不要安装 yum 仓库，ceph-deploy 会自动安装，如果存在新的文件会被命名为 ceph.repo.rpmnew\n向 RADOS 集群添加 OSD 列出并擦净磁盘 ceph-deploy disk 命令可以检查并列出OSD节点上所有可用的磁盘相关的信息。\nsh 1 ceph-deploy disk list stor01 stor02 stor03 stor04 如果遇到 Running command: sudo fdisk -l 无输出，原因为系统问中文，修改 en_us.utf8 后可正常显示。\nbash 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 $ ceph-deploy disk list stor01 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephadmin/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (2.0.1): /bin/ceph-deploy disk list stor01 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] debug : False [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] subcommand : list [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] host : ['stor01'] [ceph_deploy.cli][INFO ] func : \u003cfunction disk at 0x7fab6144e9b0\u003e [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [stor01][DEBUG ] connection detected need for sudo [stor01][DEBUG ] connected to host: stor01 [stor01][DEBUG ] detect platform information from remote host [stor01][DEBUG ] detect machine type [stor01][DEBUG ] find the location of an executable [stor01][INFO ] Running command: sudo fdisk -l 而后，在管理节点上使用 ceph-deploy 命令 擦除计划专用于OSD磁盘上的所有分区表和数据以便用于OSD，命令格式为ceph-deploy disk zab {osd-server-name} {disk-name}，需要注意的是此步会清除目标设备上的所有数据。\n擦除一个磁盘\nsh 1 2 ceph-deploy disk zap ceph-deploy disk zap {ceph_node} /dev/sdb Note：如果是未格式化的块设备不需要额外擦除，ceph 集群要求 ceph 管理的块设备必须是未格式化的，如果格式化过的需要擦除\nceph-deploy osd –help：\nblock-db 可以理解为RocksDB数据库，元数据存放的位置 block-wal 数据库的数据日志存放的位置 filestore 如果使用filestore,明确指定选项--filestore 指明数据放哪，并指明日志放哪（日志指的是文件系统日志）ceph-deploy osd create {node} --filestore --data /path/to/data --journal /path/to/journal bluestore自身没有文件系统，故无需日志，数据库需要日志 扩展集群 添加 OSD 当一个 “基本集群” 部署好并运行，下一步就是扩展集群。通常会扩展集群，扩展集群存在两种类型，集群组件与OSD，这里主要围绕 扩展 OSD\n早期版本的ceph-deploy命令支持在将添加OSD的过程分为两个步骤：准备OSD，激活OSD，但新版本中，此种操作方式已被废除，添加OSD的步骤只能由命令 ceph-deploy osd create create {node} –data {data-disk} ，一次完成，默认存储引擎为 bluestore\nsh 1 2 ceph-deploy osd create {node} --data /dev/sdb ceph-deploy osd create {node} --data /dev/sdc 而后可使用 ceph-deploy osd list {node} 命令列出指定节点上的OSD：\n移除 OSD 的 Ceph集群中的一个OSD通常对应一个设备，且运行于专用的守护进程。在某OSD设备出现故障，或管理员出于管理只需确实要移除特定的OSD设备时，需要先停止相关的守护进程，而后再进行移除操作。对于Luminous及其之后的版本来说，停止和移除命令的格式如下\n停止设备: ceph osd out {osd-num} 停止进程: sudo systemctl stop ceph-osd@{osd-num} 移除设备: ceph osd purge {id} –yes-i-really-mean-it 若类似如下的OSD的设备信息存在于ceph.conf配置文件中，管理员在删除OSD之后手动将其删除。\nconf [osd.1] host = {hostname} 不过，对于 Luminous 之前的版本来说，管理员需要依次手动执行如下步骤删除OSD设备\n于CRUSH运行图中移除设备: ceph osd crush remove {name} 移除OSD的认证key: ceph auth del osd.{osd-num} 移除设备: ceph osd purge {id} –yes-i-really-mean-it 扩展 ceph-mon Ceph 集群需要至少一个 Ceph Monitor 和一个 Ceph Manager，生产环境中，为了实现高可用，Ceph集群通常运行多个监视器，以免单监视器整个存储集群崩溃。Ceph使用 Paxos 算法，改算法是需要至少需要板书以上的监视器（大于n/2，其中n为总监视器数量），才能形成法定人数，尽管此非必须，奇数个 ceph-mon 往往更好。\n使用 ceph-deploy mon add {nodes} 命令可以一次添加一个 ceph-mon 到集群中。\nsh 1 2 ceph-deploy mon add nautilus02 ## 此处使用短格式名称，长格式名称会报错。 ceph-deploy mon add nautilus03 设置完成后，可以在ceph客户端上查看监视器及法定人数的相关信息:\nsh 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 $ ceph quorum_status --format json-pretty { \"election_epoch\": 20, \"quorum\": [ 0, 1, 2 ], \"quorum_names\": [ \"stor01\", \"stor02\", \"stor03\" ], \"quorum_leader_name\": \"stor01\", \"monmap\": { \"epoch\": 3, \"fsid\": \"69fb9b55-3fb5-42d0-8cf7-239a3b569791\", \"modified\": \"2019-06-06 21:19:41.274199\", \"created\": \"2019-06-05 12:35:31.143594\", \"features\": { \"persistent\": [ \"kraken\", \"luminous\", \"mimic\", \"osdmap-prune\" ], \"optional\": [] }, \"mons\": [ { \"rank\": 0, \"name\": \"stor01\", \"addr\": \"10.0.0.4:6789/0\", \"public_addr\": \"10.0.0.4:6789/0\" }, { \"rank\": 1, \"name\": \"stor02\", \"addr\": \"10.0.0.5:6789/0\", \"public_addr\": \"10.0.0.5:6789/0\" }, { \"rank\": 2, \"name\": \"stor03\", \"addr\": \"10.0.0.6:6789/0\", \"public_addr\": \"10.0.0.6:6789/0\" } ] } } 扩展 Manager 节点 Ceph Manager (ceph-mgr) 以 Active/Standy 模式运行，部署其他 ceph-mgr 守护进程可确保在 Active 节点的 ceph-mgr 守护进程故障时，其中一个 Standby 实例可以在不中断服务的情况下接管其任务。\nmgr 就是无状态的 web 服务，一般来讲两个足够了。\nsh 1 ceph-deploy mgr create {ceph_node} 启动 RGW RGW (Rados Gateway) 必要组件，仅在需要用到对象存储兼容 “S3” 和 “Swift” 的 RESTful 接口时才需要部署 RGW 实例，相关的命令为ceph-deploy rgw create (gateway-node) 。\nradosgw需要用自用的存储池不能与RBD混合使用，RGW 会在创建时自动初始化出存储池来，RGW 需要有相应服务才能运行起来。\nsh 1 ceph-deploy rgw create nautilus02 添加完成后，ceph -s 命令的 service 一段中会输出相关信息：\nsh 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 $ ceph -s cluster: id: 69fb9b55-3fb5-42d0-8cf7-239a3b569791 health: HEALTH_WARN application not enabled on 1 pool(s) services: mon: 3 daemons, quorum stor01,stor02,stor03 mgr: stor01(active), standbys: stor04 osd: 8 osds: 8 up, 8 in rgw: 1 daemon active data: pools: 7 pools, 160 pgs objects: 196 objects, 1.5 KiB usage: 21 GiB used, 79 GiB / 100 GiB avail pgs: 160 active+clean 默认情况下，RGW 实例监听于 TCP 协议的 7480 端口，需要修改，可以通过在运行 RGW 的节点上编辑其主配置文件 ceph.conf 进行修改，相关参数如下所示\nconf [client] rgw_frontends = \"civetweb port=8080\" RGW 会在 RADOWS 集群上生成包括如下存储池的一系列存储池\nsh 1 2 3 4 5 6 7 8 $ ceph osd pool ls mypool rbdpool testpool .rgw.root default.rgw.control default.rgw.meta default.rgw.log RGW 提供的是兼容 S3 和 Swift 的 REST 接口，客户端通过 HTTP 进行交互，完成数据的增删改查等管理操作。\n启用文件系统 (CephFS) 接口 CephFS 需要至少运行一个 Metadata (MDS) 守护进程 (ceph-mds)，此进程管理与 CephFS 上存储的文件相关的元数据，并协调对 Ceph存储集群的访问。因此，若要使用 CephFS ，需要在存储集群中至少部署一个 MDS 实例，增加 MDS 可以使用命令 ceph-deploy mds create {ceph-node} 完成\n还需主义的是，每个 CephFS 都至少需要两个存储池，一个用来存放元数据 (Metadata Pool)，一个存放数据 (Data Pool)。\nsh 1 $ ceph-deploy mds create stor01 查看 MDS 的相关状态可以发现，刚添加的 MDS 处于 standby 状态\n在运行起来还不够，还没为其创建存储池，故其不能正常工作，处于standby模式。\ntext 1 2 $ ceph mds stat , 1 up:standby 使用 CephFS 之前需要事先于集群中创建一个文件系统，并为其分别指定 “元数据” 和 “数据” 相关的存储池，下面创建一个名为 cephfs 的文件系统用于测试，使用cephfs-metadata为数据存储池，使用cephfs-data为数据存储池。\nsh 1 2 3 4 5 6 7 8 # 创建存储池 ceph osd pool create cephfs-metadata 64 ceph osd pool create cephfs-data 64 # 创建 cephfs ## 语法 ceph fs new {fs_name} {meatadata-pool} {data-pool} ## 示例 ceph fs new cephfs cephfs-metadata cephfs-data ceph fs add_data_pool： 额外添加数据池 ceph fs new： 创建新文件系统 ceph fs status： 查看CephFS 文件系统状态 sh 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 $ ceph fs status cephfs cephfs - 0 clients ====== +------+--------+--------+---------------+-------+-------+ | Rank | State | MDS | Activity | dns | inos | +------+--------+--------+---------------+-------+-------+ | 0 | active | stor02 | Reqs: 0 /s | 10 | 13 | +------+--------+--------+---------------+-------+-------+ +-----------------+----------+-------+-------+ | Pool | type | used | avail | +-----------------+----------+-------+-------+ | cephfs-metadata | metadata | 2286 | 21.7G | | cephfs-data | data | 0 | 21.7G | +-----------------+----------+-------+-------+ +-------------+ | Standby MDS | +-------------+ +-------------+ MDS version: ceph version 13.2.6 (7b695f835b03642f85998b2ae7b6dd093d9fbce4) mimic (stable) Reference [1] Network Configuration Reference\n[2] ceph_deploy RuntimeError: NoSectionError: No section: ‘ceph’\n","wordCount":"1922","inLanguage":"zh","datePublished":"2019-11-18T00:00:00Z","dateModified":"2023-09-10T23:10:36+08:00","author":{"@type":"Person","name":"cylon"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.oomkill.com/2019/11/02-2-install-ceph-with-ceph-deploy/"},"publisher":{"@type":"Organization","name":"Cylon's Collection","logo":{"@type":"ImageObject","url":"https://www.oomkill.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://www.oomkill.com/><img src=https://www.oomkill.com/favicon.ico alt aria-label=logo height=20>Cylon's Collection</a><div class=logo-switches><button id=theme-toggle><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://www.oomkill.com/archives><span>归档</span></a></li><li><a href=https://www.oomkill.com/tags><span>标签</span></a></li><li><a href=https://www.oomkill.com/search><span>搜索</span></a></li><li><a href=https://www.oomkill.com/about accesskey=/><span>关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Ceph集群安装 - ceph-deploy</h1><div class=post-meta><span class=pe-post-meta-item><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select:text"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select:text"/><line x1="16" y1="2" x2="16" y2="6" style="user-select:text"/><line x1="8" y1="2" x2="8" y2="6" style="user-select:text"/><line x1="3" y1="10" x2="21" y2="10" style="user-select:text"/></svg><span>2019-11-18</span></span>&nbsp;·&nbsp;<span class=pe-post-meta-item><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text" style="user-select:text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z" style="user-select:text"/><polyline points="14 2 14 8 20 8" style="user-select:text"/><line x1="16" y1="13" x2="8" y2="13" style="user-select:text"/><line x1="16" y1="17" x2="8" y2="17" style="user-select:text"/><polyline points="10 9 9 9 8 9" style="user-select:text"/></svg><span>1922 字</span></span>&nbsp;·&nbsp;<span class=pe-post-meta-item><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><span>10 分钟</span></span>
<span class=pe-post-meta-item>&nbsp;·&nbsp;<svg t="1714036239378" fill="currentcolor" class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" p-id="6659" width="256" height="256"><path d="M690 78.2c-18.6-18.8-49-19-67.8-.4s-19 49-.4 67.8l255.4 258.6c67.8 68.6 67.8 178.8.0 247.4L653.4 878.2c-18.6 18.8-18.4 49.2.4 67.8s49.2 18.4 67.8-.4l224-226.4c104.8-106 104.8-276.4.0-382.4L690 78.2zM485.4 101.4c-24-24-56.6-37.4-90.6-37.4H96C43 64 0 107 0 160v299c0 34 13.4 66.6 37.4 90.6l336 336c50 50 131 50 181 0l267-267c50-50 50-131 0-181l-336-336zM96 160h299c8.4.0 16.6 3.4 22.6 9.4l336 336c12.4 12.4 12.4 32.8.0 45.2l-267 267c-12.4 12.4-32.8 12.4-45.2.0l-336-336c-6-6-9.4-14.2-9.4-22.6V160zm192 128a64 64 0 10-128 0 64 64 0 10128 0z" p-id="6660"/></svg></span><ul class=pe-post-meta-item><a href=https://www.oomkill.com/tags/storage/>#Storage</a></ul></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details><summary><span class=details>目录</span></summary><div class=inner><ul><li><a href=#%e7%8e%af%e5%a2%83%e9%85%8d%e7%bd%ae aria-label=环境配置>环境配置</a><ul><li><a href=#%e9%83%a8%e7%bd%b2%e5%b7%a5%e5%85%b7 aria-label=部署工具>部署工具</a><li><a href=#ceph-%e9%9b%86%e7%be%a4%e6%8b%93%e6%89%91%e5%8f%8a%e7%bd%91%e7%bb%9c aria-label="CEPH 集群拓扑及网络">CEPH 集群拓扑及网络</a></ul><li><a href=#ceph-deploy-%e5%85%88%e5%86%b3%e6%9d%a1%e4%bb%b6%e9%85%8d%e7%bd%ae aria-label="ceph-deploy 先决条件配置">ceph-deploy 先决条件配置</a><ul><li><a href=#debianubuntu aria-label=Debian/Ubuntu>Debian/Ubuntu</a><li><a href=#rhelcentos aria-label=RHEL/CentOS>RHEL/CentOS</a></ul><li><a href=#%e5%ae%89%e8%a3%85%e9%9b%86%e7%be%a4%e7%9a%84%e9%a2%84%e5%85%88%e6%9d%a1%e4%bb%b6---ceph-node aria-label="安装集群的预先条件 - CEPH NODE">安装集群的预先条件 - CEPH NODE</a><ul><li><a href=#%e5%88%9b%e5%bb%ba%e7%94%a8%e4%ba%8e-ceph-deploy-%e7%9a%84%e7%94%a8%e6%88%b7 aria-label="创建用于 ceph-deploy 的用户">创建用于 <em>ceph-deploy</em> 的用户</a><li><a href=#%e5%90%af%e7%94%a8-ssh-%e6%97%a0%e5%af%86%e7%a0%81%e7%99%bb%e5%bd%95 aria-label="启用 SSH 无密码登录">启用 SSH 无密码登录</a><li><a href=#%e7%bd%91%e5%8d%a1%e5%bc%80%e6%9c%ba%e8%87%aa%e5%90%af%e5%8a%a8 aria-label=网卡开机自启动>网卡开机自启动</a><li><a href=#%e5%bc%80%e6%94%be%e6%89%80%e9%9c%80%e7%ab%af%e5%8f%a3 aria-label=开放所需端口>开放所需端口</a><li><a href=#%e7%a1%ae%e4%bf%9d%e5%85%b3%e9%97%ad-selinux aria-label="确保关闭 SELinux">确保关闭 SELinux</a><li><a href=#preferences aria-label=Preferences>Preferences</a></ul><li><a href=#%e5%88%9d%e5%a7%8b%e5%8c%96%e6%96%b0%e7%9a%84-ceph-%e9%9b%86%e7%be%a4 aria-label="初始化新的 CEPH 集群">初始化新的 CEPH 集群</a><ul><li><a href=#%e7%a1%ae%e4%bf%9d%e9%9b%86%e7%be%a4%e8%8a%82%e7%82%b9%e6%b8%85%e6%b4%81%e6%80%a7 aria-label=确保集群节点清洁性>确保集群节点清洁性</a><li><a href=#%e5%88%9b%e5%bb%ba%e9%9b%86%e7%be%a4 aria-label=创建集群>创建集群</a></ul><li><a href=#troubleshooting aria-label=Troubleshooting>Troubleshooting</a><ul><li><a href=#no-module-named-pkg_resources aria-label="No module named pkg_resources">No module named pkg_resources</a><li><a href=#runtimeerror-nosectionerror-no-section-ceph aria-label="RuntimeError: NoSectionError: No section: &amp;lsquo;ceph&amp;rsquo;">RuntimeError: NoSectionError: No section: &lsquo;ceph&rsquo;</a></ul><li><a href=#%e5%90%91-rados-%e9%9b%86%e7%be%a4%e6%b7%bb%e5%8a%a0-osd aria-label="向 RADOS 集群添加 OSD">向 RADOS 集群添加 OSD</a><ul><ul><li><a href=#%e5%88%97%e5%87%ba%e5%b9%b6%e6%93%a6%e5%87%80%e7%a3%81%e7%9b%98 aria-label=列出并擦净磁盘>列出并擦净磁盘</a></ul></ul><li><a href=#%e6%89%a9%e5%b1%95%e9%9b%86%e7%be%a4 aria-label=扩展集群>扩展集群</a><ul><li><a href=#%e6%b7%bb%e5%8a%a0-osd aria-label="添加 OSD">添加 OSD</a><li><a href=#%e7%a7%bb%e9%99%a4-osd-%e7%9a%84 aria-label="移除 OSD 的">移除 OSD 的</a><li><a href=#%e6%89%a9%e5%b1%95-ceph-mon aria-label="扩展 ceph-mon">扩展 ceph-mon</a><li><a href=#%e6%89%a9%e5%b1%95-manager-%e8%8a%82%e7%82%b9 aria-label="扩展 Manager 节点">扩展 Manager 节点</a><li><a href=#%e5%90%af%e5%8a%a8-rgw aria-label="启动 RGW">启动 RGW</a><li><a href=#%e5%90%af%e7%94%a8%e6%96%87%e4%bb%b6%e7%b3%bb%e7%bb%9f-cephfs-%e6%8e%a5%e5%8f%a3 aria-label="启用文件系统 (CephFS) 接口">启用文件系统 (CephFS) 接口</a></ul><li><a href=#reference aria-label=Reference>Reference</a></li></div></details></div></aside><script src=/js/pe-toc.min.445eb1bfc5e85dd13b9519fcc2a806522e9629b6224a2974052789ba00ab78af.js integrity="sha256-RF6xv8XoXdE7lRn8wqgGUi6WKbYiSil0BSeJugCreK8="></script><div class=post-content><h2 id=环境配置>环境配置<a hidden class=anchor aria-hidden=true href=#环境配置>#</a></h2><p>Ceph 是一个开源去中心化存储平台，专为满足现代存储需求而设计。 Ceph可扩展至 EB 级，并且设计为无单点故障，使其成为需要高度可用的灵活存储的应用程序的理想选择。</p><p>下图显示了具有 Ceph 存储的示例 3 节点集群的布局。 两个网络接口可用于增加带宽和冗余，这有助于保持足够的带宽来满足存储要求，而不影响客户端应用程序。</p><p><div class=pe-fancybox><a data-fancybox=gallery href=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/image-20230910161024448.png><img src=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/image-20230910161024448.png#center alt=image-20230910161024448 onerror='this.onerror=null,this.src="/placeholder.svg",this.className="pe-image-placeholder"'></a></div></p><center>图：Ceph存储集群</center><center><em>Source：</em>https://www.jamescoyle.net/how-to/1244-create-a-3-node-ceph-storage-cluster</center><br><p>图中架构表示了一个无单点故障的 3 节点 Ceph 集群，以提供高度冗余的存储。 每个节点都配置了两个磁盘； 一台运行 Linux 操作系统，另一台将用于 Ceph 存储。 下面的输出显示了可用的存储空间，每个主机上的存储空间完全相同。 <strong>/dev/sda</strong> 是包含操作系统安装的根分区， <strong>/dev/sdb</strong> 是一个未触及的分区，将用于部署 Ceph 集群，对应的硬件信息如下表所示。</p><table><thead><tr><th>主机名</th><th>public IP</th><th>cluster IP</th><th>数据盘</th></tr></thead><tbody><tr><td>ceph-nautilus01</td><td>10.0.0.50</td><td>10.0.0.50</td><td>/dev/sda<br>/dev/sdb</td></tr><tr><td>ceph-nautilus02</td><td>10.0.0.51</td><td>10.0.0.51</td><td>/dev/sda<br>/dev/sdb</td></tr><tr><td>ceph-nautilus03</td><td>10.0.0.52</td><td>10.0.0.52</td><td>/dev/sda<br>/dev/sdb</td></tr><tr><td>ceph-control</td><td>10.0.0.49</td><td>10.0.0.49</td><td>/dev/sda</td></tr></tbody></table><h3 id=部署工具>部署工具<a hidden class=anchor aria-hidden=true href=#部署工具>#</a></h3><p><em>ceph-deploy</em> 工具是在 “管理节点” (ceph-admin) 上的目录中运行。</p><ul><li>ceph-deploy 部署ceph的原生工具 (最后支持版本 octopus 15)<ul><li>借助于ssh来管理目标主机，sudo,和一些 python 模块来完成 ceph 集群的部署和后期维护。</li><li>一般讲 <em>ceph-deploy</em> 放置在专用节点，作为 ceph 集群的管理节点。</li><li>ceph-deploy 不是一个通用的部署工具，只是用于管理Ceph集群的，专门为用户快速部署并运行一个Ceph集群，这些功能和特性不依赖于其他的编排工具。</li><li>它无法处理客户端的配置，因此在部署客户端时就无法使用此工具。</li></ul></li></ul><p>下图是来自 ceph 官网的 <em>ceph-deploy</em> 部署工具的一个模型图</p><p><div class=pe-fancybox><a data-fancybox=gallery href=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/image-20230910164114089.png><img src=https://cdn.jsdelivr.net/gh/cylonchau/blogs@img/img/image-20230910164114089.png#center alt=image-20230910164114089 onerror='this.onerror=null,this.src="/placeholder.svg",this.className="pe-image-placeholder"'></a></div></p><center>图：ceph-deploy部署模型</center><center><em>Source：</em>https://docs.ceph.com/en/nautilus/start/quick-start-preflight/</center><br><h3 id=ceph-集群拓扑及网络>CEPH 集群拓扑及网络<a hidden class=anchor aria-hidden=true href=#ceph-集群拓扑及网络>#</a></h3><p>在Ceph内部存在两种流量：</p><ul><li>Ceph内部各节点之间用来处理OSD之间数据复制，因此为了避免正常向客户端提供服务请求，</li><li><strong>public network</strong> 必须，所有客户端都应位于public network</li><li><strong>cluster network</strong> 可选</li></ul><h2 id=ceph-deploy-先决条件配置>ceph-deploy 先决条件配置<a hidden class=anchor aria-hidden=true href=#ceph-deploy-先决条件配置>#</a></h2><p>将 Ceph 安装仓库添加到 “管理节点”。然后，安装 <em>ceph-deploy</em>。</p><h3 id=debianubuntu>Debian/Ubuntu<a hidden class=anchor aria-hidden=true href=#debianubuntu>#</a></h3><ol><li>添加 release key</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>wget -q -O- <span class=s1>&#39;https://download.ceph.com/keys/release.asc&#39;</span> <span class=p>|</span> sudo apt-key add -</span></span></code></pre></td></tr></table></div></div></div></div><ol start=2><li>将 Ceph deb添加到您的存储库。并替换为安装的 Ceph 版本（例如 nautilus）。例如：</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>CEPH_VERSION</span><span class=o>=</span>nautilus
</span></span><span class=line><span class=cl><span class=nb>echo</span> deb https://download.ceph.com/debian-<span class=si>${</span><span class=nv>CEPH_VERSION</span><span class=si>}</span>/ <span class=k>$(</span>lsb_release -sc<span class=k>)</span> main <span class=p>|</span> sudo tee /etc/apt/sources.list.d/ceph.list</span></span></code></pre></td></tr></table></div></div></div></div><ol start=3><li>更新仓库并安装 <em>ceph-deploy</em></li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo apt update
</span></span><span class=line><span class=cl>sudo apt install ceph-deploy</span></span></code></pre></td></tr></table></div></div></div></div><h3 id=rhelcentos>RHEL/CentOS<a hidden class=anchor aria-hidden=true href=#rhelcentos>#</a></h3><ol><li>安装 epel 源，这里方式很多可以任意选择 “<strong>你所在地区可用的 epel 源</strong>”</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm</span></span></code></pre></td></tr></table></div></div></div></div><ol start=2><li>添加 Ceph rpm 仓库</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>CEPH_VERSION</span><span class=o>=</span>nautilus
</span></span><span class=line><span class=cl>cat <span class=s>&lt;&lt; EOF &gt; /etc/yum.repos.d/ceph.repo
</span></span></span><span class=line><span class=cl><span class=s>[ceph]
</span></span></span><span class=line><span class=cl><span class=s>name=Ceph packages for $basearch
</span></span></span><span class=line><span class=cl><span class=s>baseurl=https://download.ceph.com/rpm-${CEPH_VERSION}/el7/\$basearch
</span></span></span><span class=line><span class=cl><span class=s>enabled=1
</span></span></span><span class=line><span class=cl><span class=s>priority=2
</span></span></span><span class=line><span class=cl><span class=s>gpgcheck=1
</span></span></span><span class=line><span class=cl><span class=s>gpgkey=https://download.ceph.com/keys/release.asc
</span></span></span><span class=line><span class=cl><span class=s>
</span></span></span><span class=line><span class=cl><span class=s>[ceph-noarch]
</span></span></span><span class=line><span class=cl><span class=s>name=Ceph noarch packages
</span></span></span><span class=line><span class=cl><span class=s>baseurl=https://download.ceph.com/rpm-${CEPH_VERSION}/el7/noarch
</span></span></span><span class=line><span class=cl><span class=s>enabled=1
</span></span></span><span class=line><span class=cl><span class=s>priority=2
</span></span></span><span class=line><span class=cl><span class=s>gpgcheck=1
</span></span></span><span class=line><span class=cl><span class=s>gpgkey=https://download.ceph.com/keys/release.asc
</span></span></span><span class=line><span class=cl><span class=s>
</span></span></span><span class=line><span class=cl><span class=s>[ceph-source]
</span></span></span><span class=line><span class=cl><span class=s>name=Ceph source packages
</span></span></span><span class=line><span class=cl><span class=s>baseurl=https://download.ceph.com/rpm-${CEPH_VERSION}/el7/SRPMS
</span></span></span><span class=line><span class=cl><span class=s>enabled=0
</span></span></span><span class=line><span class=cl><span class=s>priority=2
</span></span></span><span class=line><span class=cl><span class=s>gpgcheck=1
</span></span></span><span class=line><span class=cl><span class=s>gpgkey=https://download.ceph.com/keys/release.asc
</span></span></span><span class=line><span class=cl><span class=s>EOF</span></span></span></code></pre></td></tr></table></div></div></div></div><ol start=3><li>更新缓存并安装 <em>ceph-deploy</em></li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo yum clean all <span class=o>&amp;&amp;</span> sudo yum makecache
</span></span><span class=line><span class=cl>sudo yum install ceph-deploy</span></span></code></pre></td></tr></table></div></div></div></div><h2 id=安装集群的预先条件---ceph-node>安装集群的预先条件 - CEPH NODE<a hidden class=anchor aria-hidden=true href=#安装集群的预先条件---ceph-node>#</a></h2><ul><li>管理节点必须拥有所有 ceph node 的无密码登录权限</li><li>ntp</li><li>开放端口</li><li>关闭 selinux</li></ul><h3 id=创建用于-ceph-deploy-的用户>创建用于 <em>ceph-deploy</em> 的用户<a hidden class=anchor aria-hidden=true href=#创建用于-ceph-deploy-的用户>#</a></h3><p>ceph-deploy 实用程序必须以具有无密码 sudo 权限的用户身份登录 Ceph node，因为它需要在不提示输入密码的情况下安装软件和配置文件。</p><p>最新版本的 ceph-deploy 支持 &ndash;username 选项，因此您可以指定任何具有无密码的 sudo 用户（包括 root，但不推荐）。要使用 ceph-deploy &ndash;username {username}，“所指定的用户必须具有对 Ceph Node 的无密码 SSH 访问权限”，因为 ceph-deploy 不会提示您输入密码。</p><p>Ceph 官方建议在集群中的所有 Ceph 节点上为 ceph-deploy 创建特定用户。==请不要使用 “ceph” 作为用户名==。整个集群中的统一用户名可能会提高易用性（不是必需的），但您应该避免使用明显的用户名，因为黑客通常会通过暴力破解来使用它们（例如 root, admin, 或使用项目名称）。以下过程将 <code>{username}</code> 替换为您定义的用户名，描述了如何使用无密码 sudo 创建用户。</p><ol><li>在每个 Ceph Node 创建一个用户</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>CEPH_USERNAME</span><span class=o>=</span>ceph
</span></span><span class=line><span class=cl>sudo useradd -d /home/<span class=si>${</span><span class=nv>CEPH_USERNAME</span><span class=si>}</span> -m <span class=si>${</span><span class=nv>CEPH_USERNAME</span><span class=si>}</span>
</span></span><span class=line><span class=cl><span class=nb>echo</span> 1<span class=p>|</span>sudo passwd <span class=si>${</span><span class=nv>CEPH_USERNAME</span><span class=si>}</span> --stdin</span></span></code></pre></td></tr></table></div></div></div></div><ol start=2><li>对于添加到每个 Ceph Node 的新用户，请确保该用户具有 sudo 权限。</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;</span><span class=si>${</span><span class=nv>CEPH_USERNAME</span><span class=si>}</span><span class=s2> ALL = (root) NOPASSWD:ALL&#34;</span> <span class=p>|</span> sudo tee /etc/sudoers.d/<span class=si>${</span><span class=nv>CEPH_USERNAME</span><span class=si>}</span>
</span></span><span class=line><span class=cl>sudo chmod <span class=m>0440</span> /etc/sudoers.d/<span class=si>${</span><span class=nv>CEPH_USERNAME</span><span class=si>}</span></span></span></code></pre></td></tr></table></div></div></div></div><h3 id=启用-ssh-无密码登录>启用 SSH 无密码登录<a hidden class=anchor aria-hidden=true href=#启用-ssh-无密码登录>#</a></h3><p>由于 ceph-deploy 不会提示输入密码，因此必须在管理节点上生成 SSH 密钥并将公钥分发到每个 Ceph 节点。 <em>ceph-deploy</em> 将尝试为初始 monitor 生成 SSH 密钥。</p><ol><li>生成 ssh key，不要使用 sudo 或者是 root 用户</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ ssh-keygen
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Generating public/private key pair.
</span></span><span class=line><span class=cl>Enter file in which to save the key <span class=o>(</span>/ceph-admin/.ssh/id_rsa<span class=o>)</span>:
</span></span><span class=line><span class=cl>Enter passphrase <span class=o>(</span>empty <span class=k>for</span> no passphrase<span class=o>)</span>:
</span></span><span class=line><span class=cl>Enter same passphrase again:
</span></span><span class=line><span class=cl>Your identification has been saved in /ceph-admin/.ssh/id_rsa.
</span></span><span class=line><span class=cl>Your public key has been saved in /ceph-admin/.ssh/id_rsa.pub.</span></span></code></pre></td></tr></table></div></div></div></div><ol start=2><li>将 SSH 密钥复制到每个 Ceph Node，将变量 “CEPH_USERNAME” 替换为创建 Ceph 部署用户创建的用户名。</li></ol><blockquote><p>通常情况下，主机名需要解析的，如果没有需要配置在 /etc/hosts 内</p></blockquote><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ssh-copy-id <span class=si>${</span><span class=nv>CEPH_USERNAME</span><span class=si>}</span>@ceph-nautilus01
</span></span><span class=line><span class=cl>ssh-copy-id <span class=si>${</span><span class=nv>CEPH_USERNAME</span><span class=si>}</span>@ceph-nautilus02
</span></span><span class=line><span class=cl>ssh-copy-id <span class=si>${</span><span class=nv>CEPH_USERNAME</span><span class=si>}</span>@ceph-nautilus03
</span></span><span class=line><span class=cl><span class=c1># 如果是 root 用户执行下面命令</span>
</span></span><span class=line><span class=cl>sudo -u <span class=si>${</span><span class=nv>CEPH_USERNAME</span><span class=si>}</span> ssh-copy-id <span class=si>${</span><span class=nv>CEPH_USERNAME</span><span class=si>}</span>@ceph-nautilus01
</span></span><span class=line><span class=cl>sudo -u <span class=si>${</span><span class=nv>CEPH_USERNAME</span><span class=si>}</span> ssh-copy-id <span class=si>${</span><span class=nv>CEPH_USERNAME</span><span class=si>}</span>@ceph-nautilus02
</span></span><span class=line><span class=cl>sudo -u <span class=si>${</span><span class=nv>CEPH_USERNAME</span><span class=si>}</span> ssh-copy-id <span class=si>${</span><span class=nv>CEPH_USERNAME</span><span class=si>}</span>@ceph-nautilus03</span></span></code></pre></td></tr></table></div></div></div></div><ol start=3><li>添加主机名到 /etc/hosts (可选)</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ tee &gt;&gt; /etc/hosts <span class=s>&lt;&lt; EOF
</span></span></span><span class=line><span class=cl><span class=s>10.0.0.50 ceph-nautilus01
</span></span></span><span class=line><span class=cl><span class=s>10.0.0.51 ceph-nautilus02
</span></span></span><span class=line><span class=cl><span class=s>10.0.0.52 ceph-nautilus03
</span></span></span><span class=line><span class=cl><span class=s>EOF</span></span></span></code></pre></td></tr></table></div></div></div></div><h3 id=网卡开机自启动>网卡开机自启动<a hidden class=anchor aria-hidden=true href=#网卡开机自启动>#</a></h3><p>Ceph OSD Peer 并通过网络向 Ceph monitor 报告。如果默认情况下网络处于关闭状态，则在启用网络之前，Ceph 集群无法在启动期间联机。</p><p>在一些 Linux 发行版下（例如 CentOS）上的默认配置默认关闭网络接口。确保在启动过程中网络接口打开，以便 Ceph 守护进程可以通过网络进行通信。(如果你的系统是新装的)</p><h3 id=开放所需端口>开放所需端口<a hidden class=anchor aria-hidden=true href=#开放所需端口>#</a></h3><p>Ceph Monitor (ceph-mon) 默认使用端口 <strong>6789</strong> 进行通信。默认情况下，Ceph OSD 在 <strong>6800:7300</strong> 端口范围内进行通信。详细信息请参见网络配置参考 <sup><a href=#1>[1]</a></sup>。</p><h3 id=确保关闭-selinux>确保关闭 SELinux<a hidden class=anchor aria-hidden=true href=#确保关闭-selinux>#</a></h3><p>在 CentOS 和 RHEL 上，SELinux 默认设置为“Enforcing”。为了简化您的安装，我们建议将 SELinux 设置为 Permissive 或完全禁用，这是 Ceph 官方给出的建议</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo setenforce <span class=m>0</span></span></span></code></pre></td></tr></table></div></div></div></div><p>要持久配置 SELinux（如果 SELinux 存在问题，则建议这样做），请修改 <code>/etc/selinux/config</code> 中的配置文件。</p><h3 id=preferences>Preferences<a hidden class=anchor aria-hidden=true href=#preferences>#</a></h3><p>确保您的 “包管理器” 已安装并启用 “priority/preferences”。在 CentOS 上，您可能需要安装 EPEL。在 RHEL 上，您可能需要启用可选存储库。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo yum install yum-plugin-priorities</span></span></code></pre></td></tr></table></div></div></div></div><p>例如，在 RHEL 7 服务器上，执行以下命令安装 yum-plugin-priorities 并启用 rhel-7-server-optional-rpms 存储库：</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bsah</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><pre tabindex=0><code class=language-bsah data-lang=bsah>sudo yum install yum-plugin-priorities --enablerepo=rhel-7-server-optional-rpms</code></pre></div></div><h2 id=初始化新的-ceph-集群>初始化新的 CEPH 集群<a hidden class=anchor aria-hidden=true href=#初始化新的-ceph-集群>#</a></h2><p>在这里我们创建一个包含一个 Ceph Monitor (<em>ceph-mon</em>) 和 三个 Ceph OSD (<em>osd daemon</em>) 的 Ceph 集群。通常使用 <em>ceph-deploy</em> 部署集群，最佳方式是在 “管理节点” 上创建一个目录，用于维护 ceph-deploy 为集群生成的配置文件和密钥。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>mkdir ceph-cluster <span class=o>&amp;&amp;</span> <span class=nb>cd</span> ceph-cluster</span></span></code></pre></td></tr></table></div></div></div></div><p>需要注意的是，<em>ceph-deploy</em> 将文件输出到当前目录。执行 ceph-deploy 时需要确保位于此目录中。</p><p>还需要注意的是，需要使用 “<strong>SSH 免密的那个用户</strong>”</p><h3 id=确保集群节点清洁性>确保集群节点清洁性<a hidden class=anchor aria-hidden=true href=#确保集群节点清洁性>#</a></h3><p>如果在任何时候遇到问题后并想重新开始，可以执行下列命令清除所有安装包和配置：</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ceph-deploy purge <span class=o>{</span>ceph-node<span class=o>}</span> <span class=o>[{</span>ceph-node<span class=o>}]</span>
</span></span><span class=line><span class=cl>ceph-deploy purgedata <span class=o>{</span>ceph-node<span class=o>}</span> <span class=o>[{</span>ceph-node<span class=o>}]</span>
</span></span><span class=line><span class=cl>ceph-deploy forgetkeys
</span></span><span class=line><span class=cl>rm ceph.*</span></span></code></pre></td></tr></table></div></div></div></div><p>需要注意的是，执行 ceph-deploy，必须执行第四条命令 <code>rm ceph.*</code></p><h3 id=创建集群>创建集群<a hidden class=anchor aria-hidden=true href=#创建集群>#</a></h3><p>创建集群会生成配置文件保存到当前工作目录中，使用 ceph-deploy 执行命令新建一个集群。</p><ol><li>创建集群</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 语法</span>
</span></span><span class=line><span class=cl>ceph-deploy new <span class=o>{</span>initial-monitor-node<span class=o>(</span>s<span class=o>)}</span>
</span></span><span class=line><span class=cl><span class=c1># 示例, 指定节点的 hostname, fqdn or hostname:fqdn</span>
</span></span><span class=line><span class=cl>ceph-deploy new ceph-nautilus01 ceph-nautilus02 ceph-nautilus03</span></span></code></pre></td></tr></table></div></div></div></div><p>ceph-deploy 会输出到当前文件夹下的文件包含，Ceph 配置文件 (ceph.conf)、ceph-mon 的 keyring 文件 (ceph.mon.keyring) 以及新集群的日志文件。</p><ol start=2><li>如果主机存在多个网络接口（即公共网络和集群网络是分开的），需要在 Ceph 配置文件的 [global] 部分下添加公共网络设置。</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>public <span class=nv>network</span> <span class=o>=</span> <span class=o>{</span>ip-address<span class=o>}</span>/<span class=o>{</span>bits<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=c1># 示例</span>
</span></span><span class=line><span class=cl>public <span class=nv>network</span> <span class=o>=</span> 10.1.2.0/24</span></span></code></pre></td></tr></table></div></div></div></div><p>或者通过命令指定两个网络的 IP</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ceph-deploy new ceph-nautilus01 ceph-nautilus02 ceph-nautilus03 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>	--cluster-network 172.18.0.0/24 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>	--public-network 10.0.0.0/24</span></span></code></pre></td></tr></table></div></div></div></div><ol start=3><li>如果在 IPv6 环境中部署，请将以下内容添加到本地目录中的 ceph.conf 中：</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>echo</span> ms <span class=nb>bind</span> <span class=nv>ipv6</span> <span class=o>=</span> <span class=nb>true</span> &gt;&gt; ceph.conf</span></span></code></pre></td></tr></table></div></div></div></div><ol start=4><li>现在可以安装 ceph 软件包了，执行下列命令</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ceph-deploy install <span class=o>{</span>ceph-node<span class=o>}</span> <span class=o>[</span>...<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=c1># 示例</span>
</span></span><span class=line><span class=cl>ceph-deploy install ceph-nautilus01 ceph-nautilus02 ceph-nautilus03</span></span></code></pre></td></tr></table></div></div></div></div><p>在命令执行后，<em>ceph-deploy</em> 将在每个节点上安装 Ceph，所以要确保对应节点需要提前安装好了 ceph yum 仓库文件</p><p>也可以通过 <code>--release</code> 指定版本进行安装</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ceph-deploy install --release<span class=o>=</span>nautilus ceph-nautilus01 ceph-nautilus02 ceph-nautilus03</span></span></code></pre></td></tr></table></div></div></div></div><ol start=5><li>部署 <em>ceph-mon</em> 并收集密钥：</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ceph-deploy mon create-initial</span></span></code></pre></td></tr></table></div></div></div></div><p>​ 通常完成步骤5后，本地工作目录应具有以下 keyring 文件：</p><ul><li><code>ceph.client.admin.keyring</code></li><li><code>ceph.bootstrap-mgr.keyring</code></li><li><code>ceph.bootstrap-osd.keyring</code></li><li><code>ceph.bootstrap-mds.keyring</code></li><li><code>ceph.bootstrap-rgw.keyring</code></li><li><code>ceph.bootstrap-rbd.keyring</code></li><li><code>ceph.bootstrap-rbd-mirror.keyring</code></li></ul><ol start=6><li>使用 <em>ceph-deploy</em> 将配置文件和管理密钥复制到管理节点和 Ceph Node，以便可以在这些节点上使用 ceph CLI 时而无需在每次执行命令时指定 ceph-mon 地址和 keyring文件 (ceph.client.admin.keyring)。</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ceph-deploy admin <span class=o>{</span>ceph-node<span class=o>(</span>s<span class=o>)}</span>
</span></span><span class=line><span class=cl><span class=c1># 示例</span>
</span></span><span class=line><span class=cl>ceph-deploy admin ceph-nautilus01 ceph-nautilus02 ceph-nautilus03</span></span></code></pre></td></tr></table></div></div></div></div><ol start=7><li>部署 CEPH MANAGER (ceph-mgr)，此步骤仅需要 ==luminous+== 以上版本</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ceph-deploy mgr create <span class=o>{</span>ceph-node<span class=o>(</span>s<span class=o>)}</span>  *Required only <span class=k>for</span> luminous+ builds, i.e &gt;<span class=o>=</span> 12.x builds*
</span></span><span class=line><span class=cl><span class=c1># 示例</span>
</span></span><span class=line><span class=cl>ceph-deploy mgr create ceph-nautilus01</span></span></code></pre></td></tr></table></div></div></div></div><ol start=8><li>到步骤8时，只差 OSD 就完成了 RADOS 集群的安装，下面为集群添加 OSD</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ceph-deploy osd create --data <span class=o>{</span>device<span class=o>}</span> <span class=o>{</span>ceph-node<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=c1># 示例</span>
</span></span><span class=line><span class=cl>ceph-deploy osd create --data /dev/sdb ceph-nautilus01
</span></span><span class=line><span class=cl>ceph-deploy osd create --data /dev/sdb ceph-nautilus02
</span></span><span class=line><span class=cl>ceph-deploy osd create --data /dev/sdb ceph-nautilus03</span></span></code></pre></td></tr></table></div></div></div></div><blockquote><p>Note：如果要在 LVM 卷上创建 OSD，则 &ndash;data 的参数必须是 <code>{volume_group}/{lv_name}</code>，而不是卷的块设备的路径</p></blockquote><ol start=9><li>检查集群状态</li></ol><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ssh node1 sudo ceph health
</span></span><span class=line><span class=cl><span class=c1># or </span>
</span></span><span class=line><span class=cl>ceph -s</span></span></code></pre></td></tr></table></div></div></div></div><h2 id=troubleshooting>Troubleshooting<a hidden class=anchor aria-hidden=true href=#troubleshooting>#</a></h2><h3 id=no-module-named-pkg_resources>No module named pkg_resources<a hidden class=anchor aria-hidden=true href=#no-module-named-pkg_resources>#</a></h3><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ ceph-deploy new ceph-nautilus01 ceph-nautilus02 ceph-nautilus03
</span></span><span class=line><span class=cl>Traceback <span class=o>(</span>most recent call last<span class=o>)</span>:
</span></span><span class=line><span class=cl>  File <span class=s2>&#34;/usr/bin/ceph-deploy&#34;</span>, line 18, in &lt;module&gt;
</span></span><span class=line><span class=cl>    from ceph_deploy.cli import main
</span></span><span class=line><span class=cl>  File <span class=s2>&#34;/usr/lib/python2.7/site-packages/ceph_deploy/cli.py&#34;</span>, line 1, in &lt;module&gt;
</span></span><span class=line><span class=cl>    import pkg_resources
</span></span><span class=line><span class=cl>ImportError: No module named pkg_resources</span></span></code></pre></td></tr></table></div></div></div></div><p>解决：This issue can be solved by installing <code>yum install -y python-setuptools</code>.</p><h3 id=runtimeerror-nosectionerror-no-section-ceph>RuntimeError: NoSectionError: No section: &lsquo;ceph&rsquo;<a hidden class=anchor aria-hidden=true href=#runtimeerror-nosectionerror-no-section-ceph>#</a></h3><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=o>[</span>2019-09-11 05:31:42,640<span class=o>][</span>ceph-nautilus01<span class=o>][</span>DEBUG <span class=o>]</span>   Installing : ceph-release-1-1.el7.noarch                                  1/1 
</span></span><span class=line><span class=cl><span class=o>[</span>2019-09-11 05:31:42,640<span class=o>][</span>ceph-nautilus01<span class=o>][</span>DEBUG <span class=o>]</span> warning: /etc/yum.repos.d/ceph.repo created as /etc/yum.repos.d/ceph.repo.rpmnew
</span></span><span class=line><span class=cl><span class=o>[</span>2019-09-11 05:31:42,759<span class=o>][</span>ceph-nautilus01<span class=o>][</span>DEBUG <span class=o>]</span>   Verifying  : ceph-release-1-1.el7.noarch                                  1/1 
</span></span><span class=line><span class=cl><span class=o>[</span>2019-09-11 05:31:42,759<span class=o>][</span>ceph-nautilus01<span class=o>][</span>DEBUG <span class=o>]</span> 
</span></span><span class=line><span class=cl><span class=o>[</span>2019-09-11 05:31:42,759<span class=o>][</span>ceph-nautilus01<span class=o>][</span>DEBUG <span class=o>]</span> Installed:
</span></span><span class=line><span class=cl><span class=o>[</span>2019-09-11 05:31:42,759<span class=o>][</span>ceph-nautilus01<span class=o>][</span>DEBUG <span class=o>]</span>   ceph-release.noarch 0:1-1.el7                                                 
</span></span><span class=line><span class=cl><span class=o>[</span>2019-09-11 05:31:42,759<span class=o>][</span>ceph-nautilus01<span class=o>][</span>DEBUG <span class=o>]</span> 
</span></span><span class=line><span class=cl><span class=o>[</span>2019-09-11 05:31:42,759<span class=o>][</span>ceph-nautilus01<span class=o>][</span>DEBUG <span class=o>]</span> Complete!
</span></span><span class=line><span class=cl><span class=o>[</span>2019-09-11 05:31:42,759<span class=o>][</span>ceph-nautilus01<span class=o>][</span>WARNING<span class=o>]</span> ensuring that /etc/yum.repos.d/ceph.repo contains a high priority
</span></span><span class=line><span class=cl><span class=o>[</span>2019-09-11 05:31:42,767<span class=o>][</span>ceph_deploy<span class=o>][</span>ERROR <span class=o>]</span> RuntimeError: NoSectionError: No section: <span class=s1>&#39;ceph&#39;</span></span></span></code></pre></td></tr></table></div></div></div></div><p>解决：CEPH Node 上不要安装 yum 仓库，<em>ceph-deploy</em> 会自动安装，如果存在新的文件会被命名为 <code>ceph.repo.rpmnew</code></p><h2 id=向-rados-集群添加-osd>向 RADOS 集群添加 OSD<a hidden class=anchor aria-hidden=true href=#向-rados-集群添加-osd>#</a></h2><h4 id=列出并擦净磁盘>列出并擦净磁盘<a hidden class=anchor aria-hidden=true href=#列出并擦净磁盘>#</a></h4><p><em>ceph-deploy disk</em> 命令可以检查并列出OSD节点上所有可用的磁盘相关的信息。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>sh</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ceph-deploy disk list stor01 stor02 stor03 stor04</span></span></code></pre></td></tr></table></div></div></div></div><p>如果遇到 <code>Running command: sudo fdisk -l</code> 无输出，原因为系统问中文，修改 <em>en_us.utf8</em> 后可正常显示。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>bash</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ ceph-deploy disk list stor01
</span></span><span class=line><span class=cl><span class=o>[</span>ceph_deploy.conf<span class=o>][</span>DEBUG <span class=o>]</span> found configuration file at: /home/cephadmin/.cephdeploy.conf
</span></span><span class=line><span class=cl><span class=o>[</span>ceph_deploy.cli<span class=o>][</span>INFO  <span class=o>]</span> Invoked <span class=o>(</span>2.0.1<span class=o>)</span>: /bin/ceph-deploy disk list stor01
</span></span><span class=line><span class=cl><span class=o>[</span>ceph_deploy.cli<span class=o>][</span>INFO  <span class=o>]</span> ceph-deploy options:
</span></span><span class=line><span class=cl><span class=o>[</span>ceph_deploy.cli<span class=o>][</span>INFO  <span class=o>]</span>  username                      : None
</span></span><span class=line><span class=cl><span class=o>[</span>ceph_deploy.cli<span class=o>][</span>INFO  <span class=o>]</span>  verbose                       : False
</span></span><span class=line><span class=cl><span class=o>[</span>ceph_deploy.cli<span class=o>][</span>INFO  <span class=o>]</span>  debug                         : False
</span></span><span class=line><span class=cl><span class=o>[</span>ceph_deploy.cli<span class=o>][</span>INFO  <span class=o>]</span>  overwrite_conf                : False
</span></span><span class=line><span class=cl><span class=o>[</span>ceph_deploy.cli<span class=o>][</span>INFO  <span class=o>]</span>  subcommand                    : list
</span></span><span class=line><span class=cl><span class=o>[</span>ceph_deploy.cli<span class=o>][</span>INFO  <span class=o>]</span>  quiet                         : False
</span></span><span class=line><span class=cl><span class=o>[</span>ceph_deploy.cli<span class=o>][</span>INFO  <span class=o>]</span>  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fab61201488&gt;
</span></span><span class=line><span class=cl><span class=o>[</span>ceph_deploy.cli<span class=o>][</span>INFO  <span class=o>]</span>  cluster                       : ceph
</span></span><span class=line><span class=cl><span class=o>[</span>ceph_deploy.cli<span class=o>][</span>INFO  <span class=o>]</span>  host                          : <span class=o>[</span><span class=s1>&#39;stor01&#39;</span><span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>[</span>ceph_deploy.cli<span class=o>][</span>INFO  <span class=o>]</span>  func                          : &lt;<span class=k>function</span> disk at 0x7fab6144e9b0&gt;
</span></span><span class=line><span class=cl><span class=o>[</span>ceph_deploy.cli<span class=o>][</span>INFO  <span class=o>]</span>  ceph_conf                     : None
</span></span><span class=line><span class=cl><span class=o>[</span>ceph_deploy.cli<span class=o>][</span>INFO  <span class=o>]</span>  default_release               : False
</span></span><span class=line><span class=cl><span class=o>[</span>stor01<span class=o>][</span>DEBUG <span class=o>]</span> connection detected need <span class=k>for</span> sudo
</span></span><span class=line><span class=cl><span class=o>[</span>stor01<span class=o>][</span>DEBUG <span class=o>]</span> connected to host: stor01 
</span></span><span class=line><span class=cl><span class=o>[</span>stor01<span class=o>][</span>DEBUG <span class=o>]</span> detect platform information from remote host
</span></span><span class=line><span class=cl><span class=o>[</span>stor01<span class=o>][</span>DEBUG <span class=o>]</span> detect machine <span class=nb>type</span>
</span></span><span class=line><span class=cl><span class=o>[</span>stor01<span class=o>][</span>DEBUG <span class=o>]</span> find the location of an executable
</span></span><span class=line><span class=cl><span class=o>[</span>stor01<span class=o>][</span>INFO  <span class=o>]</span> Running command: sudo fdisk -l</span></span></code></pre></td></tr></table></div></div></div></div><p>而后，在管理节点上使用 <em>ceph-deploy</em> 命令 擦除计划专用于OSD磁盘上的所有分区表和数据以便用于OSD，命令格式为<code>ceph-deploy disk zab {osd-server-name} {disk-name}</code>，需要注意的是此步会清除目标设备上的所有数据。</p><p>擦除一个磁盘</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>sh</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ceph-deploy disk zap
</span></span><span class=line><span class=cl>ceph-deploy disk zap <span class=o>{</span>ceph_node<span class=o>}</span> /dev/sdb</span></span></code></pre></td></tr></table></div></div></div></div><blockquote><p>Note：如果是未格式化的块设备不需要额外擦除，ceph 集群要求 ceph 管理的块设备必须是未格式化的，如果格式化过的需要擦除</p></blockquote><p><em>ceph-deploy osd &ndash;help</em>：</p><ul><li><code>block-db</code> 可以理解为RocksDB数据库，元数据存放的位置</li><li><code>block-wal</code> 数据库的数据日志存放的位置</li><li><code>filestore</code> 如果使用<code>filestore</code>,明确指定选项<code>--filestore</code> 指明数据放哪，并指明日志放哪（日志指的是文件系统日志）<code>ceph-deploy osd create {node} --filestore --data /path/to/data --journal /path/to/journal</code></li><li>bluestore自身没有文件系统，故无需日志，数据库需要日志</li></ul><h2 id=扩展集群>扩展集群<a hidden class=anchor aria-hidden=true href=#扩展集群>#</a></h2><h3 id=添加-osd>添加 OSD<a hidden class=anchor aria-hidden=true href=#添加-osd>#</a></h3><p>当一个 “基本集群” 部署好并运行，下一步就是扩展集群。通常会扩展集群，扩展集群存在两种类型，集群组件与OSD，这里主要围绕 扩展 OSD</p><p>早期版本的ceph-deploy命令支持在将添加OSD的过程分为两个步骤：准备OSD，激活OSD，但新版本中，此种操作方式已被废除，添加OSD的步骤只能由命令 <em>ceph-deploy osd create create {node} &ndash;data {data-disk}</em> ，一次完成，默认存储引擎为 <strong>bluestore</strong></p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>sh</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ceph-deploy osd create <span class=o>{</span>node<span class=o>}</span> --data /dev/sdb 
</span></span><span class=line><span class=cl>ceph-deploy osd create <span class=o>{</span>node<span class=o>}</span> --data /dev/sdc</span></span></code></pre></td></tr></table></div></div></div></div><p>而后可使用 <em>ceph-deploy osd list {node}</em> 命令列出指定节点上的OSD：</p><h3 id=移除-osd-的>移除 OSD 的<a hidden class=anchor aria-hidden=true href=#移除-osd-的>#</a></h3><p>Ceph集群中的一个OSD通常对应一个设备，且运行于专用的守护进程。在某OSD设备出现故障，或管理员出于管理只需确实要移除特定的OSD设备时，需要先停止相关的守护进程，而后再进行移除操作。对于Luminous及其之后的版本来说，停止和移除命令的格式如下</p><ul><li>停止设备: <em>ceph osd out {osd-num}</em></li><li>停止进程: <em>sudo systemctl stop ceph-osd@{osd-num}</em></li><li>移除设备: <em>ceph osd purge {id} &ndash;yes-i-really-mean-it</em></li></ul><p>若类似如下的OSD的设备信息存在于ceph.conf配置文件中，管理员在删除OSD之后手动将其删除。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>conf</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><pre tabindex=0><code class=language-conf data-lang=conf>[osd.1]
    host = {hostname}</code></pre></div></div><p>不过，对于 <em>Luminous</em> 之前的版本来说，管理员需要依次手动执行如下步骤删除OSD设备</p><ul><li>于CRUSH运行图中移除设备: <em>ceph osd crush remove {name}</em></li><li>移除OSD的认证key: <em>ceph auth del osd.{osd-num}</em></li><li>移除设备: <em>ceph osd purge {id} &ndash;yes-i-really-mean-it</em></li></ul><h3 id=扩展-ceph-mon>扩展 ceph-mon<a hidden class=anchor aria-hidden=true href=#扩展-ceph-mon>#</a></h3><p>Ceph 集群需要至少一个 <em>Ceph Monitor</em> 和一个 <em>Ceph Manager</em>，生产环境中，为了实现高可用，Ceph集群通常运行多个监视器，以免单监视器整个存储集群崩溃。Ceph使用 Paxos 算法，改算法是需要至少需要板书以上的监视器（大于n/2，其中n为总监视器数量），才能形成法定人数，尽管此非必须，<strong>奇数个</strong> ceph-mon 往往更好。</p><p>使用 <em>ceph-deploy mon add {nodes}</em> 命令可以一次添加一个 ceph-mon 到集群中。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>sh</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ceph-deploy mon add nautilus02  <span class=c1>## 此处使用短格式名称，长格式名称会报错。</span>
</span></span><span class=line><span class=cl>ceph-deploy mon add nautilus03</span></span></code></pre></td></tr></table></div></div></div></div><p>设置完成后，可以在ceph客户端上查看监视器及法定人数的相关信息:</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>sh</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>$ ceph quorum_status --format json-pretty
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;election_epoch&#34;</span>: 20,
</span></span><span class=line><span class=cl>    <span class=s2>&#34;quorum&#34;</span>: <span class=o>[</span>
</span></span><span class=line><span class=cl>        0,
</span></span><span class=line><span class=cl>        1,
</span></span><span class=line><span class=cl>        <span class=m>2</span>
</span></span><span class=line><span class=cl>    <span class=o>]</span>,
</span></span><span class=line><span class=cl>    <span class=s2>&#34;quorum_names&#34;</span>: <span class=o>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;stor01&#34;</span>,
</span></span><span class=line><span class=cl>        <span class=s2>&#34;stor02&#34;</span>,
</span></span><span class=line><span class=cl>        <span class=s2>&#34;stor03&#34;</span>
</span></span><span class=line><span class=cl>    <span class=o>]</span>,
</span></span><span class=line><span class=cl>    <span class=s2>&#34;quorum_leader_name&#34;</span>: <span class=s2>&#34;stor01&#34;</span>,
</span></span><span class=line><span class=cl>    <span class=s2>&#34;monmap&#34;</span>: <span class=o>{</span> 
</span></span><span class=line><span class=cl>        <span class=s2>&#34;epoch&#34;</span>: 3,
</span></span><span class=line><span class=cl>        <span class=s2>&#34;fsid&#34;</span>: <span class=s2>&#34;69fb9b55-3fb5-42d0-8cf7-239a3b569791&#34;</span>,
</span></span><span class=line><span class=cl>        <span class=s2>&#34;modified&#34;</span>: <span class=s2>&#34;2019-06-06 21:19:41.274199&#34;</span>,
</span></span><span class=line><span class=cl>        <span class=s2>&#34;created&#34;</span>: <span class=s2>&#34;2019-06-05 12:35:31.143594&#34;</span>,
</span></span><span class=line><span class=cl>        <span class=s2>&#34;features&#34;</span>: <span class=o>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;persistent&#34;</span>: <span class=o>[</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;kraken&#34;</span>,
</span></span><span class=line><span class=cl>                <span class=s2>&#34;luminous&#34;</span>,
</span></span><span class=line><span class=cl>                <span class=s2>&#34;mimic&#34;</span>,
</span></span><span class=line><span class=cl>                <span class=s2>&#34;osdmap-prune&#34;</span>
</span></span><span class=line><span class=cl>            <span class=o>]</span>,
</span></span><span class=line><span class=cl>            <span class=s2>&#34;optional&#34;</span>: <span class=o>[]</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span>,
</span></span><span class=line><span class=cl>        <span class=s2>&#34;mons&#34;</span>: <span class=o>[</span>
</span></span><span class=line><span class=cl>            <span class=o>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;rank&#34;</span>: 0,
</span></span><span class=line><span class=cl>                <span class=s2>&#34;name&#34;</span>: <span class=s2>&#34;stor01&#34;</span>,
</span></span><span class=line><span class=cl>                <span class=s2>&#34;addr&#34;</span>: <span class=s2>&#34;10.0.0.4:6789/0&#34;</span>,
</span></span><span class=line><span class=cl>                <span class=s2>&#34;public_addr&#34;</span>: <span class=s2>&#34;10.0.0.4:6789/0&#34;</span>
</span></span><span class=line><span class=cl>            <span class=o>}</span>,
</span></span><span class=line><span class=cl>            <span class=o>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;rank&#34;</span>: 1,
</span></span><span class=line><span class=cl>                <span class=s2>&#34;name&#34;</span>: <span class=s2>&#34;stor02&#34;</span>,
</span></span><span class=line><span class=cl>                <span class=s2>&#34;addr&#34;</span>: <span class=s2>&#34;10.0.0.5:6789/0&#34;</span>,
</span></span><span class=line><span class=cl>                <span class=s2>&#34;public_addr&#34;</span>: <span class=s2>&#34;10.0.0.5:6789/0&#34;</span>
</span></span><span class=line><span class=cl>            <span class=o>}</span>,
</span></span><span class=line><span class=cl>            <span class=o>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;rank&#34;</span>: 2,
</span></span><span class=line><span class=cl>                <span class=s2>&#34;name&#34;</span>: <span class=s2>&#34;stor03&#34;</span>,
</span></span><span class=line><span class=cl>                <span class=s2>&#34;addr&#34;</span>: <span class=s2>&#34;10.0.0.6:6789/0&#34;</span>,
</span></span><span class=line><span class=cl>                <span class=s2>&#34;public_addr&#34;</span>: <span class=s2>&#34;10.0.0.6:6789/0&#34;</span>
</span></span><span class=line><span class=cl>            <span class=o>}</span>
</span></span><span class=line><span class=cl>        <span class=o>]</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span></span></span></code></pre></td></tr></table></div></div></div></div><h3 id=扩展-manager-节点>扩展 Manager 节点<a hidden class=anchor aria-hidden=true href=#扩展-manager-节点>#</a></h3><p>Ceph Manager (ceph-mgr) 以 <em>Active/Standy</em> 模式运行，部署其他 ceph-mgr 守护进程可确保在 Active 节点的 ceph-mgr 守护进程故障时，其中一个 Standby 实例可以在不中断服务的情况下接管其任务。</p><p>mgr 就是无状态的 web 服务，一般来讲两个足够了。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>sh</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ceph-deploy mgr create <span class=o>{</span>ceph_node<span class=o>}</span></span></span></code></pre></td></tr></table></div></div></div></div><h3 id=启动-rgw>启动 RGW<a hidden class=anchor aria-hidden=true href=#启动-rgw>#</a></h3><p>RGW (<strong>R</strong>ados <strong>G</strong>ateway) 必要组件，仅在需要用到对象存储兼容 “S3” 和 “Swift” 的 RESTful 接口时才需要部署 RGW 实例，相关的命令为<em>ceph-deploy rgw create (gateway-node)</em> 。</p><p>radosgw需要用自用的存储池不能与RBD混合使用，RGW 会在创建时自动初始化出存储池来，RGW 需要有相应服务才能运行起来。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>sh</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ceph-deploy rgw create nautilus02</span></span></code></pre></td></tr></table></div></div></div></div><p>添加完成后，<em>ceph -s</em> 命令的 service 一段中会输出相关信息：</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>sh</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>$ ceph -s
</span></span><span class=line><span class=cl>  cluster:
</span></span><span class=line><span class=cl>    id:     69fb9b55-3fb5-42d0-8cf7-239a3b569791
</span></span><span class=line><span class=cl>    health: HEALTH_WARN
</span></span><span class=line><span class=cl>            application not enabled on <span class=m>1</span> pool<span class=o>(</span>s<span class=o>)</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl>  services:
</span></span><span class=line><span class=cl>    mon: <span class=m>3</span> daemons, quorum stor01,stor02,stor03
</span></span><span class=line><span class=cl>    mgr: stor01<span class=o>(</span>active<span class=o>)</span>, standbys: stor04
</span></span><span class=line><span class=cl>    osd: <span class=m>8</span> osds: <span class=m>8</span> up, <span class=m>8</span> in
</span></span><span class=line><span class=cl>    rgw: <span class=m>1</span> daemon active
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl>  data:
</span></span><span class=line><span class=cl>    pools:   <span class=m>7</span> pools, <span class=m>160</span> pgs
</span></span><span class=line><span class=cl>    objects: <span class=m>196</span>  objects, 1.5 KiB
</span></span><span class=line><span class=cl>    usage:   <span class=m>21</span> GiB used, <span class=m>79</span> GiB / <span class=m>100</span> GiB avail
</span></span><span class=line><span class=cl>    pgs:     <span class=m>160</span> active+clean</span></span></code></pre></td></tr></table></div></div></div></div><p>默认情况下，RGW 实例监听于 TCP 协议的 7480 端口，需要修改，可以通过在运行 RGW 的节点上编辑其主配置文件 ceph.conf 进行修改，相关参数如下所示</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>conf</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><pre tabindex=0><code class=language-conf data-lang=conf>[client]
rgw_frontends = &#34;civetweb port=8080&#34;</code></pre></div></div><p>RGW 会在 RADOWS 集群上生成包括如下存储池的一系列存储池</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>sh</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>$  ceph osd pool ls
</span></span><span class=line><span class=cl>mypool
</span></span><span class=line><span class=cl>rbdpool
</span></span><span class=line><span class=cl>testpool
</span></span><span class=line><span class=cl>.rgw.root
</span></span><span class=line><span class=cl>default.rgw.control
</span></span><span class=line><span class=cl>default.rgw.meta
</span></span><span class=line><span class=cl>default.rgw.log</span></span></code></pre></td></tr></table></div></div></div></div><p>RGW 提供的是兼容 S3 和 Swift 的 REST 接口，客户端通过 HTTP 进行交互，完成数据的增删改查等管理操作。</p><h3 id=启用文件系统-cephfs-接口>启用文件系统 (CephFS) 接口<a hidden class=anchor aria-hidden=true href=#启用文件系统-cephfs-接口>#</a></h3><p>CephFS 需要至少运行一个 Metadata (MDS) 守护进程 (ceph-mds)，此进程管理与 CephFS 上存储的文件相关的元数据，并协调对 Ceph存储集群的访问。因此，若要使用 CephFS ，需要在存储集群中至少部署一个 MDS 实例，增加 MDS 可以使用命令 <em>ceph-deploy mds create {ceph-node}</em> 完成</p><p>还需主义的是，每个 CephFS 都至少需要两个存储池，一个用来存放元数据 (Metadata Pool)，一个存放数据 (Data Pool)。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>sh</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>$ ceph-deploy mds create stor01</span></span></code></pre></td></tr></table></div></div></div></div><p>查看 MDS 的相关状态可以发现，刚添加的 MDS 处于 standby 状态</p><p>在运行起来还不够，还没为其创建存储池，故其不能正常工作，处于standby模式。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>text</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>$ ceph mds stat
</span></span><span class=line><span class=cl>, 1 up:standby</span></span></code></pre></td></tr></table></div></div></div></div><p>使用 CephFS 之前需要事先于集群中创建一个文件系统，并为其分别指定 “元数据” 和 “数据” 相关的存储池，下面创建一个名为 <em>cephfs</em> 的文件系统用于测试，使用cephfs-metadata为数据存储池，使用cephfs-data为数据存储池。</p><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>sh</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=c1># 创建存储池</span>
</span></span><span class=line><span class=cl>ceph osd pool create cephfs-metadata <span class=m>64</span>
</span></span><span class=line><span class=cl>ceph osd pool create cephfs-data <span class=m>64</span>
</span></span><span class=line><span class=cl><span class=c1># 创建 cephfs</span>
</span></span><span class=line><span class=cl><span class=c1>## 语法</span>
</span></span><span class=line><span class=cl>ceph fs new <span class=o>{</span>fs_name<span class=o>}</span> <span class=o>{</span>meatadata-pool<span class=o>}</span> <span class=o>{</span>data-pool<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=c1>## 示例</span>
</span></span><span class=line><span class=cl>ceph fs new cephfs cephfs-metadata cephfs-data</span></span></code></pre></td></tr></table></div></div></div></div><ul><li><em>ceph fs add_data_pool</em>： 额外添加数据池</li><li><em>ceph fs new</em>： 创建新文件系统</li><li><em>ceph fs status</em>： 查看CephFS 文件系统状态</li></ul><div class="pe-code-block-wrap pe-code-details open scrollable"><div class="pe-code-block-header pe-code-details-summary"><div class=pe-code-block-header-left><i class="arrow fas fa-chevron-right fa-fw pe-code-details-icon" aria-hidden=true></i>
<span>sh</span></div><div class=pe-code-block-header-center><span></span></div><div class=pe-code-block-header-right><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i>
<button class=pe-code-copy-button><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" class="pe-icon"><path fill="currentcolor" fill-rule="evenodd" d="M7 5a3 3 0 013-3h9a3 3 0 013 3v9a3 3 0 01-3 3h-2v2a3 3 0 01-3 3H5a3 3 0 01-3-3v-9a3 3 0 013-3h2zm2 2h5a3 3 0 013 3v5h2a1 1 0 001-1V5a1 1 0 00-1-1h-9A1 1 0 009 5zM5 9a1 1 0 00-1 1v9a1 1 0 001 1h9a1 1 0 001-1v-9a1 1 0 00-1-1z" clip-rule="evenodd"/></svg></button></div></div><div class="pe-code-details-content scrollable"><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>$ ceph fs status cephfs
</span></span><span class=line><span class=cl>cephfs - <span class=m>0</span> <span class=nv>clients</span>
</span></span><span class=line><span class=cl><span class=o>======</span>
</span></span><span class=line><span class=cl>+------+--------+--------+---------------+-------+-------+
</span></span><span class=line><span class=cl><span class=p>|</span> Rank <span class=p>|</span> State  <span class=p>|</span>  MDS   <span class=p>|</span>    Activity   <span class=p>|</span>  dns  <span class=p>|</span>  inos <span class=p>|</span>
</span></span><span class=line><span class=cl>+------+--------+--------+---------------+-------+-------+
</span></span><span class=line><span class=cl><span class=p>|</span>  <span class=m>0</span>   <span class=p>|</span> active <span class=p>|</span> stor02 <span class=p>|</span> Reqs:    <span class=m>0</span> /s <span class=p>|</span>   <span class=m>10</span>  <span class=p>|</span>   <span class=m>13</span>  <span class=p>|</span>
</span></span><span class=line><span class=cl>+------+--------+--------+---------------+-------+-------+
</span></span><span class=line><span class=cl>+-----------------+----------+-------+-------+
</span></span><span class=line><span class=cl><span class=p>|</span>       Pool      <span class=p>|</span>   <span class=nb>type</span>   <span class=p>|</span>  used <span class=p>|</span> avail <span class=p>|</span>
</span></span><span class=line><span class=cl>+-----------------+----------+-------+-------+
</span></span><span class=line><span class=cl><span class=p>|</span> cephfs-metadata <span class=p>|</span> metadata <span class=p>|</span> <span class=m>2286</span>  <span class=p>|</span> 21.7G <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>   cephfs-data   <span class=p>|</span>   data   <span class=p>|</span>    <span class=m>0</span>  <span class=p>|</span> 21.7G <span class=p>|</span>
</span></span><span class=line><span class=cl>+-----------------+----------+-------+-------+
</span></span><span class=line><span class=cl>+-------------+
</span></span><span class=line><span class=cl><span class=p>|</span> Standby MDS <span class=p>|</span>
</span></span><span class=line><span class=cl>+-------------+
</span></span><span class=line><span class=cl>+-------------+
</span></span><span class=line><span class=cl>MDS version: ceph version 13.2.6 <span class=o>(</span>7b695f835b03642f85998b2ae7b6dd093d9fbce4<span class=o>)</span> mimic <span class=o>(</span>stable<span class=o>)</span></span></span></code></pre></td></tr></table></div></div></div></div><h2 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h2><p><sup id=1>[1]</sup> <a href=https://docs.ceph.com/en/nautilus/rados/configuration/network-config-ref/ target=_blank rel="noopener nofollow noreferrer"><em><strong>Network Configuration Reference</strong></em></a></p><p><sup id=2>[2]</sup> <a href=https://unix.stackexchange.com/questions/379791/ceph-deployerror-runtimeerror-nosectionerror-no-section-ceph target=_blank rel="noopener nofollow noreferrer"><em><strong>ceph_deploy RuntimeError: NoSectionError: No section: &lsquo;ceph&rsquo;</strong></em></a></p></div><div class=pe-copyright><hr><blockquote><p>本文为原创内容，版权归作者所有。如需转载，请在文章中声明本文标题及链接。</p><p>文章标题：Ceph集群安装 - ceph-deploy</p><p>文章链接：<a href=https://www.oomkill.com/2019/11/02-2-install-ceph-with-ceph-deploy/ target=_blank>https://www.oomkill.com/2019/11/02-2-install-ceph-with-ceph-deploy/</a></p><p>许可协议：<a href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></p></blockquote></div><div class=comments-separator></div><h3 class=relatedContentTitle>相关阅读</h3><ul class=relatedContent><li><a href=/2019/09/03-1-acquaintance-rdb/><span>Ceph RBD - 初识块存储RBD</span></a></li><li><a href=/2019/07/03-2-rbd-management/><span>Ceph RBD - 关于RBD的操作与管理</span></a></li><li><a href=/2019/07/05-1-rgw/><span>Ceph对象存储概述</span></a></li><li><a href=/2019/07/04-1-cephfs/><span>Ceph文件系统概述</span></a></li><li><a href=/2019/06/07-1-cephx/><span>Ceph安全 - CephX</span></a></li></ul><div class=comments-separator></div><footer class=post-footer><ul class=post-tags><li><a href=https://www.oomkill.com/tags/storage/>Storage</a></li></ul><nav class=paginav><a class=prev href=https://www.oomkill.com/2019/11/helm/><span class=title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left" style="user-select:text"><line x1="19" y1="12" x2="5" y2="12" style="user-select:text"/><polyline points="12 19 5 12 12 5" style="user-select:text"/></polyline></svg>&nbsp;</span>
<span>Kubernetes包管理 - Helm</span>
</a><a class=next href=https://www.oomkill.com/2019/11/ch1-introduction/><span class=title></span>
<span>ch1 VPN与OpenVPN应用场景分析&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right" style="user-select:text"><line x1="5" y1="12" x2="19" y2="12" style="user-select:text"/><polyline points="12 5 19 12 12 19" style="user-select:text"/></svg></span></a></nav></footer><div class=pe-comments-decoration><p class=pe-comments-title></p><p class=pe-comments-subtitle></p></div><div id=pe-comments></div><script src=/js/pe-go-comment.min.86a214102576ba5f9b7bdc29eed8d58dd56e34aef80b3c65c73ea9cc88443696.js integrity="sha256-hqIUECV2ul+be9wp7tjVjdVuNK74Czxlxz6pzIhENpY="></script><script>const getStoredTheme=()=>localStorage.getItem("pref-theme")==="dark"?"dark":"light",setGiscusTheme=()=>{const e=e=>{const t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:e},"https://giscus.app")};e({setConfig:{theme:getStoredTheme()}})};document.addEventListener("DOMContentLoaded",()=>{const s={src:"https://giscus.app/client.js","data-repo":"cylonchau/blogs","data-repo-id":"R_kgDOIRlNSQ","data-category":"Announcements","data-category-id":"DIC_kwDOIRlNSc4CXy1U","data-mapping":"pathname","data-term":"posts/02-2 install ceph with ceph-deploy","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"top","data-theme":getStoredTheme(),"data-lang":"zh-TW","data-loading":"lazy",crossorigin:"anonymous",async:""},e=document.createElement("script");Object.entries(s).forEach(([t,n])=>e.setAttribute(t,n)),document.querySelector("#pe-comments").appendChild(e);const t=document.querySelector("#theme-toggle");t&&t.addEventListener("click",setGiscusTheme);const n=document.querySelector("#theme-toggle-float");n&&n.addEventListener("click",setGiscusTheme)})</script></article></main><footer class=footer><span>&copy; 2024 <a href=https://www.oomkill.com/>Cylon's Collection</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> on
<a href=https://pages.github.com/ rel=noopener target=_blank>GitHub Pages</a> & Theme
        <a href=https://github.com/tofuwine/PaperMod-PE rel=noopener target=_blank>PaperMod-PE</a></span></footer><div class=pe-right-sidebar><a href=javascript:void(0); id=theme-toggle-float class=pe-float-btn><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</a><a href=#top class=pe-float-btn id=top-link><span id=pe-read-progress></span></a></div><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>